{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn v75 med walkthrough-metoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from catboost import CatBoostClassifier,Pool,cv,utils\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel')\n",
    "import V75_scraping as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df skall innehålla datum,avd,vodds\n",
    "def proba_order_score(df_, y,proba):\n",
    "    kassa=1000\n",
    "    df = df_.copy()\n",
    "    df['proba'] = proba[:,1]\n",
    "    df['f'] = (df.proba*df.vodds - 1) / (df.vodds-1)  # kelly formel\n",
    "    df['spela'] = df.f >0\n",
    "    df['insats'] = df.spela * df.f * kassa\n",
    "\n",
    "    df.sort_values(['datum','avd','proba'],ascending=[True,True,False],inplace=True)\n",
    "    proba_order=df.groupby(['datum','avd']).proba.cumcount()\n",
    "\n",
    "    df['prob_order']=proba_order+1\n",
    "    df['y'] = y\n",
    "    \n",
    "    print('log(proba)',np.log(df.loc[df.y==1].proba).mean())\n",
    "    return df, df.loc[df.y==1].prob_order.mean()   # mean prob_order för vinnarhäst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ekipage(df_):\n",
    "    df=df_.copy()\n",
    "    prefs = ['','h1_','h2_','h3_','h4_','h5_',]\n",
    "    for pr in prefs:\n",
    "        df[pr+'ekipage'] = df[pr+'kusk'].str.cat(df['häst'], sep =\", \")\n",
    "        df.drop([pr+'kusk'],axis=1, inplace=True)\n",
    "        \n",
    "    return df.drop(['häst'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returnera en modell med parametrar satta\n",
    "def get_model(d=6,l2=2,iterations=3000,use_best=True,verbose=False):\n",
    "    model = CatBoostClassifier(iterations=iterations,use_best_model=use_best, \n",
    "        custom_metric=['Logloss', 'AUC','Recall', 'Precision', 'F1', 'Accuracy'],\n",
    "\n",
    "        eval_metric='Accuracy', \n",
    "        depth=d,l2_leaf_reg=l2,\n",
    "        auto_class_weights='Balanced',verbose=verbose, random_state=2021) \n",
    "    return model                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Features som inte används vid träning\n",
    "def remove_features(df_,remove_mer=[]):\n",
    "    # df = df_.copy()\n",
    "    #remove_mer=['h5_perf','h5_auto','h4_perf','h4_auto', 'h3_perf', 'h2_perf']\n",
    "    df = df_.drop(['avd','startnr','vodds','podds','bins','h1_dat','h2_dat','h3_dat','h4_dat','h5_dat'],axis=1) #\n",
    "    if remove_mer:\n",
    "        df = df.drop(remove_mer,axis=1)\n",
    "    \n",
    "    # df=check_unique(df.copy())\n",
    "    # df=check_corr(df.copy())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## byt ut alla NaN till text för cat_features\n",
    "def replace_NaN(X_train,X_test=None, cat_features=[]):\n",
    "    # print('cat_features',cat_features)\n",
    "    for c in cat_features:\n",
    "        # print(c)\n",
    "        X_train.loc[X_train[c].isna(),c] = 'None'       ### byt ut None-värden till texten 'None\n",
    "        if X_test is not None:  ## om X_test är med\n",
    "            X_test.loc [X_test[c].isna(),c] = 'None'    ### byt ut None-värden till texten 'None\n",
    "\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nya_lopp():\n",
    "    nya_lopp,strukna = vs.v75_scraping(resultat=True,history=True)\n",
    "\n",
    "    df=pd.concat([pd.read_csv('all_data.csv'), nya_lopp])\n",
    "    print('shape med nya lopp',df.shape)\n",
    "    #ta bort dubletter\n",
    "    df.drop_duplicates(['datum','avd','häst'],inplace=True)\n",
    "    df.sort_values(by=['datum','avd'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    print('shape med dubletter bort',df.shape)\n",
    "\n",
    "    df.to_csv('all_data.csv', index=False)\n",
    "\n",
    "    print(\"första datum i df =\",df.datum.head(1).to_list()[0])\n",
    "    print(\"sista  datum i df =\",df.datum.tail(1).to_list()[0])\n",
    "\n",
    "    return df,nya_lopp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beräkna vilka datum att använda ###\n",
    "def get_alla_datum(test_from_proc=0.75, train_from_proc=0, total_omlärning = False):\n",
    "    if total_omlärning:\n",
    "        nya_lopp=None\n",
    "        df = pd.read_csv('all_data.csv')     \n",
    "        alla_datum = df.datum.unique()\n",
    "        split_ix = int(len(alla_datum)*test_from_proc)\n",
    "    else:\n",
    "        # normalt adderar vi bara 1 eller flera veckor från \"omg_att_spela_link.csv\"\n",
    "        df, nya_lopp = scrape_nya_lopp()  # scrape från 'omg_att_spela_link.csv' och addera till df\n",
    "        omg_df = pd.read_csv('omg_att_spela_link.csv')     \n",
    "        startix=omg_df.Link.str.find('spel')[0]    # index till 'spel' i url\n",
    "        alla_datum = omg_df.Link.str.slice(start=startix+5,stop=startix+15).to_list() # en datum \n",
    "        split_ix=0\n",
    "        print(f'datum att lära från {alla_datum}')\n",
    "\n",
    "    return df,nya_lopp,alla_datum,split_ix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough-funktionen  här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Kör en walkthrough learn här, en datum i taget framåt\n",
    "\n",
    "# Jag har ändrat till att alla steg kör utan test-datam ed fast iterations=100\n",
    "def walkthrough(classic_test=False, verbose=False):\n",
    "    \n",
    "    df, nya_lopp, alla_datum, split_ix = get_alla_datum(0.8)\n",
    "\n",
    "    l2_leaf_regs=2\n",
    "    model=get_model(use_best=False,iterations=100)\n",
    "    df=remove_features(df.copy())\n",
    "    cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "    df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "    print(f'cat_features {cat_features}\\n')\n",
    "\n",
    "    df['plac']=(df.plac==1)*1\n",
    "        \n",
    "    for nr,datum in enumerate(alla_datum[split_ix:]):\n",
    "        print(f'walk-iter {nr+1} av {len(alla_datum[split_ix:])} ',end=': ')\n",
    "\n",
    "        X_train = df.loc[df.datum<datum,:].copy()\n",
    "        y_train = X_train.plac; X_train.drop(['plac'],axis=1,inplace=True)\n",
    "\n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            X_test  = df.loc[df.datum>=datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=True, verbose=verbose,eval_set=test_pool)\n",
    "        else:\n",
    "            X_test  = df.loc[df.datum==datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=False, verbose=verbose)\n",
    "\n",
    "        print('best iteration',model.get_best_iteration(), '\\tbest score', round(model.get_best_score()['learn']['Accuracy'],3) )\n",
    "        ##['validation']['Logloss'],3),'\\t', round(model.get_best_score()['validation']['Accuracy:use_weights=true'],3))\n",
    "        \n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            return model,cat_features\n",
    "    \n",
    "        model.save_model('modeller/model_'+datum)\n",
    "\n",
    "    X_train =df.copy().drop('plac',axis=1)\n",
    "    y_train = df.plac \n",
    "    model.fit(X_train,y=y_train,cat_features=cat_features)\n",
    "    print(f'spara model_senaste',datum)\n",
    "    model.save_model('modeller/model_senaste')\n",
    "\n",
    "    return df,nya_lopp, model,cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Här körs hela walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omgång 1: https://www.atg.se/spel/2021-12-23/V75/\n",
      "klickade på ANPASSA\n",
      "anpassa klar - break\n",
      "ant resultat 7\n",
      "ant lopp 7\n",
      "EUR: False NOK: False\n",
      "priser ['Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 kr (8 priser). Lägst 500 kr till alla tävlande.', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 kr (8 priser). Lägst 500 kr till alla tävlande.', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)']\n",
      "Ant priser 7\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 1 HALMSTAD 1640 AUTOSTART ............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 8 8 8 8\n",
      "AVD 2 HALMSTAD 2140 VOLTSTART ........\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 3 HALMSTAD 2640 AUTOSTART ...............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 4 HALMSTAD 2140 VOLTSTART ...............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 5 HALMSTAD 2140 AUTOSTART ............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 6 HALMSTAD 2640 AUTOSTART ...............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 7 HALMSTAD 1640 AUTOSTART ............\n",
      "\n",
      "det tog 127.488 sekunder\n",
      "utdelning: 0, 52507, 1937\n",
      "startar Fixa mer\n",
      "tog bort 5 strukna från 89 till 84\n",
      "rensade totalt bort 5 hästar i städa_och_rensa. Från 89 till 84\n",
      "shape med nya lopp (43125, 79)\n",
      "shape med dubletter bort (43041, 79)\n",
      "första datum i df = 2014-12-28\n",
      "sista  datum i df = 2021-12-23\n",
      "datum att lära från ['2021-12-23']\n",
      "cat_features ['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n",
      "\n",
      "walk-iter 1 av 1 : best iteration None \tbest score 0.754\n",
      "spara model_senaste 2021-12-23\n"
     ]
    }
   ],
   "source": [
    "df, nya_lopp, model, cat_features = walkthrough(classic_test=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kör allt ovanför walkthrough\n",
    "### Se till att \"omg_att_spela_link.csv\" är ifylld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init  - kör först allt t.o.m 'replace_NaN()' ovan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model().load_model('modeller/model_senaste')\n",
    "dforg = pd.read_csv('all_data.csv')     \n",
    "# print(df.columns)\n",
    "df=remove_features(dforg.copy())\n",
    "# df['avd']=dforg.avd\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "y=df.plac\n",
    "y=(y==1)*1\n",
    "df.drop('plac',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6665308\tbest: 0.6665308 (0)\n",
      "50:\ttest: 0.8111028\tbest: 0.8111028 (50)\n",
      "100:\ttest: 0.8121884\tbest: 0.8134598 (72)\n",
      "150:\ttest: 0.8103055\tbest: 0.8134598 (72)\n",
      "Stopped by overfitting detector  (100 iterations wait)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_pool = Pool(df,y,cat_features=cat_features)\n",
    "\n",
    "params = {\n",
    "         'use_best_model': True,\n",
    "         'eval_metric' : 'AUC',\n",
    "         \"loss_function\": \"Logloss\",\n",
    "         'early_stopping_rounds': 100,\n",
    "         'verbose': 50,\n",
    "}\n",
    "\n",
    "cv_score =cv(pool=cv_pool, \n",
    "   params=params, \n",
    "   dtrain=None, \n",
    "   iterations=2000, \n",
    "   num_boost_round=None,\n",
    "   fold_count=5, \n",
    "   nfold=None,\n",
    "   inverted=False,\n",
    "   partition_random_seed=0,\n",
    "   seed=2021, \n",
    "   shuffle=False, \n",
    "   logging_level=None, \n",
    "   stratified=True,\n",
    "   as_pandas=True,\n",
    "   type='TimeSeries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.666531</td>\n",
       "      <td>0.080809</td>\n",
       "      <td>0.660877</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.660723</td>\n",
       "      <td>0.002819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.735128</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.629458</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.629183</td>\n",
       "      <td>0.001401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.742560</td>\n",
       "      <td>0.026468</td>\n",
       "      <td>0.601614</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.601344</td>\n",
       "      <td>0.002803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.763305</td>\n",
       "      <td>0.017503</td>\n",
       "      <td>0.574546</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.574209</td>\n",
       "      <td>0.003056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.768340</td>\n",
       "      <td>0.018402</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.550130</td>\n",
       "      <td>0.001798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>0.810031</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.209061</td>\n",
       "      <td>0.004273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>0.810020</td>\n",
       "      <td>0.006095</td>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.208968</td>\n",
       "      <td>0.004321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0.810035</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.239704</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.208817</td>\n",
       "      <td>0.004361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>0.809947</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.239735</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.208717</td>\n",
       "      <td>0.004413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>0.809904</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.239722</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.208601</td>\n",
       "      <td>0.004550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "0             0       0.666531      0.080809           0.660877   \n",
       "1             1       0.735128      0.025100           0.629458   \n",
       "2             2       0.742560      0.026468           0.601614   \n",
       "3             3       0.763305      0.017503           0.574546   \n",
       "4             4       0.768340      0.018402           0.550562   \n",
       "..          ...            ...           ...                ...   \n",
       "168         168       0.810031      0.006089           0.239718   \n",
       "169         169       0.810020      0.006095           0.239718   \n",
       "170         170       0.810035      0.006111           0.239704   \n",
       "171         171       0.809947      0.006117           0.239735   \n",
       "172         172       0.809904      0.006138           0.239722   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "0            0.002743            0.660723           0.002819  \n",
       "1            0.001429            0.629183           0.001401  \n",
       "2            0.002945            0.601344           0.002803  \n",
       "3            0.003086            0.574209           0.003056  \n",
       "4            0.001623            0.550130           0.001798  \n",
       "..                ...                 ...                ...  \n",
       "168          0.002893            0.209061           0.004273  \n",
       "169          0.002894            0.208968           0.004321  \n",
       "170          0.002912            0.208817           0.004361  \n",
       "171          0.002902            0.208717           0.004413  \n",
       "172          0.002893            0.208601           0.004550  \n",
       "\n",
       "[173 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-12-28 2021-12-23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>0.810532</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>0.239636</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.211679</td>\n",
       "      <td>0.003249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "145         145       0.810532      0.006067           0.239636   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "145          0.002945            0.211679           0.003249  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>0.81346</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.245711</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.227543</td>\n",
       "      <td>0.000449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "72          72        0.81346      0.005594           0.245711   \n",
       "\n",
       "    test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "72          0.003151            0.227543           0.000449  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "print(df.datum.min(),df.datum.max())\n",
    "display(cv_score[cv_score['test-Logloss-mean'].min() == cv_score['test-Logloss-mean']])\n",
    "display(cv_score[cv_score['test-AUC-mean'].max() == cv_score['test-AUC-mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 2019-12-25 2021-12-23\n",
      "train: 2014-12-28 2019-12-25\n",
      "0:\tlearn: 0.6386657\ttest: 0.6155582\tbest: 0.6155582 (0)\ttotal: 96.9ms\tremaining: 4m 50s\n",
      "100:\tlearn: 0.7092717\ttest: 0.6440376\tbest: 0.6455230 (99)\ttotal: 12s\tremaining: 5m 45s\n",
      "200:\tlearn: 0.7364930\ttest: 0.6410803\tbest: 0.6475468 (188)\ttotal: 23.3s\tremaining: 5m 24s\n",
      "300:\tlearn: 0.7504547\ttest: 0.6402621\tbest: 0.6481037 (228)\ttotal: 34.5s\tremaining: 5m 9s\n",
      "400:\tlearn: 0.7690556\ttest: 0.6398636\tbest: 0.6481037 (228)\ttotal: 46.6s\tremaining: 5m 1s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6481037134\n",
      "bestIteration = 228\n",
      "\n",
      "Shrink model to first 229 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ffe7bcb790>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df[['datum','avd','streck','häst','kusk']] = dforg[['datum','avd','streck','häst','kusk']]\n",
    "\n",
    "# df.drop('datum',axis=1,inplace=True)\n",
    "df.drop('avd',axis=1,inplace=True)\n",
    "df.drop(['streck'],axis=1,inplace=True)\n",
    "# df.drop(['häst','kusk'],axis=1,inplace=True)\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "X_train,X_test,y_train,y_test = train_test_split(df,y,shuffle=False,)\n",
    "print(\"test:\",X_test.datum.min(),X_test.datum.max())\n",
    "print(\"train:\",X_train.datum.min(),X_train.datum.max())\n",
    "cb=get_model(use_best=True)\n",
    "cb.fit(X_train,y_train,eval_set= (X_test,y_test),early_stopping_rounds=200, cat_features=cat_features,verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -0.7850375605750977\n",
      "cb med ekipage 4.047516198704104 0.7068065851122353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "predict_prob = cb.predict_proba(X_test)\n",
    "\n",
    "_,prob_score = proba_order_score(X_test ,y_test, predict_prob)\n",
    "\n",
    "print('cb med ekipage',prob_score, cb.best_score_['validation']['AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAML (med och utan ekipage och streck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_,train_from_proc=0,test_proc=0.25):\n",
    "    # train_from_proc = where to start both train and test\n",
    "    # test_proc = how much of the data is test\n",
    "    df=df_.copy()\n",
    "    alla_datum = df.datum.unique()\n",
    "    train_from_datum = alla_datum[ int(len(alla_datum)*train_from_proc)]\n",
    "    print(\"train from\",train_from_datum)\n",
    "    X_test=None\n",
    "    y_test=None\n",
    "    test_from_datum=alla_datum[-1]\n",
    "    if test_proc:\n",
    "        selected_data = alla_datum[ alla_datum >= train_from_datum ]\n",
    "        test_from_datum = selected_data[ int(len(selected_data)*(1-test_proc)) ]\n",
    "        print(\"test from\",test_from_datum)\n",
    "        X_test  = df[df.datum >= test_from_datum]\n",
    "        y_test  = (X_test.plac==1)*1\n",
    "        X_test  = X_test.drop('plac',axis=1)\n",
    "        \n",
    "    \n",
    "    X_train = df[(df.datum >= train_from_datum) & (df.datum < test_from_datum) ]\n",
    "    y_train = (X_train.plac==1)*1\n",
    "    \n",
    "    return X_train.drop('plac', axis=1), X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train from 2017-02-26\n",
      "test from 2020-07-04\n",
      "['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((22525, 68), (7575, 68))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "\n",
    "X_train, X_test, y_train, y_test= split_data(dforg,train_from_proc=0.3,test_proc=0.25)\n",
    "X_train = remove_features(X_train)\n",
    "X_test  = remove_features( X_test)\n",
    "\n",
    "# X_train = X_train.drop('streck', axis=1)\n",
    "# X_test  = X_test.drop ('streck', axis=1)\n",
    "# X_train.drop('datum', axis=1, inplace=True)\n",
    "# X_test.drop( 'datum', axis=1, inplace=True)\n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "# X_train, X_test = replace_NaN(X_train.copy(),X_test=X_test.copy(), cat_features=cat_features) \n",
    "# X_train.fillna(-1)\n",
    "# X_test.fillna(-1)\n",
    "print(cat_features)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 12-24 00:44:32] {1541} WARNING - Time taken to find the best model is 92% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "2021-12-24 00:44:32.329 WARNING flaml.automl: Time taken to find the best model is 92% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML \n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "starting_points={'lgbm': {'n_estimators': 38,\n",
    "  'num_leaves': 4,\n",
    "  'min_child_samples': 2,\n",
    "  'learning_rate': 0.19098448074739216,\n",
    "  'log_max_bin': 7,\n",
    "  'colsample_bytree': 0.8827412174089042,\n",
    "  'reg_alpha': 0.004577823970660193,\n",
    "  'reg_lambda': 0.03815584533462228},\n",
    " 'rf': {'n_estimators': 33,\n",
    "  'max_features': 0.3251674877768946,\n",
    "  'max_leaves': 89,\n",
    "  'criterion': 'entropy'},\n",
    " 'catboost': {'early_stopping_rounds': 10,\n",
    "  'learning_rate': 0.007511731949060241},\n",
    " 'xgboost': {'n_estimators': 575,\n",
    "  'max_leaves': 46,\n",
    "  'min_child_weight': 1.032235057697502,\n",
    "  'learning_rate': 0.013318439439138472,\n",
    "  'subsample': 0.7908401179782586,\n",
    "  'colsample_bylevel': 0.6924750037579576,\n",
    "  'colsample_bytree': 0.7174828796230647,\n",
    "  'reg_alpha': 0.15461500385937774,\n",
    "  'reg_lambda': 0.6619886587472544},\n",
    " 'extra_tree': {'n_estimators': 47,\n",
    "  'max_features': 0.7934349565988307,\n",
    "  'max_leaves': 213,\n",
    "  'criterion': 'entropy'}}\n",
    "flml_raw_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc', 'starting_points': starting_points,'verbose':False,\n",
    "        'time_budget':700, 'max_iter':50000000,'n_jobs':5, 'X_val': X_test, 'y_val':y_test,'early_stop':True, 'ensemble':True}\n",
    "\n",
    "automl_raw = AutoML()\n",
    "automl_raw.fit(X_train,y_train, **flml_raw_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -1.8916444589446935\n",
      "timeserie, datum,häst, kusk 3.17357910906298 0.8151079173399853\n"
     ]
    }
   ],
   "source": [
    "flm_raw_train_pred= automl_raw.predict_proba(X_train)\n",
    "flm_raw_test_pred = automl_raw.predict_proba(X_test)\n",
    "\n",
    "X_test_raw = X_test.copy()\n",
    "X_test_raw[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "_,prob_score = proba_order_score(X_test_raw,y_test, flm_raw_test_pred)\n",
    "\n",
    "print('timeserie, datum,häst, kusk', prob_score, 1-automl_raw.best_loss)\n",
    "# X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timeserie  0.3 0.25, datum, häst, kusk 3.720565149136578  0.7213763318649257 ... 1.9827526807785034 .....   best    \n",
    "timeserie  0.4 0.25, datum, häst, kusk 3.7362637362637363 0.7214144007762124  \n",
    "timeserie, 0.2 0.25, datum, häst, kusk 3.760989010989011  0.72561915325073230    \n",
    "timeserie, 0.1 0.25  datum, häst, kusk 3.8180708180708183 0.726597977829505    \n",
    "timeserie, 0.5 0.25, datum, häst, kusk 3.936263736263736  0.7216626969090024  \n",
    "timeserie, 0.3 0.25, datum, häst, kusk streck, NaN 3.0706436420722136  0.8230307821948237   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk,streck  3.0549450549450547 0.8232840226857013 ... -1.7710182666778564 .......... best   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk streck, NaN, fillna, 3.0549450549450547 0.8237003593459333   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk, streck 3.06436420722135   0.8232840226857013       \n",
    "timeserie, 0.4 0.25, datum, häst, kusk, streck 3.1483516483516483 0.8169106155467452  \n",
    "timeserie, 0.2 0.25, datum, häst, kusk, streck 3.0824175824175826 0.8220287891340522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final FLML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flaml(X_train, y_train):\n",
    "    import pickle\n",
    "\n",
    "    for with_streck in [True, False]:\n",
    "        if with_streck: \n",
    "            X_tr = X_train.copy()    \n",
    "            filename = 'modeller\\\\FLAML_model.sav'\n",
    "        else:\n",
    "            X_tr = X_train.drop('streck', axis=1).copy()\n",
    "            filename = 'modeller\\\\FLAML2_model.sav'\n",
    "            \n",
    "        print('with_streck = ',with_streck)    \n",
    "    \n",
    "        automl = AutoML()\n",
    "        flml_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc','starting_points': starting_points, 'verbose':False,\n",
    "        'time_budget':1700, 'max_iter':400000000,'n_jobs':5, 'early_stop':True, 'ensemble':True}\n",
    "\n",
    "        automl.fit(X_tr, y_train, **flml_parms)\n",
    "        print(1-automl.best_loss, 'for streck in columns', 'streck' in X_tr.columns)\n",
    "        \n",
    "        # save_model\n",
    "        print('save in',filename)        \n",
    "        pickle.dump(automl, open(filename, 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train from 2017-02-26\n",
      "with_streck =  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 12-24 01:16:59] {1541} WARNING - Time taken to find the best model is 90% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "2021-12-24 01:16:59.791 WARNING flaml.automl: Time taken to find the best model is 90% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8199529789259956 for streck in columns True\n",
      "save in modeller\\FLAML_model.sav\n",
      "with_streck =  False\n",
      "0.7223298119880645 for streck in columns False\n",
      "save in modeller\\FLAML2_model.sav\n"
     ]
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "X_train, _, y_train, _ = split_data(dforg,train_from_proc=0.3,test_proc=None)\n",
    "X_train = remove_features(X_train)\n",
    "\n",
    "run_flaml(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove dirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call([r'C:/Users/peter/Documents/MyProjects/PyProj/Trav/spel/remove_dirt.bat'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
