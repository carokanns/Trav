{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn v75 med walkthrough-metoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from catboost import CatBoostClassifier,Pool,cv,utils\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel')\n",
    "import V75_scraping as vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def proba_order_score(df_, y, proba):  # df skall innehålla datum,avd,vodds\n",
    "    kassa=1000\n",
    "    df = df_.copy()\n",
    "    df['proba'] = proba[:,1]\n",
    "    df['f'] = (df.proba*df.vodds - 1) / (df.vodds-1)  # kelly formel\n",
    "    df['spela'] = df.f >0\n",
    "    df['insats'] = df.spela * df.f * kassa\n",
    "\n",
    "    df.sort_values(['datum','avd','proba'],ascending=[True,True,False],inplace=True)\n",
    "    proba_order=df.groupby(['datum','avd']).proba.cumcount()\n",
    "\n",
    "    df['prob_order']=proba_order+1\n",
    "    df['y'] = y\n",
    "\n",
    "    print('log(proba)',np.log(df.loc[df.y==1].proba).mean())\n",
    "    return df, df.loc[df.y==1].prob_order.mean()   # mean prob_order för vinnarhäst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ekipage(df_):\n",
    "    df=df_.copy()\n",
    "    prefs = ['','h1_','h2_','h3_','h4_','h5_',]\n",
    "    for pr in prefs:\n",
    "        df[pr+'ekipage'] = df[pr+'kusk'].str.cat(df['häst'], sep =\", \")\n",
    "        df.drop([pr+'kusk'],axis=1, inplace=True)\n",
    "        \n",
    "    return df.drop(['häst'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returnera en modell med parametrar satta\n",
    "def get_model(d=6,l2=2,iterations=3000,use_best=True,verbose=False):\n",
    "    model = CatBoostClassifier(iterations=iterations,use_best_model=use_best, \n",
    "        custom_metric=['Logloss', 'AUC','Recall', 'Precision', 'F1', 'Accuracy'],\n",
    "\n",
    "        eval_metric='Accuracy', \n",
    "        depth=d,l2_leaf_reg=l2,\n",
    "        auto_class_weights='Balanced',verbose=verbose, random_state=2021) \n",
    "    return model                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Features som inte används vid träning\n",
    "def remove_features(df_,remove_mer=[]):\n",
    "    # df = df_.copy()\n",
    "    #remove_mer=['h5_perf','h5_auto','h4_perf','h4_auto', 'h3_perf', 'h2_perf']\n",
    "    df = df_.drop(['avd','startnr','vodds','podds','bins','h1_dat','h2_dat','h3_dat','h4_dat','h5_dat'],axis=1) #\n",
    "    if remove_mer:\n",
    "        df = df.drop(remove_mer,axis=1)\n",
    "    \n",
    "    # df=check_unique(df.copy())\n",
    "    # df=check_corr(df.copy())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## byt ut alla NaN till text för cat_features\n",
    "def replace_NaN(X_train,X_test=None, cat_features=[]):\n",
    "    # print('cat_features',cat_features)\n",
    "    for c in cat_features:\n",
    "        # print(c)\n",
    "        X_train.loc[X_train[c].isna(),c] = 'None'       ### byt ut None-värden till texten 'None\n",
    "        if X_test is not None:  ## om X_test är med\n",
    "            X_test.loc [X_test[c].isna(),c] = 'None'    ### byt ut None-värden till texten 'None\n",
    "\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nya_lopp():\n",
    "    \"\"\"scrape nya lopp och lägg in i all_data.csv\"\"\"\n",
    "    nya_lopp,strukna = vs.v75_scraping(resultat=True,history=True)\n",
    "\n",
    "    df=pd.concat([pd.read_csv('all_data.csv'), nya_lopp])\n",
    "    print('shape med nya lopp',df.shape)\n",
    "    #ta bort dubletter\n",
    "    df.drop_duplicates(['datum','avd','häst'],inplace=True)\n",
    "    df.sort_values(by=['datum','avd'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    print('shape med dubletter bort',df.shape)\n",
    "\n",
    "    df.to_csv('all_data.csv', index=False)\n",
    "\n",
    "    print(\"första datum i df =\",df.datum.head(1).to_list()[0])\n",
    "    print(\"sista  datum i df =\",df.datum.tail(1).to_list()[0])\n",
    "\n",
    "    return df,nya_lopp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beräkna vilka datum att använda ###\n",
    "def get_alla_datum(test_from_proc=0.75, train_from_proc=0, total_omlärning = False):\n",
    "    if total_omlärning:\n",
    "        nya_lopp=None\n",
    "        df = pd.read_csv('all_data.csv')     \n",
    "        datum_att_lära = df.datum.unique()\n",
    "        split_ix = int(len(datum_att_lära)*test_from_proc)\n",
    "    else:\n",
    "        # normalt adderar vi bara 1 eller flera veckor från \"omg_att_spela_link.csv\"\n",
    "        df, nya_lopp = scrape_nya_lopp()  # scrape från 'omg_att_spela_link.csv' och addera till df\n",
    "        omg_df = pd.read_csv('omg_att_spela_link.csv')     \n",
    "        startix=omg_df.Link.str.find('spel')[0]    # index till 'spel' i url\n",
    "        datum_att_lära = omg_df.Link.str.slice(start=startix+5,stop=startix+15).to_list() # en datum \n",
    "        split_ix=0\n",
    "        print(f'datum att lära: {datum_att_lära}')\n",
    "\n",
    "    return df,nya_lopp,datum_att_lära,split_ix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough-funktionen  här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Kör en walkthrough learn här, en datum i taget framåt\n",
    "\n",
    "# Jag har ändrat till att alla steg kör utan test-datam ed fast iterations=100\n",
    "def walkthrough(classic_test=False, verbose=False):\n",
    "    \n",
    "    df, nya_lopp, alla_datum, split_ix = get_alla_datum(0.8)\n",
    "\n",
    "    l2_leaf_regs=2\n",
    "    model=get_model(use_best=False,iterations=100)\n",
    "    df=remove_features(df.copy())\n",
    "    cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "    df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "    print(f'cat_features {cat_features}\\n')\n",
    "\n",
    "    df['plac']=(df.plac==1)*1\n",
    "        \n",
    "    for nr,datum in enumerate(alla_datum[split_ix:]):\n",
    "        print(f'walk-iter {nr+1} av {len(alla_datum[split_ix:])} ',end=': ')\n",
    "\n",
    "        X_train = df.loc[df.datum<datum,:].copy()\n",
    "        y_train = X_train.plac; X_train.drop(['plac'],axis=1,inplace=True)\n",
    "\n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            X_test  = df.loc[df.datum>=datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=True, verbose=verbose,eval_set=test_pool)\n",
    "        else:\n",
    "            X_test  = df.loc[df.datum==datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=False, verbose=verbose)\n",
    "\n",
    "        print('best iteration',model.get_best_iteration(), '\\tbest score', round(model.get_best_score()['learn']['Accuracy'],3) )\n",
    "        ##['validation']['Logloss'],3),'\\t', round(model.get_best_score()['validation']['Accuracy:use_weights=true'],3))\n",
    "        \n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            return model,cat_features\n",
    "    \n",
    "        model.save_model('modeller/model_'+datum)\n",
    "\n",
    "    X_train =df.copy().drop('plac',axis=1)\n",
    "    y_train = df.plac \n",
    "    model.fit(X_train,y=y_train,cat_features=cat_features)\n",
    "    print(f'spara model_senaste',datum)\n",
    "    model.save_model('modeller/model_senaste')\n",
    "\n",
    "    return df,nya_lopp, model,cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Här körs hela walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omgång 1: https://www.atg.se/spel/2022-03-05/V75/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:464: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "klickade på ANPASSA\n",
      "hoppar över voods click (verkar vara förifyllt\n",
      "anpassa klar - break\n",
      "ant resultat 7\n",
      "ant lopp 7\n",
      "EUR: False NOK: False\n",
      "priser ['Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 150.000-75.000-40.000-25.000-15.000-11.500-7.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 125.000-62.500-34.000-21.000-13.500-10.500-7.000-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.']\n",
      "Ant priser 7\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 1 KALMAR 2640 VOLTSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 2 KALMAR 1640 AUTOSTART ............\n",
      "pris: 150.000\n",
      "ant names,vodds,podds,rader,streck 8 8 8 8\n",
      "AVD 3 KALMAR 2140 AUTOSTART ........\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 4 KALMAR 2140 VOLTSTART ...............\n",
      "pris: 125.000\n",
      "ant names,vodds,podds,rader,streck 11 11 11 11\n",
      "AVD 5 KALMAR 2140 AUTOSTART ...........\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 6 KALMAR 2140 VOLTSTART ...............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 7 KALMAR 2140 AUTOSTART ............\n",
      "\n",
      "det tog 121.559 sekunder\n",
      "utdelning: 0, 12487, 394\n",
      "startar Fixa mer\n",
      "tog bort 3 strukna från 85 till 82\n",
      "rensade totalt bort 3 hästar i städa_och_rensa. Från 85 till 82\n",
      "shape med nya lopp (43978, 79)\n",
      "shape med dubletter bort (43978, 79)\n",
      "första datum i df = 2014-12-28\n",
      "sista  datum i df = 2022-03-05\n",
      "datum att lära: ['2022-03-05']\n",
      "cat_features ['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n",
      "\n",
      "walk-iter 1 av 1 : best iteration None \tbest score 0.749\n",
      "spara model_senaste 2022-03-05\n"
     ]
    }
   ],
   "source": [
    "df, nya_lopp, model, cat_features = walkthrough(classic_test=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kör allt ovanför walkthrough\n",
    "### Se till att \"omg_att_spela_link.csv\" är ifylld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init  - kör först allt t.o.m 'replace_NaN()' ovan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model().load_model('modeller/model_senaste')\n",
    "dforg = pd.read_csv('all_data.csv')     \n",
    "# print(df.columns)\n",
    "df=remove_features(dforg.copy())\n",
    "# df['avd']=dforg.avd\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "y=df.plac\n",
    "y=(y==1)*1\n",
    "df.drop('plac',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "0:\ttest: 0.6870743\tbest: 0.6870743 (0)\ttotal: 41.7ms\tremaining: 1m 23s\n",
      "50:\ttest: 0.8164949\tbest: 0.8164949 (50)\ttotal: 2.87s\tremaining: 1m 49s\n",
      "100:\ttest: 0.8170444\tbest: 0.8177909 (87)\ttotal: 5.83s\tremaining: 1m 49s\n",
      "150:\ttest: 0.8141373\tbest: 0.8177909 (87)\ttotal: 8.43s\tremaining: 1m 43s\n",
      "\n",
      "bestTest = 0.8177908766\n",
      "bestIteration = 87\n",
      "\n",
      "Training on fold [1/5]\n",
      "0:\ttest: 0.6960316\tbest: 0.6960316 (0)\ttotal: 52.1ms\tremaining: 1m 44s\n",
      "50:\ttest: 0.8038476\tbest: 0.8062768 (38)\ttotal: 3.38s\tremaining: 2m 9s\n",
      "100:\ttest: 0.8120015\tbest: 0.8120770 (87)\ttotal: 6.95s\tremaining: 2m 10s\n",
      "150:\ttest: 0.8101797\tbest: 0.8122038 (109)\ttotal: 10.5s\tremaining: 2m 8s\n",
      "200:\ttest: 0.8084889\tbest: 0.8122038 (109)\ttotal: 13.9s\tremaining: 2m 4s\n",
      "\n",
      "bestTest = 0.8122037661\n",
      "bestIteration = 109\n",
      "\n",
      "Training on fold [2/5]\n",
      "0:\ttest: 0.6279293\tbest: 0.6279293 (0)\ttotal: 92.6ms\tremaining: 3m 5s\n",
      "50:\ttest: 0.8064775\tbest: 0.8074158 (43)\ttotal: 3.83s\tremaining: 2m 26s\n",
      "100:\ttest: 0.8030975\tbest: 0.8074158 (43)\ttotal: 7.51s\tremaining: 2m 21s\n",
      "\n",
      "bestTest = 0.807415826\n",
      "bestIteration = 43\n",
      "\n",
      "Training on fold [3/5]\n",
      "0:\ttest: 0.6834217\tbest: 0.6834217 (0)\ttotal: 93.5ms\tremaining: 3m 6s\n",
      "50:\ttest: 0.8140092\tbest: 0.8142871 (47)\ttotal: 4.17s\tremaining: 2m 39s\n",
      "100:\ttest: 0.8154941\tbest: 0.8162815 (97)\ttotal: 8.79s\tremaining: 2m 45s\n",
      "150:\ttest: 0.8155899\tbest: 0.8162815 (97)\ttotal: 13s\tremaining: 2m 38s\n",
      "\n",
      "bestTest = 0.8162815109\n",
      "bestIteration = 97\n",
      "\n",
      "Training on fold [4/5]\n",
      "0:\ttest: 0.7205535\tbest: 0.7205535 (0)\ttotal: 94.3ms\tremaining: 3m 8s\n",
      "50:\ttest: 0.8082228\tbest: 0.8082228 (50)\ttotal: 4.71s\tremaining: 2m 59s\n",
      "100:\ttest: 0.8114689\tbest: 0.8121877 (68)\ttotal: 10.1s\tremaining: 3m 10s\n",
      "150:\ttest: 0.8100050\tbest: 0.8121877 (68)\ttotal: 15.6s\tremaining: 3m 11s\n",
      "\n",
      "bestTest = 0.8121877143\n",
      "bestIteration = 68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_pool = Pool(df,y,cat_features=cat_features)\n",
    "\n",
    "params = {\n",
    "         'use_best_model': True,\n",
    "         'eval_metric' : 'AUC',\n",
    "         \"loss_function\": \"Logloss\",\n",
    "         'early_stopping_rounds': 100,\n",
    "         'verbose': 50,\n",
    "}\n",
    "\n",
    "cv_score =cv(pool=cv_pool, \n",
    "   params=params, \n",
    "   dtrain=None, \n",
    "   iterations=2000, \n",
    "   num_boost_round=None,\n",
    "   fold_count=5, \n",
    "   nfold=None,\n",
    "   inverted=False,\n",
    "   partition_random_seed=0,\n",
    "   seed=2021, \n",
    "   shuffle=False, \n",
    "   logging_level=None, \n",
    "   stratified=True,\n",
    "   as_pandas=True,\n",
    "   type='TimeSeries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.683002</td>\n",
       "      <td>0.034021</td>\n",
       "      <td>0.659567</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.659518</td>\n",
       "      <td>0.000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.754246</td>\n",
       "      <td>0.033698</td>\n",
       "      <td>0.626065</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.625836</td>\n",
       "      <td>0.002686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.757761</td>\n",
       "      <td>0.033026</td>\n",
       "      <td>0.598072</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.597654</td>\n",
       "      <td>0.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.759813</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>0.572086</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.571593</td>\n",
       "      <td>0.003109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.774361</td>\n",
       "      <td>0.019781</td>\n",
       "      <td>0.546906</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.546298</td>\n",
       "      <td>0.003783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>0.809739</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.239894</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.207548</td>\n",
       "      <td>0.007370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>0.809727</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.239898</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.207537</td>\n",
       "      <td>0.007378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>207</td>\n",
       "      <td>0.809705</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>0.239903</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.207520</td>\n",
       "      <td>0.007388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>208</td>\n",
       "      <td>0.809698</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.239898</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.207489</td>\n",
       "      <td>0.007408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>209</td>\n",
       "      <td>0.809701</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.239898</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.207474</td>\n",
       "      <td>0.007418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "0             0       0.683002      0.034021           0.659567   \n",
       "1             1       0.754246      0.033698           0.626065   \n",
       "2             2       0.757761      0.033026           0.598072   \n",
       "3             3       0.759813      0.032176           0.572086   \n",
       "4             4       0.774361      0.019781           0.546906   \n",
       "..          ...            ...           ...                ...   \n",
       "205         205       0.809739      0.005448           0.239894   \n",
       "206         206       0.809727      0.005452           0.239898   \n",
       "207         207       0.809705      0.005460           0.239903   \n",
       "208         208       0.809698      0.005463           0.239898   \n",
       "209         209       0.809701      0.005462           0.239898   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "0            0.000790            0.659518           0.000781  \n",
       "1            0.002684            0.625836           0.002686  \n",
       "2            0.002733            0.597654           0.002721  \n",
       "3            0.003137            0.571593           0.003109  \n",
       "4            0.003834            0.546298           0.003783  \n",
       "..                ...                 ...                ...  \n",
       "205          0.002817            0.207548           0.007370  \n",
       "206          0.002819            0.207537           0.007378  \n",
       "207          0.002821            0.207520           0.007388  \n",
       "208          0.002819            0.207489           0.007408  \n",
       "209          0.002819            0.207474           0.007418  \n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-12-28 2022-03-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.239852</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.207833</td>\n",
       "      <td>0.007241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "195         195       0.809818      0.005412           0.239852   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "195          0.002811            0.207833           0.007241  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>0.812328</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.24331</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.222798</td>\n",
       "      <td>0.002185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "86          86       0.812328      0.005129            0.24331   \n",
       "\n",
       "    test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "86          0.002539            0.222798           0.002185  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "print(df.datum.min(),df.datum.max())\n",
    "display(cv_score[cv_score['test-Logloss-mean'].min() == cv_score['test-Logloss-mean']])\n",
    "display(cv_score[cv_score['test-AUC-mean'].max() == cv_score['test-AUC-mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 2020-01-18 2022-03-05\n",
      "train: 2014-12-28 2020-01-18\n",
      "0:\tlearn: 0.6306328\ttest: 0.6201398\tbest: 0.6201398 (0)\ttotal: 77.8ms\tremaining: 3m 53s\n",
      "100:\tlearn: 0.7093068\ttest: 0.6405142\tbest: 0.6427984 (69)\ttotal: 9.83s\tremaining: 4m 42s\n",
      "200:\tlearn: 0.7312751\ttest: 0.6419910\tbest: 0.6497777 (151)\ttotal: 19.7s\tremaining: 4m 34s\n",
      "300:\tlearn: 0.7512802\ttest: 0.6399053\tbest: 0.6497777 (151)\ttotal: 29.4s\tremaining: 4m 23s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6497777346\n",
      "bestIteration = 151\n",
      "\n",
      "Shrink model to first 152 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x258d3d13190>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df[['datum','avd','streck','häst','kusk']] = dforg[['datum','avd','streck','häst','kusk']]\n",
    "\n",
    "# df.drop('datum',axis=1,inplace=True)\n",
    "df.drop('avd',axis=1,inplace=True)\n",
    "df.drop(['streck'],axis=1,inplace=True)\n",
    "# df.drop(['häst','kusk'],axis=1,inplace=True)\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "X_train,X_test,y_train,y_test = train_test_split(df,y,shuffle=False,)\n",
    "print(\"test:\",X_test.datum.min(),X_test.datum.max())\n",
    "print(\"train:\",X_train.datum.min(),X_train.datum.max())\n",
    "cb=get_model(use_best=True)\n",
    "cb.fit(X_train,y_train,eval_set= (X_test,y_test),early_stopping_rounds=200, cat_features=cat_features,verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -0.6808309810850233\n",
      "cb med ekipage 4.102972399150743 0.705252395847655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "predict_prob = cb.predict_proba(X_test)\n",
    "\n",
    "_,prob_score = proba_order_score(X_test ,y_test, predict_prob)\n",
    "\n",
    "print('cb med ekipage',prob_score, cb.best_score_['validation']['AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAML (med och utan ekipage och streck)\n",
    "För att köra enbart FLAML initiera först med allt innan plus walkthrough  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_enc(df_, features):\n",
    "    df = df_.copy()\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=100000)\n",
    "    enc.fit(df[[features]])\n",
    "    df[features] = enc.transform(df[[features]])\n",
    "    return df,enc\n",
    "\n",
    "# df,enc = ordinal_enc(dforg,'häst')\n",
    "# import pickle\n",
    "# pickle.dump(enc, open('modeller/encoder.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_,train_from_proc=0,test_proc=0.25):\n",
    "    # train_from_proc = where to start both train and test\n",
    "    # test_proc = how much of the data is test\n",
    "    df=df_.copy()\n",
    "    alla_datum = df.datum.unique()\n",
    "    train_from_datum = alla_datum[ int(len(alla_datum)*train_from_proc)]\n",
    "    X_test=None\n",
    "    y_test=None\n",
    "    \n",
    "    if test_proc:\n",
    "        selected_data = alla_datum[ alla_datum >= train_from_datum ]\n",
    "        test_from_datum = selected_data[ int(len(selected_data)*(1-test_proc)) ]\n",
    "        X_test  = df[df.datum >= test_from_datum]\n",
    "        y_test  = (X_test.plac==1)*1\n",
    "        X_test  = X_test.drop('plac',axis=1)\n",
    "        print(f'test from {X_test.datum.min()} to {X_test.datum.max()} (incl)')\n",
    "    \n",
    "        X_train = df[(df.datum >= train_from_datum) & (df.datum < test_from_datum) ]\n",
    "    else:\n",
    "        print('Only train data - No test')\n",
    "        X_train = df[(df.datum >= train_from_datum)]\n",
    "    \n",
    "    y_train = (X_train.plac==1)*1\n",
    "    \n",
    "    print(f'train from {X_train.datum.min()} to {X_train.datum.max()} (incl)')\n",
    "    \n",
    "    return X_train.drop('plac', axis=1), X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test from 2020-01-11 to 2022-03-05 (incl)\n",
      "train from 2014-12-28 to 2020-01-04 (incl)\n",
      "['datum', 'bana', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32861, 68), (11117, 68))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "\n",
    "### enc is the encoder that we will save for use during v75_spel.py ###\n",
    "### It will be used and finally saved later in this code ###\n",
    "df,env = ordinal_enc(dforg,'häst')\n",
    "\n",
    "X_train, X_test, y_train, y_test= split_data(df,train_from_proc=0,test_proc=0.25)\n",
    "X_train = remove_features(X_train)\n",
    "X_test  = remove_features( X_test)\n",
    "\n",
    "# X_train = X_train.drop('streck', axis=1)\n",
    "# X_test  = X_test.drop ('streck', axis=1)\n",
    "# X_train.drop('datum', axis=1, inplace=True)\n",
    "# X_test.drop( 'datum', axis=1, inplace=True)\n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "# X_train, X_test = replace_NaN(X_train.copy(),X_test=X_test.copy(), cat_features=cat_features) \n",
    "# X_train.fillna(-1)\n",
    "# X_test.fillna(-1)\n",
    "print(cat_features)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML \n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "starting_points={'lgbm': {'n_estimators': 38,\n",
    "  'num_leaves': 4,\n",
    "  'min_child_samples': 2,\n",
    "  'learning_rate': 0.19098448074739216,\n",
    "  'log_max_bin': 7,\n",
    "  'colsample_bytree': 0.8827412174089042,\n",
    "  'reg_alpha': 0.004577823970660193,\n",
    "  'reg_lambda': 0.03815584533462228},\n",
    " 'rf': {'n_estimators': 33,\n",
    "  'max_features': 0.3251674877768946,\n",
    "  'max_leaves': 89,\n",
    "  'criterion': 'entropy'},\n",
    " 'catboost': {'early_stopping_rounds': 50,\n",
    "  'learning_rate': 0.007511731949060241},\n",
    " 'xgboost': {'n_estimators': 575,\n",
    "  'max_leaves': 46,\n",
    "  'min_child_weight': 1.032235057697502,\n",
    "  'learning_rate': 0.013318439439138472,\n",
    "  'subsample': 0.7908401179782586,\n",
    "  'colsample_bylevel': 0.6924750037579576,\n",
    "  'colsample_bytree': 0.7174828796230647,\n",
    "  'reg_alpha': 0.15461500385937774,\n",
    "  'reg_lambda': 0.6619886587472544},\n",
    " 'extra_tree': {'n_estimators': 47,\n",
    "  'max_features': 0.7934349565988307,\n",
    "  'max_leaves': 213,\n",
    "  'criterion': 'entropy'}}\n",
    "flml_raw_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc', 'starting_points': starting_points,'verbose':False,\n",
    "        'time_budget':1200, 'max_iter':50000000,'n_jobs':5, 'X_val': X_test, 'y_val':y_test,'early_stop':True, 'ensemble':True}\n",
    "\n",
    "automl_raw = AutoML()\n",
    "automl_raw.fit(X_train,y_train, **flml_raw_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -1.8577109580524114\n",
      "timeserie, datum,häst, kusk 3.1081932773109244 0.8200770273677597\n"
     ]
    }
   ],
   "source": [
    "flm_raw_train_pred= automl_raw.predict_proba(X_train)\n",
    "flm_raw_test_pred = automl_raw.predict_proba(X_test)\n",
    "\n",
    "X_test_raw = X_test.copy()\n",
    "X_test_raw[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "_,prob_score = proba_order_score(X_test_raw,y_test, flm_raw_test_pred)\n",
    "\n",
    "print('timeserie, datum,häst, kusk', prob_score, 1-automl_raw.best_loss)\n",
    "# X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final FLML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_config(best_config):\n",
    "    # save best_config\n",
    "    import pickle\n",
    "    with open('best_config_per_estimator.sav', \"wb\") as f:\n",
    "        pickle.dump(best_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flaml(X_train, y_train, df_perf, save=True):\n",
    "    # read best_config\n",
    "    with open('best_config_per_estimator.sav', \"rb\") as f:\n",
    "        best_config = pickle.load(f)\n",
    "        \n",
    "    from_date = X_train.datum.min()\n",
    "    to_date = X_train.datum.max()\n",
    "    automl = [None,None]\n",
    "    for with_streck in [True, False]:\n",
    "        if with_streck: \n",
    "            X_tr = X_train.copy()    \n",
    "            filename = 'modeller\\\\FLAML_model.sav'\n",
    "        else:\n",
    "            X_tr = X_train.drop('streck', axis=1).copy()\n",
    "            filename = 'modeller\\\\FLAML2_model.sav'\n",
    "            \n",
    "        print('with_streck = ',with_streck)   \n",
    "    \n",
    "        automl[with_streck] = AutoML()\n",
    "        \n",
    "        with open('best_config_per_estimator.sav', \"rb\") as f:\n",
    "            best_config = pickle.load(f)\n",
    "            \n",
    "        flml_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc','starting_points': best_config[with_streck], 'verbose':False,\n",
    "        'time_budget':2600,'n_jobs':5, 'early_stop':True, 'ensemble':True}\n",
    "\n",
    "        automl[with_streck].fit(X_tr, y_train, **flml_parms)\n",
    "        perf = 1-automl[with_streck].best_loss\n",
    "        print(perf, 'for streck in columns', with_streck)\n",
    "        df_perf.loc[len(df_perf)] = [from_date, to_date, with_streck, perf]\n",
    "        \n",
    "        # save_model\n",
    "        if save:\n",
    "            print('save model in',filename)   \n",
    "            with open(filename,\"wb\") as f:\n",
    "                pickle.dump(automl[with_streck], f, pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "            print('save encoder enc in encoder.sav')\n",
    "            with open('encoder.sav',\"wb\") as f:\n",
    "                pickle.dump(enc, f, pickle.HIGHEST_PROTOCOL)\n",
    "             \n",
    "    save_best_config(best_config)  \n",
    "\n",
    "    # remove duplicates\n",
    "    df_perf.drop_duplicates(subset=['learn_from','learn_to','streck'], keep='last', inplace=True)\n",
    "\n",
    "    print('\\n','\\n')\n",
    "    display(df_perf.tail(30).sort_values(by=['perf'], ascending=False))\n",
    "    print('Med streck max:',df_perf.loc[df_perf.streck == True].perf.max())\n",
    "    print('Ej  streck max:',df_perf.loc[df_perf.streck == False].perf.max())\n",
    "\n",
    "    df_perf.to_csv('perf_flaml.csv', index=False)\n",
    "    return automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only train data - No test\n",
      "train from 2014-12-28 to 2022-03-05 (incl)\n",
      "with_streck =  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 10:09:09.434 INFO    flaml.searcher.blendsearch: No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.817578749158179 for streck in columns True\n",
      "save model in modeller\\FLAML_model.sav\n",
      "save encoder enc in encoder.sav\n",
      "with_streck =  False\n",
      "0.7274465110751244 for streck in columns False\n",
      "save model in modeller\\FLAML2_model.sav\n",
      "save encoder enc in encoder.sav\n",
      "\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learn_from</th>\n",
       "      <th>learn_to</th>\n",
       "      <th>streck</th>\n",
       "      <th>perf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>0.818728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>True</td>\n",
       "      <td>0.818714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-26</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-19</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-03-05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.728704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>False</td>\n",
       "      <td>0.728591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-26</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-03-05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.726912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>False</td>\n",
       "      <td>0.726116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>False</td>\n",
       "      <td>0.725764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-19</td>\n",
       "      <td>False</td>\n",
       "      <td>0.725710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>0.721107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.721041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learn_from    learn_to  streck      perf\n",
       "2   2017-02-26  2022-01-01    True  0.818728\n",
       "0   2017-02-26  2021-12-31    True  0.818714\n",
       "20  2014-12-28  2022-02-26    True  0.817911\n",
       "18  2014-12-28  2022-02-19    True  0.817896\n",
       "16  2014-12-28  2022-02-12    True  0.817811\n",
       "22  2014-12-28  2022-03-05    True  0.817579\n",
       "14  2014-12-28  2022-02-05    True  0.817489\n",
       "12  2014-12-28  2022-01-29    True  0.817124\n",
       "10  2014-12-28  2022-01-22    True  0.816984\n",
       "4   2014-12-28  2022-01-01    True  0.816678\n",
       "6   2014-12-28  2022-01-08    True  0.816579\n",
       "8   2014-12-28  2022-01-15    True  0.816330\n",
       "5   2014-12-28  2022-01-01   False  0.728704\n",
       "7   2014-12-28  2022-01-08   False  0.728591\n",
       "11  2014-12-28  2022-01-22   False  0.727775\n",
       "9   2014-12-28  2022-01-15   False  0.727692\n",
       "21  2014-12-28  2022-02-26   False  0.727589\n",
       "23  2014-12-28  2022-03-05   False  0.727447\n",
       "15  2014-12-28  2022-02-05   False  0.726912\n",
       "17  2014-12-28  2022-02-12   False  0.726116\n",
       "13  2014-12-28  2022-01-29   False  0.725764\n",
       "19  2014-12-28  2022-02-19   False  0.725710\n",
       "1   2017-02-26  2021-12-31   False  0.721107\n",
       "3   2017-02-26  2022-01-01   False  0.721041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Med streck max: 0.8187283877462516\n",
      "Ej  streck max: 0.7287040948165976\n"
     ]
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "df,enc = ordinal_enc(dforg, 'häst')\n",
    "X_train, _, y_train, _ = split_data(df,train_from_proc=0,test_proc=None)\n",
    "X_train = remove_features(X_train)\n",
    "\n",
    "df_perf = pd.read_csv('perf_flaml.csv')\n",
    "automl = run_flaml(X_train, y_train, df_perf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_garbage():\n",
    "    import subprocess\n",
    "    subprocess.call([r'C:/Users/peter/Documents/MyProjects/PyProj/Trav/spel/remove_dirt.bat'])\n",
    "remove_garbage()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tid None\n"
     ]
    }
   ],
   "source": [
    "# Kolla autmoml-grejer från dokumntationen\n",
    "#### How much time is needed to find the best model​\n",
    "#### If you want to get a sense of how much time is needed to find the best model, you can use max_iter = 2 to perform two trials first.\n",
    "#### You will see the time to finish the first and cheapest trial in seconds. \n",
    "#### The estimated necessary time budget in, and the estimated sufficient time budget inseconds. \n",
    "def set_time_budget():\n",
    "  import time\n",
    "  start_time = time.time()\n",
    "\n",
    "  automl = AutoML()\n",
    "\n",
    "  with open('best_config_per_estimator.sav', \"rb\") as f:\n",
    "      best_config = pickle.load(f)\n",
    "      \n",
    "  flml_parms = {'task': 'classification', 'split_type': 'time', 'metric': 'roc_auc', 'starting_points': best_config[0], \n",
    "                'time_budget':2600, 'n_jobs': 5, 'early_stop': True, 'ensemble': True}\n",
    "              # 'time_budget': 1700, 'max_iter': 400000000, 'n_jobs': 5, 'early_stop': True, 'ensemble': True,'verbose': True,}\n",
    "\n",
    "  automl.fit(X_train, y_train, log_file_name='flaml_log.json', **flml_parms)\n",
    "\n",
    "  return automl, time.time() - start_time\n",
    "\n",
    "tid=None\n",
    "# automl, tid = set_time_budget()  # tid in sekunder\n",
    "print('tid', tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'best_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6560/130252251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best eest. config:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nbest per est.:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_config_per_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nbest_config train time:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_config_train_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best iteration:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'best_estimator'"
     ]
    }
   ],
   "source": [
    "print('best_estimator:', automl.best_estimator)\n",
    "print('best eest. config:',automl.best_config)\n",
    "print('\\nbest per est.:',automl.best_config_per_estimator)\n",
    "print('\\nbest_config train time:',automl.best_config_train_time)\n",
    "print('best iteration:',automl.best_iteration)\n",
    "print('best loss:',automl.best_loss)\n",
    "print('time to find best mod.',automl.time_to_find_best_model)\n",
    "print('\\nhistory:',automl.config_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = get_output_from_log(\n",
    "    filename=\"flaml_log.json\", time_budget=120)\n",
    "\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Wall Clock Time (s)\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where=\"post\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hur skall vi köra den ny modellen \n",
    "1. preprocessa datat (nya kolumner)\n",
    "    - proba och eller Kelly, ant hästar i loppet, favoriter, bara solklara favoriter\n",
    "2. bestäm cat_features\n",
    "3. Kör catboost eller flaml?\n",
    "   - om flaml träna upp den\n",
    "   - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_garbage()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
