{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn v75 med walkthrough-metoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from catboost import CatBoostClassifier,Pool,cv,utils\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel')\n",
    "import V75_scraping as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df skall innehålla datum,avd,vodds\n",
    "def proba_order_score(df_, y,proba):\n",
    "    kassa=1000\n",
    "    df = df_.copy()\n",
    "    df['proba'] = proba[:,1]\n",
    "    df['f'] = (df.proba*df.vodds - 1) / (df.vodds-1)  # kelly formel\n",
    "    df['spela'] = df.f >0\n",
    "    df['insats'] = df.spela * df.f * kassa\n",
    "\n",
    "    df.sort_values(['datum','avd','proba'],ascending=[True,True,False],inplace=True)\n",
    "    proba_order=df.groupby(['datum','avd']).proba.cumcount()\n",
    "\n",
    "    df['prob_order']=proba_order+1\n",
    "    df['y'] = y\n",
    "    \n",
    "    print('log(proba)',np.log(df.loc[df.y==1].proba).mean())\n",
    "    return df, df.loc[df.y==1].prob_order.mean()   # mean prob_order för vinnarhäst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ekipage(df_):\n",
    "    df=df_.copy()\n",
    "    prefs = ['','h1_','h2_','h3_','h4_','h5_',]\n",
    "    for pr in prefs:\n",
    "        df[pr+'ekipage'] = df[pr+'kusk'].str.cat(df['häst'], sep =\", \")\n",
    "        df.drop([pr+'kusk'],axis=1, inplace=True)\n",
    "        \n",
    "    return df.drop(['häst'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returnera en modell med parametrar satta\n",
    "def get_model(d=6,l2=2,iterations=3000,use_best=True,verbose=False):\n",
    "    model = CatBoostClassifier(iterations=iterations,use_best_model=use_best, \n",
    "        custom_metric=['Logloss', 'AUC','Recall', 'Precision', 'F1', 'Accuracy'],\n",
    "\n",
    "        eval_metric='Accuracy', \n",
    "        depth=d,l2_leaf_reg=l2,\n",
    "        auto_class_weights='Balanced',verbose=verbose, random_state=2021) \n",
    "    return model                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Features som inte används vid träning\n",
    "def remove_features(df_,remove_mer=[]):\n",
    "    # df = df_.copy()\n",
    "    #remove_mer=['h5_perf','h5_auto','h4_perf','h4_auto', 'h3_perf', 'h2_perf']\n",
    "    df = df_.drop(['avd','startnr','vodds','podds','bins','h1_dat','h2_dat','h3_dat','h4_dat','h5_dat'],axis=1) #\n",
    "    if remove_mer:\n",
    "        df = df.drop(remove_mer,axis=1)\n",
    "    \n",
    "    # df=check_unique(df.copy())\n",
    "    # df=check_corr(df.copy())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## byt ut alla NaN till text för cat_features\n",
    "def replace_NaN(X_train,X_test=None, cat_features=[]):\n",
    "    # print('cat_features',cat_features)\n",
    "    for c in cat_features:\n",
    "        # print(c)\n",
    "        X_train.loc[X_train[c].isna(),c] = 'None'       ### byt ut None-värden till texten 'None\n",
    "        if X_test is not None:  ## om X_test är med\n",
    "            X_test.loc [X_test[c].isna(),c] = 'None'    ### byt ut None-värden till texten 'None\n",
    "\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nya_lopp():\n",
    "    nya_lopp,strukna = vs.v75_scraping(resultat=True,history=True)\n",
    "\n",
    "    df=pd.concat([pd.read_csv('all_data.csv'), nya_lopp])\n",
    "    print('shape med nya lopp',df.shape)\n",
    "    #ta bort dubletter\n",
    "    df.drop_duplicates(['datum','avd','häst'],inplace=True)\n",
    "    df.sort_values(by=['datum','avd'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    print('shape med dubletter bort',df.shape)\n",
    "\n",
    "    df.to_csv('all_data.csv', index=False)\n",
    "\n",
    "    print(\"första datum i df =\",df.datum.head(1).to_list()[0])\n",
    "    print(\"sista  datum i df =\",df.datum.tail(1).to_list()[0])\n",
    "\n",
    "    return df,nya_lopp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beräkna vilka datum att använda ###\n",
    "def get_alla_datum(test_from_proc=0.75, train_from_proc=0, total_omlärning = False):\n",
    "    if total_omlärning:\n",
    "        nya_lopp=None\n",
    "        df = pd.read_csv('all_data.csv')     \n",
    "        alla_datum = df.datum.unique()\n",
    "        split_ix = int(len(alla_datum)*test_from_proc)\n",
    "    else:\n",
    "        # normalt adderar vi bara 1 eller flera veckor från \"omg_att_spela_link.csv\"\n",
    "        df, nya_lopp = scrape_nya_lopp()  # scrape från 'omg_att_spela_link.csv' och addera till df\n",
    "        omg_df = pd.read_csv('omg_att_spela_link.csv')     \n",
    "        startix=omg_df.Link.str.find('spel')[0]    # index till 'spel' i url\n",
    "        alla_datum = omg_df.Link.str.slice(start=startix+5,stop=startix+15).to_list() # en datum \n",
    "        split_ix=0\n",
    "        print(f'datum att lära från {alla_datum}')\n",
    "\n",
    "    return df,nya_lopp,alla_datum,split_ix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough-funktionen  här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Kör en walkthrough learn här, en datum i taget framåt\n",
    "\n",
    "# Jag har ändrat till att alla steg kör utan test-datam ed fast iterations=100\n",
    "def walkthrough(classic_test=False, verbose=False):\n",
    "    \n",
    "    df, nya_lopp, alla_datum, split_ix = get_alla_datum(0.8)\n",
    "\n",
    "    l2_leaf_regs=2\n",
    "    model=get_model(use_best=False,iterations=100)\n",
    "    df=remove_features(df.copy())\n",
    "    cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "    df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "    print(f'cat_features {cat_features}\\n')\n",
    "\n",
    "    df['plac']=(df.plac==1)*1\n",
    "        \n",
    "    for nr,datum in enumerate(alla_datum[split_ix:]):\n",
    "        print(f'walk-iter {nr+1} av {len(alla_datum[split_ix:])} ',end=': ')\n",
    "\n",
    "        X_train = df.loc[df.datum<datum,:].copy()\n",
    "        y_train = X_train.plac; X_train.drop(['plac'],axis=1,inplace=True)\n",
    "\n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            X_test  = df.loc[df.datum>=datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=True, verbose=verbose,eval_set=test_pool)\n",
    "        else:\n",
    "            X_test  = df.loc[df.datum==datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=False, verbose=verbose)\n",
    "\n",
    "        print('best iteration',model.get_best_iteration(), '\\tbest score', round(model.get_best_score()['learn']['Accuracy'],3) )\n",
    "        ##['validation']['Logloss'],3),'\\t', round(model.get_best_score()['validation']['Accuracy:use_weights=true'],3))\n",
    "        \n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            return model,cat_features\n",
    "    \n",
    "        model.save_model('modeller/model_'+datum)\n",
    "\n",
    "    X_train =df.copy().drop('plac',axis=1)\n",
    "    y_train = df.plac \n",
    "    model.fit(X_train,y=y_train,cat_features=cat_features)\n",
    "    print(f'spara model_senaste',datum)\n",
    "    model.save_model('modeller/model_senaste')\n",
    "\n",
    "    return df,nya_lopp, model,cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Här körs hela walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omgång 1: https://www.atg.se/spel/2021-12-31/V75/\n",
      "klickade på ANPASSA\n",
      "anpassa klar - break\n",
      "ant resultat 7\n",
      "ant lopp 7\n",
      "EUR: False NOK: False\n",
      "priser ['Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 100.000-50.000-29.000-17.500-11.500-9.000-5.500-4.000 (8 priser)', 'Pris: 537.629-268.814-107.526-53.763-26.881-18.129-17.129-16.129 kr (8 priser). Lägst 500 kr till alla tävlande.']\n",
      "Ant priser 7\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 1 AXEVALLA 1640 AUTOSTART ............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 2 AXEVALLA 2140 VOLTSTART ...............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 3 AXEVALLA 2640 AUTOSTART ............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 4 AXEVALLA 2140 AUTOSTART ...............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 5 AXEVALLA 2140 AUTOSTART ............\n",
      "pris: 100.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 6 AXEVALLA 2140 VOLTSTART ...............\n",
      "pris: 537.629\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 7 AXEVALLA 2640 VOLTSTART ...............\n",
      "\n",
      "det tog 144.109 sekunder\n",
      "utdelning: 2966280, 3921, 232\n",
      "startar Fixa mer\n",
      "tog bort 13 strukna från 96 till 83\n",
      "rensade totalt bort 13 hästar i städa_och_rensa. Från 96 till 83\n",
      "shape med nya lopp (43124, 79)\n",
      "shape med dubletter bort (43124, 79)\n",
      "första datum i df = 2014-12-28\n",
      "sista  datum i df = 2021-12-31\n",
      "datum att lära från ['2021-12-31']\n",
      "cat_features ['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n",
      "\n",
      "walk-iter 1 av 1 : best iteration None \tbest score 0.75\n",
      "spara model_senaste 2021-12-31\n"
     ]
    }
   ],
   "source": [
    "df, nya_lopp, model, cat_features = walkthrough(classic_test=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kör allt ovanför walkthrough\n",
    "### Se till att \"omg_att_spela_link.csv\" är ifylld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init  - kör först allt t.o.m 'replace_NaN()' ovan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model().load_model('modeller/model_senaste')\n",
    "dforg = pd.read_csv('all_data.csv')     \n",
    "# print(df.columns)\n",
    "df=remove_features(dforg.copy())\n",
    "# df['avd']=dforg.avd\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "y=df.plac\n",
    "y=(y==1)*1\n",
    "df.drop('plac',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6738885\tbest: 0.6738885 (0)\n",
      "50:\ttest: 0.8078916\tbest: 0.8079766 (48)\n",
      "100:\ttest: 0.8105772\tbest: 0.8119305 (77)\n",
      "150:\ttest: 0.8099710\tbest: 0.8119305 (77)\n",
      "Stopped by overfitting detector  (100 iterations wait)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_pool = Pool(df,y,cat_features=cat_features)\n",
    "\n",
    "params = {\n",
    "         'use_best_model': True,\n",
    "         'eval_metric' : 'AUC',\n",
    "         \"loss_function\": \"Logloss\",\n",
    "         'early_stopping_rounds': 100,\n",
    "         'verbose': 50,\n",
    "}\n",
    "\n",
    "cv_score =cv(pool=cv_pool, \n",
    "   params=params, \n",
    "   dtrain=None, \n",
    "   iterations=2000, \n",
    "   num_boost_round=None,\n",
    "   fold_count=5, \n",
    "   nfold=None,\n",
    "   inverted=False,\n",
    "   partition_random_seed=0,\n",
    "   seed=2021, \n",
    "   shuffle=False, \n",
    "   logging_level=None, \n",
    "   stratified=True,\n",
    "   as_pandas=True,\n",
    "   type='TimeSeries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.673888</td>\n",
       "      <td>0.103032</td>\n",
       "      <td>0.659866</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>0.002931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.735127</td>\n",
       "      <td>0.035755</td>\n",
       "      <td>0.628266</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.627762</td>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.764486</td>\n",
       "      <td>0.021460</td>\n",
       "      <td>0.599323</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.598756</td>\n",
       "      <td>0.002032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.764955</td>\n",
       "      <td>0.021106</td>\n",
       "      <td>0.573438</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.573217</td>\n",
       "      <td>0.001814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.771361</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>0.549853</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.549564</td>\n",
       "      <td>0.002825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>0.809219</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>0.240494</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.208104</td>\n",
       "      <td>0.005033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>0.809216</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>0.240502</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.208006</td>\n",
       "      <td>0.005113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>0.809240</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.240477</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.207905</td>\n",
       "      <td>0.005133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>0.809163</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>0.240521</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.207825</td>\n",
       "      <td>0.005193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>0.809215</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.240519</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.207733</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "0             0       0.673888      0.103032           0.659866   \n",
       "1             1       0.735127      0.035755           0.628266   \n",
       "2             2       0.764486      0.021460           0.599323   \n",
       "3             3       0.764955      0.021106           0.573438   \n",
       "4             4       0.771361      0.010268           0.549853   \n",
       "..          ...            ...           ...                ...   \n",
       "173         173       0.809219      0.007061           0.240494   \n",
       "174         174       0.809216      0.007084           0.240502   \n",
       "175         175       0.809240      0.007083           0.240477   \n",
       "176         176       0.809163      0.007063           0.240521   \n",
       "177         177       0.809215      0.007098           0.240519   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "0            0.002833            0.659631           0.002931  \n",
       "1            0.002505            0.627762           0.002453  \n",
       "2            0.002086            0.598756           0.002032  \n",
       "3            0.002138            0.573217           0.001814  \n",
       "4            0.003263            0.549564           0.002825  \n",
       "..                ...                 ...                ...  \n",
       "173          0.003096            0.208104           0.005033  \n",
       "174          0.003120            0.208006           0.005113  \n",
       "175          0.003127            0.207905           0.005133  \n",
       "176          0.003131            0.207825           0.005193  \n",
       "177          0.003123            0.207733           0.005242  \n",
       "\n",
       "[178 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-12-28 2021-12-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>0.810263</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>0.239944</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.212652</td>\n",
       "      <td>0.00323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "135         135       0.810263      0.006747           0.239944   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "135          0.003297            0.212652            0.00323  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>0.81193</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.244058</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.225377</td>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "77          77        0.81193      0.005839           0.244058   \n",
       "\n",
       "    test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "77          0.003744            0.225377           0.001317  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "print(df.datum.min(),df.datum.max())\n",
    "display(cv_score[cv_score['test-Logloss-mean'].min() == cv_score['test-Logloss-mean']])\n",
    "display(cv_score[cv_score['test-AUC-mean'].max() == cv_score['test-AUC-mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 2019-12-26 2021-12-31\n",
      "train: 2014-12-28 2019-12-26\n",
      "0:\tlearn: 0.6410528\ttest: 0.6154424\tbest: 0.6154424 (0)\ttotal: 109ms\tremaining: 5m 25s\n",
      "100:\tlearn: 0.7136332\ttest: 0.6373571\tbest: 0.6448591 (32)\ttotal: 10.1s\tremaining: 4m 49s\n",
      "200:\tlearn: 0.7354847\ttest: 0.6425083\tbest: 0.6459617 (172)\ttotal: 20s\tremaining: 4m 38s\n",
      "300:\tlearn: 0.7529548\ttest: 0.6459007\tbest: 0.6479300 (288)\ttotal: 31.3s\tremaining: 4m 41s\n",
      "400:\tlearn: 0.7723118\ttest: 0.6449699\tbest: 0.6490408 (310)\ttotal: 41.2s\tremaining: 4m 27s\n",
      "500:\tlearn: 0.7931724\ttest: 0.6435773\tbest: 0.6490408 (310)\ttotal: 52.2s\tremaining: 4m 20s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6490407762\n",
      "bestIteration = 310\n",
      "\n",
      "Shrink model to first 311 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1a7deeefc70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df[['datum','avd','streck','häst','kusk']] = dforg[['datum','avd','streck','häst','kusk']]\n",
    "\n",
    "# df.drop('datum',axis=1,inplace=True)\n",
    "df.drop('avd',axis=1,inplace=True)\n",
    "df.drop(['streck'],axis=1,inplace=True)\n",
    "# df.drop(['häst','kusk'],axis=1,inplace=True)\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "X_train,X_test,y_train,y_test = train_test_split(df,y,shuffle=False,)\n",
    "print(\"test:\",X_test.datum.min(),X_test.datum.max())\n",
    "print(\"train:\",X_train.datum.min(),X_train.datum.max())\n",
    "cb=get_model(use_best=True)\n",
    "cb.fit(X_train,y_train,eval_set= (X_test,y_test),early_stopping_rounds=200, cat_features=cat_features,verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -0.6917986146567653\n",
      "cb med ekipage 4.060409924487594 0.7033987479334202\n"
     ]
    }
   ],
   "source": [
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "predict_prob = cb.predict_proba(X_test)\n",
    "\n",
    "_,prob_score = proba_order_score(X_test ,y_test, predict_prob)\n",
    "\n",
    "print('cb med ekipage',prob_score, cb.best_score_['validation']['AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAML (med och utan ekipage och streck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_,train_from_proc=0,test_proc=0.25):\n",
    "    # train_from_proc = where to start both train and test\n",
    "    # test_proc = how much of the data is test\n",
    "    df=df_.copy()\n",
    "    alla_datum = df.datum.unique()\n",
    "    train_from_datum = alla_datum[ int(len(alla_datum)*train_from_proc)]\n",
    "    print(\"train from\",train_from_datum)\n",
    "    X_test=None\n",
    "    y_test=None\n",
    "    test_from_datum=alla_datum[-1]\n",
    "    if test_proc:\n",
    "        selected_data = alla_datum[ alla_datum >= train_from_datum ]\n",
    "        test_from_datum = selected_data[ int(len(selected_data)*(1-test_proc)) ]\n",
    "        print(\"test from\",test_from_datum)\n",
    "        X_test  = df[df.datum >= test_from_datum]\n",
    "        y_test  = (X_test.plac==1)*1\n",
    "        X_test  = X_test.drop('plac',axis=1)\n",
    "        \n",
    "    \n",
    "    X_train = df[(df.datum >= train_from_datum) & (df.datum < test_from_datum) ]\n",
    "    y_train = (X_train.plac==1)*1\n",
    "    \n",
    "    return X_train.drop('plac', axis=1), X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train from 2017-02-26\n",
      "test from 2020-07-05\n",
      "['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((22608, 68), (7575, 68))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "\n",
    "X_train, X_test, y_train, y_test= split_data(dforg,train_from_proc=0.3,test_proc=0.25)\n",
    "X_train = remove_features(X_train)\n",
    "X_test  = remove_features( X_test)\n",
    "\n",
    "# X_train = X_train.drop('streck', axis=1)\n",
    "# X_test  = X_test.drop ('streck', axis=1)\n",
    "# X_train.drop('datum', axis=1, inplace=True)\n",
    "# X_test.drop( 'datum', axis=1, inplace=True)\n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "# X_train, X_test = replace_NaN(X_train.copy(),X_test=X_test.copy(), cat_features=cat_features) \n",
    "# X_train.fillna(-1)\n",
    "# X_test.fillna(-1)\n",
    "print(cat_features)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML \n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "starting_points={'lgbm': {'n_estimators': 38,\n",
    "  'num_leaves': 4,\n",
    "  'min_child_samples': 2,\n",
    "  'learning_rate': 0.19098448074739216,\n",
    "  'log_max_bin': 7,\n",
    "  'colsample_bytree': 0.8827412174089042,\n",
    "  'reg_alpha': 0.004577823970660193,\n",
    "  'reg_lambda': 0.03815584533462228},\n",
    " 'rf': {'n_estimators': 33,\n",
    "  'max_features': 0.3251674877768946,\n",
    "  'max_leaves': 89,\n",
    "  'criterion': 'entropy'},\n",
    " 'catboost': {'early_stopping_rounds': 10,\n",
    "  'learning_rate': 0.007511731949060241},\n",
    " 'xgboost': {'n_estimators': 575,\n",
    "  'max_leaves': 46,\n",
    "  'min_child_weight': 1.032235057697502,\n",
    "  'learning_rate': 0.013318439439138472,\n",
    "  'subsample': 0.7908401179782586,\n",
    "  'colsample_bylevel': 0.6924750037579576,\n",
    "  'colsample_bytree': 0.7174828796230647,\n",
    "  'reg_alpha': 0.15461500385937774,\n",
    "  'reg_lambda': 0.6619886587472544},\n",
    " 'extra_tree': {'n_estimators': 47,\n",
    "  'max_features': 0.7934349565988307,\n",
    "  'max_leaves': 213,\n",
    "  'criterion': 'entropy'}}\n",
    "flml_raw_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc', 'starting_points': starting_points,'verbose':False,\n",
    "        'time_budget':700, 'max_iter':50000000,'n_jobs':5, 'X_val': X_test, 'y_val':y_test,'early_stop':True, 'ensemble':True}\n",
    "\n",
    "automl_raw = AutoML()\n",
    "automl_raw.fit(X_train,y_train, **flml_raw_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -1.8802313804626465\n",
      "timeserie, datum,häst, kusk 3.187403993855607 0.8145972156776093\n"
     ]
    }
   ],
   "source": [
    "flm_raw_train_pred= automl_raw.predict_proba(X_train)\n",
    "flm_raw_test_pred = automl_raw.predict_proba(X_test)\n",
    "\n",
    "X_test_raw = X_test.copy()\n",
    "X_test_raw[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "_,prob_score = proba_order_score(X_test_raw,y_test, flm_raw_test_pred)\n",
    "\n",
    "print('timeserie, datum,häst, kusk', prob_score, 1-automl_raw.best_loss)\n",
    "# X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timeserie  0.3 0.25, datum, häst, kusk 3.720565149136578  0.7213763318649257 ... 1.9827526807785034 .....   best    \n",
    "timeserie  0.4 0.25, datum, häst, kusk 3.7362637362637363 0.7214144007762124  \n",
    "timeserie, 0.2 0.25, datum, häst, kusk 3.760989010989011  0.72561915325073230    \n",
    "timeserie, 0.1 0.25  datum, häst, kusk 3.8180708180708183 0.726597977829505    \n",
    "timeserie, 0.5 0.25, datum, häst, kusk 3.936263736263736  0.7216626969090024  \n",
    "timeserie, 0.3 0.25, datum, häst, kusk streck, NaN 3.0706436420722136  0.8230307821948237   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk,streck  3.0549450549450547 0.8232840226857013 ... -1.7710182666778564 .......... best   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk streck, NaN, fillna, 3.0549450549450547 0.8237003593459333   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk, streck 3.06436420722135   0.8232840226857013       \n",
    "timeserie, 0.4 0.25, datum, häst, kusk, streck 3.1483516483516483 0.8169106155467452  \n",
    "timeserie, 0.2 0.25, datum, häst, kusk, streck 3.0824175824175826 0.8220287891340522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final FLML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flaml(X_train, y_train):\n",
    "    import pickle\n",
    "\n",
    "    for with_streck in [True, False]:\n",
    "        if with_streck: \n",
    "            X_tr = X_train.copy()    \n",
    "            filename = 'modeller\\\\FLAML_model.sav'\n",
    "        else:\n",
    "            X_tr = X_train.drop('streck', axis=1).copy()\n",
    "            filename = 'modeller\\\\FLAML2_model.sav'\n",
    "            \n",
    "        print('with_streck = ',with_streck)    \n",
    "    \n",
    "        automl = AutoML()\n",
    "        flml_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc','starting_points': starting_points, 'verbose':False,\n",
    "        'time_budget':1700, 'max_iter':400000000,'n_jobs':5, 'early_stop':True, 'ensemble':True}\n",
    "\n",
    "        automl.fit(X_tr, y_train, **flml_parms)\n",
    "        print(1-automl.best_loss, 'for streck in columns', 'streck' in X_tr.columns)\n",
    "        \n",
    "        # save_model\n",
    "        print('save in',filename)        \n",
    "        pickle.dump(automl, open(filename, 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train from 2017-02-26\n",
      "with_streck =  True\n",
      "0.819062784305765 for streck in columns True\n",
      "save in modeller\\FLAML_model.sav\n",
      "with_streck =  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 12-31 20:09:49] {1541} WARNING - Time taken to find the best model is 88% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "2021-12-31 20:09:49.019 WARNING flaml.automl: Time taken to find the best model is 88% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7220758393192013 for streck in columns False\n",
      "save in modeller\\FLAML2_model.sav\n"
     ]
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "X_train, _, y_train, _ = split_data(dforg,train_from_proc=0.3,test_proc=None)\n",
    "X_train = remove_features(X_train)\n",
    "\n",
    "run_flaml(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove dirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call([r'C:/Users/peter/Documents/MyProjects/PyProj/Trav/spel/remove_dirt.bat'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
