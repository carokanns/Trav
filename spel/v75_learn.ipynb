{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn v75 med walkthrough-metoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from catboost import CatBoostClassifier,Pool,cv,utils\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel')\n",
    "import V75_scraping as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df skall innehålla datum,avd,vodds\n",
    "def proba_order_score(df_, y,proba):\n",
    "    kassa=1000\n",
    "    df = df_.copy()\n",
    "    df['proba'] = proba[:,1]\n",
    "    df['f'] = (df.proba*df.vodds - 1) / (df.vodds-1)  # kelly formel\n",
    "    df['spela'] = df.f >0\n",
    "    df['insats'] = df.spela * df.f * kassa\n",
    "\n",
    "    df.sort_values(['datum','avd','proba'],ascending=[True,True,False],inplace=True)\n",
    "    proba_order=df.groupby(['datum','avd']).proba.cumcount()\n",
    "\n",
    "    df['prob_order']=proba_order+1\n",
    "    df['y'] = y\n",
    "    \n",
    "    print('log(proba)',np.log(df.loc[df.y==1].proba).mean())\n",
    "    return df, df.loc[df.y==1].prob_order.mean()   # mean prob_order för vinnarhäst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ekipage(df_):\n",
    "    df=df_.copy()\n",
    "    prefs = ['','h1_','h2_','h3_','h4_','h5_',]\n",
    "    for pr in prefs:\n",
    "        df[pr+'ekipage'] = df[pr+'kusk'].str.cat(df['häst'], sep =\", \")\n",
    "        df.drop([pr+'kusk'],axis=1, inplace=True)\n",
    "        \n",
    "    return df.drop(['häst'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returnera en modell med parametrar satta\n",
    "def get_model(d=6,l2=2,iterations=3000,use_best=True,verbose=False):\n",
    "    model = CatBoostClassifier(iterations=iterations,use_best_model=use_best, \n",
    "        custom_metric=['Logloss', 'AUC','Recall', 'Precision', 'F1', 'Accuracy'],\n",
    "\n",
    "        eval_metric='Accuracy', \n",
    "        depth=d,l2_leaf_reg=l2,\n",
    "        auto_class_weights='Balanced',verbose=verbose, random_state=2021) \n",
    "    return model                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Features som inte används vid träning\n",
    "def remove_features(df_,remove_mer=[]):\n",
    "    # df = df_.copy()\n",
    "    #remove_mer=['h5_perf','h5_auto','h4_perf','h4_auto', 'h3_perf', 'h2_perf']\n",
    "    df = df_.drop(['avd','startnr','vodds','podds','bins','h1_dat','h2_dat','h3_dat','h4_dat','h5_dat'],axis=1) #\n",
    "    if remove_mer:\n",
    "        df = df.drop(remove_mer,axis=1)\n",
    "    \n",
    "    # df=check_unique(df.copy())\n",
    "    # df=check_corr(df.copy())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## byt ut alla NaN till text för cat_features\n",
    "def replace_NaN(X_train,X_test=None, cat_features=[]):\n",
    "    # print('cat_features',cat_features)\n",
    "    for c in cat_features:\n",
    "        # print(c)\n",
    "        X_train.loc[X_train[c].isna(),c] = 'None'       ### byt ut None-värden till texten 'None\n",
    "        if X_test is not None:  ## om X_test är med\n",
    "            X_test.loc [X_test[c].isna(),c] = 'None'    ### byt ut None-värden till texten 'None\n",
    "\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nya_lopp():\n",
    "    nya_lopp,strukna = vs.v75_scraping(resultat=True,history=True)\n",
    "\n",
    "    df=pd.concat([pd.read_csv('all_data.csv'), nya_lopp])\n",
    "    print('shape med nya lopp',df.shape)\n",
    "    #ta bort dubletter\n",
    "    df.drop_duplicates(['datum','avd','häst'],inplace=True)\n",
    "    df.sort_values(by=['datum','avd'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    print('shape med dubletter bort',df.shape)\n",
    "\n",
    "    df.to_csv('all_data.csv', index=False)\n",
    "\n",
    "    print(\"första datum i df =\",df.datum.head(1).to_list()[0])\n",
    "    print(\"sista  datum i df =\",df.datum.tail(1).to_list()[0])\n",
    "\n",
    "    return df,nya_lopp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beräkna vilka datum att använda ###\n",
    "def get_alla_datum(test_from_proc=0.75, train_from_proc=0, total_omlärning = False):\n",
    "    if total_omlärning:\n",
    "        nya_lopp=None\n",
    "        df = pd.read_csv('all_data.csv')     \n",
    "        alla_datum = df.datum.unique()\n",
    "        split_ix = int(len(alla_datum)*test_from_proc)\n",
    "    else:\n",
    "        # normalt adderar vi bara 1 eller flera veckor från \"omg_att_spela_link.csv\"\n",
    "        df, nya_lopp = scrape_nya_lopp()  # scrape från 'omg_att_spela_link.csv' och addera till df\n",
    "        omg_df = pd.read_csv('omg_att_spela_link.csv')     \n",
    "        startix=omg_df.Link.str.find('spel')[0]    # index till 'spel' i url\n",
    "        alla_datum = omg_df.Link.str.slice(start=startix+5,stop=startix+15).to_list() # en datum \n",
    "        split_ix=0\n",
    "        print(f'datum att lära från {alla_datum}')\n",
    "\n",
    "    return df,nya_lopp,alla_datum,split_ix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough-funktionen  här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Kör en walkthrough learn här, en datum i taget framåt\n",
    "\n",
    "# Jag har ändrat till att alla steg kör utan test-datam ed fast iterations=100\n",
    "def walkthrough(classic_test=False, verbose=False):\n",
    "    \n",
    "    df, nya_lopp, alla_datum, split_ix = get_alla_datum()\n",
    "\n",
    "    l2_leaf_regs=2\n",
    "    model=get_model(use_best=False,iterations=100)\n",
    "    df=remove_features(df.copy())\n",
    "    cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "    df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "    print(f'cat_features {cat_features}\\n')\n",
    "\n",
    "    df['plac']=(df.plac==1)*1\n",
    "        \n",
    "    for nr,datum in enumerate(alla_datum[split_ix:]):\n",
    "        print(f'walk-iter {nr+1} av {len(alla_datum[split_ix:])} ',end=': ')\n",
    "\n",
    "        X_train = df.loc[df.datum<datum,:].copy()\n",
    "        y_train = X_train.plac; X_train.drop(['plac'],axis=1,inplace=True)\n",
    "\n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            X_test  = df.loc[df.datum>=datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=True, verbose=verbose,eval_set=test_pool)\n",
    "        else:\n",
    "            X_test  = df.loc[df.datum==datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=False, verbose=verbose)\n",
    "\n",
    "        print('best iteration',model.get_best_iteration(), '\\tbest score', round(model.get_best_score()['learn']['Accuracy'],3) )\n",
    "        ##['validation']['Logloss'],3),'\\t', round(model.get_best_score()['validation']['Accuracy:use_weights=true'],3))\n",
    "        \n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            return model,cat_features\n",
    "    \n",
    "        model.save_model('modeller/model_'+datum)\n",
    "\n",
    "    X_train =df.copy().drop('plac',axis=1)\n",
    "    y_train = df.plac \n",
    "    model.fit(X_train,y=y_train,cat_features=cat_features)\n",
    "    print(f'spara model_senaste',datum)\n",
    "    model.save_model('modeller/model_senaste')\n",
    "\n",
    "    return df,nya_lopp, model,cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Här körs hela walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omgång 1: https://www.atg.se/spel/2021-12-11/V75/\n",
      "klickade på ANPASSA\n",
      "anpassa klar - break\n",
      "ant resultat 7\n",
      "ant lopp 7\n",
      "EUR: False NOK: False\n",
      "priser ['Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 (8 priser)', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 (8 priser)', 'Pris: 125.000-62.500-34.000-21.000-13.500-10.500-7.000-5.000 (8 priser)', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 (8 priser)', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 (8 priser)', 'Pris: 200.000-100.000-55.000-30.000-20.000-12.500-8.000-6.000 (8 priser)', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 (8 priser)']\n",
      "Ant priser 7\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 1 ÅBY 2140 VOLTSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 2 ÅBY 2140 AUTOSTART ............\n",
      "pris: 125.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 3 ÅBY 2640 AUTOSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 4 ÅBY 2140 VOLTSTART ...............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 5 ÅBY 1640 AUTOSTART ............\n",
      "pris: 200.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 6 ÅBY 2140 AUTOSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 7 ÅBY 1640 AUTOSTART ............\n",
      "\n",
      "det tog 123.723 sekunder\n",
      "utdelning: 23747399, 32352, 1024\n",
      "startar Fixa mer\n",
      "tog bort 6 strukna från 87 till 81\n",
      "rensade totalt bort 6 hästar i städa_och_rensa. Från 87 till 81\n",
      "shape med nya lopp (42881, 79)\n",
      "shape med dubletter bort (42881, 79)\n",
      "första datum i df = 2014-12-28\n",
      "sista  datum i df = 2021-12-11\n",
      "datum att lära från ['2021-12-11']\n",
      "cat_features ['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n",
      "\n",
      "walk-iter 1 av 1 : best iteration None \tbest score 0.753\n",
      "spara model_senaste 2021-12-11\n"
     ]
    }
   ],
   "source": [
    "df, nya_lopp, model, cat_features = walkthrough(classic_test=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kör allt ovanför walkthrough\n",
    "### Se till att \"omg_att_spela_link.csv\" är ifylld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init  - kör först allt t.o.m 'replace_NaN()' ovan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model().load_model('modeller/model_senaste')\n",
    "dforg = pd.read_csv('all_data.csv')     \n",
    "# print(df.columns)\n",
    "df=remove_features(dforg.copy())\n",
    "# df['avd']=dforg.avd\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "y=df.plac\n",
    "y=(y==1)*1\n",
    "df.drop('plac',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6715721\tbest: 0.6715721 (0)\n",
      "50:\ttest: 0.8091859\tbest: 0.8093337 (48)\n",
      "100:\ttest: 0.8110610\tbest: 0.8125450 (81)\n",
      "150:\ttest: 0.8100676\tbest: 0.8125450 (81)\n",
      "Stopped by overfitting detector  (100 iterations wait)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_pool = Pool(df,y,cat_features=cat_features)\n",
    "\n",
    "params = {\n",
    "         'use_best_model': True,\n",
    "         'eval_metric' : 'AUC',\n",
    "         \"loss_function\": \"Logloss\",\n",
    "         'early_stopping_rounds': 100,\n",
    "         'verbose': 50,\n",
    "}\n",
    "\n",
    "cv_score =cv(pool=cv_pool, \n",
    "   params=params, \n",
    "   dtrain=None, \n",
    "   iterations=2000, \n",
    "   num_boost_round=None,\n",
    "   fold_count=5, \n",
    "   nfold=None,\n",
    "   inverted=False,\n",
    "   partition_random_seed=0,\n",
    "   seed=2021, \n",
    "   shuffle=False, \n",
    "   logging_level=None, \n",
    "   stratified=True,\n",
    "   as_pandas=True,\n",
    "   type='TimeSeries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.671572</td>\n",
       "      <td>0.080227</td>\n",
       "      <td>0.659980</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.659857</td>\n",
       "      <td>0.002391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.710216</td>\n",
       "      <td>0.056149</td>\n",
       "      <td>0.629399</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.629261</td>\n",
       "      <td>0.003616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.746274</td>\n",
       "      <td>0.020243</td>\n",
       "      <td>0.600444</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.600254</td>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.573025</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.001374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.774066</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>0.548594</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.548019</td>\n",
       "      <td>0.001980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>0.809925</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.239790</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.005594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>0.809879</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.239793</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.207911</td>\n",
       "      <td>0.005616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>0.809900</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>0.239802</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.207829</td>\n",
       "      <td>0.005655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>0.809869</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.239805</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.207742</td>\n",
       "      <td>0.005680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>0.809828</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.239792</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.207636</td>\n",
       "      <td>0.005699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "0             0       0.671572      0.080227           0.659980   \n",
       "1             1       0.710216      0.056149           0.629399   \n",
       "2             2       0.746274      0.020243           0.600444   \n",
       "3             3       0.762440      0.026000           0.573025   \n",
       "4             4       0.774066      0.023003           0.548594   \n",
       "..          ...            ...           ...                ...   \n",
       "177         177       0.809925      0.006580           0.239790   \n",
       "178         178       0.809879      0.006561           0.239793   \n",
       "179         179       0.809900      0.006571           0.239802   \n",
       "180         180       0.809869      0.006557           0.239805   \n",
       "181         181       0.809828      0.006495           0.239792   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "0            0.002454            0.659857           0.002391  \n",
       "1            0.003577            0.629261           0.003616  \n",
       "2            0.001814            0.600254           0.001918  \n",
       "3            0.001462            0.572549           0.001374  \n",
       "4            0.002035            0.548019           0.001980  \n",
       "..                ...                 ...                ...  \n",
       "177          0.002800            0.208015           0.005594  \n",
       "178          0.002790            0.207911           0.005616  \n",
       "179          0.002798            0.207829           0.005655  \n",
       "180          0.002783            0.207742           0.005680  \n",
       "181          0.002766            0.207636           0.005699  \n",
       "\n",
       "[182 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>0.810082</td>\n",
       "      <td>0.00621</td>\n",
       "      <td>0.239606</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.210848</td>\n",
       "      <td>0.004178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "152         152       0.810082       0.00621           0.239606   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "152          0.002514            0.210848           0.004178  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>0.812545</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.244062</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.22377</td>\n",
       "      <td>0.001593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "81          81       0.812545      0.005769           0.244062   \n",
       "\n",
       "    test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "81          0.002483             0.22377           0.001593  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "print(df.datum.max())\n",
    "display(cv_score[cv_score['test-Logloss-mean'].min() == cv_score['test-Logloss-mean']])\n",
    "display(cv_score[cv_score['test-AUC-mean'].max() == cv_score['test-AUC-mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6424521\ttest: 0.6195158\tbest: 0.6195158 (0)\ttotal: 73.8ms\tremaining: 3m 41s\n",
      "100:\tlearn: 0.7136842\ttest: 0.6390009\tbest: 0.6430593 (82)\ttotal: 9.47s\tremaining: 4m 31s\n",
      "200:\tlearn: 0.7387412\ttest: 0.6425145\tbest: 0.6438953 (191)\ttotal: 19.3s\tremaining: 4m 28s\n",
      "300:\tlearn: 0.7538757\ttest: 0.6377944\tbest: 0.6453652 (208)\ttotal: 29.1s\tremaining: 4m 20s\n",
      "400:\tlearn: 0.7735686\ttest: 0.6391981\tbest: 0.6453652 (208)\ttotal: 38.9s\tremaining: 4m 11s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6453651523\n",
      "bestIteration = 208\n",
      "\n",
      "Shrink model to first 209 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ed40367400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df[['datum','avd','streck','häst','kusk']] = dforg[['datum','avd','streck','häst','kusk']]\n",
    "\n",
    "# df.drop('datum',axis=1,inplace=True)\n",
    "df.drop('avd',axis=1,inplace=True)\n",
    "df.drop(['streck'],axis=1,inplace=True)\n",
    "# df.drop(['häst','kusk'],axis=1,inplace=True)\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "X_train,X_test,y_train,y_test = train_test_split(df,y,shuffle=False,)\n",
    "cb=get_model(use_best=True)\n",
    "cb.fit(X_train,y_train,eval_set= (X_test,y_test),early_stopping_rounds=200, cat_features=cat_features,verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -0.6935275267087648\n",
      "cb med ekipage 4.056399132321041 0.707299142260521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "predict_prob = cb.predict_proba(X_test)\n",
    "\n",
    "_,prob_score = proba_order_score(X_test ,y_test, predict_prob)\n",
    "\n",
    "print('cb med ekipage',prob_score, cb.best_score_['validation']['AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAML (med och utan ekipage och streck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_,train_from_proc=0,test_proc=0.25):\n",
    "    # train_from_proc = where to start both train and test\n",
    "    # test_proc = how much of the data is test\n",
    "    df=df_.copy()\n",
    "    alla_datum = df.datum.unique()\n",
    "    train_from_datum = alla_datum[ int(len(alla_datum)*train_from_proc)]\n",
    "    print(train_from_datum)\n",
    "    X_test=None\n",
    "    y_test=None\n",
    "    test_from_datum=alla_datum[-1]\n",
    "    if test_proc:\n",
    "        selected_data = alla_datum[ alla_datum >= train_from_datum ]\n",
    "        test_from_datum = selected_data[ int(len(selected_data)*(1-test_proc)) ]\n",
    "        print(test_from_datum)\n",
    "        X_test  = df[df.datum >= test_from_datum]\n",
    "        y_test  = (X_test.plac==1)*1\n",
    "        X_test  = X_test.drop('plac',axis=1)\n",
    "        \n",
    "    \n",
    "    X_train = df[(df.datum >= train_from_datum) & (df.datum < test_from_datum) ]\n",
    "    y_train = (X_train.plac==1)*1\n",
    "    \n",
    "    return X_train.drop('plac', axis=1), X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-25\n",
      "2020-06-27\n",
      "['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((22454, 68), (7563, 68))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "\n",
    "X_train, X_test, y_train, y_test= split_data(dforg,train_from_proc=0.3,test_proc=0.25)\n",
    "X_train = remove_features(X_train)\n",
    "X_test  = remove_features( X_test)\n",
    "\n",
    "# X_train = X_train.drop('streck', axis=1)\n",
    "# X_test  = X_test.drop ('streck', axis=1)\n",
    "# X_train.drop('datum', axis=1, inplace=True)\n",
    "# X_test.drop( 'datum', axis=1, inplace=True)\n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "# X_train, X_test = replace_NaN(X_train.copy(),X_test=X_test.copy(), cat_features=cat_features) \n",
    "# X_train.fillna(-1)\n",
    "# X_test.fillna(-1)\n",
    "print(cat_features)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 12-11 22:17:32] {1541} WARNING - Time taken to find the best model is 95% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "2021-12-11 22:17:32.300 WARNING flaml.automl: Time taken to find the best model is 95% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML \n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "starting_points={'lgbm': {'n_estimators': 38,\n",
    "  'num_leaves': 4,\n",
    "  'min_child_samples': 2,\n",
    "  'learning_rate': 0.19098448074739216,\n",
    "  'log_max_bin': 7,\n",
    "  'colsample_bytree': 0.8827412174089042,\n",
    "  'reg_alpha': 0.004577823970660193,\n",
    "  'reg_lambda': 0.03815584533462228},\n",
    " 'rf': {'n_estimators': 33,\n",
    "  'max_features': 0.3251674877768946,\n",
    "  'max_leaves': 89,\n",
    "  'criterion': 'entropy'},\n",
    " 'catboost': {'early_stopping_rounds': 10,\n",
    "  'learning_rate': 0.007511731949060241},\n",
    " 'xgboost': {'n_estimators': 575,\n",
    "  'max_leaves': 46,\n",
    "  'min_child_weight': 1.032235057697502,\n",
    "  'learning_rate': 0.013318439439138472,\n",
    "  'subsample': 0.7908401179782586,\n",
    "  'colsample_bylevel': 0.6924750037579576,\n",
    "  'colsample_bytree': 0.7174828796230647,\n",
    "  'reg_alpha': 0.15461500385937774,\n",
    "  'reg_lambda': 0.6619886587472544},\n",
    " 'extra_tree': {'n_estimators': 47,\n",
    "  'max_features': 0.7934349565988307,\n",
    "  'max_leaves': 213,\n",
    "  'criterion': 'entropy'}}\n",
    "flml_raw_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc', 'starting_points': starting_points,'verbose':False,\n",
    "        'time_budget':700, 'max_iter':50000000,'n_jobs':5, 'X_val': X_test, 'y_val':y_test,'early_stop':True, 'ensemble':True}\n",
    "\n",
    "automl_raw = AutoML()\n",
    "automl_raw.fit(X_train,y_train, **flml_raw_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -1.901437862590839\n",
      "timeserie, datum,häst, kusk 3.1044546850998462 0.8179480153396484\n"
     ]
    }
   ],
   "source": [
    "flm_raw_train_pred= automl_raw.predict_proba(X_train)\n",
    "flm_raw_test_pred = automl_raw.predict_proba(X_test)\n",
    "\n",
    "X_test_raw = X_test.copy()\n",
    "X_test_raw[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "_,prob_score = proba_order_score(X_test_raw,y_test, flm_raw_test_pred)\n",
    "\n",
    "print('timeserie, datum,häst, kusk', prob_score, 1-automl_raw.best_loss)\n",
    "# X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timeserie  0.3 0.25, datum, häst, kusk 3.720565149136578  0.7213763318649257 ... 1.9827526807785034 .....   best    \n",
    "timeserie  0.4 0.25, datum, häst, kusk 3.7362637362637363 0.7214144007762124  \n",
    "timeserie, 0.2 0.25, datum, häst, kusk 3.760989010989011  0.72561915325073230    \n",
    "timeserie, 0.1 0.25  datum, häst, kusk 3.8180708180708183 0.726597977829505    \n",
    "timeserie, 0.5 0.25, datum, häst, kusk 3.936263736263736  0.7216626969090024  \n",
    "timeserie, 0.3 0.25, datum, häst, kusk streck, NaN 3.0706436420722136  0.8230307821948237   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk,streck  3.0549450549450547 0.8232840226857013 ... -1.7710182666778564 .......... best   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk streck, NaN, fillna, 3.0549450549450547 0.8237003593459333   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk, streck 3.06436420722135   0.8232840226857013       \n",
    "timeserie, 0.4 0.25, datum, häst, kusk, streck 3.1483516483516483 0.8169106155467452  \n",
    "timeserie, 0.2 0.25, datum, häst, kusk, streck 3.0824175824175826 0.8220287891340522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final FLML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flaml(X_train, y_train):\n",
    "    import pickle\n",
    "\n",
    "    for with_streck in [True, False]:\n",
    "        if with_streck: \n",
    "            X_tr = X_train.copy()    \n",
    "            filename = 'modeller\\\\FLAML_model.sav'\n",
    "        else:\n",
    "            X_tr = X_train.drop('streck', axis=1).copy()\n",
    "            filename = 'modeller\\\\FLAML2_model.sav'\n",
    "            \n",
    "        print('with_streck = ',with_streck)    \n",
    "    \n",
    "        automl = AutoML()\n",
    "        flml_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc','starting_points': starting_points, 'verbose':False,\n",
    "        'time_budget':1700, 'max_iter':400000000,'n_jobs':5, 'early_stop':True, 'ensemble':True}\n",
    "\n",
    "        automl.fit(X_tr, y_train, **flml_parms)\n",
    "        print(1-automl.best_loss, 'for streck in columns', 'streck' in X_tr.columns)\n",
    "        \n",
    "        # save_model\n",
    "        print('save in',filename)        \n",
    "        pickle.dump(automl, open(filename, 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-25\n",
      "with_streck =  True\n",
      "0.8194439882895833 for streck in columns True\n",
      "save in modeller\\FLAML_model.sav\n",
      "with_streck =  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 23:16:43.135 WARNING flaml.searcher.blendsearch: No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'.\n",
      "C:\\Users\\peter\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\peter\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\peter\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7235882434989205 for streck in columns False\n",
      "save in modeller\\FLAML2_model.sav\n"
     ]
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "X_train, _, y_train, _ = split_data(dforg,train_from_proc=0.3,test_proc=None)\n",
    "X_train = remove_features(X_train)\n",
    "\n",
    "run_flaml(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove dirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call([r'C:/Users/peter/Documents/MyProjects/PyProj/Trav/spel/remove_dirt.bat'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
