{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn v75 med walkthrough-metoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from catboost import CatBoostClassifier,Pool,cv,utils\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel')\n",
    "import V75_scraping as vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def proba_order_score(df_, y, proba):  # df skall innehålla datum,avd,vodds\n",
    "    kassa=1000\n",
    "    df = df_.copy()\n",
    "    df['proba'] = proba[:,1]\n",
    "    df['f'] = (df.proba*df.vodds - 1) / (df.vodds-1)  # kelly formel\n",
    "    df['spela'] = df.f >0\n",
    "    df['insats'] = df.spela * df.f * kassa\n",
    "\n",
    "    df.sort_values(['datum','avd','proba'],ascending=[True,True,False],inplace=True)\n",
    "    proba_order=df.groupby(['datum','avd']).proba.cumcount()\n",
    "\n",
    "    df['prob_order']=proba_order+1\n",
    "    df['y'] = y\n",
    "\n",
    "    print('log(proba)',np.log(df.loc[df.y==1].proba).mean())\n",
    "    return df, df.loc[df.y==1].prob_order.mean()   # mean prob_order för vinnarhäst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ekipage(df_):\n",
    "    df=df_.copy()\n",
    "    prefs = ['','h1_','h2_','h3_','h4_','h5_',]\n",
    "    for pr in prefs:\n",
    "        df[pr+'ekipage'] = df[pr+'kusk'].str.cat(df['häst'], sep =\", \")\n",
    "        df.drop([pr+'kusk'],axis=1, inplace=True)\n",
    "        \n",
    "    return df.drop(['häst'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returnera en modell med parametrar satta\n",
    "def get_model(d=6,l2=2,iterations=3000,use_best=True,verbose=False):\n",
    "    model = CatBoostClassifier(iterations=iterations,use_best_model=use_best, \n",
    "        custom_metric=['Logloss', 'AUC','Recall', 'Precision', 'F1', 'Accuracy'],\n",
    "\n",
    "        eval_metric='Accuracy', \n",
    "        depth=d,l2_leaf_reg=l2,\n",
    "        auto_class_weights='Balanced',verbose=verbose, random_state=2021) \n",
    "    return model                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Features som inte används vid träning\n",
    "def remove_features(df_,remove_mer=[]):\n",
    "    # df = df_.copy()\n",
    "    #remove_mer=['h5_perf','h5_auto','h4_perf','h4_auto', 'h3_perf', 'h2_perf']\n",
    "    df = df_.drop(['avd','startnr','vodds','podds','bins','h1_dat','h2_dat','h3_dat','h4_dat','h5_dat'],axis=1) #\n",
    "    if remove_mer:\n",
    "        df = df.drop(remove_mer,axis=1)\n",
    "    \n",
    "    # df=check_unique(df.copy())\n",
    "    # df=check_corr(df.copy())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## byt ut alla NaN till text för cat_features\n",
    "def replace_NaN(X_train,X_test=None, cat_features=[]):\n",
    "    # print('cat_features',cat_features)\n",
    "    for c in cat_features:\n",
    "        # print(c)\n",
    "        X_train.loc[X_train[c].isna(),c] = 'None'       ### byt ut None-värden till texten 'None\n",
    "        if X_test is not None:  ## om X_test är med\n",
    "            X_test.loc [X_test[c].isna(),c] = 'None'    ### byt ut None-värden till texten 'None\n",
    "\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nya_lopp():\n",
    "    \"\"\"scrape nya lopp och lägg in i all_data.csv\"\"\"\n",
    "    nya_lopp,strukna = vs.v75_scraping(resultat=True,history=True)\n",
    "\n",
    "    df=pd.concat([pd.read_csv('all_data.csv'), nya_lopp])\n",
    "    print('shape med nya lopp',df.shape)\n",
    "    #ta bort dubletter\n",
    "    df.drop_duplicates(['datum','avd','häst'],inplace=True)\n",
    "    df.sort_values(by=['datum','avd'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    print('shape med dubletter bort',df.shape)\n",
    "\n",
    "    df.to_csv('all_data.csv', index=False)\n",
    "\n",
    "    print(\"första datum i df =\",df.datum.head(1).to_list()[0])\n",
    "    print(\"sista  datum i df =\",df.datum.tail(1).to_list()[0])\n",
    "\n",
    "    return df,nya_lopp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beräkna vilka datum att använda ###\n",
    "def get_alla_datum(test_from_proc=0.75, train_from_proc=0, total_omlärning = False):\n",
    "    if total_omlärning:\n",
    "        nya_lopp=None\n",
    "        df = pd.read_csv('all_data.csv')     \n",
    "        datum_att_lära = df.datum.unique()\n",
    "        split_ix = int(len(datum_att_lära)*test_from_proc)\n",
    "    else:\n",
    "        # normalt adderar vi bara 1 eller flera veckor från \"omg_att_spela_link.csv\"\n",
    "        df, nya_lopp = scrape_nya_lopp()  # scrape från 'omg_att_spela_link.csv' och addera till df\n",
    "        omg_df = pd.read_csv('omg_att_spela_link.csv')     \n",
    "        startix=omg_df.Link.str.find('spel')[0]    # index till 'spel' i url\n",
    "        datum_att_lära = omg_df.Link.str.slice(start=startix+5,stop=startix+15).to_list() # en datum \n",
    "        split_ix=0\n",
    "        print(f'datum att lära: {datum_att_lära}')\n",
    "\n",
    "    return df,nya_lopp,datum_att_lära,split_ix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough-funktionen  här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Kör en walkthrough learn här, en datum i taget framåt\n",
    "\n",
    "# Jag har ändrat till att alla steg kör utan test-datam ed fast iterations=100\n",
    "def walkthrough(classic_test=False, verbose=False):\n",
    "    \n",
    "    df, nya_lopp, alla_datum, split_ix = get_alla_datum(0.8)\n",
    "\n",
    "    l2_leaf_regs=2\n",
    "    model=get_model(use_best=False,iterations=100)\n",
    "    df=remove_features(df.copy())\n",
    "    cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "    df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "    print(f'cat_features {cat_features}\\n')\n",
    "\n",
    "    df['plac']=(df.plac==1)*1\n",
    "        \n",
    "    for nr,datum in enumerate(alla_datum[split_ix:]):\n",
    "        print(f'walk-iter {nr+1} av {len(alla_datum[split_ix:])} ',end=': ')\n",
    "\n",
    "        X_train = df.loc[df.datum<datum,:].copy()\n",
    "        y_train = X_train.plac; X_train.drop(['plac'],axis=1,inplace=True)\n",
    "\n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            X_test  = df.loc[df.datum>=datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=True, verbose=verbose,eval_set=test_pool)\n",
    "        else:\n",
    "            X_test  = df.loc[df.datum==datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=False, verbose=verbose)\n",
    "\n",
    "        print('best iteration',model.get_best_iteration(), '\\tbest score', round(model.get_best_score()['learn']['Accuracy'],3) )\n",
    "        ##['validation']['Logloss'],3),'\\t', round(model.get_best_score()['validation']['Accuracy:use_weights=true'],3))\n",
    "        \n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            return model,cat_features\n",
    "    \n",
    "        model.save_model('modeller/model_'+datum)\n",
    "\n",
    "    X_train =df.copy().drop('plac',axis=1)\n",
    "    y_train = df.plac \n",
    "    model.fit(X_train,y=y_train,cat_features=cat_features)\n",
    "    print(f'spara model_senaste',datum)\n",
    "    model.save_model('modeller/model_senaste')\n",
    "\n",
    "    return df,nya_lopp, model,cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Här körs hela walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omgång 1: https://www.atg.se/spel/2022-02-19/V75/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:464: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "klickade på ANPASSA\n",
      "hoppar över voods click (verkar vara förifyllt\n",
      "anpassa klar - break\n",
      "ant resultat 7\n",
      "ant lopp 7\n",
      "EUR: False NOK: False\n",
      "priser ['Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 125.000-62.500-34.000-21.000-13.500-10.500-7.000-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 500.000-250.000-100.000-50.000-25.000-15.000-15.000-15.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.']\n",
      "Ant priser 7\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 1 BERGSÅKER 2140 VOLTSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 2 BERGSÅKER 2140 AUTOSTART ............\n",
      "pris: 125.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 3 BERGSÅKER 1640 AUTOSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 4 BERGSÅKER 2140 VOLTSTART ...............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 5 BERGSÅKER 2140 AUTOSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 6 BERGSÅKER 3140 AUTOSTART ............\n",
      "pris: 500.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 7 BERGSÅKER 2640 AUTOSTART ............\n",
      "\n",
      "det tog 133.156 sekunder\n",
      "utdelning: 10032, 96, 0\n",
      "startar Fixa mer\n",
      "tog bort 8 strukna från 87 till 79\n",
      "rensade totalt bort 8 hästar i städa_och_rensa. Från 87 till 79\n",
      "shape med nya lopp (43812, 79)\n",
      "shape med dubletter bort (43812, 79)\n",
      "första datum i df = 2014-12-28\n",
      "sista  datum i df = 2022-02-19\n",
      "datum att lära: ['2022-02-19']\n",
      "cat_features ['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n",
      "\n",
      "walk-iter 1 av 1 : best iteration None \tbest score 0.751\n",
      "spara model_senaste 2022-02-19\n"
     ]
    }
   ],
   "source": [
    "df, nya_lopp, model, cat_features = walkthrough(classic_test=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kör allt ovanför walkthrough\n",
    "### Se till att \"omg_att_spela_link.csv\" är ifylld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init  - kör först allt t.o.m 'replace_NaN()' ovan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model().load_model('modeller/model_senaste')\n",
    "dforg = pd.read_csv('all_data.csv')     \n",
    "# print(df.columns)\n",
    "df=remove_features(dforg.copy())\n",
    "# df['avd']=dforg.avd\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "y=df.plac\n",
    "y=(y==1)*1\n",
    "df.drop('plac',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "0:\ttest: 0.7505522\tbest: 0.7505522 (0)\ttotal: 66.2ms\tremaining: 2m 12s\n",
      "50:\ttest: 0.8083368\tbest: 0.8103088 (21)\ttotal: 3.39s\tremaining: 2m 9s\n",
      "100:\ttest: 0.8182792\tbest: 0.8196515 (92)\ttotal: 6.76s\tremaining: 2m 7s\n",
      "150:\ttest: 0.8182796\tbest: 0.8199998 (119)\ttotal: 10.5s\tremaining: 2m 8s\n",
      "200:\ttest: 0.8169857\tbest: 0.8199998 (119)\ttotal: 14.5s\tremaining: 2m 9s\n",
      "\n",
      "bestTest = 0.819999776\n",
      "bestIteration = 119\n",
      "\n",
      "Training on fold [1/5]\n",
      "0:\ttest: 0.5000000\tbest: 0.5000000 (0)\ttotal: 40.8ms\tremaining: 1m 21s\n",
      "50:\ttest: 0.8090592\tbest: 0.8109396 (30)\ttotal: 4.23s\tremaining: 2m 41s\n",
      "100:\ttest: 0.8100480\tbest: 0.8123777 (80)\ttotal: 8.56s\tremaining: 2m 40s\n",
      "150:\ttest: 0.8083825\tbest: 0.8123777 (80)\ttotal: 12.9s\tremaining: 2m 37s\n",
      "\n",
      "bestTest = 0.8123777\n",
      "bestIteration = 80\n",
      "\n",
      "Training on fold [2/5]\n",
      "0:\ttest: 0.7612294\tbest: 0.7612294 (0)\ttotal: 82.5ms\tremaining: 2m 44s\n",
      "50:\ttest: 0.8048634\tbest: 0.8048634 (50)\ttotal: 4.31s\tremaining: 2m 44s\n",
      "100:\ttest: 0.8040994\tbest: 0.8057883 (62)\ttotal: 9s\tremaining: 2m 49s\n",
      "150:\ttest: 0.8011660\tbest: 0.8057883 (62)\ttotal: 13.9s\tremaining: 2m 50s\n",
      "\n",
      "bestTest = 0.805788282\n",
      "bestIteration = 62\n",
      "\n",
      "Training on fold [3/5]\n",
      "0:\ttest: 0.5000000\tbest: 0.5000000 (0)\ttotal: 29.1ms\tremaining: 58.1s\n",
      "50:\ttest: 0.8146735\tbest: 0.8150410 (42)\ttotal: 4.68s\tremaining: 2m 58s\n",
      "100:\ttest: 0.8152862\tbest: 0.8172156 (79)\ttotal: 9.91s\tremaining: 3m 6s\n",
      "150:\ttest: 0.8151598\tbest: 0.8172156 (79)\ttotal: 15.4s\tremaining: 3m 8s\n",
      "\n",
      "bestTest = 0.8172155619\n",
      "bestIteration = 79\n",
      "\n",
      "Training on fold [4/5]\n",
      "0:\ttest: 0.6183176\tbest: 0.6183176 (0)\ttotal: 65ms\tremaining: 2m 9s\n",
      "50:\ttest: 0.8134517\tbest: 0.8134517 (50)\ttotal: 5.32s\tremaining: 3m 23s\n",
      "100:\ttest: 0.8135518\tbest: 0.8153980 (71)\ttotal: 11.6s\tremaining: 3m 37s\n",
      "150:\ttest: 0.8125168\tbest: 0.8153980 (71)\ttotal: 17.9s\tremaining: 3m 39s\n",
      "\n",
      "bestTest = 0.8153979581\n",
      "bestIteration = 71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_pool = Pool(df,y,cat_features=cat_features)\n",
    "\n",
    "params = {\n",
    "         'use_best_model': True,\n",
    "         'eval_metric' : 'AUC',\n",
    "         \"loss_function\": \"Logloss\",\n",
    "         'early_stopping_rounds': 100,\n",
    "         'verbose': 50,\n",
    "}\n",
    "\n",
    "cv_score =cv(pool=cv_pool, \n",
    "   params=params, \n",
    "   dtrain=None, \n",
    "   iterations=2000, \n",
    "   num_boost_round=None,\n",
    "   fold_count=5, \n",
    "   nfold=None,\n",
    "   inverted=False,\n",
    "   partition_random_seed=0,\n",
    "   seed=2021, \n",
    "   shuffle=False, \n",
    "   logging_level=None, \n",
    "   stratified=True,\n",
    "   as_pandas=True,\n",
    "   type='TimeSeries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.626020</td>\n",
       "      <td>0.128073</td>\n",
       "      <td>0.660689</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.660392</td>\n",
       "      <td>0.004279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.721988</td>\n",
       "      <td>0.037638</td>\n",
       "      <td>0.630681</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.630407</td>\n",
       "      <td>0.003279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.744862</td>\n",
       "      <td>0.045024</td>\n",
       "      <td>0.601020</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.600562</td>\n",
       "      <td>0.003360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.770865</td>\n",
       "      <td>0.032915</td>\n",
       "      <td>0.573885</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.573295</td>\n",
       "      <td>0.005356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.779489</td>\n",
       "      <td>0.021616</td>\n",
       "      <td>0.549891</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.549204</td>\n",
       "      <td>0.004637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>215</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.239288</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.207077</td>\n",
       "      <td>0.008463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>0.810859</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.239289</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.207071</td>\n",
       "      <td>0.008474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>0.810840</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.239302</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.207053</td>\n",
       "      <td>0.008514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>0.810839</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>0.239303</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.207034</td>\n",
       "      <td>0.008555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>0.810839</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>0.239306</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.207003</td>\n",
       "      <td>0.008621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "0             0       0.626020      0.128073           0.660689   \n",
       "1             1       0.721988      0.037638           0.630681   \n",
       "2             2       0.744862      0.045024           0.601020   \n",
       "3             3       0.770865      0.032915           0.573885   \n",
       "4             4       0.779489      0.021616           0.549891   \n",
       "..          ...            ...           ...                ...   \n",
       "215         215       0.810863      0.006097           0.239288   \n",
       "216         216       0.810859      0.006092           0.239289   \n",
       "217         217       0.810840      0.006070           0.239302   \n",
       "218         218       0.810839      0.006069           0.239303   \n",
       "219         219       0.810839      0.006069           0.239306   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "0            0.003929            0.660392           0.004279  \n",
       "1            0.002849            0.630407           0.003279  \n",
       "2            0.002915            0.600562           0.003360  \n",
       "3            0.004863            0.573295           0.005356  \n",
       "4            0.004538            0.549204           0.004637  \n",
       "..                ...                 ...                ...  \n",
       "215          0.003563            0.207077           0.008463  \n",
       "216          0.003562            0.207071           0.008474  \n",
       "217          0.003552            0.207053           0.008514  \n",
       "218          0.003551            0.207034           0.008555  \n",
       "219          0.003549            0.207003           0.008621  \n",
       "\n",
       "[220 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-12-28 2022-02-19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0.811143</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.239095</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.20924</td>\n",
       "      <td>0.004747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "170         170       0.811143      0.006412           0.239095   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "170          0.003713             0.20924           0.004747  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>0.813131</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.243148</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.224869</td>\n",
       "      <td>0.001238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "80          80       0.813131      0.005499           0.243148   \n",
       "\n",
       "    test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "80          0.003928            0.224869           0.001238  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "print(df.datum.min(),df.datum.max())\n",
    "display(cv_score[cv_score['test-Logloss-mean'].min() == cv_score['test-Logloss-mean']])\n",
    "display(cv_score[cv_score['test-AUC-mean'].max() == cv_score['test-AUC-mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 2020-01-04 2022-02-19\n",
      "train: 2014-12-28 2020-01-04\n",
      "0:\tlearn: 0.6318273\ttest: 0.5839620\tbest: 0.5839620 (0)\ttotal: 122ms\tremaining: 6m 4s\n",
      "100:\tlearn: 0.7132916\ttest: 0.6513096\tbest: 0.6526427 (87)\ttotal: 12.3s\tremaining: 5m 54s\n",
      "200:\tlearn: 0.7367183\ttest: 0.6544020\tbest: 0.6558630 (138)\ttotal: 24.1s\tremaining: 5m 35s\n",
      "300:\tlearn: 0.7522288\ttest: 0.6541567\tbest: 0.6601113 (266)\ttotal: 35.3s\tremaining: 5m 16s\n",
      "400:\tlearn: 0.7718556\ttest: 0.6554911\tbest: 0.6601113 (266)\ttotal: 47.2s\tremaining: 5m 5s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6601113443\n",
      "bestIteration = 266\n",
      "\n",
      "Shrink model to first 267 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x26ba00133d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df[['datum','avd','streck','häst','kusk']] = dforg[['datum','avd','streck','häst','kusk']]\n",
    "\n",
    "# df.drop('datum',axis=1,inplace=True)\n",
    "df.drop('avd',axis=1,inplace=True)\n",
    "df.drop(['streck'],axis=1,inplace=True)\n",
    "# df.drop(['häst','kusk'],axis=1,inplace=True)\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "X_train,X_test,y_train,y_test = train_test_split(df,y,shuffle=False,)\n",
    "print(\"test:\",X_test.datum.min(),X_test.datum.max())\n",
    "print(\"train:\",X_train.datum.min(),X_train.datum.max())\n",
    "cb=get_model(use_best=True)\n",
    "cb.fit(X_train,y_train,eval_set= (X_test,y_test),early_stopping_rounds=200, cat_features=cat_features,verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -0.671432654739636\n",
      "cb med ekipage 4.049040511727079 0.7150721678676015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "predict_prob = cb.predict_proba(X_test)\n",
    "\n",
    "_,prob_score = proba_order_score(X_test ,y_test, predict_prob)\n",
    "\n",
    "print('cb med ekipage',prob_score, cb.best_score_['validation']['AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAML (med och utan ekipage och streck)\n",
    "För att köra enbart FLAML initiera först med allt innan plus walkthrough  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_enc(df_, features):\n",
    "    df = df_.copy()\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=100000)\n",
    "    enc.fit(df[[features]])\n",
    "    df[features] = enc.transform(df[[features]])\n",
    "    return df,enc\n",
    "\n",
    "# df,enc = ordinal_enc(dforg,'häst')\n",
    "# import pickle\n",
    "# pickle.dump(enc, open('modeller/encoder.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_,train_from_proc=0,test_proc=0.25):\n",
    "    # train_from_proc = where to start both train and test\n",
    "    # test_proc = how much of the data is test\n",
    "    df=df_.copy()\n",
    "    alla_datum = df.datum.unique()\n",
    "    train_from_datum = alla_datum[ int(len(alla_datum)*train_from_proc)]\n",
    "    X_test=None\n",
    "    y_test=None\n",
    "    \n",
    "    if test_proc:\n",
    "        selected_data = alla_datum[ alla_datum >= train_from_datum ]\n",
    "        test_from_datum = selected_data[ int(len(selected_data)*(1-test_proc)) ]\n",
    "        X_test  = df[df.datum >= test_from_datum]\n",
    "        y_test  = (X_test.plac==1)*1\n",
    "        X_test  = X_test.drop('plac',axis=1)\n",
    "        print(f'test from {X_test.datum.min()} to {X_test.datum.max()} (incl)')\n",
    "    \n",
    "        X_train = df[(df.datum >= train_from_datum) & (df.datum < test_from_datum) ]\n",
    "    else:\n",
    "        print('No test')\n",
    "        X_train = df[(df.datum >= train_from_datum)]\n",
    "    \n",
    "    y_train = (X_train.plac==1)*1\n",
    "    \n",
    "    print(f'train from {X_train.datum.min()} to {X_train.datum.max()} (incl)')\n",
    "    \n",
    "    return X_train.drop('plac', axis=1), X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test from 2020-01-04 to 2022-02-19 (incl)\n",
      "train from 2014-12-28 to 2019-12-31 (incl)\n",
      "['datum', 'bana', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32779, 68), (11033, 68))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "\n",
    "### enc is the encoder that we will save for use during v75_spel.py ###\n",
    "### It will be used and finally saved later in this code ###\n",
    "df,env = ordinal_enc(dforg,'häst')\n",
    "\n",
    "X_train, X_test, y_train, y_test= split_data(df,train_from_proc=0,test_proc=0.25)\n",
    "X_train = remove_features(X_train)\n",
    "X_test  = remove_features( X_test)\n",
    "\n",
    "# X_train = X_train.drop('streck', axis=1)\n",
    "# X_test  = X_test.drop ('streck', axis=1)\n",
    "# X_train.drop('datum', axis=1, inplace=True)\n",
    "# X_test.drop( 'datum', axis=1, inplace=True)\n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "# X_train, X_test = replace_NaN(X_train.copy(),X_test=X_test.copy(), cat_features=cat_features) \n",
    "# X_train.fillna(-1)\n",
    "# X_test.fillna(-1)\n",
    "print(cat_features)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML \n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "starting_points={'lgbm': {'n_estimators': 38,\n",
    "  'num_leaves': 4,\n",
    "  'min_child_samples': 2,\n",
    "  'learning_rate': 0.19098448074739216,\n",
    "  'log_max_bin': 7,\n",
    "  'colsample_bytree': 0.8827412174089042,\n",
    "  'reg_alpha': 0.004577823970660193,\n",
    "  'reg_lambda': 0.03815584533462228},\n",
    " 'rf': {'n_estimators': 33,\n",
    "  'max_features': 0.3251674877768946,\n",
    "  'max_leaves': 89,\n",
    "  'criterion': 'entropy'},\n",
    " 'catboost': {'early_stopping_rounds': 50,\n",
    "  'learning_rate': 0.007511731949060241},\n",
    " 'xgboost': {'n_estimators': 575,\n",
    "  'max_leaves': 46,\n",
    "  'min_child_weight': 1.032235057697502,\n",
    "  'learning_rate': 0.013318439439138472,\n",
    "  'subsample': 0.7908401179782586,\n",
    "  'colsample_bylevel': 0.6924750037579576,\n",
    "  'colsample_bytree': 0.7174828796230647,\n",
    "  'reg_alpha': 0.15461500385937774,\n",
    "  'reg_lambda': 0.6619886587472544},\n",
    " 'extra_tree': {'n_estimators': 47,\n",
    "  'max_features': 0.7934349565988307,\n",
    "  'max_leaves': 213,\n",
    "  'criterion': 'entropy'}}\n",
    "flml_raw_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc', 'starting_points': starting_points,'verbose':False,\n",
    "        'time_budget':1200, 'max_iter':50000000,'n_jobs':5, 'X_val': X_test, 'y_val':y_test,'early_stop':True, 'ensemble':True}\n",
    "\n",
    "automl_raw = AutoML()\n",
    "automl_raw.fit(X_train,y_train, **flml_raw_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -0.6997919670746625\n",
      "timeserie, datum,häst, kusk 4.0814814814814815 0.8211011878537651\n"
     ]
    }
   ],
   "source": [
    "flm_raw_train_pred= automl_raw.predict_proba(X_train)\n",
    "flm_raw_test_pred = automl_raw.predict_proba(X_test)\n",
    "\n",
    "X_test_raw = X_test.copy()\n",
    "X_test_raw[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "_,prob_score = proba_order_score(X_test_raw,y_test, flm_raw_test_pred)\n",
    "\n",
    "print('timeserie, datum,häst, kusk', prob_score, 1-automl_raw.best_loss)\n",
    "# X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final FLML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_config(best_config):\n",
    "    # save best_config\n",
    "    import pickle\n",
    "    with open('best_config_per_estimator.sav', \"wb\") as f:\n",
    "        pickle.dump(best_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flaml(X_train, y_train, df_perf, save=True):\n",
    "    # read best_config\n",
    "    with open('best_config_per_estimator.sav', \"rb\") as f:\n",
    "        best_config = pickle.load(f)\n",
    "        \n",
    "    from_date = X_train.datum.min()\n",
    "    to_date = X_train.datum.max()\n",
    "    automl = [None,None]\n",
    "    for with_streck in [True, False]:\n",
    "        if with_streck: \n",
    "            X_tr = X_train.copy()    \n",
    "            filename = 'modeller\\\\FLAML_model.sav'\n",
    "        else:\n",
    "            X_tr = X_train.drop('streck', axis=1).copy()\n",
    "            filename = 'modeller\\\\FLAML2_model.sav'\n",
    "            \n",
    "        print('with_streck = ',with_streck)   \n",
    "    \n",
    "        automl[with_streck] = AutoML()\n",
    "        \n",
    "        with open('best_config_per_estimator.sav', \"rb\") as f:\n",
    "            best_config = pickle.load(f)\n",
    "            \n",
    "        flml_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc','starting_points': best_config[with_streck], 'verbose':False,\n",
    "        'time_budget':2600,'n_jobs':5, 'early_stop':True, 'ensemble':True}\n",
    "\n",
    "        automl[with_streck].fit(X_tr, y_train, **flml_parms)\n",
    "        perf = 1-automl[with_streck].best_loss\n",
    "        print(perf, 'for streck in columns', with_streck)\n",
    "        df_perf.loc[len(df_perf)] = [from_date, to_date, with_streck, perf]\n",
    "        \n",
    "        # save_model\n",
    "        if save:\n",
    "            print('save model in',filename)   \n",
    "            with open(filename,\"wb\") as f:\n",
    "                pickle.dump(automl[with_streck], f, pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "            print('save encoder enc in encoder.sav')\n",
    "            with open('encoder.sav',\"wb\") as f:\n",
    "                pickle.dump(enc, f, pickle.HIGHEST_PROTOCOL)\n",
    "             \n",
    "    save_best_config(best_config)  \n",
    "\n",
    "    # remove duplicates\n",
    "    df_perf.drop_duplicates(subset=['learn_from','learn_to','streck'], keep='last', inplace=True)\n",
    "\n",
    "    print('\\n','\\n')\n",
    "    display(df_perf.tail(30).sort_values(by=['perf'], ascending=False))\n",
    "    print('Med streck max:',df_perf.loc[df_perf.streck == True].perf.max())\n",
    "    print('Ej  streck max:',df_perf.loc[df_perf.streck == False].perf.max())\n",
    "\n",
    "    df_perf.to_csv('perf_flaml.csv', index=False)\n",
    "    return automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test\n",
      "train from 2014-12-28 to 2022-02-19 (incl)\n",
      "with_streck =  True\n",
      "0.8178964758710616 for streck in columns True\n",
      "save model in modeller\\FLAML_model.sav\n",
      "save encoder enc in encoder.sav\n",
      "with_streck =  False\n",
      "0.7257099131529021 for streck in columns False\n",
      "save model in modeller\\FLAML2_model.sav\n",
      "save encoder enc in encoder.sav\n",
      "\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learn_from</th>\n",
       "      <th>learn_to</th>\n",
       "      <th>streck</th>\n",
       "      <th>perf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>0.818728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>True</td>\n",
       "      <td>0.818714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-19</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.728704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>False</td>\n",
       "      <td>0.728591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.726912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>False</td>\n",
       "      <td>0.726116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>False</td>\n",
       "      <td>0.725764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-19</td>\n",
       "      <td>False</td>\n",
       "      <td>0.725710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>0.721107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.721041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learn_from    learn_to  streck      perf\n",
       "2   2017-02-26  2022-01-01    True  0.818728\n",
       "0   2017-02-26  2021-12-31    True  0.818714\n",
       "18  2014-12-28  2022-02-19    True  0.817896\n",
       "16  2014-12-28  2022-02-12    True  0.817811\n",
       "14  2014-12-28  2022-02-05    True  0.817489\n",
       "12  2014-12-28  2022-01-29    True  0.817124\n",
       "10  2014-12-28  2022-01-22    True  0.816984\n",
       "4   2014-12-28  2022-01-01    True  0.816678\n",
       "6   2014-12-28  2022-01-08    True  0.816579\n",
       "8   2014-12-28  2022-01-15    True  0.816330\n",
       "5   2014-12-28  2022-01-01   False  0.728704\n",
       "7   2014-12-28  2022-01-08   False  0.728591\n",
       "11  2014-12-28  2022-01-22   False  0.727775\n",
       "9   2014-12-28  2022-01-15   False  0.727692\n",
       "15  2014-12-28  2022-02-05   False  0.726912\n",
       "17  2014-12-28  2022-02-12   False  0.726116\n",
       "13  2014-12-28  2022-01-29   False  0.725764\n",
       "19  2014-12-28  2022-02-19   False  0.725710\n",
       "1   2017-02-26  2021-12-31   False  0.721107\n",
       "3   2017-02-26  2022-01-01   False  0.721041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Med streck max: 0.8187283877462516\n",
      "Ej  streck max: 0.7287040948165976\n"
     ]
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "df,enc = ordinal_enc(dforg, 'häst')\n",
    "X_train, _, y_train, _ = split_data(df,train_from_proc=0,test_proc=None)\n",
    "X_train = remove_features(X_train)\n",
    "\n",
    "df_perf = pd.read_csv('perf_flaml.csv')\n",
    "automl = run_flaml(X_train, y_train, df_perf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_garbage():\n",
    "    import subprocess\n",
    "    subprocess.call([r'C:/Users/peter/Documents/MyProjects/PyProj/Trav/spel/remove_dirt.bat'])\n",
    "remove_garbage()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tid None\n"
     ]
    }
   ],
   "source": [
    "# Kolla autmoml-grejer från dokumntationen\n",
    "#### How much time is needed to find the best model​\n",
    "#### If you want to get a sense of how much time is needed to find the best model, you can use max_iter = 2 to perform two trials first.\n",
    "#### You will see the time to finish the first and cheapest trial in seconds. \n",
    "#### The estimated necessary time budget in, and the estimated sufficient time budget inseconds. \n",
    "def set_time_budget():\n",
    "  import time\n",
    "  start_time = time.time()\n",
    "\n",
    "  automl = AutoML()\n",
    "\n",
    "  with open('best_config_per_estimator.sav', \"rb\") as f:\n",
    "      best_config = pickle.load(f)\n",
    "      \n",
    "  flml_parms = {'task': 'classification', 'split_type': 'time', 'metric': 'roc_auc', 'starting_points': best_config[0], \n",
    "                'time_budget':2600, 'n_jobs': 5, 'early_stop': True, 'ensemble': True}\n",
    "              # 'time_budget': 1700, 'max_iter': 400000000, 'n_jobs': 5, 'early_stop': True, 'ensemble': True,'verbose': True,}\n",
    "\n",
    "  automl.fit(X_train, y_train, log_file_name='flaml_log.json', **flml_parms)\n",
    "\n",
    "  return automl, time.time() - start_time\n",
    "\n",
    "tid=None\n",
    "# automl, tid = set_time_budget()  # tid in sekunder\n",
    "print('tid', tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_estimator: extra_tree\n",
      "best eest. config: {'n_estimators': 70, 'max_features': 0.9969126323328488, 'max_leaves': 7, 'criterion': 'gini'}\n",
      "\n",
      "best per est.: {'lgbm': {'n_estimators': 122, 'num_leaves': 4, 'min_child_samples': 4, 'learning_rate': 0.02198872521192745, 'log_max_bin': 10, 'colsample_bytree': 0.9703483726732456, 'reg_alpha': 0.07228776149813766, 'reg_lambda': 0.06398821059524888}, 'rf': {'n_estimators': 71, 'max_features': 0.4656731896872569, 'max_leaves': 24, 'criterion': 'entropy'}, 'catboost': {'early_stopping_rounds': 50, 'learning_rate': 0.007511731949060241, 'n_estimators': 980}, 'xgboost': {'n_estimators': 116, 'max_leaves': 4, 'min_child_weight': 0.33159711211830895, 'learning_rate': 0.053000266497342456, 'subsample': 0.6327895538868441, 'colsample_bylevel': 0.8666018637477523, 'colsample_bytree': 0.9082549950738142, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.002736337018786481}, 'extra_tree': {'n_estimators': 70, 'max_features': 0.9969126323328488, 'max_leaves': 7, 'criterion': 'gini'}, 'xgb_limitdepth': {'n_estimators': 20, 'max_depth': 3, 'min_child_weight': 96.37568108324592, 'learning_rate': 0.23652575162470577, 'subsample': 1.0, 'colsample_bylevel': 0.9142889726755011, 'colsample_bytree': 0.8783568545575503, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5841977937376286}, 'lrl1': {'C': 1.0}}\n",
      "\n",
      "best_config train time: 4.840592861175537\n",
      "best iteration: 33\n",
      "best loss: 0.18189303327885267\n",
      "time to find best mod. 129.46568965911865\n",
      "\n",
      "history: {0: ('lgbm', {'n_estimators': 122, 'num_leaves': 4, 'min_child_samples': 4, 'learning_rate': 0.02198872521192745, 'log_max_bin': 10, 'colsample_bytree': 0.9703483726732456, 'reg_alpha': 0.07228776149813766, 'reg_lambda': 0.06398821059524888}, 2.1575000286102295), 3: ('xgboost', {'n_estimators': 116, 'max_leaves': 4, 'min_child_weight': 0.33159711211830895, 'learning_rate': 0.053000266497342456, 'subsample': 0.6327895538868441, 'colsample_bylevel': 0.8666018637477523, 'colsample_bytree': 0.9082549950738142, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.002736337018786481}, 7.581773281097412), 11: ('extra_tree', {'n_estimators': 33, 'max_features': 0.9999999999999996, 'max_leaves': 12, 'criterion': 'entropy'}, 23.470669984817505), 25: ('extra_tree', {'n_estimators': 70, 'max_features': 0.9969126323328492, 'max_leaves': 7, 'criterion': 'entropy'}, 90.01363444328308), 29: ('extra_tree', {'n_estimators': 198, 'max_features': 0.8461998220162169, 'max_leaves': 13, 'criterion': 'gini'}, 119.21183276176453), 33: ('extra_tree', {'n_estimators': 70, 'max_features': 0.9969126323328488, 'max_leaves': 7, 'criterion': 'gini'}, 129.46568965911865)}\n"
     ]
    }
   ],
   "source": [
    "print('best_estimator:', automl.best_estimator)\n",
    "print('best eest. config:',automl.best_config)\n",
    "print('\\nbest per est.:',automl.best_config_per_estimator)\n",
    "print('\\nbest_config train time:',automl.best_config_train_time)\n",
    "print('best iteration:',automl.best_iteration)\n",
    "print('best loss:',automl.best_loss)\n",
    "print('time to find best mod.',automl.time_to_find_best_model)\n",
    "print('\\nhistory:',automl.config_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = get_output_from_log(\n",
    "    filename=\"flaml_log.json\", time_budget=120)\n",
    "\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Wall Clock Time (s)\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where=\"post\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hur skall vi köra den ny modellen \n",
    "1. preprocessa datat (nya kolumner)\n",
    "    - proba och eller Kelly, ant hästar i loppet, favoriter, bara solklara favoriter\n",
    "2. bestäm cat_features\n",
    "3. Kör catboost eller flaml?\n",
    "   - om flaml träna upp den\n",
    "   - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_garbage()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
