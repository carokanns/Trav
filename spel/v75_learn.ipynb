{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn v75 med walkthrough-metoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from catboost import CatBoostClassifier,Pool,cv,utils\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel')\n",
    "import V75_scraping as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def proba_order_score(df_, y, proba):  # df skall innehålla datum,avd,vodds\n",
    "    kassa=1000\n",
    "    df = df_.copy()\n",
    "    df['proba'] = proba[:,1]\n",
    "    df['f'] = (df.proba*df.vodds - 1) / (df.vodds-1)  # kelly formel\n",
    "    df['spela'] = df.f >0\n",
    "    df['insats'] = df.spela * df.f * kassa\n",
    "\n",
    "    df.sort_values(['datum','avd','proba'],ascending=[True,True,False],inplace=True)\n",
    "    proba_order=df.groupby(['datum','avd']).proba.cumcount()\n",
    "\n",
    "    df['prob_order']=proba_order+1\n",
    "    df['y'] = y\n",
    "\n",
    "    print('log(proba)',np.log(df.loc[df.y==1].proba).mean())\n",
    "    return df, df.loc[df.y==1].prob_order.mean()   # mean prob_order för vinnarhäst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ekipage(df_):\n",
    "    df=df_.copy()\n",
    "    prefs = ['','h1_','h2_','h3_','h4_','h5_',]\n",
    "    for pr in prefs:\n",
    "        df[pr+'ekipage'] = df[pr+'kusk'].str.cat(df['häst'], sep =\", \")\n",
    "        df.drop([pr+'kusk'],axis=1, inplace=True)\n",
    "        \n",
    "    return df.drop(['häst'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returnera en modell med parametrar satta\n",
    "def get_model(d=6,l2=2,iterations=3000,use_best=True,verbose=False):\n",
    "    model = CatBoostClassifier(iterations=iterations,use_best_model=use_best, \n",
    "        custom_metric=['Logloss', 'AUC','Recall', 'Precision', 'F1', 'Accuracy'],\n",
    "\n",
    "        eval_metric='Accuracy', \n",
    "        depth=d,l2_leaf_reg=l2,\n",
    "        auto_class_weights='Balanced',verbose=verbose, random_state=2021) \n",
    "    return model                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Features som inte används vid träning\n",
    "def remove_features(df_,remove_mer=[]):\n",
    "    # df = df_.copy()\n",
    "    #remove_mer=['h5_perf','h5_auto','h4_perf','h4_auto', 'h3_perf', 'h2_perf']\n",
    "    df = df_.drop(['avd','startnr','vodds','podds','bins','h1_dat','h2_dat','h3_dat','h4_dat','h5_dat'],axis=1) #\n",
    "    if remove_mer:\n",
    "        df = df.drop(remove_mer,axis=1)\n",
    "    \n",
    "    # df=check_unique(df.copy())\n",
    "    # df=check_corr(df.copy())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## byt ut alla NaN till text för cat_features\n",
    "def replace_NaN(X_train,X_test=None, cat_features=[]):\n",
    "    # print('cat_features',cat_features)\n",
    "    for c in cat_features:\n",
    "        # print(c)\n",
    "        X_train.loc[X_train[c].isna(),c] = 'None'       ### byt ut None-värden till texten 'None\n",
    "        if X_test is not None:  ## om X_test är med\n",
    "            X_test.loc [X_test[c].isna(),c] = 'None'    ### byt ut None-värden till texten 'None\n",
    "\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nya_lopp():\n",
    "    \"\"\"scrape nya lopp och lägg in i all_data.csv\"\"\"\n",
    "    nya_lopp,strukna = vs.v75_scraping(resultat=True,history=True)\n",
    "\n",
    "    df=pd.concat([pd.read_csv('all_data.csv'), nya_lopp])\n",
    "    print('shape med nya lopp',df.shape)\n",
    "    #ta bort dubletter\n",
    "    df.drop_duplicates(['datum','avd','häst'],inplace=True)\n",
    "    df.sort_values(by=['datum','avd'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    print('shape med dubletter bort',df.shape)\n",
    "\n",
    "    df.to_csv('all_data.csv', index=False)\n",
    "\n",
    "    print(\"första datum i df =\",df.datum.head(1).to_list()[0])\n",
    "    print(\"sista  datum i df =\",df.datum.tail(1).to_list()[0])\n",
    "\n",
    "    return df,nya_lopp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### beräkna vilka datum att använda ###\n",
    "def get_alla_datum(test_from_proc=0.75, train_from_proc=0, total_omlärning = False):\n",
    "    if total_omlärning:\n",
    "        nya_lopp=None\n",
    "        df = pd.read_csv('all_data.csv')     \n",
    "        datum_att_lära = df.datum.unique()\n",
    "        split_ix = int(len(datum_att_lära)*test_from_proc)\n",
    "    else:\n",
    "        # normalt adderar vi bara 1 eller flera veckor från \"omg_att_spela_link.csv\"\n",
    "        df, nya_lopp = scrape_nya_lopp()  # scrape från 'omg_att_spela_link.csv' och addera till df\n",
    "        omg_df = pd.read_csv('omg_att_spela_link.csv')     \n",
    "        startix=omg_df.Link.str.find('spel')[0]    # index till 'spel' i url\n",
    "        datum_att_lära = omg_df.Link.str.slice(start=startix+5,stop=startix+15).to_list() # en datum \n",
    "        split_ix=0\n",
    "        print(f'datum att lära: {datum_att_lära}')\n",
    "\n",
    "    return df,nya_lopp,datum_att_lära,split_ix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough-funktionen  här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Kör en walkthrough learn här, en datum i taget framåt\n",
    "\n",
    "# Jag har ändrat till att alla steg kör utan test-datam ed fast iterations=100\n",
    "def walkthrough(classic_test=False, verbose=False):\n",
    "    \n",
    "    df, nya_lopp, alla_datum, split_ix = get_alla_datum(0.8)\n",
    "\n",
    "    l2_leaf_regs=2\n",
    "    model=get_model(use_best=False,iterations=100)\n",
    "    df=remove_features(df.copy())\n",
    "    cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "    df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "    print(f'cat_features {cat_features}\\n')\n",
    "\n",
    "    df['plac']=(df.plac==1)*1\n",
    "        \n",
    "    for nr,datum in enumerate(alla_datum[split_ix:]):\n",
    "        print(f'walk-iter {nr+1} av {len(alla_datum[split_ix:])} ',end=': ')\n",
    "\n",
    "        X_train = df.loc[df.datum<datum,:].copy()\n",
    "        y_train = X_train.plac; X_train.drop(['plac'],axis=1,inplace=True)\n",
    "\n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            X_test  = df.loc[df.datum>=datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=True, verbose=verbose,eval_set=test_pool)\n",
    "        else:\n",
    "            X_test  = df.loc[df.datum==datum,:].copy()\n",
    "            y_test  = X_test.plac;  X_test.drop(['plac'],axis=1,inplace=True)\n",
    "            train_pool = Pool(X_train,y_train,cat_features=cat_features)\n",
    "            test_pool = Pool(X_test,y_test,cat_features=cat_features)\n",
    "            model.fit(train_pool,use_best_model=False, verbose=verbose)\n",
    "\n",
    "        print('best iteration',model.get_best_iteration(), '\\tbest score', round(model.get_best_score()['learn']['Accuracy'],3) )\n",
    "        ##['validation']['Logloss'],3),'\\t', round(model.get_best_score()['validation']['Accuracy:use_weights=true'],3))\n",
    "        \n",
    "        if classic_test:    ### klassisk train/test utan walkthrough\n",
    "            return model,cat_features\n",
    "    \n",
    "        model.save_model('modeller/model_'+datum)\n",
    "\n",
    "    X_train =df.copy().drop('plac',axis=1)\n",
    "    y_train = df.plac \n",
    "    model.fit(X_train,y=y_train,cat_features=cat_features)\n",
    "    print(f'spara model_senaste',datum)\n",
    "    model.save_model('modeller/model_senaste')\n",
    "\n",
    "    return df,nya_lopp, model,cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Här körs hela walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omgång 1: https://www.atg.se/spel/2022-02-12/V75/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:464: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "klickade på ANPASSA\n",
      "anpassa klar - break\n",
      "ant resultat 7\n",
      "ant lopp 7\n",
      "EUR: False NOK: False\n",
      "priser ['Pris: 150.000-75.000-40.000-25.000-15.000-11.500-7.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 150.000-75.000-40.000-25.000-15.000-11.500-7.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 150.000-75.000-40.000-25.000-15.000-11.500-7.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 150.000-75.000-40.000-25.000-15.000-11.500-7.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 150.000-75.000-40.000-25.000-15.000-11.500-7.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 150.000-75.000-40.000-25.000-15.000-11.500-7.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 150.000-75.000-40.000-25.000-15.000-11.500-7.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.']\n",
      "Ant priser 7\n",
      "pris: 150.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 1 ÅBY 2140 VOLTSTART ...............\n",
      "pris: 150.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 2 ÅBY 3140 VOLTSTART ...............\n",
      "pris: 150.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 3 ÅBY 2140 VOLTSTART ...............\n",
      "pris: 150.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 4 ÅBY 2140 VOLTSTART ...............\n",
      "pris: 150.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 5 ÅBY 2640 AUTOSTART ...............\n",
      "pris: 150.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 6 ÅBY 2140 AUTOSTART ...............\n",
      "pris: 150.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 7 ÅBY 2140 VOLTSTART ...............\n",
      "\n",
      "det tog 163.933 sekunder\n",
      "utdelning: 9866, 129, 17\n",
      "startar Fixa mer\n",
      "tog bort 6 strukna från 105 till 99\n",
      "rensade totalt bort 6 hästar i städa_och_rensa. Från 105 till 99\n",
      "shape med nya lopp (43832, 79)\n",
      "shape med dubletter bort (43733, 79)\n",
      "första datum i df = 2014-12-28\n",
      "sista  datum i df = 2022-02-12\n",
      "datum att lära: ['2022-02-12']\n",
      "cat_features ['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n",
      "\n",
      "walk-iter 1 av 1 : best iteration None \tbest score 0.751\n",
      "spara model_senaste 2022-02-12\n"
     ]
    }
   ],
   "source": [
    "df, nya_lopp, model, cat_features = walkthrough(classic_test=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kör allt ovanför walkthrough\n",
    "### Se till att \"omg_att_spela_link.csv\" är ifylld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init  - kör först allt t.o.m 'replace_NaN()' ovan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model().load_model('modeller/model_senaste')\n",
    "dforg = pd.read_csv('all_data.csv')     \n",
    "# print(df.columns)\n",
    "df=remove_features(dforg.copy())\n",
    "# df['avd']=dforg.avd\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "df,_ = replace_NaN(df.copy(), cat_features=cat_features)    \n",
    "y=df.plac\n",
    "y=(y==1)*1\n",
    "df.drop('plac',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "0:\ttest: 0.7577436\tbest: 0.7577436 (0)\ttotal: 60.9ms\tremaining: 2m 1s\n",
      "50:\ttest: 0.8104227\tbest: 0.8104940 (48)\ttotal: 3.42s\tremaining: 2m 10s\n",
      "100:\ttest: 0.8169849\tbest: 0.8174740 (92)\ttotal: 6.1s\tremaining: 1m 54s\n",
      "150:\ttest: 0.8151948\tbest: 0.8174740 (92)\ttotal: 8.93s\tremaining: 1m 49s\n",
      "\n",
      "bestTest = 0.8174739923\n",
      "bestIteration = 92\n",
      "\n",
      "Training on fold [1/5]\n",
      "0:\ttest: 0.7232253\tbest: 0.7232253 (0)\ttotal: 43.2ms\tremaining: 1m 26s\n",
      "50:\ttest: 0.8096841\tbest: 0.8096841 (50)\ttotal: 3.87s\tremaining: 2m 27s\n",
      "100:\ttest: 0.8138909\tbest: 0.8153313 (84)\ttotal: 7.52s\tremaining: 2m 21s\n",
      "150:\ttest: 0.8111057\tbest: 0.8153313 (84)\ttotal: 11s\tremaining: 2m 15s\n",
      "\n",
      "bestTest = 0.8153312554\n",
      "bestIteration = 84\n",
      "\n",
      "Training on fold [2/5]\n",
      "0:\ttest: 0.7242193\tbest: 0.7242193 (0)\ttotal: 57.8ms\tremaining: 1m 55s\n",
      "50:\ttest: 0.8016739\tbest: 0.8016739 (50)\ttotal: 4.04s\tremaining: 2m 34s\n",
      "100:\ttest: 0.8022281\tbest: 0.8044334 (72)\ttotal: 8.01s\tremaining: 2m 30s\n",
      "150:\ttest: 0.8006545\tbest: 0.8044334 (72)\ttotal: 12.1s\tremaining: 2m 27s\n",
      "\n",
      "bestTest = 0.8044333682\n",
      "bestIteration = 72\n",
      "\n",
      "Training on fold [3/5]\n",
      "0:\ttest: 0.7357787\tbest: 0.7357787 (0)\ttotal: 68.2ms\tremaining: 2m 16s\n",
      "50:\ttest: 0.8168770\tbest: 0.8168770 (50)\ttotal: 4.39s\tremaining: 2m 47s\n",
      "100:\ttest: 0.8178252\tbest: 0.8185449 (89)\ttotal: 9.01s\tremaining: 2m 49s\n",
      "150:\ttest: 0.8169348\tbest: 0.8185449 (89)\ttotal: 13.6s\tremaining: 2m 47s\n",
      "\n",
      "bestTest = 0.8185449281\n",
      "bestIteration = 89\n",
      "\n",
      "Training on fold [4/5]\n",
      "0:\ttest: 0.6968221\tbest: 0.6968221 (0)\ttotal: 92.6ms\tremaining: 3m 5s\n",
      "50:\ttest: 0.8117711\tbest: 0.8117711 (50)\ttotal: 5.04s\tremaining: 3m 12s\n",
      "100:\ttest: 0.8121075\tbest: 0.8131099 (80)\ttotal: 10.5s\tremaining: 3m 16s\n",
      "150:\ttest: 0.8130718\tbest: 0.8138429 (129)\ttotal: 15.7s\tremaining: 3m 11s\n",
      "200:\ttest: 0.8130468\tbest: 0.8138429 (129)\ttotal: 20.8s\tremaining: 3m 5s\n",
      "\n",
      "bestTest = 0.8138429471\n",
      "bestIteration = 129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_pool = Pool(df,y,cat_features=cat_features)\n",
    "\n",
    "params = {\n",
    "         'use_best_model': True,\n",
    "         'eval_metric' : 'AUC',\n",
    "         \"loss_function\": \"Logloss\",\n",
    "         'early_stopping_rounds': 100,\n",
    "         'verbose': 50,\n",
    "}\n",
    "\n",
    "cv_score =cv(pool=cv_pool, \n",
    "   params=params, \n",
    "   dtrain=None, \n",
    "   iterations=2000, \n",
    "   num_boost_round=None,\n",
    "   fold_count=5, \n",
    "   nfold=None,\n",
    "   inverted=False,\n",
    "   partition_random_seed=0,\n",
    "   seed=2021, \n",
    "   shuffle=False, \n",
    "   logging_level=None, \n",
    "   stratified=True,\n",
    "   as_pandas=True,\n",
    "   type='TimeSeries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.727558</td>\n",
       "      <td>0.022098</td>\n",
       "      <td>0.657984</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.657805</td>\n",
       "      <td>0.001459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.738448</td>\n",
       "      <td>0.029622</td>\n",
       "      <td>0.627612</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.627290</td>\n",
       "      <td>0.001548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.767376</td>\n",
       "      <td>0.022454</td>\n",
       "      <td>0.598089</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.597492</td>\n",
       "      <td>0.001689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.778122</td>\n",
       "      <td>0.022743</td>\n",
       "      <td>0.570242</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.569492</td>\n",
       "      <td>0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.781344</td>\n",
       "      <td>0.020052</td>\n",
       "      <td>0.547427</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.546633</td>\n",
       "      <td>0.002818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>0.811179</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.239623</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.206466</td>\n",
       "      <td>0.006852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>0.811178</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.239624</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.206461</td>\n",
       "      <td>0.006851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>227</td>\n",
       "      <td>0.811182</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>0.239621</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.206451</td>\n",
       "      <td>0.006848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>228</td>\n",
       "      <td>0.811180</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.239622</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.206443</td>\n",
       "      <td>0.006846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>229</td>\n",
       "      <td>0.811160</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>0.239630</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.206434</td>\n",
       "      <td>0.006843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "0             0       0.727558      0.022098           0.657984   \n",
       "1             1       0.738448      0.029622           0.627612   \n",
       "2             2       0.767376      0.022454           0.598089   \n",
       "3             3       0.778122      0.022743           0.570242   \n",
       "4             4       0.781344      0.020052           0.547427   \n",
       "..          ...            ...           ...                ...   \n",
       "225         225       0.811179      0.006108           0.239623   \n",
       "226         226       0.811178      0.006107           0.239624   \n",
       "227         227       0.811182      0.006109           0.239621   \n",
       "228         228       0.811180      0.006108           0.239622   \n",
       "229         229       0.811160      0.006101           0.239630   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "0            0.001240            0.657805           0.001459  \n",
       "1            0.001277            0.627290           0.001548  \n",
       "2            0.001852            0.597492           0.001689  \n",
       "3            0.002050            0.569492           0.001882  \n",
       "4            0.003342            0.546633           0.002818  \n",
       "..                ...                 ...                ...  \n",
       "225          0.003490            0.206466           0.006852  \n",
       "226          0.003490            0.206461           0.006851  \n",
       "227          0.003491            0.206451           0.006848  \n",
       "228          0.003490            0.206443           0.006846  \n",
       "229          0.003487            0.206434           0.006843  \n",
       "\n",
       "[230 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-12-28 2022-02-12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>0.812133</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.238761</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.213453</td>\n",
       "      <td>0.003744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "129         129       0.812133      0.006302           0.238761   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "129          0.003573            0.213453           0.003744  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>0.813145</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.239911</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.221208</td>\n",
       "      <td>0.001907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "91          91       0.813145      0.006311           0.239911   \n",
       "\n",
       "    test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "91          0.003354            0.221208           0.001907  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "print(df.datum.min(),df.datum.max())\n",
    "display(cv_score[cv_score['test-Logloss-mean'].min() == cv_score['test-Logloss-mean']])\n",
    "display(cv_score[cv_score['test-AUC-mean'].max() == cv_score['test-AUC-mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 2020-01-04 2022-02-12\n",
      "train: 2014-12-28 2020-01-04\n",
      "0:\tlearn: 0.6328976\ttest: 0.6073440\tbest: 0.6073440 (0)\ttotal: 108ms\tremaining: 5m 24s\n",
      "100:\tlearn: 0.7078480\ttest: 0.6397288\tbest: 0.6422302 (79)\ttotal: 11s\tremaining: 5m 15s\n",
      "200:\tlearn: 0.7316776\ttest: 0.6422295\tbest: 0.6448526 (118)\ttotal: 21s\tremaining: 4m 51s\n",
      "300:\tlearn: 0.7509815\ttest: 0.6432699\tbest: 0.6455066 (269)\ttotal: 30.9s\tremaining: 4m 37s\n",
      "400:\tlearn: 0.7722690\ttest: 0.6368436\tbest: 0.6459278 (305)\ttotal: 41.1s\tremaining: 4m 26s\n",
      "500:\tlearn: 0.7941278\ttest: 0.6357897\tbest: 0.6459278 (305)\ttotal: 51.2s\tremaining: 4m 15s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6459277776\n",
      "bestIteration = 305\n",
      "\n",
      "Shrink model to first 306 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x20da48e6310>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df[['datum','avd','streck','häst','kusk']] = dforg[['datum','avd','streck','häst','kusk']]\n",
    "\n",
    "# df.drop('datum',axis=1,inplace=True)\n",
    "df.drop('avd',axis=1,inplace=True)\n",
    "df.drop(['streck'],axis=1,inplace=True)\n",
    "# df.drop(['häst','kusk'],axis=1,inplace=True)\n",
    "cat_features = list(df.loc[:,df.dtypes=='O'].columns)\n",
    "X_train,X_test,y_train,y_test = train_test_split(df,y,shuffle=False,)\n",
    "print(\"test:\",X_test.datum.min(),X_test.datum.max())\n",
    "print(\"train:\",X_train.datum.min(),X_train.datum.max())\n",
    "cb=get_model(use_best=True)\n",
    "cb.fit(X_train,y_train,eval_set= (X_test,y_test),early_stopping_rounds=200, cat_features=cat_features,verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -0.7567074968513359\n",
      "cb med ekipage 4.049145299145299 0.7077197490780207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "predict_prob = cb.predict_proba(X_test)\n",
    "\n",
    "_,prob_score = proba_order_score(X_test ,y_test, predict_prob)\n",
    "\n",
    "print('cb med ekipage',prob_score, cb.best_score_['validation']['AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAML (med och utan ekipage och streck)\n",
    "För att köra enbart FLAML initiera först med allt innan plus walkthrough  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_enc(df_, features):\n",
    "    df = df_.copy()\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=100000)\n",
    "    enc.fit(df[[features]])\n",
    "    df[features] = enc.transform(df[[features]])\n",
    "    return df,enc\n",
    "\n",
    "# df,enc = ordinal_enc(dforg,'häst')\n",
    "# import pickle\n",
    "# pickle.dump(enc, open('modeller/encoder.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_,train_from_proc=0,test_proc=0.25):\n",
    "    # train_from_proc = where to start both train and test\n",
    "    # test_proc = how much of the data is test\n",
    "    df=df_.copy()\n",
    "    alla_datum = df.datum.unique()\n",
    "    train_from_datum = alla_datum[ int(len(alla_datum)*train_from_proc)]\n",
    "    X_test=None\n",
    "    y_test=None\n",
    "    \n",
    "    if test_proc:\n",
    "        selected_data = alla_datum[ alla_datum >= train_from_datum ]\n",
    "        test_from_datum = selected_data[ int(len(selected_data)*(1-test_proc)) ]\n",
    "        X_test  = df[df.datum >= test_from_datum]\n",
    "        y_test  = (X_test.plac==1)*1\n",
    "        X_test  = X_test.drop('plac',axis=1)\n",
    "        print(f'test from {X_test.datum.min()} to {X_test.datum.max()} (incl)')\n",
    "    \n",
    "        X_train = df[(df.datum >= train_from_datum) & (df.datum < test_from_datum) ]\n",
    "    else:\n",
    "        print('No test')\n",
    "        X_train = df[(df.datum >= train_from_datum)]\n",
    "    \n",
    "    y_train = (X_train.plac==1)*1\n",
    "    \n",
    "    print(f'train from {X_train.datum.min()} to {X_train.datum.max()} (incl)')\n",
    "    \n",
    "    return X_train.drop('plac', axis=1), X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test from 2019-12-31 to 2022-02-12 (incl)\n",
      "train from 2014-12-28 to 2019-12-30 (incl)\n",
      "['datum', 'bana', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32692, 68), (11041, 68))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "\n",
    "### enc is the encoder that we will save for use during v75_spel.py ###\n",
    "### It will be used and finally saved later in this code ###\n",
    "df,env = ordinal_enc(dforg,'häst')\n",
    "\n",
    "X_train, X_test, y_train, y_test= split_data(df,train_from_proc=0,test_proc=0.25)\n",
    "X_train = remove_features(X_train)\n",
    "X_test  = remove_features( X_test)\n",
    "\n",
    "# X_train = X_train.drop('streck', axis=1)\n",
    "# X_test  = X_test.drop ('streck', axis=1)\n",
    "# X_train.drop('datum', axis=1, inplace=True)\n",
    "# X_test.drop( 'datum', axis=1, inplace=True)\n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "# X_train, X_test = replace_NaN(X_train.copy(),X_test=X_test.copy(), cat_features=cat_features) \n",
    "# X_train.fillna(-1)\n",
    "# X_test.fillna(-1)\n",
    "print(cat_features)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML \n",
    "cat_features = list(X_train.select_dtypes('object').columns)\n",
    "starting_points={'lgbm': {'n_estimators': 38,\n",
    "  'num_leaves': 4,\n",
    "  'min_child_samples': 2,\n",
    "  'learning_rate': 0.19098448074739216,\n",
    "  'log_max_bin': 7,\n",
    "  'colsample_bytree': 0.8827412174089042,\n",
    "  'reg_alpha': 0.004577823970660193,\n",
    "  'reg_lambda': 0.03815584533462228},\n",
    " 'rf': {'n_estimators': 33,\n",
    "  'max_features': 0.3251674877768946,\n",
    "  'max_leaves': 89,\n",
    "  'criterion': 'entropy'},\n",
    " 'catboost': {'early_stopping_rounds': 50,\n",
    "  'learning_rate': 0.007511731949060241},\n",
    " 'xgboost': {'n_estimators': 575,\n",
    "  'max_leaves': 46,\n",
    "  'min_child_weight': 1.032235057697502,\n",
    "  'learning_rate': 0.013318439439138472,\n",
    "  'subsample': 0.7908401179782586,\n",
    "  'colsample_bylevel': 0.6924750037579576,\n",
    "  'colsample_bytree': 0.7174828796230647,\n",
    "  'reg_alpha': 0.15461500385937774,\n",
    "  'reg_lambda': 0.6619886587472544},\n",
    " 'extra_tree': {'n_estimators': 47,\n",
    "  'max_features': 0.7934349565988307,\n",
    "  'max_leaves': 213,\n",
    "  'criterion': 'entropy'}}\n",
    "flml_raw_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc', 'starting_points': starting_points,'verbose':False,\n",
    "        'time_budget':1200, 'max_iter':50000000,'n_jobs':5, 'X_val': X_test, 'y_val':y_test,'early_stop':True, 'ensemble':True}\n",
    "\n",
    "automl_raw = AutoML()\n",
    "automl_raw.fit(X_train,y_train, **flml_raw_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(proba) -1.866482924373347\n",
      "timeserie, datum,häst, kusk 3.0984126984126985 0.8223201708047192\n"
     ]
    }
   ],
   "source": [
    "flm_raw_train_pred= automl_raw.predict_proba(X_train)\n",
    "flm_raw_test_pred = automl_raw.predict_proba(X_test)\n",
    "\n",
    "X_test_raw = X_test.copy()\n",
    "X_test_raw[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "_,prob_score = proba_order_score(X_test_raw,y_test, flm_raw_test_pred)\n",
    "\n",
    "print('timeserie, datum,häst, kusk', prob_score, 1-automl_raw.best_loss)\n",
    "# X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timeserie  0.3 0.25, datum, häst, kusk 3.720565149136578  0.7213763318649257 ... 1.9827526807785034 .....   best    \n",
    "timeserie  0.4 0.25, datum, häst, kusk 3.7362637362637363 0.7214144007762124  \n",
    "timeserie, 0.2 0.25, datum, häst, kusk 3.760989010989011  0.72561915325073230    \n",
    "timeserie, 0.1 0.25  datum, häst, kusk 3.8180708180708183 0.726597977829505    \n",
    "timeserie, 0.5 0.25, datum, häst, kusk 3.936263736263736  0.7216626969090024  \n",
    "timeserie, 0.3 0.25, datum, häst, kusk streck, NaN 3.0706436420722136  0.8230307821948237   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk,streck  3.0549450549450547 0.8232840226857013 ... -1.7710182666778564 .......... best   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk streck, NaN, fillna, 3.0549450549450547 0.8237003593459333   \n",
    "timeserie, 0.3 0.25, datum, häst, kusk, streck 3.06436420722135   0.8232840226857013       \n",
    "timeserie, 0.4 0.25, datum, häst, kusk, streck 3.1483516483516483 0.8169106155467452  \n",
    "timeserie, 0.2 0.25, datum, häst, kusk, streck 3.0824175824175826 0.8220287891340522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final FLML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flaml(X_train, y_train, df_perf, save=True):\n",
    "    import pickle\n",
    "    from_date = X_train.datum.min()\n",
    "    to_date = X_train.datum.max()\n",
    "    \n",
    "    for with_streck in [True, False]:\n",
    "        if with_streck: \n",
    "            X_tr = X_train.copy()    \n",
    "            filename = 'modeller\\\\FLAML_model.sav'\n",
    "        else:\n",
    "            X_tr = X_train.drop('streck', axis=1).copy()\n",
    "            filename = 'modeller\\\\FLAML2_model.sav'\n",
    "            \n",
    "        print('with_streck = ',with_streck)   \n",
    "    \n",
    "        automl = AutoML()\n",
    "        flml_parms={'task': 'classification','split_type':'time', 'metric':'roc_auc','starting_points': starting_points, 'verbose':False,\n",
    "        'time_budget':1700, 'max_iter':400000000,'n_jobs':5, 'early_stop':True, 'ensemble':True}\n",
    "\n",
    "        automl.fit(X_tr, y_train, **flml_parms)\n",
    "        perf = 1-automl.best_loss\n",
    "        print(perf, 'for streck in columns', with_streck)\n",
    "        df_perf.loc[len(df_perf)] = [from_date, to_date, with_streck, perf]\n",
    "        \n",
    "        # save_model\n",
    "        if save:\n",
    "            print('save model in',filename)        \n",
    "            pickle.dump(automl, open(filename, 'wb')) \n",
    "            print('save encoder enc in encoder.sav')\n",
    "            pickle.dump(enc, open('modeller/encoder.sav', 'wb'))\n",
    "\n",
    "    # remove duplicates\n",
    "    df_perf.drop_duplicates(subset=['learn_from','learn_to','streck'], keep='last', inplace=True)\n",
    "\n",
    "    print('\\n','\\n')\n",
    "    display(df_perf.tail(30).sort_values(by=['perf'], ascending=False))\n",
    "    print('Med streck max:',df_perf.loc[df_perf.streck == True].perf.max())\n",
    "    print('Ej  streck max:',df_perf.loc[df_perf.streck == False].perf.max())\n",
    "\n",
    "    df_perf.to_csv('perf_flaml.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test\n",
      "train from 2014-12-28 to 2022-02-12 (incl)\n",
      "with_streck =  True\n",
      "0.8178110106472746 for streck in columns True\n",
      "save model in modeller\\FLAML_model.sav\n",
      "save encoder enc in encoder.sav\n",
      "with_streck =  False\n",
      "0.7261161075195017 for streck in columns False\n",
      "save model in modeller\\FLAML2_model.sav\n",
      "save encoder enc in encoder.sav\n",
      "\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learn_from</th>\n",
       "      <th>learn_to</th>\n",
       "      <th>streck</th>\n",
       "      <th>perf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>0.818728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>True</td>\n",
       "      <td>0.818714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>True</td>\n",
       "      <td>0.817124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.816330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.728704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>False</td>\n",
       "      <td>0.728591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.726912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>False</td>\n",
       "      <td>0.726116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>False</td>\n",
       "      <td>0.725764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>0.721107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>0.721041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learn_from    learn_to  streck      perf\n",
       "2   2017-02-26  2022-01-01    True  0.818728\n",
       "0   2017-02-26  2021-12-31    True  0.818714\n",
       "16  2014-12-28  2022-02-12    True  0.817811\n",
       "14  2014-12-28  2022-02-05    True  0.817489\n",
       "12  2014-12-28  2022-01-29    True  0.817124\n",
       "10  2014-12-28  2022-01-22    True  0.816984\n",
       "4   2014-12-28  2022-01-01    True  0.816678\n",
       "6   2014-12-28  2022-01-08    True  0.816579\n",
       "8   2014-12-28  2022-01-15    True  0.816330\n",
       "5   2014-12-28  2022-01-01   False  0.728704\n",
       "7   2014-12-28  2022-01-08   False  0.728591\n",
       "11  2014-12-28  2022-01-22   False  0.727775\n",
       "9   2014-12-28  2022-01-15   False  0.727692\n",
       "15  2014-12-28  2022-02-05   False  0.726912\n",
       "17  2014-12-28  2022-02-12   False  0.726116\n",
       "13  2014-12-28  2022-01-29   False  0.725764\n",
       "1   2017-02-26  2021-12-31   False  0.721107\n",
       "3   2017-02-26  2022-01-01   False  0.721041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Med streck max: 0.8187283877462516\n",
      "Ej  streck max: 0.7287040948165976\n"
     ]
    }
   ],
   "source": [
    "# prepare all data för flaml\n",
    "dforg = pd.read_csv('all_data.csv')  \n",
    "df,enc = ordinal_enc(dforg, 'häst')\n",
    "X_train, _, y_train, _ = split_data(df,train_from_proc=0,test_proc=None)\n",
    "X_train = remove_features(X_train)\n",
    "\n",
    "df_perf = pd.read_csv('perf_flaml.csv')\n",
    "run_flaml(X_train, y_train, df_perf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call([r'C:/Users/peter/Documents/MyProjects/PyProj/Trav/spel/remove_dirt.bat'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
