{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "import pandas as pd \r\n",
    "import numpy as np \r\n",
    "from catboost import CatBoostClassifier,Pool,cv,utils\r\n",
    "\r\n",
    "# import sys\r\n",
    "# sys.path.append('C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel')\r\n",
    "# import V75_scraping as vs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "dforg = pd.read_csv('..//all_data.csv')     \r\n",
    "print(dforg.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['datum', 'avd', 'bana', 'häst', 'kusk', 'streck', 'vodds', 'podds',\n",
      "       'kr', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'kön', 'plac',\n",
      "       'pris', 'h1_dat', 'h1_kusk', 'h1_bana', 'h1_spår', 'h1_plac', 'h1_pris',\n",
      "       'h1_odds', 'h1_kmtid', 'h2_dat', 'h2_kusk', 'h2_bana', 'h2_spår',\n",
      "       'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_dat', 'h3_kusk',\n",
      "       'h3_bana', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid',\n",
      "       'h4_dat', 'h4_kusk', 'h4_bana', 'h4_spår', 'h4_plac', 'h4_pris',\n",
      "       'h4_odds', 'h4_kmtid', 'h5_dat', 'h5_kusk', 'h5_bana', 'h5_spår',\n",
      "       'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist',\n",
      "       'h3_dist', 'h4_dist', 'h5_dist', 'bins', 'h1_auto', 'h2_auto',\n",
      "       'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf',\n",
      "       'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4',\n",
      "       'startnr'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "### Features som inte används vid träning\r\n",
    "def remove_features(df,remove_mer=[]):\r\n",
    "    #remove_mer=['h5_perf','h5_auto','h4_perf','h4_auto', 'h3_perf', 'h2_perf']\r\n",
    "    df.drop(['startnr','vodds','podds','bins','h1_dat','h2_dat','h3_dat','h4_dat','h5_dat'],axis=1,inplace=True) #\r\n",
    "    if remove_mer:\r\n",
    "        df.drop(remove_mer,axis=1,inplace=True)\r\n",
    "    \r\n",
    "    # df=check_unique(df.copy())\r\n",
    "    # df=check_corr(df.copy())\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    " ## byt ut alla NaN till text för cat_features\r\n",
    "def replace_NaN(X_train,X_test=None, cat_features=[]):\r\n",
    "    # print('cat_features',cat_features)\r\n",
    "    X_train[cat_features]=X_train[cat_features].fillna('missing')\r\n",
    "    if X_test is not None:  ## om X_test är med\r\n",
    "        X_test[cat_features]=X_test[cat_features].fillnal('missing')    ### byt ut None-värden till texten 'None\r\n",
    "\r\n",
    "    return X_train,X_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# create basic and clean X_train, X_test etc that can be used as is -- \r\n",
    "def basic_data(df, frac=0.25):\r\n",
    "    X_train,X_test,y_train,y_test = None,None,None,None\r\n",
    "    dfnew = remove_features(df.copy())\r\n",
    "    dfnew['plac'] = (dfnew.plac==1) * 1\r\n",
    "    cat_features = list(dfnew.loc[:,df.dtypes=='O'].columns)\r\n",
    "    dfnew,_ = replace_NaN(dfnew.copy(), cat_features=cat_features)    \r\n",
    "    \r\n",
    "    alla_datum = df.datum.unique()\r\n",
    "    split_dat = alla_datum[int(len(alla_datum)* (1 - 0.25))]     # större än split_dat är test\r\n",
    "\r\n",
    "    X_train = dfnew.loc[dfnew.datum <= split_dat].copy()\r\n",
    "    y_train=X_train.plac\r\n",
    "    X_train.drop('plac',axis=1,inplace=True)\r\n",
    "    \r\n",
    "    X_test = dfnew.loc[dfnew.datum > split_dat].copy()\r\n",
    "    y_test=X_test.plac\r\n",
    "    X_test.drop('plac',axis=1,inplace=True)\r\n",
    "    \r\n",
    "    return X_train,X_test, y_train,y_test\r\n",
    "\r\n",
    "# split_dat = dforg.datum.unique()[int(len(dforg.datum.unique())* (1 - 0.25))]  \r\n",
    "# dforg.loc[dforg.datum<'2021-09-18']\r\n",
    "# X_train,X_test,y_train,y_test = basic_data(dforg.copy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "# Handle ekipage (häst and kusk)\r\n",
    "# Set a smooth mean value to the features in X_train  ##\r\n",
    "def calc_smooth_mean(X, y, by, m=100, tot_mean=None):\r\n",
    "    Xcopy = X.copy()\r\n",
    "    Xcopy['plac'] = y\r\n",
    "\r\n",
    "    # Compute the number of values and the mean of each group\r\n",
    "    agg = Xcopy.groupby(by)['plac'].agg(['count', 'mean'])\r\n",
    "    counts = agg['count']\r\n",
    "    means = agg['mean']\r\n",
    "\r\n",
    "    # Compute the \"smoothed\" means\r\n",
    "    smooth = (counts * means + m * tot_mean) / (counts + m)\r\n",
    "    \r\n",
    "    return smooth.to_dict()\r\n",
    "\r\n",
    "\r\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "from sklearn.pipeline import make_pipeline\r\n",
    "from sklearn.compose import make_column_transformer\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "# df skall innehålla datum,avd,vodds\r\n",
    "def proba_order_score(df_, y,proba):\r\n",
    "    kassa=200\r\n",
    "    df = df_.copy()\r\n",
    "    df['proba'] = proba[:,1]\r\n",
    "    df['f'] = (df.proba*df.vodds - 1) / (df.vodds-1)  # kelly formel\r\n",
    "    df['spela'] = df.f >0\r\n",
    "    df['insats'] = df.spela * df.f * kassa\r\n",
    "\r\n",
    "    df.sort_values(['datum','avd','proba'],ascending=[True,True,False],inplace=True)\r\n",
    "    proba_order=df.groupby(['datum','avd']).proba.cumcount()\r\n",
    "\r\n",
    "    df['prob_order']=proba_order+1\r\n",
    "    df['y'] = y\r\n",
    "    \r\n",
    "    return df, df.loc[df.y==1].prob_order.mean()   # mean vann per avd\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kolla olika features och dess betydelse på resultatet\r\n",
    "## data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "\r\n",
    "dforg = pd.read_csv('..\\\\all_data.csv')     \r\n",
    "#\r\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\r\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "# datum, avd, ekipage (raw, kodat) - blir det skillnad med och utan 'streck' \r\n",
    "# Spara alla värden nedan                           proba_order         AUC                 Accuracy\r\n",
    "# 1.  datun, avd, häst och kusk                     3.1316964285714284  0.8154899734619122  0.7407225221611429                     \r\n",
    "# 2.  ej avd                                        3.146205357142857   0.8151640292105853  0.7406341992435652\r\n",
    "# 3.  ej datum+avd   (bara avd borde ge sämre res)  3.1361607142857144  0.8162590757456829  0.7453960511909773 \r\n",
    "# 4.  datum, raw_ekipage                            3.1573660714285716  0.8154180216042461  0.7378602742086335\r\n",
    "# 5.  ej datum+avd  med raw_ekipage                 3.166294642857143   0.8143806767212379  0.737153650575579 \r\n",
    "# 6.  datum, kodat_ekipage                          VÄNTA\r\n",
    "# 7.  ej datum+avd, kodat_ekipage                   VÄNTA\r\n",
    "# 8.  bästa val enligt ovan med kodad bana          VÄNTA\r\n",
    "# 9.  gör en cv (timeSeries) med bästa val (val=3)  0.2426               0.812119            -----\r\n",
    "     \r\n",
    "cb = CatBoostClassifier(iterations=2000, early_stopping_rounds=100, use_best_model=True,auto_class_weights='Balanced', \r\n",
    "                        custom_metric=['Logloss','Accuracy','Recall','Precision','F1','AUC'], eval_metric='Accuracy', random_state=2021, verbose=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## De olika modellern med/utan vissa features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "dict_res = {'prob_score':[],'auc':[],'accuracy':[],'kommentar':[]} "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "# 1.    datum, avd, häst och kusk\r\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\r\n",
    "X_train.drop('streck',axis=1,inplace=True)\r\n",
    "X_test.drop('streck',axis=1,inplace=True)\r\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\r\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\r\n",
    "\r\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\r\n",
    "X,prob_score = proba_order_score(X_test,y_test,res.predict_proba(X_test))\r\n",
    "\r\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\r\n",
    "dict_res['kommentar'].append('inkl datum,avd, kusk,häst')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "source": [
    "# 2.    drop avd\r\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\r\n",
    "\r\n",
    "X_train.drop('streck',axis=1,inplace=True)\r\n",
    "X_test.drop('streck',axis=1,inplace=True)\r\n",
    "X_train.drop(['avd'],axis=1,inplace=True)\r\n",
    "X_test.drop(['avd'],axis=1,inplace=True)\r\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\r\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\r\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\r\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\r\n",
    "X,prob_score = proba_order_score(X_test,y_test,res.predict_proba(X_test))\r\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\r\n",
    "dict_res['kommentar'].append('inkl datum,kusk,häst')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "# 3.  ej datum+avd\r\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\r\n",
    "X_train.drop('streck',axis=1,inplace=True)\r\n",
    "X_test.drop('streck',axis=1,inplace=True)\r\n",
    "X_train.drop(['datum','avd'],axis=1,inplace=True)\r\n",
    "X_test.drop(['datum','avd'],axis=1,inplace=True)\r\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\r\n",
    "\r\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\r\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\r\n",
    "proba = res.predict_proba(X_test)\r\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\r\n",
    "X,prob_score = proba_order_score(X_test,y_test, proba)\r\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\r\n",
    "dict_res['kommentar'].append('inkl kusk,häst')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "# 4.  datum + raw_ekipage\r\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\r\n",
    "X_train.drop('streck',axis=1,inplace=True)\r\n",
    "X_test.drop('streck',axis=1,inplace=True)\r\n",
    "X_train.drop(['avd'],axis=1,inplace=True)\r\n",
    "X_test.drop(['avd'],axis=1,inplace=True)\r\n",
    "X_train['ekipage'] = X_train['häst'].str.cat(X_train.kusk,sep=',')\r\n",
    "X_train.drop(['häst','kusk'],axis=1,inplace=True) \r\n",
    "X_test['ekipage'] = X_test['häst'].str.cat(X_test.kusk,sep=',')\r\n",
    "X_test.drop(['häst','kusk'],axis=1,inplace=True) \r\n",
    "\r\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\r\n",
    "\r\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\r\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\r\n",
    "proba = res.predict_proba(X_test)\r\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\r\n",
    "X,prob_score = proba_order_score(X_test,y_test,proba)\r\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\r\n",
    "dict_res['kommentar'].append('inkl datum, raw_ekipage')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "# 5.  ej datum+avd  med raw_ekipage\r\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\r\n",
    "X_train.drop('streck',axis=1,inplace=True)\r\n",
    "X_test.drop('streck',axis=1,inplace=True)\r\n",
    "X_train.drop(['datum','avd'],axis=1,inplace=True)\r\n",
    "X_test.drop(['datum','avd'],axis=1,inplace=True)\r\n",
    "X_train['ekipage'] = X_train['häst'].str.cat(X_train.kusk,sep=',')\r\n",
    "X_train.drop(['häst','kusk'],axis=1,inplace=True) \r\n",
    "X_test['ekipage'] = X_test['häst'].str.cat(X_test.kusk,sep=',')\r\n",
    "X_test.drop(['häst','kusk'],axis=1,inplace=True) \r\n",
    "\r\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\r\n",
    "\r\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\r\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\r\n",
    "proba = res.predict_proba(X_test)\r\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\r\n",
    "X,prob_score = proba_order_score(X_test,y_test, proba)\r\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\r\n",
    "dict_res['kommentar'].append('inkl raw_ekipage')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## cv\r\n",
    "p9.  gör en cv med bästa val enl ovan  val=3 (ej datum+avd)\r\n",
    "cv på FLAML låter sig ej göras!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\r\n",
    "X_train.drop('streck',axis=1,inplace=True)\r\n",
    "X_test.drop('streck',axis=1,inplace=True)\r\n",
    "X_train.drop(['datum','avd'],axis=1,inplace=True)\r\n",
    "X_test.drop(['datum','avd'],axis=1,inplace=True)\r\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\r\n",
    "\r\n",
    "df = pd.concat([X_train,X_test],axis=0)\r\n",
    "y = pd.concat([y_train,y_test])\r\n",
    "cv_pool = Pool(df,y,cat_features=cat_features)\r\n",
    "\r\n",
    "params = {\r\n",
    "         'use_best_model': True,\r\n",
    "         'eval_metric' : 'AUC',\r\n",
    "         \"loss_function\": \"Logloss\",\r\n",
    "         'early_stopping_rounds': 100,\r\n",
    "         'verbose': 50,\r\n",
    "}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "\r\n",
    "cv_score =cv(pool=cv_pool, \r\n",
    "   params=params, \r\n",
    "   dtrain=None, \r\n",
    "   iterations=2000, \r\n",
    "   num_boost_round=None,\r\n",
    "   fold_count=5, \r\n",
    "   nfold=None,\r\n",
    "   inverted=False,\r\n",
    "   partition_random_seed=0,\r\n",
    "   seed=2021, \r\n",
    "   shuffle=False, \r\n",
    "   logging_level=None, \r\n",
    "   stratified=True,\r\n",
    "   as_pandas=True,\r\n",
    "   type='TimeSeries')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:\ttest: 0.5298131\tbest: 0.5298131 (0)\n",
      "50:\ttest: 0.7066526\tbest: 0.7066526 (50)\n",
      "100:\ttest: 0.7097250\tbest: 0.7140150 (76)\n",
      "150:\ttest: 0.7057194\tbest: 0.7140150 (76)\n",
      "Stopped by overfitting detector  (100 iterations wait)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "cv_score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.685566</td>\n",
       "      <td>0.031138</td>\n",
       "      <td>0.659116</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.659082</td>\n",
       "      <td>0.001414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.785142</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.623803</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.623434</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.793489</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.594773</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.594257</td>\n",
       "      <td>0.002040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.795764</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.570290</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.569590</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.798462</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.545006</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.544244</td>\n",
       "      <td>0.000614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>0.809656</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.240312</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.219811</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>0.809653</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.219681</td>\n",
       "      <td>0.009647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>0.809649</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.219620</td>\n",
       "      <td>0.009649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>0.809561</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.240335</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.219528</td>\n",
       "      <td>0.009628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>0.809497</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>0.240372</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.219430</td>\n",
       "      <td>0.009674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "0             0       0.685566      0.031138           0.659116   \n",
       "1             1       0.785142      0.009562           0.623803   \n",
       "2             2       0.793489      0.010459           0.594773   \n",
       "3             3       0.795764      0.008138           0.570290   \n",
       "4             4       0.798462      0.008920           0.545006   \n",
       "..          ...            ...           ...                ...   \n",
       "173         173       0.809656      0.005633           0.240312   \n",
       "174         174       0.809653      0.005669           0.240320   \n",
       "175         175       0.809649      0.005703           0.240319   \n",
       "176         176       0.809561      0.005666           0.240335   \n",
       "177         177       0.809497      0.005640           0.240372   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "0            0.001195            0.659082           0.001414  \n",
       "1            0.001406            0.623434           0.001732  \n",
       "2            0.001503            0.594257           0.002040  \n",
       "3            0.001322            0.569590           0.000968  \n",
       "4            0.000998            0.544244           0.000614  \n",
       "..                ...                 ...                ...  \n",
       "173          0.002036            0.219811           0.009642  \n",
       "174          0.002044            0.219681           0.009647  \n",
       "175          0.002056            0.219620           0.009649  \n",
       "176          0.002056            0.219528           0.009628  \n",
       "177          0.002043            0.219430           0.009674  \n",
       "\n",
       "[178 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "# cv utan streck\r\n",
    "cv_score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.529813</td>\n",
       "      <td>0.039838</td>\n",
       "      <td>0.664029</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.664043</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.578647</td>\n",
       "      <td>0.054225</td>\n",
       "      <td>0.636741</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.636813</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.609640</td>\n",
       "      <td>0.040873</td>\n",
       "      <td>0.611487</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.611561</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.609823</td>\n",
       "      <td>0.039733</td>\n",
       "      <td>0.588440</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.588568</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.634255</td>\n",
       "      <td>0.029440</td>\n",
       "      <td>0.566424</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.566448</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>0.706424</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.273079</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.246480</td>\n",
       "      <td>0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>0.706388</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.273113</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.008624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>0.706563</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.273074</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.246170</td>\n",
       "      <td>0.008727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>0.706563</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.273059</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.246073</td>\n",
       "      <td>0.008780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>0.706587</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.273046</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.246008</td>\n",
       "      <td>0.008763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "0             0       0.529813      0.039838           0.664029   \n",
       "1             1       0.578647      0.054225           0.636741   \n",
       "2             2       0.609640      0.040873           0.611487   \n",
       "3             3       0.609823      0.039733           0.588440   \n",
       "4             4       0.634255      0.029440           0.566424   \n",
       "..          ...            ...           ...                ...   \n",
       "172         172       0.706424      0.005919           0.273079   \n",
       "173         173       0.706388      0.006018           0.273113   \n",
       "174         174       0.706563      0.005908           0.273074   \n",
       "175         175       0.706563      0.005752           0.273059   \n",
       "176         176       0.706587      0.005810           0.273046   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "0            0.000554            0.664043           0.000244  \n",
       "1            0.001253            0.636813           0.000758  \n",
       "2            0.001475            0.611561           0.000898  \n",
       "3            0.001846            0.588568           0.001151  \n",
       "4            0.002042            0.566448           0.001155  \n",
       "..                ...                 ...                ...  \n",
       "172          0.002314            0.246480           0.008582  \n",
       "173          0.002443            0.246325           0.008624  \n",
       "174          0.002440            0.246170           0.008727  \n",
       "175          0.002423            0.246073           0.008780  \n",
       "176          0.002415            0.246008           0.008763  \n",
       "\n",
       "[177 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "from IPython.display import display\r\n",
    "print(dforg.datum.max())\r\n",
    "display(cv_score[cv_score['test-Logloss-mean'].min() == cv_score['test-Logloss-mean']])\r\n",
    "display(cv_score[cv_score['test-AUC-mean'].max() == cv_score['test-AUC-mean']])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-09-18\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>0.708863</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.272656</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.258568</td>\n",
       "      <td>0.004413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "107         107       0.708863      0.003304           0.272656   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "107          0.001119            0.258568           0.004413  "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>0.714015</td>\n",
       "      <td>0.00437</td>\n",
       "      <td>0.276211</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.269489</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "76          76       0.714015       0.00437           0.276211   \n",
       "\n",
       "    test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "76          0.001243            0.269489           0.002334  "
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FLAML"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\r\n",
    "X_train.drop('streck',axis=1,inplace=True)\r\n",
    "X_test.drop('streck',axis=1,inplace=True)\r\n",
    "X_train.drop(['avd'],axis=1,inplace=True)\r\n",
    "X_test.drop(['avd'],axis=1,inplace=True)\r\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "source": [
    "from flaml import AutoML\r\n",
    "automl = AutoML()\r\n",
    "automl.fit(X_train,y_train, X_val=X_test, y_val=y_test, task='classification',  metric='roc_auc', ensemble=True, \r\n",
    "            n_jobs=5,split_type='time',seed=2021,early_stop=True, time_budget=240,  max_iter=2000000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[flaml.automl: 09-23 22:24:44] {1427} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 09-23 22:24:44] {1473} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl: 09-23 22:24:44] {1505} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl: 09-23 22:24:44] {1735} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:45] {1914} INFO -  at 1.1s,\tbest lgbm's error=0.3423,\tbest lgbm's error=0.3423\n",
      "[flaml.automl: 09-23 22:24:45] {1735} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:45] {1914} INFO -  at 1.5s,\tbest lgbm's error=0.3423,\tbest lgbm's error=0.3423\n",
      "[flaml.automl: 09-23 22:24:45] {1735} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:46] {1914} INFO -  at 2.1s,\tbest lgbm's error=0.3286,\tbest lgbm's error=0.3286\n",
      "[flaml.automl: 09-23 22:24:46] {1735} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:46] {1914} INFO -  at 2.5s,\tbest xgboost's error=0.3435,\tbest lgbm's error=0.3286\n",
      "[flaml.automl: 09-23 22:24:46] {1735} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:47] {1914} INFO -  at 3.2s,\tbest lgbm's error=0.3270,\tbest lgbm's error=0.3270\n",
      "[flaml.automl: 09-23 22:24:47] {1735} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:47] {1914} INFO -  at 3.7s,\tbest lgbm's error=0.3270,\tbest lgbm's error=0.3270\n",
      "[flaml.automl: 09-23 22:24:47] {1735} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:48] {1914} INFO -  at 4.3s,\tbest lgbm's error=0.3270,\tbest lgbm's error=0.3270\n",
      "[flaml.automl: 09-23 22:24:48] {1735} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:49] {1914} INFO -  at 5.1s,\tbest lgbm's error=0.3270,\tbest lgbm's error=0.3270\n",
      "[flaml.automl: 09-23 22:24:49] {1735} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:49] {1914} INFO -  at 5.3s,\tbest xgboost's error=0.3435,\tbest lgbm's error=0.3270\n",
      "[flaml.automl: 09-23 22:24:49] {1735} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:49] {1914} INFO -  at 5.6s,\tbest xgboost's error=0.3435,\tbest lgbm's error=0.3270\n",
      "[flaml.automl: 09-23 22:24:49] {1735} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:49] {1914} INFO -  at 5.9s,\tbest xgboost's error=0.3271,\tbest lgbm's error=0.3270\n",
      "[flaml.automl: 09-23 22:24:49] {1735} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:50] {1914} INFO -  at 6.2s,\tbest xgboost's error=0.3271,\tbest lgbm's error=0.3270\n",
      "[flaml.automl: 09-23 22:24:50] {1735} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:50] {1914} INFO -  at 6.4s,\tbest xgboost's error=0.3271,\tbest lgbm's error=0.3270\n",
      "[flaml.automl: 09-23 22:24:50] {1735} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:50] {1914} INFO -  at 6.9s,\tbest xgboost's error=0.3019,\tbest xgboost's error=0.3019\n",
      "[flaml.automl: 09-23 22:24:50] {1735} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:24:51] {1914} INFO -  at 7.1s,\tbest extra_tree's error=0.3348,\tbest xgboost's error=0.3019\n",
      "[flaml.automl: 09-23 22:24:51] {1735} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:51] {1914} INFO -  at 7.6s,\tbest xgboost's error=0.2844,\tbest xgboost's error=0.2844\n",
      "[flaml.automl: 09-23 22:24:51] {1735} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:24:51] {1914} INFO -  at 7.9s,\tbest extra_tree's error=0.3101,\tbest xgboost's error=0.2844\n",
      "[flaml.automl: 09-23 22:24:51] {1735} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:52] {1914} INFO -  at 8.4s,\tbest lgbm's error=0.3270,\tbest xgboost's error=0.2844\n",
      "[flaml.automl: 09-23 22:24:52] {1735} INFO - iteration 18, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:24:52] {1914} INFO -  at 8.7s,\tbest extra_tree's error=0.3101,\tbest xgboost's error=0.2844\n",
      "[flaml.automl: 09-23 22:24:52] {1735} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:53] {1914} INFO -  at 9.2s,\tbest xgboost's error=0.2844,\tbest xgboost's error=0.2844\n",
      "[flaml.automl: 09-23 22:24:53] {1735} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:24:53] {1914} INFO -  at 9.6s,\tbest extra_tree's error=0.3078,\tbest xgboost's error=0.2844\n",
      "[flaml.automl: 09-23 22:24:53] {1735} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:54] {1914} INFO -  at 10.2s,\tbest xgboost's error=0.2844,\tbest xgboost's error=0.2844\n",
      "[flaml.automl: 09-23 22:24:54] {1735} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:54] {1914} INFO -  at 10.7s,\tbest xgboost's error=0.2828,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:54] {1735} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:24:54] {1914} INFO -  at 11.0s,\tbest extra_tree's error=0.3078,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:54] {1735} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:24:55] {1914} INFO -  at 11.4s,\tbest extra_tree's error=0.3025,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:55] {1735} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 09-23 22:24:55] {1914} INFO -  at 11.9s,\tbest xgboost's error=0.2828,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:55] {1735} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:24:56] {1914} INFO -  at 12.3s,\tbest extra_tree's error=0.3025,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:56] {1735} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:24:57] {1914} INFO -  at 13.2s,\tbest extra_tree's error=0.2953,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:57] {1735} INFO - iteration 28, current learner rf\n",
      "[flaml.automl: 09-23 22:24:57] {1914} INFO -  at 13.8s,\tbest rf's error=0.3400,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:57] {1735} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:24:58] {1914} INFO -  at 14.2s,\tbest extra_tree's error=0.2953,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:58] {1735} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:58] {1914} INFO -  at 15.0s,\tbest lgbm's error=0.3186,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:58] {1735} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 09-23 22:24:59] {1914} INFO -  at 15.7s,\tbest lgbm's error=0.3186,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:24:59] {1735} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 09-23 22:25:00] {1914} INFO -  at 16.4s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:25:00] {1735} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:01] {1914} INFO -  at 17.1s,\tbest extra_tree's error=0.2953,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:25:01] {1735} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:02] {1914} INFO -  at 18.4s,\tbest lgbm's error=0.3186,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:25:02] {1735} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 09-23 22:25:02] {1914} INFO -  at 18.9s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:25:02] {1735} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:03] {1914} INFO -  at 19.8s,\tbest extra_tree's error=0.2924,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:25:03] {1735} INFO - iteration 37, current learner rf\n",
      "[flaml.automl: 09-23 22:25:04] {1914} INFO -  at 20.5s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2828\n",
      "[flaml.automl: 09-23 22:25:04] {1735} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:04] {1914} INFO -  at 21.0s,\tbest xgboost's error=0.2791,\tbest xgboost's error=0.2791\n",
      "[flaml.automl: 09-23 22:25:04] {1735} INFO - iteration 39, current learner rf\n",
      "[flaml.automl: 09-23 22:25:05] {1914} INFO -  at 21.7s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2791\n",
      "[flaml.automl: 09-23 22:25:05] {1735} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:06] {1914} INFO -  at 22.2s,\tbest xgboost's error=0.2791,\tbest xgboost's error=0.2791\n",
      "[flaml.automl: 09-23 22:25:06] {1735} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:06] {1914} INFO -  at 22.8s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2791\n",
      "[flaml.automl: 09-23 22:25:06] {1735} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:07] {1914} INFO -  at 23.5s,\tbest lgbm's error=0.3186,\tbest xgboost's error=0.2791\n",
      "[flaml.automl: 09-23 22:25:07] {1735} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:08] {1914} INFO -  at 24.7s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2791\n",
      "[flaml.automl: 09-23 22:25:08] {1735} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:09] {1914} INFO -  at 25.1s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2791\n",
      "[flaml.automl: 09-23 22:25:09] {1735} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:09] {1914} INFO -  at 25.9s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:09] {1735} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 09-23 22:25:10] {1914} INFO -  at 26.9s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:10] {1735} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:11] {1914} INFO -  at 27.7s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:11] {1735} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:12] {1914} INFO -  at 28.4s,\tbest lgbm's error=0.3021,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:12] {1735} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:13] {1914} INFO -  at 29.2s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:13] {1735} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:13] {1914} INFO -  at 30.0s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:13] {1735} INFO - iteration 51, current learner rf\n",
      "[flaml.automl: 09-23 22:25:14] {1914} INFO -  at 30.6s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:14] {1735} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 09-23 22:25:15] {1914} INFO -  at 31.8s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:15] {1735} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:16] {1914} INFO -  at 32.5s,\tbest lgbm's error=0.3021,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:16] {1735} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:17] {1914} INFO -  at 33.2s,\tbest lgbm's error=0.3021,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:17] {1735} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:18] {1914} INFO -  at 34.3s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:18] {1735} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:18] {1914} INFO -  at 35.0s,\tbest lgbm's error=0.3021,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:18] {1735} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 09-23 22:25:19] {1914} INFO -  at 35.6s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:19] {1735} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:20] {1914} INFO -  at 36.1s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:20] {1735} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:20] {1914} INFO -  at 36.8s,\tbest lgbm's error=0.3021,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:20] {1735} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:23] {1914} INFO -  at 39.1s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:23] {1735} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:23] {1914} INFO -  at 39.8s,\tbest lgbm's error=0.3021,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:23] {1735} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:24] {1914} INFO -  at 40.3s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:24] {1735} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:24] {1914} INFO -  at 40.8s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:24] {1735} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:25] {1914} INFO -  at 41.4s,\tbest lgbm's error=0.3021,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:25] {1735} INFO - iteration 65, current learner rf\n",
      "[flaml.automl: 09-23 22:25:26] {1914} INFO -  at 42.1s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:26] {1735} INFO - iteration 66, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:26] {1914} INFO -  at 42.5s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:26] {1735} INFO - iteration 67, current learner rf\n",
      "[flaml.automl: 09-23 22:25:27] {1914} INFO -  at 43.2s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:27] {1735} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:27] {1914} INFO -  at 43.8s,\tbest lgbm's error=0.3021,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:27] {1735} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:30] {1914} INFO -  at 46.8s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:30] {1735} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:31] {1914} INFO -  at 47.4s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:31] {1735} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:32] {1914} INFO -  at 48.8s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:32] {1735} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:33] {1914} INFO -  at 49.7s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:33] {1735} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:34] {1914} INFO -  at 50.3s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:34] {1735} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:35] {1914} INFO -  at 51.2s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:35] {1735} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:35] {1914} INFO -  at 51.9s,\tbest lgbm's error=0.3021,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:35] {1735} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:36] {1914} INFO -  at 52.6s,\tbest lgbm's error=0.3011,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:36] {1735} INFO - iteration 77, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:36] {1914} INFO -  at 53.0s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:36] {1735} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 09-23 22:25:37] {1914} INFO -  at 53.4s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:37] {1735} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:38] {1914} INFO -  at 54.1s,\tbest lgbm's error=0.3011,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:38] {1735} INFO - iteration 80, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:38] {1914} INFO -  at 54.7s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:38] {1735} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 09-23 22:25:40] {1914} INFO -  at 56.1s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:40] {1735} INFO - iteration 82, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:40] {1914} INFO -  at 56.6s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:40] {1735} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:43] {1914} INFO -  at 59.1s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:43] {1735} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:43] {1914} INFO -  at 59.7s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:43] {1735} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:44] {1914} INFO -  at 60.3s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:44] {1735} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:44] {1914} INFO -  at 60.8s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:44] {1735} INFO - iteration 87, current learner rf\n",
      "[flaml.automl: 09-23 22:25:45] {1914} INFO -  at 61.6s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:45] {1735} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:46] {1914} INFO -  at 62.4s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:46] {1735} INFO - iteration 89, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:46] {1914} INFO -  at 62.9s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:46] {1735} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:47] {1914} INFO -  at 63.7s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:47] {1735} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:48] {1914} INFO -  at 64.2s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:48] {1735} INFO - iteration 92, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:49] {1914} INFO -  at 65.2s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:49] {1735} INFO - iteration 93, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:49] {1914} INFO -  at 66.0s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:49] {1735} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:51] {1914} INFO -  at 67.1s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:51] {1735} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:51] {1914} INFO -  at 67.7s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:51] {1735} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:52] {1914} INFO -  at 68.3s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:52] {1735} INFO - iteration 97, current learner rf\n",
      "[flaml.automl: 09-23 22:25:53] {1914} INFO -  at 69.3s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:53] {1735} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:53] {1914} INFO -  at 70.0s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:53] {1735} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:55] {1914} INFO -  at 71.2s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:55] {1735} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:25:55] {1914} INFO -  at 71.7s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:55] {1735} INFO - iteration 101, current learner rf\n",
      "[flaml.automl: 09-23 22:25:56] {1914} INFO -  at 72.7s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:56] {1735} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl: 09-23 22:25:57] {1914} INFO -  at 73.4s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:57] {1735} INFO - iteration 103, current learner xgboost\n",
      "[flaml.automl: 09-23 22:25:59] {1914} INFO -  at 75.9s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:25:59] {1735} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 09-23 22:26:00] {1914} INFO -  at 76.9s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:00] {1735} INFO - iteration 105, current learner catboost\n",
      "[flaml.automl: 09-23 22:26:11] {1914} INFO -  at 87.3s,\tbest catboost's error=0.2860,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:11] {1735} INFO - iteration 106, current learner catboost\n",
      "[flaml.automl: 09-23 22:26:24] {1914} INFO -  at 100.8s,\tbest catboost's error=0.2836,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:24] {1735} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:26:25] {1914} INFO -  at 101.5s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:25] {1735} INFO - iteration 108, current learner rf\n",
      "[flaml.automl: 09-23 22:26:26] {1914} INFO -  at 102.1s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:26] {1735} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:26:26] {1914} INFO -  at 102.7s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:26] {1735} INFO - iteration 110, current learner catboost\n",
      "[flaml.automl: 09-23 22:26:36] {1914} INFO -  at 112.3s,\tbest catboost's error=0.2836,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:36] {1735} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl: 09-23 22:26:37] {1914} INFO -  at 113.1s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:37] {1735} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:26:37] {1914} INFO -  at 113.9s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:37] {1735} INFO - iteration 113, current learner xgboost\n",
      "[flaml.automl: 09-23 22:26:38] {1914} INFO -  at 114.6s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:38] {1735} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:26:39] {1914} INFO -  at 115.1s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:39] {1735} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl: 09-23 22:26:40] {1914} INFO -  at 116.1s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:40] {1735} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl: 09-23 22:26:42] {1914} INFO -  at 118.1s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:42] {1735} INFO - iteration 117, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:26:42] {1914} INFO -  at 118.7s,\tbest extra_tree's error=0.2897,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:42] {1735} INFO - iteration 118, current learner xgboost\n",
      "[flaml.automl: 09-23 22:26:44] {1914} INFO -  at 120.9s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:44] {1735} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl: 09-23 22:26:45] {1914} INFO -  at 121.5s,\tbest lgbm's error=0.2986,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:45] {1735} INFO - iteration 120, current learner xgboost\n",
      "[flaml.automl: 09-23 22:26:46] {1914} INFO -  at 122.1s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:46] {1735} INFO - iteration 121, current learner xgboost\n",
      "[flaml.automl: 09-23 22:26:48] {1914} INFO -  at 124.4s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:48] {1735} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:26:49] {1914} INFO -  at 125.2s,\tbest extra_tree's error=0.2858,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:49] {1735} INFO - iteration 123, current learner xgboost\n",
      "[flaml.automl: 09-23 22:26:49] {1914} INFO -  at 126.0s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:49] {1735} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl: 09-23 22:26:50] {1914} INFO -  at 126.9s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:50] {1735} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 09-23 22:26:51] {1914} INFO -  at 127.7s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:51] {1735} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 09-23 22:26:55] {1914} INFO -  at 131.5s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:55] {1735} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 09-23 22:26:56] {1914} INFO -  at 132.2s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:56] {1735} INFO - iteration 128, current learner rf\n",
      "[flaml.automl: 09-23 22:26:56] {1914} INFO -  at 132.8s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:56] {1735} INFO - iteration 129, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:26:57] {1914} INFO -  at 133.8s,\tbest extra_tree's error=0.2858,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:26:57] {1735} INFO - iteration 130, current learner catboost\n",
      "[flaml.automl: 09-23 22:27:11] {1914} INFO -  at 147.1s,\tbest catboost's error=0.2836,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:11] {1735} INFO - iteration 131, current learner catboost\n",
      "[flaml.automl: 09-23 22:27:21] {1914} INFO -  at 157.4s,\tbest catboost's error=0.2836,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:21] {1735} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:27:21] {1914} INFO -  at 157.9s,\tbest extra_tree's error=0.2858,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:21] {1735} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl: 09-23 22:27:22] {1914} INFO -  at 158.6s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:22] {1735} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 09-23 22:27:23] {1914} INFO -  at 159.8s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:23] {1735} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl: 09-23 22:27:37] {1914} INFO -  at 173.1s,\tbest catboost's error=0.2836,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:37] {1735} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:27:37] {1914} INFO -  at 173.6s,\tbest extra_tree's error=0.2858,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:37] {1735} INFO - iteration 137, current learner catboost\n",
      "[flaml.automl: 09-23 22:27:42] {1914} INFO -  at 178.2s,\tbest catboost's error=0.2836,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:42] {1735} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl: 09-23 22:27:45] {1914} INFO -  at 181.7s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:45] {1735} INFO - iteration 139, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:27:46] {1914} INFO -  at 182.6s,\tbest extra_tree's error=0.2858,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:46] {1735} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl: 09-23 22:27:48] {1914} INFO -  at 184.8s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:48] {1735} INFO - iteration 141, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:27:49] {1914} INFO -  at 185.9s,\tbest extra_tree's error=0.2858,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:49] {1735} INFO - iteration 142, current learner rf\n",
      "[flaml.automl: 09-23 22:27:50] {1914} INFO -  at 186.7s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:50] {1735} INFO - iteration 143, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:27:51] {1914} INFO -  at 187.1s,\tbest extra_tree's error=0.2858,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:51] {1735} INFO - iteration 144, current learner xgboost\n",
      "[flaml.automl: 09-23 22:27:52] {1914} INFO -  at 188.7s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:52] {1735} INFO - iteration 145, current learner catboost\n",
      "[flaml.automl: 09-23 22:27:59] {1914} INFO -  at 195.8s,\tbest catboost's error=0.2836,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:27:59] {1735} INFO - iteration 146, current learner lgbm\n",
      "[flaml.automl: 09-23 22:28:00] {1914} INFO -  at 196.7s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:00] {1735} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 09-23 22:28:01] {1914} INFO -  at 197.4s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:01] {1735} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 09-23 22:28:05] {1914} INFO -  at 201.3s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:05] {1735} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl: 09-23 22:28:05] {1914} INFO -  at 202.0s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:05] {1735} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 09-23 22:28:09] {1914} INFO -  at 205.8s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:09] {1735} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 09-23 22:28:10] {1914} INFO -  at 206.4s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:10] {1735} INFO - iteration 152, current learner xgboost\n",
      "[flaml.automl: 09-23 22:28:11] {1914} INFO -  at 207.4s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:11] {1735} INFO - iteration 153, current learner xgboost\n",
      "[flaml.automl: 09-23 22:28:12] {1914} INFO -  at 208.3s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:12] {1735} INFO - iteration 154, current learner lgbm\n",
      "[flaml.automl: 09-23 22:28:12] {1914} INFO -  at 208.9s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:12] {1735} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 09-23 22:28:18] {1914} INFO -  at 215.0s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:18] {1735} INFO - iteration 156, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:28:19] {1914} INFO -  at 215.6s,\tbest extra_tree's error=0.2858,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:19] {1735} INFO - iteration 157, current learner xgboost\n",
      "[flaml.automl: 09-23 22:28:24] {1914} INFO -  at 220.6s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:24] {1735} INFO - iteration 158, current learner rf\n",
      "[flaml.automl: 09-23 22:28:25] {1914} INFO -  at 221.2s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:25] {1735} INFO - iteration 159, current learner rf\n",
      "[flaml.automl: 09-23 22:28:25] {1914} INFO -  at 221.8s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:25] {1735} INFO - iteration 160, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:28:26] {1914} INFO -  at 222.4s,\tbest extra_tree's error=0.2858,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:26] {1735} INFO - iteration 161, current learner rf\n",
      "[flaml.automl: 09-23 22:28:27] {1914} INFO -  at 223.3s,\tbest rf's error=0.3128,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:27] {1735} INFO - iteration 162, current learner xgboost\n",
      "[flaml.automl: 09-23 22:28:27] {1914} INFO -  at 223.7s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:27] {1735} INFO - iteration 163, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:28:28] {1914} INFO -  at 224.7s,\tbest extra_tree's error=0.2855,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:28] {1735} INFO - iteration 164, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:28:29] {1914} INFO -  at 225.2s,\tbest extra_tree's error=0.2855,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:29] {1735} INFO - iteration 165, current learner rf\n",
      "[flaml.automl: 09-23 22:28:29] {1914} INFO -  at 225.9s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:29] {1735} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 09-23 22:28:30] {1914} INFO -  at 226.9s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:30] {1735} INFO - iteration 167, current learner rf\n",
      "[flaml.automl: 09-23 22:28:31] {1914} INFO -  at 227.5s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:31] {1735} INFO - iteration 168, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:28:32] {1914} INFO -  at 228.2s,\tbest extra_tree's error=0.2855,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:32] {1735} INFO - iteration 169, current learner rf\n",
      "[flaml.automl: 09-23 22:28:33] {1914} INFO -  at 229.2s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:33] {1735} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl: 09-23 22:28:36] {1914} INFO -  at 232.8s,\tbest lgbm's error=0.2975,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:36] {1735} INFO - iteration 171, current learner rf\n",
      "[flaml.automl: 09-23 22:28:37] {1914} INFO -  at 233.4s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:37] {1735} INFO - iteration 172, current learner rf\n",
      "[flaml.automl: 09-23 22:28:37] {1914} INFO -  at 234.0s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:37] {1735} INFO - iteration 173, current learner rf\n",
      "[flaml.automl: 09-23 22:28:38] {1914} INFO -  at 234.9s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:38] {1735} INFO - iteration 174, current learner rf\n",
      "[flaml.automl: 09-23 22:28:39] {1914} INFO -  at 235.6s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:39] {1735} INFO - iteration 175, current learner rf\n",
      "[flaml.automl: 09-23 22:28:40] {1914} INFO -  at 236.2s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:40] {1735} INFO - iteration 176, current learner extra_tree\n",
      "[flaml.automl: 09-23 22:28:41] {1914} INFO -  at 237.2s,\tbest extra_tree's error=0.2855,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:41] {1735} INFO - iteration 177, current learner xgboost\n",
      "[flaml.automl: 09-23 22:28:42] {1914} INFO -  at 238.2s,\tbest xgboost's error=0.2698,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:42] {1735} INFO - iteration 178, current learner rf\n",
      "[flaml.automl: 09-23 22:28:43] {1914} INFO -  at 239.2s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:43] {1735} INFO - iteration 179, current learner rf\n",
      "[flaml.automl: 09-23 22:28:43] {1914} INFO -  at 239.9s,\tbest rf's error=0.3107,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:43] {1735} INFO - iteration 180, current learner lrl1\n",
      "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'.\n",
      "C:\\Users\\peter\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[flaml.automl: 09-23 22:28:46] {1914} INFO -  at 242.9s,\tbest lrl1's error=0.4049,\tbest xgboost's error=0.2698\n",
      "[flaml.automl: 09-23 22:28:46] {2021} INFO - selected model: XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.7156656011446916, colsample_bynode=1,\n",
      "              colsample_bytree=0.759477843839015, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.13989125388684256,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=4,\n",
      "              min_child_weight=128.0, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=150, n_jobs=5, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.0009765625, reg_lambda=2.0723318433796223,\n",
      "              scale_pos_weight=1, subsample=1.0, tree_method='hist',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=0)\n",
      "[flaml.automl: 09-23 22:28:46] {2037} INFO - [('xgboost', <flaml.model.XGBoostSklearnEstimator object at 0x0000017E4889F730>), ('catboost', <flaml.model.CatBoostEstimator object at 0x0000017E48704C70>), ('extra_tree', <flaml.model.ExtraTreeEstimator object at 0x0000017E7610C6A0>), ('lgbm', <flaml.model.LGBMEstimator object at 0x0000017E3C3E72B0>), ('rf', <flaml.model.RandomForestEstimator object at 0x0000017E42F988B0>), ('lrl1', <flaml.model.LRL1Classifier object at 0x0000017E3C8BEBE0>)]\n",
      "[flaml.automl: 09-23 22:29:44] {2063} INFO - ensemble: StackingClassifier(estimators=[('xgboost',\n",
      "                                <flaml.model.XGBoostSklearnEstimator object at 0x0000017E4889F730>),\n",
      "                               ('catboost',\n",
      "                                <flaml.model.CatBoostEstimator object at 0x0000017E48704C70>),\n",
      "                               ('extra_tree',\n",
      "                                <flaml.model.ExtraTreeEstimator object at 0x0000017E7610C6A0>),\n",
      "                               ('lgbm',\n",
      "                                <flaml.model.LGBMEstimator object at 0x0000017E3C3E72B0>),\n",
      "                               ('rf',\n",
      "                                <flaml.model.RandomForestEstimator object at 0x0000017E42F988B0>),\n",
      "                               ('lrl1',\n",
      "                                <flaml.model.LRL1Classifier object at 0x0000017E3C8BEBE0>)],\n",
      "                   final_estimator=<flaml.model.XGBoostSklearnEstimator object at 0x0000017E4889F730>,\n",
      "                   n_jobs=5, passthrough=True)\n",
      "[flaml.automl: 09-23 22:29:44] {1529} INFO - fit succeeded\n",
      "[flaml.automl: 09-23 22:29:44] {1530} INFO - Time taken to find the best model: 25.87493109703064\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "# automl.best_loss, 1-automl.best_loss\r\n",
    "proba = automl.predict_proba(X_test)\r\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\r\n",
    "\r\n",
    "X,prob_score = proba_order_score(X_test,y_test,proba)\r\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(1-automl.best_loss), dict_res['accuracy'].append(None)\r\n",
    "dict_res['kommentar'].append('FLML datum,kusk,häst')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "df_res = pd.DataFrame.from_dict(dict_res)\r\n",
    "\r\n",
    "df_res.sort_values(by='prob_score')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>kommentar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.128348</td>\n",
       "      <td>0.818311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FLML datum,kusk,häst ,streck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.131696</td>\n",
       "      <td>0.815490</td>\n",
       "      <td>0.740723</td>\n",
       "      <td>inkl datum,avd, kusk,häst,streck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.136161</td>\n",
       "      <td>0.816259</td>\n",
       "      <td>0.745396</td>\n",
       "      <td>inkl kusk,häst,streck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.146205</td>\n",
       "      <td>0.815164</td>\n",
       "      <td>0.740634</td>\n",
       "      <td>inkl datum,kusk,häst,streck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.157366</td>\n",
       "      <td>0.815418</td>\n",
       "      <td>0.737860</td>\n",
       "      <td>inkl datum, raw_ekipage,streck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.166295</td>\n",
       "      <td>0.814381</td>\n",
       "      <td>0.737154</td>\n",
       "      <td>inkl raw_ekipage,streck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.746652</td>\n",
       "      <td>0.730153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FLML datum,kusk,häst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.994420</td>\n",
       "      <td>0.711846</td>\n",
       "      <td>0.655643</td>\n",
       "      <td>inkl datum, raw_ekipage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.995536</td>\n",
       "      <td>0.714390</td>\n",
       "      <td>0.653876</td>\n",
       "      <td>inkl datum,avd, kusk,häst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.080357</td>\n",
       "      <td>0.703390</td>\n",
       "      <td>0.648999</td>\n",
       "      <td>inkl datum,kusk,häst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.094866</td>\n",
       "      <td>0.706266</td>\n",
       "      <td>0.646981</td>\n",
       "      <td>inkl raw_ekipage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.101562</td>\n",
       "      <td>0.705540</td>\n",
       "      <td>0.644358</td>\n",
       "      <td>inkl kusk,häst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prob_score       auc  accuracy                         kommentar\n",
       "5     3.128348  0.818311       NaN      FLML datum,kusk,häst ,streck\n",
       "0     3.131696  0.815490  0.740723  inkl datum,avd, kusk,häst,streck\n",
       "2     3.136161  0.816259  0.745396             inkl kusk,häst,streck\n",
       "1     3.146205  0.815164  0.740634       inkl datum,kusk,häst,streck\n",
       "3     3.157366  0.815418  0.737860    inkl datum, raw_ekipage,streck\n",
       "4     3.166295  0.814381  0.737154           inkl raw_ekipage,streck\n",
       "11    3.746652  0.730153       NaN              FLML datum,kusk,häst\n",
       "9     3.994420  0.711846  0.655643           inkl datum, raw_ekipage\n",
       "6     3.995536  0.714390  0.653876         inkl datum,avd, kusk,häst\n",
       "7     4.080357  0.703390  0.648999              inkl datum,kusk,häst\n",
       "10    4.094866  0.706266  0.646981                  inkl raw_ekipage\n",
       "8     4.101562  0.705540  0.644358                    inkl kusk,häst"
      ]
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\r\n",
    "filename = 'feature_selection.pkl'\r\n",
    "pickle.dump(automl, open(filename, 'wb'))\r\n",
    "\r\n",
    "df_res.to_csv('df_res.csv',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}