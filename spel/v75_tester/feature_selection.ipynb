{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from catboost import CatBoostClassifier,Pool,cv,utils\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel')\n",
    "# import V75_scraping as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforg = pd.read_csv('..//all_data.csv')     \n",
    "print(dforg.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Features som inte används vid träning\n",
    "def remove_features(df,remove_mer=[]):\n",
    "    #remove_mer=['h5_perf','h5_auto','h4_perf','h4_auto', 'h3_perf', 'h2_perf']\n",
    "    df.drop(['startnr','vodds','podds','bins','h1_dat','h2_dat','h3_dat','h4_dat','h5_dat'],axis=1,inplace=True) #\n",
    "    if remove_mer:\n",
    "        df.drop(remove_mer,axis=1,inplace=True)\n",
    "    \n",
    "    # df=check_unique(df.copy())\n",
    "    # df=check_corr(df.copy())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## byt ut alla NaN till text för cat_features\n",
    "def replace_NaN(X_train,X_test=None, cat_features=[]):\n",
    "    # print('cat_features',cat_features)\n",
    "    X_train[cat_features]=X_train[cat_features].fillna('missing')\n",
    "    if X_test is not None:  ## om X_test är med\n",
    "        X_test[cat_features]=X_test[cat_features].fillnal('missing')    ### byt ut None-värden till texten 'None\n",
    "\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic and clean X_train, X_test etc that can be used as is -- \n",
    "def basic_data(df, frac=0.25):\n",
    "    X_train,X_test,y_train,y_test = None,None,None,None\n",
    "    dfnew = remove_features(df.copy())\n",
    "    dfnew['plac'] = (dfnew.plac==1) * 1\n",
    "    cat_features = list(dfnew.loc[:,df.dtypes=='O'].columns)\n",
    "    dfnew,_ = replace_NaN(dfnew.copy(), cat_features=cat_features)    \n",
    "    \n",
    "    alla_datum = df.datum.unique()\n",
    "    split_dat = alla_datum[int(len(alla_datum)* (1 - 0.25))]     # större än split_dat är test\n",
    "\n",
    "    X_train = dfnew.loc[dfnew.datum <= split_dat].copy()\n",
    "    y_train=X_train.plac\n",
    "    X_train.drop('plac',axis=1,inplace=True)\n",
    "    \n",
    "    X_test = dfnew.loc[dfnew.datum > split_dat].copy()\n",
    "    y_test=X_test.plac\n",
    "    X_test.drop('plac',axis=1,inplace=True)\n",
    "    \n",
    "    return X_train,X_test, y_train,y_test\n",
    "\n",
    "# split_dat = dforg.datum.unique()[int(len(dforg.datum.unique())* (1 - 0.25))]  \n",
    "# dforg.loc[dforg.datum<'2021-09-18']\n",
    "# X_train,X_test,y_train,y_test = basic_data(dforg.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle ekipage (häst and kusk)\n",
    "# Set a smooth mean value to the features in X_train  ##\n",
    "def calc_smooth_mean(X, y, by, m=100, tot_mean=None):\n",
    "    Xcopy = X.copy()\n",
    "    Xcopy['plac'] = y\n",
    "\n",
    "    # Compute the number of values and the mean of each group\n",
    "    agg = Xcopy.groupby(by)['plac'].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "\n",
    "    # Compute the \"smoothed\" means\n",
    "    smooth = (counts * means + m * tot_mean) / (counts + m)\n",
    "    \n",
    "    return smooth.to_dict()\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df skall innehålla datum,avd,vodds\n",
    "def proba_order_score(df_, y,proba):\n",
    "    kassa=200\n",
    "    df = df_.copy()\n",
    "    df['proba'] = proba[:,1]\n",
    "    df['f'] = (df.proba*df.vodds - 1) / (df.vodds-1)  # kelly formel\n",
    "    df['spela'] = df.f >0\n",
    "    df['insats'] = df.spela * df.f * kassa\n",
    "\n",
    "    df.sort_values(['datum','avd','proba'],ascending=[True,True,False],inplace=True)\n",
    "    proba_order=df.groupby(['datum','avd']).proba.cumcount()\n",
    "\n",
    "    df['prob_order']=proba_order+1\n",
    "    df['y'] = y\n",
    "    \n",
    "    return df, df.loc[df.y==1].prob_order.mean()   # mean vann per avd\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolla olika features och dess betydelse på resultatet\n",
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dforg = pd.read_csv('..\\\\all_data.csv')     \n",
    "#\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datum, avd, ekipage (raw, kodat) - blir det skillnad med och utan 'streck' \n",
    "# Spara alla värden nedan                           proba_order         AUC                 Accuracy\n",
    "# 1.  datun, avd, häst och kusk                     3.1316964285714284  0.8154899734619122  0.7407225221611429                     \n",
    "# 2.  ej avd                                        3.146205357142857   0.8151640292105853  0.7406341992435652\n",
    "# 3.  ej datum+avd   (bara avd borde ge sämre res)  3.1361607142857144  0.8162590757456829  0.7453960511909773 \n",
    "# 4.  datum, raw_ekipage                            3.1573660714285716  0.8154180216042461  0.7378602742086335\n",
    "# 5.  ej datum+avd  med raw_ekipage                 3.166294642857143   0.8143806767212379  0.737153650575579 \n",
    "# 6.  datum, kodat_ekipage                          VÄNTA\n",
    "# 7.  ej datum+avd, kodat_ekipage                   VÄNTA\n",
    "# 8.  bästa val enligt ovan med kodad bana          VÄNTA\n",
    "# 9.  gör en cv (timeSeries) med bästa val (val=3)  0.2426               0.812119            -----\n",
    "     \n",
    "cb = CatBoostClassifier(iterations=2000, early_stopping_rounds=100, use_best_model=True,auto_class_weights='Balanced', \n",
    "                        custom_metric=['Logloss','Accuracy','Recall','Precision','F1','AUC'], eval_metric='Accuracy', random_state=2021, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De olika modellern med/utan vissa features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_res = {'prob_score':[],'auc':[],'accuracy':[],'kommentar':[]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.    datum, avd, häst och kusk\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\n",
    "X_train.drop('streck',axis=1,inplace=True)\n",
    "X_test.drop('streck',axis=1,inplace=True)\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\n",
    "\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "X,prob_score = proba_order_score(X_test,y_test,res.predict_proba(X_test))\n",
    "\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\n",
    "dict_res['kommentar'].append('inkl datum,avd, kusk,häst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.    drop avd\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\n",
    "\n",
    "X_train.drop('streck',axis=1,inplace=True)\n",
    "X_test.drop('streck',axis=1,inplace=True)\n",
    "X_train.drop(['avd'],axis=1,inplace=True)\n",
    "X_test.drop(['avd'],axis=1,inplace=True)\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "X,prob_score = proba_order_score(X_test,y_test,res.predict_proba(X_test))\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\n",
    "dict_res['kommentar'].append('inkl datum,kusk,häst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.  ej datum+avd\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\n",
    "X_train.drop('streck',axis=1,inplace=True)\n",
    "X_test.drop('streck',axis=1,inplace=True)\n",
    "X_train.drop(['datum','avd'],axis=1,inplace=True)\n",
    "X_test.drop(['datum','avd'],axis=1,inplace=True)\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\n",
    "\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\n",
    "proba = res.predict_proba(X_test)\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "X,prob_score = proba_order_score(X_test,y_test, proba)\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\n",
    "dict_res['kommentar'].append('inkl kusk,häst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.  datum + raw_ekipage\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\n",
    "X_train.drop('streck',axis=1,inplace=True)\n",
    "X_test.drop('streck',axis=1,inplace=True)\n",
    "X_train.drop(['avd'],axis=1,inplace=True)\n",
    "X_test.drop(['avd'],axis=1,inplace=True)\n",
    "X_train['ekipage'] = X_train['häst'].str.cat(X_train.kusk,sep=',')\n",
    "X_train.drop(['häst','kusk'],axis=1,inplace=True) \n",
    "X_test['ekipage'] = X_test['häst'].str.cat(X_test.kusk,sep=',')\n",
    "X_test.drop(['häst','kusk'],axis=1,inplace=True) \n",
    "\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\n",
    "\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\n",
    "proba = res.predict_proba(X_test)\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "X,prob_score = proba_order_score(X_test,y_test,proba)\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\n",
    "dict_res['kommentar'].append('inkl datum, raw_ekipage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.  ej datum+avd  med raw_ekipage\n",
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\n",
    "X_train.drop('streck',axis=1,inplace=True)\n",
    "X_test.drop('streck',axis=1,inplace=True)\n",
    "X_train.drop(['datum','avd'],axis=1,inplace=True)\n",
    "X_test.drop(['datum','avd'],axis=1,inplace=True)\n",
    "X_train['ekipage'] = X_train['häst'].str.cat(X_train.kusk,sep=',')\n",
    "X_train.drop(['häst','kusk'],axis=1,inplace=True) \n",
    "X_test['ekipage'] = X_test['häst'].str.cat(X_test.kusk,sep=',')\n",
    "X_test.drop(['häst','kusk'],axis=1,inplace=True) \n",
    "\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\n",
    "\n",
    "res=cb.fit(X_train,y_train,eval_set=(X_test,y_test),cat_features=cat_features)\n",
    "logloss, auc, accuracy = res.get_best_score()['validation']['Logloss'],res.get_best_score()['validation']['AUC'],res.get_best_score()['validation']['Accuracy']\n",
    "proba = res.predict_proba(X_test)\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "X,prob_score = proba_order_score(X_test,y_test, proba)\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(auc), dict_res['accuracy'].append(accuracy)\n",
    "dict_res['kommentar'].append('inkl raw_ekipage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv\n",
    "p9.  gör en cv med bästa val enl ovan  val=3 (ej datum+avd)\n",
    "cv på FLAML låter sig ej göras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\n",
    "X_train.drop('streck',axis=1,inplace=True)\n",
    "X_test.drop('streck',axis=1,inplace=True)\n",
    "X_train.drop(['datum','avd'],axis=1,inplace=True)\n",
    "X_test.drop(['datum','avd'],axis=1,inplace=True)\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)\n",
    "\n",
    "df = pd.concat([X_train,X_test],axis=0)\n",
    "y = pd.concat([y_train,y_test])\n",
    "cv_pool = Pool(df,y,cat_features=cat_features)\n",
    "\n",
    "params = {\n",
    "         'use_best_model': True,\n",
    "         'eval_metric' : 'AUC',\n",
    "         \"loss_function\": \"Logloss\",\n",
    "         'early_stopping_rounds': 100,\n",
    "         'verbose': 50,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv_score =cv(pool=cv_pool, \n",
    "   params=params, \n",
    "   dtrain=None, \n",
    "   iterations=2000, \n",
    "   num_boost_round=None,\n",
    "   fold_count=5, \n",
    "   nfold=None,\n",
    "   inverted=False,\n",
    "   partition_random_seed=0,\n",
    "   seed=2021, \n",
    "   shuffle=False, \n",
    "   logging_level=None, \n",
    "   stratified=True,\n",
    "   as_pandas=True,\n",
    "   type='TimeSeries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv utan streck\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "print(dforg.datum.max())\n",
    "display(cv_score[cv_score['test-Logloss-mean'].min() == cv_score['test-Logloss-mean']])\n",
    "display(cv_score[cv_score['test-AUC-mean'].max() == cv_score['test-AUC-mean']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = basic_data(dforg.copy())\n",
    "X_train.drop('streck',axis=1,inplace=True)\n",
    "X_test.drop('streck',axis=1,inplace=True)\n",
    "X_train.drop(['avd'],axis=1,inplace=True)\n",
    "X_test.drop(['avd'],axis=1,inplace=True)\n",
    "cat_features = list(X_train.loc[:,X_train.dtypes=='O'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "automl.fit(X_train,y_train, X_val=X_test, y_val=y_test, task='classification',  metric='roc_auc', ensemble=True, \n",
    "            n_jobs=5,split_type='time',seed=2021,early_stop=True, time_budget=240,  max_iter=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automl.best_loss, 1-automl.best_loss\n",
    "proba = automl.predict_proba(X_test)\n",
    "X_test[['datum','avd','vodds']] = dforg[['datum','avd','vodds']]\n",
    "\n",
    "X,prob_score = proba_order_score(X_test,y_test,proba)\n",
    "dict_res['prob_score'].append(prob_score), dict_res['auc'].append(1-automl.best_loss), dict_res['accuracy'].append(None)\n",
    "dict_res['kommentar'].append('FLML datum,kusk,häst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame.from_dict(dict_res)\n",
    "\n",
    "df_res.sort_values(by='prob_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'feature_selection.pkl'\n",
    "pickle.dump(automl, open(filename, 'wb'))\n",
    "\n",
    "df_res.to_csv('df_res.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "3d733caf4ffc39d0fbd9a2ba54ef4b7d515956d8048931f8241efe3827fb2d1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
