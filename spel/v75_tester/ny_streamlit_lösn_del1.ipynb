{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testar logiken i jupyter innan jag går över till python med streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beskrivning:  \n",
    "\n",
    "- Läser in fejkad web scraping data.  \n",
    "- gör predict proba och kelly för varje modell.  \n",
    "- Använder sedan meta_modellen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Först kolla artiklar om stacking, cv för stacking samt cv för stacking av timeseries \n",
    "https://machinelearningmastery.com/implementing-stacking-scratch-python/   (Även kod i Pieces)  \n",
    "Även allmänt om stacking ensembles  \n",
    "https://machinelearningmastery.com/essence-of-stacking-ensembles-for-machine-learning/  \n",
    "Slutligen CV för Timeseries stacking  (se kod i Pieces)  \n",
    "https://datascience.stackexchange.com/questions/41378/how-to-apply-stacking-cross-validation-for-time-series-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moduler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from IPython.display import display\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(df_, remove_mer=[]):\n",
    "    df = df_.copy()\n",
    "    df.drop(['startnr', 'vodds', 'podds', 'bins', 'h1_dat',\n",
    "             'h2_dat', 'h3_dat', 'h4_dat', 'h5_dat'], axis=1, inplace=True)\n",
    "    if remove_mer:\n",
    "        df.drop(remove_mer, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaN for cat_features in X and return (X, cat_features)\n",
    "# ta bort alla features som inte används innan call\n",
    "def prepare_for_catboost(X_, features=[]):\n",
    "    X = X_.copy()\n",
    "    Xtemp = remove_features(X, remove_mer=['avd', 'datum'])\n",
    "    \n",
    "    if len(features) > 0:\n",
    "      Xtemp = Xtemp[features]\n",
    "    # get numerical features and cat_features\n",
    "    num_features = list(Xtemp.select_dtypes(include=[np.number]).columns)\n",
    "    cat_features = list(Xtemp.select_dtypes(include=['object']).columns)\n",
    "\n",
    "    # check cat_features isna\n",
    "    print('NaN in cat before:', X[cat_features].isna().sum()[\n",
    "          X[cat_features].isna().sum() > 0].sort_values(ascending=False).sum())\n",
    "\n",
    "    # impute 'missing' for all NaN in cat_features\n",
    "    X[cat_features] = X[cat_features].fillna('missing')\n",
    "    print('NaN in cat after:', X[cat_features].isna().sum().sum())\n",
    "    return X, cat_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funktioner för att prioritera mellan hästar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa ett Kelly-värde baserat på streck omvandlat till odds\n",
    "def kelly(proba, streck, odds):  # proba = prob winning, streck i % = streck\n",
    "    with open('rf_streck_odds.pkl', 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "\n",
    "    if odds is None:\n",
    "        o = rf.predict(streck.copy())\n",
    "    else:\n",
    "        o = rf.predict(streck.copy())\n",
    "\n",
    "    # for each values > 40 in odds set to 1\n",
    "    o[o > 40] = 1\n",
    "    return (o*proba - (1-proba))/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# för en omgång (ett datum) ta ut största diff för streck per avd \n",
    "# om only_clear=True, enbart för diff >= 25\n",
    "def lista_med_favoriter(df_, ant, only_clear):\n",
    "    df = df_.copy()\n",
    "    min_diff = 25 if only_clear else 0\n",
    "    # sortera på avd,streck\n",
    "    df = df.sort_values(['avd', 'streck'], ascending=[False, False])\n",
    "    diff_list = []\n",
    "    for avd in range(1, 8):\n",
    "        diff = df.loc[df.avd == avd].streck.iloc[0] - \\\n",
    "            df.loc[df.avd == avd].streck.iloc[1]\n",
    "        if diff >= min_diff:\n",
    "            diff_list.append((avd, diff))\n",
    "\n",
    "     # sortera på diff\n",
    "    diff_list = sorted(diff_list, key=lambda x: x[1], reverse=True)\n",
    "    return diff_list[:ant]\n",
    "\n",
    "# temp is a list of tuples (avd, diff). check if avd is in the list\n",
    "def check_avd(avd, temp):\n",
    "    for t in temp:\n",
    "        if t[0] == avd:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_insats(df):\n",
    "    insats = 0\n",
    "    # group by avd\n",
    "    summa = df.groupby('avd').avd.count().prod() / 2\n",
    "    return summa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funktioner som modiferar data beroende på model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# antal hästar per avdeling\n",
    "def lägg_in_antal_hästar(df_):\n",
    "    df = df_.copy()\n",
    "    df['ant_per_lopp'] = None\n",
    "    df['ant_per_lopp'] = df.groupby(['datum', 'avd'])['avd'].transform('count')\n",
    "    return df\n",
    "\n",
    "# mest streck per avdeling\n",
    "def mest_streck(X_, i, datum, avd):\n",
    "    X = X_.copy()\n",
    "    X.sort_values(by=['datum', 'avd', 'streck'], ascending=[\n",
    "                  True, True, False], inplace=True)\n",
    "    return X.loc[(X.datum == datum) & (X.avd == avd), 'streck'].iloc[i]\n",
    "\n",
    "# n flest streck per avd som features\n",
    "def lägg_in_motståndare(X_, ant_motståndare):\n",
    "    X = X_.copy()\n",
    "\n",
    "    # set X['motståndare1'] to largest streck in every avd\n",
    "    grouped = X.groupby(['datum', 'avd'])['streck']\n",
    "    X['motståndare1'] = grouped.transform(max)\n",
    "\n",
    "    for i in range(2, ant_motståndare+1):\n",
    "        # set X['motståndare'+str(i)] to ith largest streck in every avd\n",
    "        X['motståndare' + str(i)] = grouped.transform(lambda x: x.nlargest(i).min())\n",
    "\n",
    "    return X\n",
    "\n",
    "# som föregående men med diff istf faktiska värden\n",
    "def lägg_in_diff_motståndare(X_, motståndare):\n",
    "    X = X_.copy()\n",
    "\n",
    "    # set X['motståndare1'] to largest streck in every avd\n",
    "    grouped = X.groupby(['datum', 'avd'])['streck']\n",
    "    X['diff1'] = grouped.transform(max) - X.streck\n",
    "\n",
    "    for i in range(2, motståndare+1):\n",
    "        # set X['motståndare'+str(i)] to ith largest streck in every avd\n",
    "        X['diff' + str(i)] = grouped.transform(lambda x: x.nlargest(i).min()) - X.streck\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class Typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Typ():\n",
    "    def __init__(self, name, ant_hästar, proba, kelly, motst_ant, motst_diff,  ant_favoriter, only_clear, streck):\n",
    "        assert (motst_diff == False and motst_ant == 0) or (motst_ant > 0)\n",
    "        assert (ant_favoriter == 0 and only_clear == False) or (ant_favoriter > 0)\n",
    "        self.name = name                # string för filnamn mm\n",
    "\n",
    "        # inkludera features eller ej\n",
    "        self.ant_hästar = ant_hästar    # int feature med antal hästar per avdelning\n",
    "        # int inkludera n features med bästa motståndare (streck)\n",
    "        self.motst_ant = motst_ant\n",
    "        self.motst_diff = motst_diff    # bool ovanstående med diff istf fasta värden\n",
    "        self.streck = streck            # bool inkludera feature med streck\n",
    "\n",
    "        # urval av rader\n",
    "        self.proba = proba              # bool för prioritering vid urval av rader\n",
    "        self.kelly = kelly              # bool för prioritering vid urval av rader\n",
    "        # int för hur många favoriter (avd med en häst) som ska användas\n",
    "        self.ant_favoriter = ant_favoriter\n",
    "        self.only_clear = only_clear    # bool för att bara avvända klara favoriter\n",
    "\n",
    "    def load_model(self):\n",
    "        with open('../modeller/'+self.name+'.model', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        return model\n",
    "\n",
    "    def save_model(self, model):\n",
    "        with open('../modeller/'+self.name+'.model', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    def prepare_for_model(self, X_):\n",
    "        # X_ måste ha datum och avd\n",
    "        X = X_.copy()\n",
    "        print(self.name)\n",
    "        if self.ant_hästar:\n",
    "            print('Lägg in ant_hästar')\n",
    "            X = lägg_in_antal_hästar(X)\n",
    "        if self.motst_diff:\n",
    "            print('Lägg in diff motståndare')\n",
    "            X = lägg_in_diff_motståndare(X, self.motst_ant)\n",
    "        elif self.motst_ant > 0:\n",
    "            print('Lägg in motståndare')\n",
    "            X = lägg_in_motståndare(X, self.motst_ant)\n",
    "        # Behåll streck ända tills learn och predict (används för prioritera rader)\n",
    "        return X\n",
    "\n",
    "    def learn(self, X_, y, features, iterations=1000, save=True, verbose=False):\n",
    "        # X_ måste ha datum och avd\n",
    "            \n",
    "        cbc = CatBoostClassifier(\n",
    "            iterations=iterations, loss_function='Logloss', eval_metric='AUC', verbose=verbose)\n",
    "\n",
    "        X = self.prepare_for_model(X_)\n",
    "        if not self.streck:\n",
    "            X.drop('streck', axis=1, inplace=True)\n",
    "\n",
    "        X, cat_features = prepare_for_catboost(X)\n",
    "        \n",
    "        X=remove_features(X, remove_mer=['datum','avd'])\n",
    "        cbc.fit(X, y, cat_features, use_best_model=False)\n",
    "    \n",
    "        print('best score', cbc.best_score_)\n",
    "        if save:\n",
    "            self.save_model(cbc)\n",
    "        return cbc\n",
    "    \n",
    "    def predict(self, X_):\n",
    "        # X_ måste ha datum och avd\n",
    "        X = self.prepare_for_model(X_)\n",
    "        model = self.load_model()\n",
    "        if not self.streck:\n",
    "            print('drop streck')\n",
    "            X.drop('streck', axis=1, inplace=True)\n",
    "            \n",
    "        X, cat_features = prepare_for_catboost(X, model.feature_names_)\n",
    "\n",
    "        # all features in model\n",
    "        X = remove_features(X, remove_mer=['datum', 'avd'])\n",
    "        # print(len(X.columns), len(model.feature_names_))\n",
    "        # print('Diff', set(X.columns) - set(model.feature_names_))\n",
    "        # print('X.columns\\n',X.columns)\n",
    "        # print('model features names\\n',model.feature_names_)\n",
    "        \n",
    "        assert len(X.columns) == len(model.feature_names_), f'len(X.columns)  != len(model.feature_names_) in predict {self.name}'\n",
    "        assert set(X.columns) == set(model.feature_names_), 'features in model and in X not equal'\n",
    "        # assert list(X.columns) == list(model.feature_names_), f'features in model {self.name} and X not in same order'\n",
    "        X = X[model.feature_names_]\n",
    "        print('predict '+self.name)   \n",
    "        print(model.get_feature_importance(prettified=True)[:3])\n",
    "        \n",
    "        return model.predict_proba(X)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skapa modeller\n",
    "#           name, ant_hästar, proba, kelly, motst_ant, motst_diff,  ant_favoriter, only_clear, streck\n",
    "typ6 = Typ('typ6', True,       True, False,     0,      False,          0,            False,    True)\n",
    "typ1 = Typ('typ1', False,      True, False,     2,      True,           2,            True,     False)\n",
    "typ9 = Typ('typ9', True,       True, True,      2,      True,           2,            True,     True)\n",
    "typ16 = Typ('typ16',True,      True, True,      2,      True,           2,            False,    True)\n",
    "\n",
    "typer = [typ6, typ1, typ9, typ16]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning-fasen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gör en scrape på senaste veckan (behövs inte i denna test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Läs in all_data.csv \n",
    "Baka ihop senaste vekan med all_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# läs in data\n",
    "def läs_in_data_för_learning():\n",
    "    df = pd.read_csv('..\\\\all_data.csv')\n",
    "    # Följande datum saknar avd==5 och kan inte användas\n",
    "    saknas = ['2015-08-15', '2016-08-13', '2017-08-12']\n",
    "    df = df[~df.datum.isin(saknas)]\n",
    "    X = df.copy()\n",
    "    X.drop('plac', axis=1, inplace=True)\n",
    "    \n",
    "    y = (df.plac == 1)*1   # plac 1 eller 0\n",
    "\n",
    "    for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        X[f] = X[f].str.lower()\n",
    "\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skapa_stack_learning(X_, y, features, iterations=1000, random_state=2022, verbose=False, save=True):\n",
    "    \"\"\"\n",
    "    Skapar en stack med proba och kelly\n",
    "    X måste ha datum och avd\n",
    "    \"\"\"\n",
    "    X = X_.copy()\n",
    "    stacked_data = pd.DataFrame()\n",
    "    \n",
    "    cbc = CatBoostClassifier(iterations=iterations, loss_function='Logloss', eval_metric='AUC', verbose=verbose)\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        model = typ.learn(X, y, features, iterations=iterations, save=save, verbose=verbose)\n",
    "        stacked_data['proba'+nr] = typ.predict(X) \n",
    "        stacked_data['kelly'+nr] = kelly(stacked_data['proba' + nr], X[['streck']], None)\n",
    "    \n",
    "    # print(stacked_data.columns)\n",
    "    return stacked_data   # enbart stack-info\n",
    "\n",
    "# fit meta_model\n",
    "def learn_meta_model(X,y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    print('\\nFitting meta_model on X with all models predictions')\n",
    "    \n",
    "    meta_model = RandomForestClassifier(max_depth=None, n_estimators=100, oob_score=True, verbose=1, n_jobs=10, random_state=2022)\n",
    "    meta_model.fit(X, y)\n",
    "    \n",
    "    print('OOB_score', meta_model.oob_score_)   # 0.9305314451043094\n",
    "    # pickle save stacking\n",
    "    pickle.dump(meta_model, open('..\\\\modeller\\\\meta.model', 'wb'))\n",
    "    \n",
    "    return meta_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read feature list from a file (ej plac)\n",
    "def read_feature_list(file='../FEATURES.txt'):\n",
    "    with open(file, 'r') as f:\n",
    "        return f.read().splitlines()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liten_cv_timeseries_demo(x_,y_):\n",
    "    X = x_.copy()\n",
    "    y = y_.copy()\n",
    "    print('Holdout validation data from X = X[~validation]')\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        print(f\"TRAIN each model on this: {train_index[0]}-{train_index[-1]}, Predict on: {test_index[0]}-{test_index[-1]}\")\n",
    "        print('save the predictions of each model')\n",
    "        X_train = X.loc[train_index]\n",
    "        X_test = X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    print('Train meta_model on all models predictions')\n",
    "    print('validate meta_model on the validation data')\n",
    "    \n",
    "    print('\\nHandle stratified and unbalanced data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kör learning-skiten här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout validation data from X = X[~validation]\n",
      "TRAIN each model on this: 0-7313, Predict on: 7314-14623\n",
      "save the predictions of each model\n",
      "TRAIN each model on this: 0-14623, Predict on: 14624-21933\n",
      "save the predictions of each model\n",
      "TRAIN each model on this: 0-21933, Predict on: 21934-29243\n",
      "save the predictions of each model\n",
      "TRAIN each model on this: 0-29243, Predict on: 29244-36553\n",
      "save the predictions of each model\n",
      "TRAIN each model on this: 0-36553, Predict on: 36554-43863\n",
      "save the predictions of each model\n",
      "Train meta_model on all models predictions\n",
      "validate meta_model on the validation data\n",
      "\n",
      "Handle stratified and unbalanced data\n"
     ]
    }
   ],
   "source": [
    "FEATURES = read_feature_list(\"../FEATURES.txt\")\n",
    "\n",
    "X_train, y_train = läs_in_data_för_learning()\n",
    "assert X_train.shape[1] == len(FEATURES), f'X_train.shape[1] {X_train.shape[1]} != len(FEATURES) {len(FEATURES)}'\n",
    "assert set(X_train.columns) == set(FEATURES), f'set(X_train.columns) {set(X_train.columns)} != set(FEATURES) {set(FEATURES)}'\n",
    "X_train = X_train[FEATURES]  # för att få kolumner i rätt ordning\n",
    "\n",
    "if True:\n",
    "    liten_cv_timeseries_demo(X_train, y_train)\n",
    "else:    \n",
    "    X_stacked = skapa_stack_learning(X_train, y_train, FEATURES, iterations=100,random_state=2022, verbose=False, save=True)\n",
    "    # display(X_stacked)\n",
    "    meta_model = learn_meta_model(X_stacked, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spela-fasen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    'C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel\\\\')\n",
    "import V75_scraping as vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape-funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v75_scrape():\n",
    "    df, strukna = vs.v75_scraping(history=True, resultat=False)\n",
    "    \n",
    "    # df = pd.read_csv('../sparad_scrape.csv')\n",
    "    for f in ['häst','bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        df[f] = df[f].str.lower()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativ metod\n",
    "# Ta fram rader för varje typ enligt test-resultaten innan\n",
    "# låt meta_model välja mellan typerna - hur? Hur maximer insatsen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion som bygger stack-data från modellerna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# för stacking ta med alla hästar per typ och proba plus kelly\n",
    "def build_stack_df(X_):\n",
    "    X = X_.copy()\n",
    "    stacked_data = X[['datum','avd', 'startnr','häst']].copy()\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        stacked_data['proba'+nr] = typ.predict(X)\n",
    "        stacked_data['kelly'+nr] = kelly(stacked_data['proba'+nr], X[['streck']], None)\n",
    "    return stacked_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion där meta_model gör predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_predict(X_):\n",
    "    # X_ innehåller även datum,startnr och avd\n",
    "    extra = ['datum', 'avd', 'startnr', 'häst']\n",
    "    assert list(X_.columns[:4]) == extra, 'meta_model måste ha datum, avd och startnr, häst för att kunna välja'\n",
    "    X = X_.copy()\n",
    "    with open('../modeller\\\\meta.model', 'rb') as f:\n",
    "        meta_model = pickle.load(f)\n",
    "        \n",
    "    # print(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "    X['meta_predict'] = meta_model.predict_proba(X.iloc[:,-8:])[:,1]\n",
    "    my_columns = extra + list(X.columns)[-9:] \n",
    "    \n",
    "    return X[my_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion som väljer rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_cost(antal_rader):\n",
    "    cost = (antal_rader**2)/2\n",
    "    return antal_rader,cost\n",
    "\n",
    "def välj_rad(X_):\n",
    "    \n",
    "    max_insats=320\n",
    "    veckans_rad = X_.copy()\n",
    "    veckans_rad['välj'] = False\n",
    "\n",
    "    for avd in veckans_rad.avd.unique():\n",
    "        max_pred = veckans_rad[veckans_rad.avd == avd]['meta_predict'].max()\n",
    "        veckans_rad.loc[(veckans_rad.avd == avd) & (veckans_rad.meta_predict == max_pred), 'välj'] = True\n",
    "    antal_rader=1    \n",
    "    veckans_rad = veckans_rad.sort_values(by=['meta_predict'], ascending=False)\n",
    "    \n",
    "    # 3. Använda ensam favorit för ett par avd? Kolla test-resultat\n",
    "    # for each row in rad, välj=True if select_func(cost,avd) == True\n",
    "    cost = antal_rader*0.5\n",
    "    for i, row in veckans_rad.iterrows():\n",
    "        new_antal,new_cost = comp_cost(antal_rader+1)\n",
    "        # print(the_cost)\n",
    "        if new_cost > max_insats:\n",
    "            break\n",
    "        \n",
    "        antal_rader = new_antal\n",
    "        cost = new_cost\n",
    "        veckans_rad.loc[i, 'välj'] = True\n",
    "        # print(cost)\n",
    "    veckans_rad.sort_values(by=['välj', 'avd'], ascending=[False, True], inplace=True)\n",
    "\n",
    "    return veckans_rad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kör hela välj-rad-skiten här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omgång 1: https://www.atg.se/spel/2022-04-23/V75/\n",
      "klickade på Anpassa\n",
      "hoppar över voods click (verkar vara förifyllt\n",
      "före click Spara\n",
      "efter click Spara\n",
      "ant lopp 7\n",
      "EUR: False NOK: False\n",
      "priser ['Pris: 125.000-62.500-34.000-21.000-13.500-10.500-7.000-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 150.000-75.000-40.000-25.000-15.000-11.500-7.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.', 'Pris: 110.000-55.000-32.000-19.000-12.500-10.000-6.500-5.000 kr (8 priser). Lägst 2.500 kr till alla tävlande.']\n",
      "Ant priser 7\n",
      "pris: 125.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 1 HALMSTAD 1640 AUTOSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 2 HALMSTAD 2140 AUTOSTART ............\n",
      "pris: 150.000\n",
      "ant names,vodds,podds,rader,streck 10 10 10 10\n",
      "AVD 3 HALMSTAD 2140 AUTOSTART ..........\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 4 HALMSTAD 2140 AUTOSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 5 HALMSTAD 2640 AUTOSTART ............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 15 15 15 15\n",
      "AVD 6 HALMSTAD 2140 VOLTSTART ...............\n",
      "pris: 110.000\n",
      "ant names,vodds,podds,rader,streck 12 12 12 12\n",
      "AVD 7 HALMSTAD 2140 VOLTSTART ............\n",
      "\n",
      "det tog 124.031 sekunder\n",
      "startar Fixa mer\n",
      "tog bort 1 strukna från 85 till 84\n",
      "plac saknas eller är felaktig\n",
      "rensade totalt bort 1 hästar i städa_och_rensa. Från 85 till 84\n",
      "['2022-04-23']\n",
      "typ6\n",
      "Lägg in ant_hästar\n",
      "NaN in cat before: 0\n",
      "NaN in cat after: 0\n",
      "predict typ6\n",
      "  Feature Id  Importances\n",
      "0     streck    36.951123\n",
      "1       häst     4.760482\n",
      "2     senast     3.254997\n",
      "typ1\n",
      "Lägg in diff motståndare\n",
      "drop streck\n",
      "NaN in cat before: 0\n",
      "NaN in cat after: 0\n",
      "predict typ1\n",
      "  Feature Id  Importances\n",
      "0      diff2    17.334921\n",
      "1      diff1    16.038588\n",
      "2       häst     5.518587\n",
      "typ9\n",
      "Lägg in ant_hästar\n",
      "Lägg in diff motståndare\n",
      "NaN in cat before: 0\n",
      "NaN in cat after: 0\n",
      "predict typ9\n",
      "  Feature Id  Importances\n",
      "0     streck    24.800184\n",
      "1      diff2    10.990879\n",
      "2       häst     4.192724\n",
      "typ16\n",
      "Lägg in ant_hästar\n",
      "Lägg in diff motståndare\n",
      "NaN in cat before: 0\n",
      "NaN in cat after: 0\n",
      "predict typ16\n",
      "  Feature Id  Importances\n",
      "0     streck    24.800184\n",
      "1      diff2    10.990879\n",
      "2       häst     4.192724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datum</th>\n",
       "      <th>avd</th>\n",
       "      <th>startnr</th>\n",
       "      <th>häst</th>\n",
       "      <th>proba6</th>\n",
       "      <th>kelly6</th>\n",
       "      <th>proba1</th>\n",
       "      <th>kelly1</th>\n",
       "      <th>proba9</th>\n",
       "      <th>kelly9</th>\n",
       "      <th>proba16</th>\n",
       "      <th>kelly16</th>\n",
       "      <th>meta_predict</th>\n",
       "      <th>välj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sweetman</td>\n",
       "      <td>0.372471</td>\n",
       "      <td>0.167920</td>\n",
       "      <td>0.384778</td>\n",
       "      <td>0.184239</td>\n",
       "      <td>0.277854</td>\n",
       "      <td>0.042461</td>\n",
       "      <td>0.277854</td>\n",
       "      <td>0.042461</td>\n",
       "      <td>0.48</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>upper face</td>\n",
       "      <td>0.152854</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>0.217893</td>\n",
       "      <td>0.086780</td>\n",
       "      <td>0.221111</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.221111</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>0.23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>counterfeightr</td>\n",
       "      <td>0.055250</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.023278</td>\n",
       "      <td>-0.012157</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>0.06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>randemar r.d.</td>\n",
       "      <td>0.078147</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>0.049228</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.028722</td>\n",
       "      <td>-0.015610</td>\n",
       "      <td>0.028722</td>\n",
       "      <td>-0.015610</td>\n",
       "      <td>0.06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>ready to go</td>\n",
       "      <td>0.175501</td>\n",
       "      <td>-0.011703</td>\n",
       "      <td>0.098718</td>\n",
       "      <td>-0.105919</td>\n",
       "      <td>0.227283</td>\n",
       "      <td>0.051836</td>\n",
       "      <td>0.227283</td>\n",
       "      <td>0.051836</td>\n",
       "      <td>0.23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>gliding eagle</td>\n",
       "      <td>0.111937</td>\n",
       "      <td>-0.000503</td>\n",
       "      <td>0.156028</td>\n",
       "      <td>0.049171</td>\n",
       "      <td>0.070860</td>\n",
       "      <td>-0.046780</td>\n",
       "      <td>0.070860</td>\n",
       "      <td>-0.046780</td>\n",
       "      <td>0.13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>bull's eyes</td>\n",
       "      <td>0.258106</td>\n",
       "      <td>0.097821</td>\n",
       "      <td>0.152452</td>\n",
       "      <td>-0.030660</td>\n",
       "      <td>0.167605</td>\n",
       "      <td>-0.012233</td>\n",
       "      <td>0.167605</td>\n",
       "      <td>-0.012233</td>\n",
       "      <td>0.07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>sangria pellini</td>\n",
       "      <td>0.059597</td>\n",
       "      <td>0.005932</td>\n",
       "      <td>0.029812</td>\n",
       "      <td>-0.025552</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>-0.011785</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>-0.011785</td>\n",
       "      <td>0.04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>aberdeen face</td>\n",
       "      <td>0.131914</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>0.053313</td>\n",
       "      <td>-0.066550</td>\n",
       "      <td>0.099796</td>\n",
       "      <td>-0.014181</td>\n",
       "      <td>0.099796</td>\n",
       "      <td>-0.014181</td>\n",
       "      <td>0.04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>extreme</td>\n",
       "      <td>0.859681</td>\n",
       "      <td>0.767056</td>\n",
       "      <td>0.938801</td>\n",
       "      <td>0.898403</td>\n",
       "      <td>0.707129</td>\n",
       "      <td>0.513804</td>\n",
       "      <td>0.707129</td>\n",
       "      <td>0.513804</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>night brodde</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>-0.062467</td>\n",
       "      <td>0.053723</td>\n",
       "      <td>-0.029754</td>\n",
       "      <td>0.192955</td>\n",
       "      <td>0.121760</td>\n",
       "      <td>0.192955</td>\n",
       "      <td>0.121760</td>\n",
       "      <td>0.21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>guzz mearas</td>\n",
       "      <td>0.033753</td>\n",
       "      <td>-0.001302</td>\n",
       "      <td>0.030642</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>0.047086</td>\n",
       "      <td>0.012515</td>\n",
       "      <td>0.047086</td>\n",
       "      <td>0.012515</td>\n",
       "      <td>0.04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>donna</td>\n",
       "      <td>0.188748</td>\n",
       "      <td>0.081790</td>\n",
       "      <td>0.175397</td>\n",
       "      <td>0.066680</td>\n",
       "      <td>0.097811</td>\n",
       "      <td>-0.021136</td>\n",
       "      <td>0.097811</td>\n",
       "      <td>-0.021136</td>\n",
       "      <td>0.42</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>kabor boko</td>\n",
       "      <td>0.088827</td>\n",
       "      <td>0.016633</td>\n",
       "      <td>0.031916</td>\n",
       "      <td>-0.044787</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>nanny's girl</td>\n",
       "      <td>0.115807</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>0.051441</td>\n",
       "      <td>-0.073620</td>\n",
       "      <td>0.136567</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.136567</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>readly's dream</td>\n",
       "      <td>0.162520</td>\n",
       "      <td>-0.071963</td>\n",
       "      <td>0.303365</td>\n",
       "      <td>0.108317</td>\n",
       "      <td>0.266781</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.266781</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>velten red red red</td>\n",
       "      <td>0.197712</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.191413</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.308534</td>\n",
       "      <td>0.151536</td>\n",
       "      <td>0.308534</td>\n",
       "      <td>0.151536</td>\n",
       "      <td>0.16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>hannibal face</td>\n",
       "      <td>0.214597</td>\n",
       "      <td>-0.011940</td>\n",
       "      <td>0.432986</td>\n",
       "      <td>0.269440</td>\n",
       "      <td>0.084657</td>\n",
       "      <td>-0.179360</td>\n",
       "      <td>0.084657</td>\n",
       "      <td>-0.179360</td>\n",
       "      <td>0.08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>bahama passion</td>\n",
       "      <td>0.042631</td>\n",
       "      <td>-0.012003</td>\n",
       "      <td>0.074164</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>0.036967</td>\n",
       "      <td>-0.017989</td>\n",
       "      <td>0.036967</td>\n",
       "      <td>-0.017989</td>\n",
       "      <td>0.21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>velten isabel</td>\n",
       "      <td>0.151294</td>\n",
       "      <td>0.043838</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>-0.009647</td>\n",
       "      <td>0.094141</td>\n",
       "      <td>-0.020552</td>\n",
       "      <td>0.094141</td>\n",
       "      <td>-0.020552</td>\n",
       "      <td>0.11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>beawinner</td>\n",
       "      <td>0.124723</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.120722</td>\n",
       "      <td>-0.004396</td>\n",
       "      <td>0.136243</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>0.136243</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>0.06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>honesty</td>\n",
       "      <td>0.182979</td>\n",
       "      <td>0.013390</td>\n",
       "      <td>0.228260</td>\n",
       "      <td>0.068070</td>\n",
       "      <td>0.073549</td>\n",
       "      <td>-0.118754</td>\n",
       "      <td>0.073549</td>\n",
       "      <td>-0.118754</td>\n",
       "      <td>0.04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>titan yoda</td>\n",
       "      <td>0.428181</td>\n",
       "      <td>0.052156</td>\n",
       "      <td>0.614043</td>\n",
       "      <td>0.360240</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>-0.040407</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>-0.040407</td>\n",
       "      <td>0.52</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>bravo sabotage</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>-0.026365</td>\n",
       "      <td>0.081643</td>\n",
       "      <td>-0.039435</td>\n",
       "      <td>0.081643</td>\n",
       "      <td>-0.039435</td>\n",
       "      <td>0.14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         datum  avd  startnr                häst    proba6    kelly6    proba1    kelly1    proba9    kelly9   proba16   kelly16  meta_predict  välj\n",
       "1   2022-04-23    1        2            sweetman  0.372471  0.167920  0.384778  0.184239  0.277854  0.042461  0.277854  0.042461          0.48  True\n",
       "8   2022-04-23    1        9          upper face  0.152854  0.010838  0.217893  0.086780  0.221111  0.090539  0.221111  0.090539          0.23  True\n",
       "9   2022-04-23    1       10      counterfeightr  0.055250  0.020975  0.023278 -0.012157  0.034321 -0.000713  0.034321 -0.000713          0.06  True\n",
       "4   2022-04-23    1        5       randemar r.d.  0.078147  0.036070  0.049228  0.005832  0.028722 -0.015610  0.028722 -0.015610          0.06  True\n",
       "14  2022-04-23    2        3         ready to go  0.175501 -0.011703  0.098718 -0.105919  0.227283  0.051836  0.227283  0.051836          0.23  True\n",
       "15  2022-04-23    2        4       gliding eagle  0.111937 -0.000503  0.156028  0.049171  0.070860 -0.046780  0.070860 -0.046780          0.13  True\n",
       "17  2022-04-23    2        6         bull's eyes  0.258106  0.097821  0.152452 -0.030660  0.167605 -0.012233  0.167605 -0.012233          0.07  True\n",
       "22  2022-04-23    2       12     sangria pellini  0.059597  0.005932  0.029812 -0.025552  0.042836 -0.011785  0.042836 -0.011785          0.04  True\n",
       "21  2022-04-23    2       10       aberdeen face  0.131914  0.022004  0.053313 -0.066550  0.099796 -0.014181  0.099796 -0.014181          0.04  True\n",
       "28  2022-04-23    3        6             extreme  0.859681  0.767056  0.938801  0.898403  0.707129  0.513804  0.707129  0.513804          1.00  True\n",
       "25  2022-04-23    3        3        night brodde  0.023663 -0.062467  0.053723 -0.029754  0.192955  0.121760  0.192955  0.121760          0.21  True\n",
       "30  2022-04-23    3        8         guzz mearas  0.033753 -0.001302  0.030642 -0.004525  0.047086  0.012515  0.047086  0.012515          0.04  True\n",
       "42  2022-04-23    4       10               donna  0.188748  0.081790  0.175397  0.066680  0.097811 -0.021136  0.097811 -0.021136          0.42  True\n",
       "37  2022-04-23    4        5          kabor boko  0.088827  0.016633  0.031916 -0.044787  0.078400  0.005380  0.078400  0.005380          0.08  True\n",
       "41  2022-04-23    4        9        nanny's girl  0.115807 -0.000767  0.051441 -0.073620  0.136567  0.022730  0.136567  0.022730          0.07  True\n",
       "35  2022-04-23    4        3      readly's dream  0.162520 -0.071963  0.303365  0.108317  0.266781  0.061490  0.266781  0.061490          0.06  True\n",
       "46  2022-04-23    5        2  velten red red red  0.197712  0.015551  0.191413  0.007822  0.308534  0.151536  0.308534  0.151536          0.16  True\n",
       "50  2022-04-23    5        6       hannibal face  0.214597 -0.011940  0.432986  0.269440  0.084657 -0.179360  0.084657 -0.179360          0.08  True\n",
       "66  2022-04-23    6       10      bahama passion  0.042631 -0.012003  0.074164  0.021330  0.036967 -0.017989  0.036967 -0.017989          0.21  True\n",
       "61  2022-04-23    6        5       velten isabel  0.151294  0.043838  0.103821 -0.009647  0.094141 -0.020552  0.094141 -0.020552          0.11  True\n",
       "60  2022-04-23    6        4           beawinner  0.124723  0.000175  0.120722 -0.004396  0.136243  0.013334  0.136243  0.013334          0.06  True\n",
       "62  2022-04-23    6        6             honesty  0.182979  0.013390  0.228260  0.068070  0.073549 -0.118754  0.073549 -0.118754          0.04  True\n",
       "73  2022-04-23    7        2          titan yoda  0.428181  0.052156  0.614043  0.360240  0.372340 -0.040407  0.372340 -0.040407          0.52  True\n",
       "77  2022-04-23    7        6      bravo sabotage  0.153208  0.041565  0.093191 -0.026365  0.081643 -0.039435  0.081643 -0.039435          0.14  True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kostnad 288.0\n"
     ]
    }
   ],
   "source": [
    "X = v75_scrape()\n",
    "print(X.datum.unique())\n",
    "df_stack = build_stack_df(X)\n",
    "df_meta = meta_predict(df_stack)\n",
    "df_meta.reset_index(drop=True, inplace=True)\n",
    "veckans_rad = välj_rad(df_meta)\n",
    "# rename columns \n",
    "veckans_rad.rename(columns={'startnr':'nr', 'meta_predict':'Meta', 'välj':'Välj'}, inplace=True)\n",
    "\n",
    "display(veckans_rad[veckans_rad.välj])\n",
    "print('kostnad', veckans_rad.välj.sum()**2/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En massa gammal - kanske reusable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Läs in all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for Learn!\n",
    "df = pd.read_csv('..\\\\all_data.csv')\n",
    "# Följande datum saknar avd==5 och kan inte användas\n",
    "saknas = ['2015-08-15', '2016-08-13', '2017-08-12']\n",
    "df = df[~df.datum.isin(saknas)]\n",
    "X = df.copy()\n",
    "X.drop('plac', axis=1, inplace=True)\n",
    "# X = ordinal_enc(X, 'häst')\n",
    "y = (df.plac == 1)*1   # plac 1 eller 0\n",
    "\n",
    "for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "    X[f] = X[f].str.lower()\n",
    "\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X, cat_features = prepare_for_catboost(X)\n",
    "print('cat_features:', cat_features)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modell för streck_to_odds - skall vara fix och inte ändras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_streck_to_odds(X_):\n",
    "    X = X_.copy()\n",
    "    # import modules for linear regression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "    # import random forest module\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    X_odds = X.loc[X.vodds <= 40]  # remove outliers\n",
    "    ix_break = int(len(X_odds.datum.unique())*0.75)\n",
    "    test_start = X_odds.datum.unique()[ix_break]\n",
    "\n",
    "    X_train, X_test = X_odds[X_odds.datum <\n",
    "                             test_start], X_odds[X_odds.datum >= test_start]\n",
    "    y_train, y_test = X_train['vodds'], X_test['vodds']\n",
    "    X_train = X_train[['streck']].astype(float)\n",
    "    X_test = X_test[['streck']].astype(float)\n",
    "\n",
    "    # make a model of RF\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_predrf = rf.predict(X_test)\n",
    "    # make a model and fit it\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_predlr = linreg.predict(X_test)\n",
    "\n",
    "    # print the coefficients\n",
    "    print('Coefficients:', linreg.coef_)\n",
    "    # print the mean absolute error\n",
    "    print(\"LR Mean absolute error: %.2f\" % mae(y_test, y_predlr))\n",
    "    print(\"RF Mean absolute error: %.2f\" % mae(y_test, y_predrf))\n",
    "\n",
    "    return linreg, rf\n",
    "\n",
    "\n",
    "linreg, rf = model_streck_to_odds(X)   # used in next cell\n",
    "# spara rf\n",
    "import pickle\n",
    "with open('rf_streck_odds.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engångsgrej för att initiera typ-instanserna med learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bara första gången. Initierar Typ-klassen\n",
    "def learn(X_train, y_train, X_test=None, y_test=None, iterations=1000, cat_features=cat_features, verbose=False):\n",
    "    cbc = CatBoostClassifier(iterations=iterations, loss_function='Logloss', eval_metric='AUC', verbose=verbose)\n",
    "    X_train = remove_features(X_train, remove_mer=['avd','datum'])\n",
    "    cat_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "    if X_test is not None:\n",
    "        X_test = remove_features(X_test, remove_mer=['avd', 'datum'])\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "        cbc.fit(train_pool, eval_set=test_pool, early_stopping_rounds=100, use_best_model=True, verbose=verbose)\n",
    "    else:\n",
    "        cbc.fit(train_pool, use_best_model=True, verbose=verbose)\n",
    "    return cbc\n",
    "\n",
    "def beräkna_datum(X,fract=0.75):\n",
    "    ix_break = int(len(X.datum.unique())*fract)\n",
    "    test_start = X.datum.unique()[ix_break]\n",
    "    return test_start\n",
    "\n",
    "if False:    \n",
    "    Xlearn, cat_features= prepare_for_catboost(X)  \n",
    "    # print(Xlearn.columns)\n",
    "    for typ in [typ6, typ1, typ9, typ16]:\n",
    "        print(typ.name)\n",
    "        Xtyp = typ.prepare_for_model(Xlearn)                                 ###########\n",
    "\n",
    "        if not typ.streck:                                                ################\n",
    "            Xtyp.drop('streck', axis=1, inplace=True)\n",
    "            \n",
    "        if True: # använda X_test    \n",
    "            test_start = beräkna_datum(Xtyp)    \n",
    "            X_train, X_test = Xtyp[Xtyp.datum < test_start], Xtyp[Xtyp.datum >= test_start]\n",
    "            y_train, y_test = y[X_train.index], y[X_test.index]\n",
    "            # print('innan learn',X_train.columns)\n",
    "            typ_model = learn(X_train, y_train, X_test, y_test)  ##########\n",
    "            print('best iteration',typ_model.best_iteration_)                             ##########\n",
    "            print('best score',    typ_model.best_score_)                                 ##########\n",
    "        # save model\n",
    "        typ.save_model(typ_model)                                                       ##########                          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapa typ6 till typ16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,cat_features = prepare_for_catboost(X)\n",
    "typ6.learn(X,y, iterations=33) # best iter = 25 {'Logloss': 0.23245952928761984, 'AUC': 0.8262112132692319}\n",
    "typ1.learn(X,y, iterations=39) # best iter = 39 {'Logloss': 0.23278308932319106, 'AUC': 0.826883367187688}\n",
    "typ9.learn(X,y, iterations=37) # best iter = 37 {'Logloss': 0.23312091900160384, 'AUC': 0.8257515762557716}\n",
    "typ16.learn(X,y,iterations=37) # best iter = 37 {'Logloss': 0.23312091900160384, 'AUC': 0.8257515762557716}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapa stack predict med alla typer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack predict for all models\n",
    "def stack_predict(X_, models):\n",
    "    X = X_.copy()\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        X['proba'+nr] = typ.predict(X)\n",
    "        X['kelly'+nr] = kelly(X['proba'+nr], X[['streck']], None)\n",
    "    # cols=X.columns[-8]    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The complete learning process with all steps in stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()  # The meta model\n",
    "    \n",
    "# fit my models on split date for timeseries   \n",
    "print('START fitting and predicting TimeseriesSplit') \n",
    "cross_val_predict=pd.DataFrame()\n",
    "for id_train, id_test in TimeSeriesSplit(n_splits=5).split(df_stack):  \n",
    "    for typ in [typ6, typ1, typ9, typ16]:\n",
    "        typ.learn(df_stack.loc[id_train],y.loc[id_train], iterations=25)\n",
    "    df_pred = stack_predict(df_stack.loc[id_test], [typ6, typ1, typ9, typ16])\n",
    "    df_pred['y']=y.loc[id_test]\n",
    "    cross_val_predict = pd.concat([cross_val_predict, df_pred.iloc[:,-9:]])\n",
    "       \n",
    "print('\\nFitting my models with all data')\n",
    "# final fit with all the available data\n",
    "for typ in [typ6, typ1, typ9, typ16]:\n",
    "    typ.learn(df_stack, y, iterations=20)\n",
    "\n",
    "print('\\nFitting meta_model on predicted above')\n",
    "# fit a rf meta_model on cross_val_predict\n",
    "meta_model = RandomForestClassifier(max_depth=None, n_estimators=100, oob_score=True, verbose=1, n_jobs=10, random_state=2022)\n",
    "meta_model.fit(cross_val_predict.iloc[:, :-1], cross_val_predict.iloc[:, -1])\n",
    "print('OOB_score', meta_model.oob_score_)   # 0.9305314451043094\n",
    "# pickle save stacking\n",
    "pickle.dump(meta_model, open('..\\\\modeller\\\\meta_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on unseen data\n",
    "def unseen_predictions(X_, models, meta_model):\n",
    "    X = X_.copy()\n",
    "    for model in models:\n",
    "        nr = model.name[3:]\n",
    "        X['proba'+nr] = model.predict(X)\n",
    "        X['kelly'+nr] = kelly(X['proba'+nr], X[['streck']], None)\n",
    "        \n",
    "    return(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "\n",
    "# a small test:\n",
    "unseen_predictions(df_stack.iloc[-80:,:], [typ6, typ1, typ9, typ16], meta_model)[:,1],y.iloc[-80:].values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
