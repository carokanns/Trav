{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testar logiken i jupyter innan jag går över till python med streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beskrivning:  \n",
    "\n",
    "- Läser in fejkad web scraping data.  \n",
    "- gör predict proba och kelly för varje modell.  \n",
    "- Använder sedan meta_modellen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moduler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from IPython.display import display\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(df_, remove_mer=[]):\n",
    "    df = df_.copy()\n",
    "    df.drop(['startnr', 'vodds', 'podds', 'bins', 'h1_dat',\n",
    "             'h2_dat', 'h3_dat', 'h4_dat', 'h5_dat'], axis=1, inplace=True)\n",
    "    if remove_mer:\n",
    "        df.drop(remove_mer, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaN for cat_features in X and return (X, cat_features)\n",
    "# ta bort alla features som inte används innan call\n",
    "def prepare_for_catboost(X_, features=[]):\n",
    "    X = X_.copy()\n",
    "    Xtemp = remove_features(X, remove_mer=['avd', 'datum'])\n",
    "    \n",
    "    if len(features) > 0:\n",
    "      Xtemp = Xtemp[features]\n",
    "    # get numerical features and cat_features\n",
    "    num_features = list(Xtemp.select_dtypes(include=[np.number]).columns)\n",
    "    cat_features = list(Xtemp.select_dtypes(include=['object']).columns)\n",
    "\n",
    "    # check cat_features isna\n",
    "    print('NaN in cat before:', X[cat_features].isna().sum()[\n",
    "          X[cat_features].isna().sum() > 0].sort_values(ascending=False).sum())\n",
    "\n",
    "    # impute 'missing' for all NaN in cat_features\n",
    "    X[cat_features] = X[cat_features].fillna('missing')\n",
    "    print('NaN in cat after:', X[cat_features].isna().sum().sum())\n",
    "    return X, cat_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funktioner för att prioritera mellan hästar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa ett Kelly-värde baserat på streck omvandlat till odds\n",
    "def kelly(proba, streck, odds):  # proba = prob winning, streck i % = streck\n",
    "    with open('rf_streck_odds.pkl', 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "\n",
    "    if odds is None:\n",
    "        o = rf.predict(streck.copy())\n",
    "    else:\n",
    "        o = rf.predict(streck.copy())\n",
    "\n",
    "    # for each values > 40 in odds set to 1\n",
    "    o[o > 40] = 1\n",
    "    return (o*proba - (1-proba))/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# för en omgång (ett datum) ta ut största diff för streck per avd \n",
    "# om only_clear=True, enbart för diff >= 25\n",
    "def lista_med_favoriter(df_, ant, only_clear):\n",
    "    df = df_.copy()\n",
    "    min_diff = 25 if only_clear else 0\n",
    "    # sortera på avd,streck\n",
    "    df = df.sort_values(['avd', 'streck'], ascending=[False, False])\n",
    "    diff_list = []\n",
    "    for avd in range(1, 8):\n",
    "        diff = df.loc[df.avd == avd].streck.iloc[0] - \\\n",
    "            df.loc[df.avd == avd].streck.iloc[1]\n",
    "        if diff >= min_diff:\n",
    "            diff_list.append((avd, diff))\n",
    "\n",
    "     # sortera på diff\n",
    "    diff_list = sorted(diff_list, key=lambda x: x[1], reverse=True)\n",
    "    return diff_list[:ant]\n",
    "\n",
    "# temp is a list of tuples (avd, diff). check if avd is in the list\n",
    "def check_avd(avd, temp):\n",
    "    for t in temp:\n",
    "        if t[0] == avd:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_insats(df):\n",
    "    insats = 0\n",
    "    # group by avd\n",
    "    summa = df.groupby('avd').avd.count().prod() / 2\n",
    "    return summa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funktioner som modiferar data beroende på model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# antal hästar per avdeling\n",
    "def lägg_in_antal_hästar(df_):\n",
    "    df = df_.copy()\n",
    "    df['ant_per_lopp'] = None\n",
    "    df['ant_per_lopp'] = df.groupby(['datum', 'avd'])['avd'].transform('count')\n",
    "    return df\n",
    "\n",
    "# mest streck per avdeling\n",
    "def mest_streck(X_, i, datum, avd):\n",
    "    X = X_.copy()\n",
    "    X.sort_values(by=['datum', 'avd', 'streck'], ascending=[\n",
    "                  True, True, False], inplace=True)\n",
    "    return X.loc[(X.datum == datum) & (X.avd == avd), 'streck'].iloc[i]\n",
    "\n",
    "# n flest streck per avd som features\n",
    "def lägg_in_motståndare(X_, ant_motståndare):\n",
    "    X = X_.copy()\n",
    "\n",
    "    # set X['motståndare1'] to largest streck in every avd\n",
    "    grouped = X.groupby(['datum', 'avd'])['streck']\n",
    "    X['motståndare1'] = grouped.transform(max)\n",
    "\n",
    "    for i in range(2, ant_motståndare+1):\n",
    "        # set X['motståndare'+str(i)] to ith largest streck in every avd\n",
    "        X['motståndare' + str(i)] = grouped.transform(lambda x: x.nlargest(i).min())\n",
    "\n",
    "    return X\n",
    "\n",
    "# som föregående men med diff istf faktiska värden\n",
    "def lägg_in_diff_motståndare(X_, motståndare):\n",
    "    X = X_.copy()\n",
    "\n",
    "    # set X['motståndare1'] to largest streck in every avd\n",
    "    grouped = X.groupby(['datum', 'avd'])['streck']\n",
    "    X['diff1'] = grouped.transform(max) - X.streck\n",
    "\n",
    "    for i in range(2, motståndare+1):\n",
    "        # set X['motståndare'+str(i)] to ith largest streck in every avd\n",
    "        X['diff' + str(i)] = grouped.transform(lambda x: x.nlargest(i).min()) - X.streck\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class Typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Typ():\n",
    "    def __init__(self, name, ant_hästar, proba, kelly, motst_ant, motst_diff,  ant_favoriter, only_clear, streck):\n",
    "        assert (motst_diff == False and motst_ant == 0) or (motst_ant > 0)\n",
    "        assert (ant_favoriter == 0 and only_clear == False) or (ant_favoriter > 0)\n",
    "        self.name = name                # string för filnamn mm\n",
    "\n",
    "        # inkludera features eller ej\n",
    "        self.ant_hästar = ant_hästar    # int feature med antal hästar per avdelning\n",
    "        # int inkludera n features med bästa motståndare (streck)\n",
    "        self.motst_ant = motst_ant\n",
    "        self.motst_diff = motst_diff    # bool ovanstående med diff istf fasta värden\n",
    "        self.streck = streck            # bool inkludera feature med streck\n",
    "\n",
    "        # urval av rader\n",
    "        self.proba = proba              # bool för prioritering vid urval av rader\n",
    "        self.kelly = kelly              # bool för prioritering vid urval av rader\n",
    "        # int för hur många favoriter (avd med en häst) som ska användas\n",
    "        self.ant_favoriter = ant_favoriter\n",
    "        self.only_clear = only_clear    # bool för att bara avvända klara favoriter\n",
    "\n",
    "    def load_model(self):\n",
    "        with open('../modeller/'+self.name+'.model', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        return model\n",
    "\n",
    "    def save_model(self, model):\n",
    "        with open('../modeller/'+self.name+'.model', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    def prepare_for_model(self, X_):\n",
    "        # X_ måste ha datum och avd\n",
    "        X = X_.copy()\n",
    "        print(self.name)\n",
    "        if self.ant_hästar:\n",
    "            print('Lägg in ant_hästar')\n",
    "            X = lägg_in_antal_hästar(X)\n",
    "        if self.motst_diff:\n",
    "            print('Lägg in diff motståndare')\n",
    "            X = lägg_in_diff_motståndare(X, self.motst_ant)\n",
    "        elif self.motst_ant > 0:\n",
    "            print('Lägg in motståndare')\n",
    "            X = lägg_in_motståndare(X, self.motst_ant)\n",
    "        # Behåll streck ända tills learn och predict (används för prioritera rader)\n",
    "        return X\n",
    "\n",
    "    def learn(self, X_, y, features, iterations=1000, save=True, verbose=False):\n",
    "        # X_ måste ha datum och avd\n",
    "            \n",
    "        cbc = CatBoostClassifier(\n",
    "            iterations=iterations, loss_function='Logloss', eval_metric='AUC', verbose=verbose)\n",
    "\n",
    "        X = self.prepare_for_model(X_)\n",
    "        if not self.streck:\n",
    "            X.drop('streck', axis=1, inplace=True)\n",
    "\n",
    "        X, cat_features = prepare_for_catboost(X)\n",
    "        \n",
    "        X=remove_features(X, remove_mer=['datum','avd'])\n",
    "        cbc.fit(X, y, cat_features, use_best_model=False)\n",
    "    \n",
    "        print('best score', cbc.best_score_)\n",
    "        if save:\n",
    "            self.save_model(cbc)\n",
    "        return cbc\n",
    "    \n",
    "    def predict(self, X_):\n",
    "        # X_ måste ha datum och avd\n",
    "        X = self.prepare_for_model(X_)\n",
    "        model = self.load_model()\n",
    "        if not self.streck:\n",
    "            print('drop streck')\n",
    "            X.drop('streck', axis=1, inplace=True)\n",
    "            \n",
    "        X, cat_features = prepare_for_catboost(X, model.feature_names_)\n",
    "\n",
    "        # all features in model\n",
    "        X = remove_features(X, remove_mer=['datum', 'avd'])\n",
    "        # print(len(X.columns), len(model.feature_names_))\n",
    "        # print('Diff', set(X.columns) - set(model.feature_names_))\n",
    "        # print('X.columns\\n',X.columns)\n",
    "        # print('model features names\\n',model.feature_names_)\n",
    "        \n",
    "        assert len(X.columns) == len(model.feature_names_), f'len(X.columns)  != len(model.feature_names_) in predict {self.name}'\n",
    "        assert set(X.columns) == set(model.feature_names_), 'features in model and in X not equal'\n",
    "        # assert list(X.columns) == list(model.feature_names_), f'features in model {self.name} and X not in same order'\n",
    "        X = X[model.feature_names_]\n",
    "        print('predict '+self.name)   \n",
    "        print(model.get_feature_importance(prettified=True)[:3])\n",
    "        \n",
    "        return model.predict_proba(X)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skapa modeller\n",
    "#           name, ant_hästar, proba, kelly, motst_ant, motst_diff,  ant_favoriter, only_clear, streck\n",
    "typ6 = Typ('typ6', True,       True, False,     0,      False,          0,            False,    True)\n",
    "typ1 = Typ('typ1', False,      True, False,     2,      True,           2,            True,     False)\n",
    "typ9 = Typ('typ9', True,       True, True,      2,      True,           2,            True,     True)\n",
    "typ16 = Typ('typ16',True,      True, True,      2,      True,           2,            False,    True)\n",
    "\n",
    "typer = [typ6, typ1, typ9, typ16]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning-fasen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gör en scrape på senaste veckan (behövs inte i denna test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Läs in all_data.csv \n",
    "Baka ihop senaste vekan med all_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# läs in data\n",
    "def läs_in_data_för_learning():\n",
    "    df = pd.read_csv('..\\\\all_data.csv')\n",
    "    # Följande datum saknar avd==5 och kan inte användas\n",
    "    saknas = ['2015-08-15', '2016-08-13', '2017-08-12']\n",
    "    df = df[~df.datum.isin(saknas)]\n",
    "    X = df.copy()\n",
    "    X.drop('plac', axis=1, inplace=True)\n",
    "    \n",
    "    y = (df.plac == 1)*1   # plac 1 eller 0\n",
    "\n",
    "    for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        X[f] = X[f].str.lower()\n",
    "\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skapa_stack_learning(X_, y, features, iterations=1000, random_state=2022, verbose=False, save=True):\n",
    "    \"\"\"\n",
    "    Skapar en stack med proba och kelly\n",
    "    X måste ha datum och avd\n",
    "    \"\"\"\n",
    "    X = X_.copy()\n",
    "    stacked_data = pd.DataFrame()\n",
    "    \n",
    "    cbc = CatBoostClassifier(iterations=iterations, loss_function='Logloss', eval_metric='AUC', verbose=verbose)\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        model = typ.learn(X, y, features, iterations=iterations, save=save, verbose=verbose)\n",
    "        stacked_data['proba'+nr] = typ.predict(X) \n",
    "        stacked_data['kelly'+nr] = kelly(stacked_data['proba' + nr], X[['streck']], None)\n",
    "    \n",
    "    # print(stacked_data.columns)\n",
    "    return stacked_data   # enbart stack-info\n",
    "\n",
    "# fit meta_model\n",
    "def learn_meta_model(X,y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    print('\\nFitting meta_model on X with all models predictions')\n",
    "    \n",
    "    meta_model = RandomForestClassifier(max_depth=None, n_estimators=100, oob_score=True, verbose=1, n_jobs=10, random_state=2022)\n",
    "    meta_model.fit(X, y)\n",
    "    \n",
    "    print('OOB_score', meta_model.oob_score_)   # 0.9305314451043094\n",
    "    # pickle save stacking\n",
    "    pickle.dump(meta_model, open('..\\\\modeller\\\\meta.model', 'wb'))\n",
    "    \n",
    "    return meta_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read feature list from a file (ej plac)\n",
    "def read_feature_list(file='../FEATURES.txt'):\n",
    "    with open(file, 'r') as f:\n",
    "        return f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kör learning-skiten här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typ6\n",
      "Lägg in ant_hästar\n",
      "NaN in cat before: 246\n",
      "NaN in cat after: 0\n",
      "best score {'learn': {'Logloss': 0.19120583769208682}}\n",
      "typ6\n",
      "Lägg in ant_hästar\n",
      "NaN in cat before: 246\n",
      "NaN in cat after: 0\n",
      "predict typ6\n",
      "  Feature Id  Importances\n",
      "0     streck    36.951123\n",
      "1       häst     4.760482\n",
      "2     senast     3.254997\n",
      "3    h2_odds     2.871381\n",
      "4         kr     2.248639\n",
      "typ1\n",
      "Lägg in diff motståndare\n",
      "NaN in cat before: 246\n",
      "NaN in cat after: 0\n",
      "best score {'learn': {'Logloss': 0.19606831883977294}}\n",
      "typ1\n",
      "Lägg in diff motståndare\n",
      "drop streck\n",
      "NaN in cat before: 246\n",
      "NaN in cat after: 0\n",
      "predict typ1\n",
      "  Feature Id  Importances\n",
      "0      diff2    17.334921\n",
      "1      diff1    16.038588\n",
      "2       häst     5.518587\n",
      "3         kr     2.706512\n",
      "4       pris     2.592018\n",
      "typ9\n",
      "Lägg in ant_hästar\n",
      "Lägg in diff motståndare\n",
      "NaN in cat before: 246\n",
      "NaN in cat after: 0\n",
      "best score {'learn': {'Logloss': 0.18883593142791752}}\n",
      "typ9\n",
      "Lägg in ant_hästar\n",
      "Lägg in diff motståndare\n",
      "NaN in cat before: 246\n",
      "NaN in cat after: 0\n",
      "predict typ9\n",
      "  Feature Id  Importances\n",
      "0     streck    24.800184\n",
      "1      diff2    10.990879\n",
      "2       häst     4.192724\n",
      "3    h5_odds     3.833646\n",
      "4    h1_perf     3.010518\n",
      "typ16\n",
      "Lägg in ant_hästar\n",
      "Lägg in diff motståndare\n",
      "NaN in cat before: 246\n",
      "NaN in cat after: 0\n",
      "best score {'learn': {'Logloss': 0.18883593142791752}}\n",
      "typ16\n",
      "Lägg in ant_hästar\n",
      "Lägg in diff motståndare\n",
      "NaN in cat before: 246\n",
      "NaN in cat after: 0\n",
      "predict typ16\n",
      "  Feature Id  Importances\n",
      "0     streck    24.800184\n",
      "1      diff2    10.990879\n",
      "2       häst     4.192724\n",
      "3    h5_odds     3.833646\n",
      "4    h1_perf     3.010518\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.9459237643625752\n"
     ]
    }
   ],
   "source": [
    "FEATURES = read_feature_list(\"../FEATURES.txt\")\n",
    "\n",
    "X_train, y_train = läs_in_data_för_learning()\n",
    "assert X_train.shape[1] == len(FEATURES), f'X_train.shape[1] {X_train.shape[1]} != len(FEATURES) {len(FEATURES)}'\n",
    "assert set(X_train.columns) == set(FEATURES), f'set(X_train.columns) {set(X_train.columns)} != set(FEATURES) {set(FEATURES)}'\n",
    "X_train = X_train[FEATURES]  # för att få kolumner i rätt ordning\n",
    "X_stacked = skapa_stack_learning(X_train, y_train, FEATURES, iterations=100,random_state=2022, verbose=False, save=True)\n",
    "# display(X_stacked)\n",
    "meta_model = learn_meta_model(X_stacked, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spela-fasen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fejkad Scrape-funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    df = pd.read_csv('../sparad_scrape.csv')\n",
    "    for f in ['häst','bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        df[f] = df[f].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativ metod\n",
    "# Ta fram rader för varje typ enligt test-resultaten innan\n",
    "# låt meta_model välja mellan typerna - hur? Hur maximer insatsen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion som bygger stack-data från modellerna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# för stacking ta med alla hästar per typ och proba plus kelly\n",
    "def build_stack_df(X_):\n",
    "    X = X_.copy()\n",
    "    stacked_data = X[['datum','avd', 'startnr','häst']].copy()\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        stacked_data['proba'+nr] = typ.predict(X)\n",
    "        stacked_data['kelly'+nr] = kelly(stacked_data['proba'+nr], X[['streck']], None)\n",
    "    return stacked_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion där meta_model för predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_predict(X_):\n",
    "    # X_ innehåller även datum,startnr och avd\n",
    "    extra = ['datum', 'avd', 'startnr', 'häst']\n",
    "    assert list(X_.columns[:4]) == extra, 'meta_model måste ha datum, avd och startnr, häst för att kunna välja'\n",
    "    X = X_.copy()\n",
    "    with open('../modeller\\\\meta.model', 'rb') as f:\n",
    "        meta_model = pickle.load(f)\n",
    "        \n",
    "    # print(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "    X['meta_predict'] = meta_model.predict_proba(X.iloc[:,-8:])[:,1]\n",
    "    my_columns = extra + list(X.columns)[-9:] \n",
    "    \n",
    "    return X[my_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion som väljer rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_cost(antal_rader):\n",
    "    cost = (antal_rader**2)/2\n",
    "    return antal_rader,cost\n",
    "\n",
    "def välj_rad(X_):\n",
    "    \n",
    "    max_insats=320\n",
    "    veckans_rad = X_.copy()\n",
    "    veckans_rad['välj'] = False\n",
    "\n",
    "    for avd in veckans_rad.avd.unique():\n",
    "        max_pred = veckans_rad[veckans_rad.avd == avd]['meta_predict'].max()\n",
    "        veckans_rad.loc[(veckans_rad.avd == avd) & (veckans_rad.meta_predict == max_pred), 'välj'] = True\n",
    "    antal_rader=1    \n",
    "    veckans_rad = veckans_rad.sort_values(by=['meta_predict'], ascending=False)\n",
    "    \n",
    "    # 3. Använda ensam favorit för ett par avd? Kolla test-resultat\n",
    "    # for each row in rad, välj=True if select_func(cost,avd) == True\n",
    "    cost = antal_rader*0.5\n",
    "    for i, row in veckans_rad.iterrows():\n",
    "        new_antal,new_cost = comp_cost(antal_rader+1)\n",
    "        # print(the_cost)\n",
    "        if new_cost > max_insats:\n",
    "            break\n",
    "        \n",
    "        antal_rader = new_antal\n",
    "        cost = new_cost\n",
    "        veckans_rad.loc[i, 'välj'] = True\n",
    "        # print(cost)\n",
    "    veckans_rad.sort_values(by=['välj', 'avd'], ascending=[False, True], inplace=True)\n",
    "\n",
    "    return veckans_rad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kör hela välj-rad-skiten här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-03-12']\n",
      "typ6\n",
      "Lägg in ant_hästar\n",
      "NaN in cat before: 0\n",
      "NaN in cat after: 0\n",
      "predict typ6\n",
      "  Feature Id  Importances\n",
      "0     streck    36.951123\n",
      "1       häst     4.760482\n",
      "2     senast     3.254997\n",
      "3    h2_odds     2.871381\n",
      "4         kr     2.248639\n",
      "typ1\n",
      "Lägg in diff motståndare\n",
      "drop streck\n",
      "NaN in cat before: 0\n",
      "NaN in cat after: 0\n",
      "predict typ1\n",
      "  Feature Id  Importances\n",
      "0      diff2    17.334921\n",
      "1      diff1    16.038588\n",
      "2       häst     5.518587\n",
      "3         kr     2.706512\n",
      "4       pris     2.592018\n",
      "typ9\n",
      "Lägg in ant_hästar\n",
      "Lägg in diff motståndare\n",
      "NaN in cat before: 0\n",
      "NaN in cat after: 0\n",
      "predict typ9\n",
      "  Feature Id  Importances\n",
      "0     streck    24.800184\n",
      "1      diff2    10.990879\n",
      "2       häst     4.192724\n",
      "3    h5_odds     3.833646\n",
      "4    h1_perf     3.010518\n",
      "typ16\n",
      "Lägg in ant_hästar\n",
      "Lägg in diff motståndare\n",
      "NaN in cat before: 0\n",
      "NaN in cat after: 0\n",
      "predict typ16\n",
      "  Feature Id  Importances\n",
      "0     streck    24.800184\n",
      "1      diff2    10.990879\n",
      "2       häst     4.192724\n",
      "3    h5_odds     3.833646\n",
      "4    h1_perf     3.010518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datum</th>\n",
       "      <th>avd</th>\n",
       "      <th>startnr</th>\n",
       "      <th>häst</th>\n",
       "      <th>proba6</th>\n",
       "      <th>kelly6</th>\n",
       "      <th>proba1</th>\n",
       "      <th>kelly1</th>\n",
       "      <th>proba9</th>\n",
       "      <th>kelly9</th>\n",
       "      <th>proba16</th>\n",
       "      <th>kelly16</th>\n",
       "      <th>meta_predict</th>\n",
       "      <th>välj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>dear friend</td>\n",
       "      <td>0.478491</td>\n",
       "      <td>0.225132</td>\n",
       "      <td>0.491550</td>\n",
       "      <td>0.244536</td>\n",
       "      <td>0.417039</td>\n",
       "      <td>0.133826</td>\n",
       "      <td>0.417039</td>\n",
       "      <td>0.133826</td>\n",
       "      <td>0.86</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>chablis ribb</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>-0.087249</td>\n",
       "      <td>0.043265</td>\n",
       "      <td>-0.053881</td>\n",
       "      <td>0.149861</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>0.149861</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>0.12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>borups tornado</td>\n",
       "      <td>0.501085</td>\n",
       "      <td>0.397525</td>\n",
       "      <td>0.304825</td>\n",
       "      <td>0.160527</td>\n",
       "      <td>0.163491</td>\n",
       "      <td>-0.010143</td>\n",
       "      <td>0.163491</td>\n",
       "      <td>-0.010143</td>\n",
       "      <td>0.86</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>alert vendil</td>\n",
       "      <td>0.054399</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.054385</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.065319</td>\n",
       "      <td>0.011981</td>\n",
       "      <td>0.065319</td>\n",
       "      <td>0.011981</td>\n",
       "      <td>0.03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>tycoon conway hall</td>\n",
       "      <td>0.123378</td>\n",
       "      <td>0.091575</td>\n",
       "      <td>0.136737</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.047318</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.047318</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>stoletheshow</td>\n",
       "      <td>0.309036</td>\n",
       "      <td>0.040401</td>\n",
       "      <td>0.291468</td>\n",
       "      <td>0.016003</td>\n",
       "      <td>0.254073</td>\n",
       "      <td>-0.035931</td>\n",
       "      <td>0.254073</td>\n",
       "      <td>-0.035931</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>upstate face</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>-0.092339</td>\n",
       "      <td>0.022308</td>\n",
       "      <td>-0.141592</td>\n",
       "      <td>0.335138</td>\n",
       "      <td>0.223681</td>\n",
       "      <td>0.335138</td>\n",
       "      <td>0.223681</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>niky flax</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>-0.023738</td>\n",
       "      <td>0.038771</td>\n",
       "      <td>0.011463</td>\n",
       "      <td>0.010983</td>\n",
       "      <td>-0.017114</td>\n",
       "      <td>0.010983</td>\n",
       "      <td>-0.017114</td>\n",
       "      <td>0.04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>pacific face</td>\n",
       "      <td>0.026313</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>-0.026427</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>-0.023920</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>-0.023920</td>\n",
       "      <td>0.03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>listas tinge ling</td>\n",
       "      <td>0.120025</td>\n",
       "      <td>0.050303</td>\n",
       "      <td>0.110526</td>\n",
       "      <td>0.040050</td>\n",
       "      <td>0.113913</td>\n",
       "      <td>0.043707</td>\n",
       "      <td>0.113913</td>\n",
       "      <td>0.043707</td>\n",
       "      <td>0.76</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>magical mile</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.108652</td>\n",
       "      <td>0.211564</td>\n",
       "      <td>0.032549</td>\n",
       "      <td>0.183126</td>\n",
       "      <td>-0.002346</td>\n",
       "      <td>0.183126</td>\n",
       "      <td>-0.002346</td>\n",
       "      <td>0.09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>genie am</td>\n",
       "      <td>0.099697</td>\n",
       "      <td>0.038369</td>\n",
       "      <td>0.038666</td>\n",
       "      <td>-0.026819</td>\n",
       "      <td>0.101283</td>\n",
       "      <td>0.040063</td>\n",
       "      <td>0.101283</td>\n",
       "      <td>0.040063</td>\n",
       "      <td>0.06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>diversity pellini</td>\n",
       "      <td>0.212205</td>\n",
       "      <td>0.067921</td>\n",
       "      <td>0.192114</td>\n",
       "      <td>0.044150</td>\n",
       "      <td>0.156643</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.156643</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>lisa lisieux</td>\n",
       "      <td>0.160683</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.134972</td>\n",
       "      <td>-0.023457</td>\n",
       "      <td>0.135634</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>0.135634</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>0.03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>amalencius b.b.</td>\n",
       "      <td>0.623815</td>\n",
       "      <td>0.375494</td>\n",
       "      <td>0.817402</td>\n",
       "      <td>0.696868</td>\n",
       "      <td>0.677072</td>\n",
       "      <td>0.463906</td>\n",
       "      <td>0.677072</td>\n",
       "      <td>0.463906</td>\n",
       "      <td>0.99</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>best ofdream trio</td>\n",
       "      <td>0.273556</td>\n",
       "      <td>0.193507</td>\n",
       "      <td>0.093918</td>\n",
       "      <td>-0.005924</td>\n",
       "      <td>0.173382</td>\n",
       "      <td>0.082295</td>\n",
       "      <td>0.173382</td>\n",
       "      <td>0.082295</td>\n",
       "      <td>0.16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>cala mayor de b.</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>-0.012117</td>\n",
       "      <td>0.053537</td>\n",
       "      <td>0.024049</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>-0.009874</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>-0.009874</td>\n",
       "      <td>0.63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>olga tooma</td>\n",
       "      <td>0.176485</td>\n",
       "      <td>0.085741</td>\n",
       "      <td>0.134467</td>\n",
       "      <td>0.039092</td>\n",
       "      <td>0.150619</td>\n",
       "      <td>0.057024</td>\n",
       "      <td>0.150619</td>\n",
       "      <td>0.057024</td>\n",
       "      <td>0.16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>jeopardy</td>\n",
       "      <td>0.131614</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.090707</td>\n",
       "      <td>-0.038681</td>\n",
       "      <td>0.186035</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.186035</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>use face</td>\n",
       "      <td>0.082013</td>\n",
       "      <td>-0.034215</td>\n",
       "      <td>0.113125</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>-0.043540</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>-0.043540</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>love you sweden</td>\n",
       "      <td>0.187554</td>\n",
       "      <td>-0.017190</td>\n",
       "      <td>0.234387</td>\n",
       "      <td>0.041445</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>-0.001578</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>-0.001578</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>unico broline</td>\n",
       "      <td>0.277928</td>\n",
       "      <td>0.121925</td>\n",
       "      <td>0.328757</td>\n",
       "      <td>0.183736</td>\n",
       "      <td>0.196334</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.196334</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.83</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>sweetman</td>\n",
       "      <td>0.467574</td>\n",
       "      <td>0.298496</td>\n",
       "      <td>0.328481</td>\n",
       "      <td>0.115233</td>\n",
       "      <td>0.315977</td>\n",
       "      <td>0.098758</td>\n",
       "      <td>0.315977</td>\n",
       "      <td>0.098758</td>\n",
       "      <td>0.28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>devs daffodil</td>\n",
       "      <td>0.067805</td>\n",
       "      <td>0.014609</td>\n",
       "      <td>0.050618</td>\n",
       "      <td>-0.003559</td>\n",
       "      <td>0.095576</td>\n",
       "      <td>0.043964</td>\n",
       "      <td>0.095576</td>\n",
       "      <td>0.043964</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         datum  avd  startnr                häst    proba6    kelly6    proba1    kelly1    proba9    kelly9   proba16   kelly16  meta_predict  välj\n",
       "5   2022-03-12    1        6         dear friend  0.478491  0.225132  0.491550  0.244536  0.417039  0.133826  0.417039  0.133826          0.86  True\n",
       "1   2022-03-12    1        2        chablis ribb  0.012974 -0.087249  0.043265 -0.053881  0.149861  0.063538  0.149861  0.063538          0.12  True\n",
       "13  2022-03-12    2        5      borups tornado  0.501085  0.397525  0.304825  0.160527  0.163491 -0.010143  0.163491 -0.010143          0.86  True\n",
       "19  2022-03-12    2       11        alert vendil  0.054399  0.000438  0.054385  0.000423  0.065319  0.011981  0.065319  0.011981          0.03  True\n",
       "23  2022-03-12    3        3  tycoon conway hall  0.123378  0.091575  0.136737  0.105418  0.047318  0.012755  0.047318  0.012755          0.75  True\n",
       "30  2022-03-12    3       10        stoletheshow  0.309036  0.040401  0.291468  0.016003  0.254073 -0.035931  0.254073 -0.035931          0.05  True\n",
       "27  2022-03-12    3        7        upstate face  0.064489 -0.092339  0.022308 -0.141592  0.335138  0.223681  0.335138  0.223681          0.05  True\n",
       "28  2022-03-12    3        8           niky flax  0.004543 -0.023738  0.038771  0.011463  0.010983 -0.017114  0.010983 -0.017114          0.04  True\n",
       "29  2022-03-12    3        9        pacific face  0.026313 -0.001349  0.001928 -0.026427  0.004366 -0.023920  0.004366 -0.023920          0.03  True\n",
       "41  2022-03-12    4       12   listas tinge ling  0.120025  0.050303  0.110526  0.040050  0.113913  0.043707  0.113913  0.043707          0.76  True\n",
       "34  2022-03-12    4        3        magical mile  0.273585  0.108652  0.211564  0.032549  0.183126 -0.002346  0.183126 -0.002346          0.09  True\n",
       "42  2022-03-12    4       13            genie am  0.099697  0.038369  0.038666 -0.026819  0.101283  0.040063  0.101283  0.040063          0.06  True\n",
       "40  2022-03-12    4       10   diversity pellini  0.212205  0.067921  0.192114  0.044150  0.156643  0.002182  0.156643  0.002182          0.06  True\n",
       "43  2022-03-12    4       14        lisa lisieux  0.160683  0.006963  0.134972 -0.023457  0.135634 -0.022674  0.135634 -0.022674          0.03  True\n",
       "50  2022-03-12    5        6     amalencius b.b.  0.623815  0.375494  0.817402  0.696868  0.677072  0.463906  0.677072  0.463906          0.99  True\n",
       "56  2022-03-12    5       12   best ofdream trio  0.273556  0.193507  0.093918 -0.005924  0.173382  0.082295  0.173382  0.082295          0.16  True\n",
       "62  2022-03-12    6        7    cala mayor de b.  0.018464 -0.012117  0.053537  0.024049  0.020639 -0.009874  0.020639 -0.009874          0.63  True\n",
       "61  2022-03-12    6        6          olga tooma  0.176485  0.085741  0.134467  0.039092  0.150619  0.057024  0.150619  0.057024          0.16  True\n",
       "63  2022-03-12    6        8            jeopardy  0.131614  0.008047  0.090707 -0.038681  0.186035  0.070211  0.186035  0.070211          0.07  True\n",
       "66  2022-03-12    6       11            use face  0.082013 -0.034215  0.113125  0.000836  0.073736 -0.043540  0.073736 -0.043540          0.05  True\n",
       "60  2022-03-12    6        5     love you sweden  0.187554 -0.017190  0.234387  0.041445  0.200023 -0.001578  0.200023 -0.001578          0.05  True\n",
       "80  2022-03-12    7       10       unico broline  0.277928  0.121925  0.328757  0.183736  0.196334  0.022702  0.196334  0.022702          0.83  True\n",
       "75  2022-03-12    7        5            sweetman  0.467574  0.298496  0.328481  0.115233  0.315977  0.098758  0.315977  0.098758          0.28  True\n",
       "79  2022-03-12    7        9       devs daffodil  0.067805  0.014609  0.050618 -0.003559  0.095576  0.043964  0.095576  0.043964          0.05  True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kostnad 288.0\n"
     ]
    }
   ],
   "source": [
    "X = scrape()\n",
    "print(X.datum.unique())\n",
    "df_stack = build_stack_df(X)\n",
    "df_meta = meta_predict(df_stack)\n",
    "df_meta.reset_index(drop=True, inplace=True)\n",
    "veckans_rad = välj_rad(df_meta)\n",
    "\n",
    "display(veckans_rad[veckans_rad.välj])\n",
    "print('kostnad', veckans_rad.välj.sum()**2/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En massa gammal - kanske reusable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Läs in all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for Learn!\n",
    "df = pd.read_csv('..\\\\all_data.csv')\n",
    "# Följande datum saknar avd==5 och kan inte användas\n",
    "saknas = ['2015-08-15', '2016-08-13', '2017-08-12']\n",
    "df = df[~df.datum.isin(saknas)]\n",
    "X = df.copy()\n",
    "X.drop('plac', axis=1, inplace=True)\n",
    "# X = ordinal_enc(X, 'häst')\n",
    "y = (df.plac == 1)*1   # plac 1 eller 0\n",
    "\n",
    "for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "    X[f] = X[f].str.lower()\n",
    "\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X, cat_features = prepare_for_catboost(X)\n",
    "print('cat_features:', cat_features)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modell för streck_to_odds - skall vara fix och inte ändras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_streck_to_odds(X_):\n",
    "    X = X_.copy()\n",
    "    # import modules for linear regression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "    # import random forest module\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    X_odds = X.loc[X.vodds <= 40]  # remove outliers\n",
    "    ix_break = int(len(X_odds.datum.unique())*0.75)\n",
    "    test_start = X_odds.datum.unique()[ix_break]\n",
    "\n",
    "    X_train, X_test = X_odds[X_odds.datum <\n",
    "                             test_start], X_odds[X_odds.datum >= test_start]\n",
    "    y_train, y_test = X_train['vodds'], X_test['vodds']\n",
    "    X_train = X_train[['streck']].astype(float)\n",
    "    X_test = X_test[['streck']].astype(float)\n",
    "\n",
    "    # make a model of RF\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_predrf = rf.predict(X_test)\n",
    "    # make a model and fit it\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_predlr = linreg.predict(X_test)\n",
    "\n",
    "    # print the coefficients\n",
    "    print('Coefficients:', linreg.coef_)\n",
    "    # print the mean absolute error\n",
    "    print(\"LR Mean absolute error: %.2f\" % mae(y_test, y_predlr))\n",
    "    print(\"RF Mean absolute error: %.2f\" % mae(y_test, y_predrf))\n",
    "\n",
    "    return linreg, rf\n",
    "\n",
    "\n",
    "linreg, rf = model_streck_to_odds(X)   # used in next cell\n",
    "# spara rf\n",
    "import pickle\n",
    "with open('rf_streck_odds.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engångsgrej för att initiera typ-instanserna med learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bara första gången. Initierar Typ-klassen\n",
    "def learn(X_train, y_train, X_test=None, y_test=None, iterations=1000, cat_features=cat_features, verbose=False):\n",
    "    cbc = CatBoostClassifier(iterations=iterations, loss_function='Logloss', eval_metric='AUC', verbose=verbose)\n",
    "    X_train = remove_features(X_train, remove_mer=['avd','datum'])\n",
    "    cat_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "    if X_test is not None:\n",
    "        X_test = remove_features(X_test, remove_mer=['avd', 'datum'])\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "        cbc.fit(train_pool, eval_set=test_pool, early_stopping_rounds=100, use_best_model=True, verbose=verbose)\n",
    "    else:\n",
    "        cbc.fit(train_pool, use_best_model=True, verbose=verbose)\n",
    "    return cbc\n",
    "\n",
    "def beräkna_datum(X,fract=0.75):\n",
    "    ix_break = int(len(X.datum.unique())*fract)\n",
    "    test_start = X.datum.unique()[ix_break]\n",
    "    return test_start\n",
    "\n",
    "if False:    \n",
    "    Xlearn, cat_features= prepare_for_catboost(X)  \n",
    "    # print(Xlearn.columns)\n",
    "    for typ in [typ6, typ1, typ9, typ16]:\n",
    "        print(typ.name)\n",
    "        Xtyp = typ.prepare_for_model(Xlearn)                                 ###########\n",
    "\n",
    "        if not typ.streck:                                                ################\n",
    "            Xtyp.drop('streck', axis=1, inplace=True)\n",
    "            \n",
    "        if True: # använda X_test    \n",
    "            test_start = beräkna_datum(Xtyp)    \n",
    "            X_train, X_test = Xtyp[Xtyp.datum < test_start], Xtyp[Xtyp.datum >= test_start]\n",
    "            y_train, y_test = y[X_train.index], y[X_test.index]\n",
    "            # print('innan learn',X_train.columns)\n",
    "            typ_model = learn(X_train, y_train, X_test, y_test)  ##########\n",
    "            print('best iteration',typ_model.best_iteration_)                             ##########\n",
    "            print('best score',    typ_model.best_score_)                                 ##########\n",
    "        # save model\n",
    "        typ.save_model(typ_model)                                                       ##########                          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapa typ6 till typ16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,cat_features = prepare_for_catboost(X)\n",
    "typ6.learn(X,y, iterations=33) # best iter = 25 {'Logloss': 0.23245952928761984, 'AUC': 0.8262112132692319}\n",
    "typ1.learn(X,y, iterations=39) # best iter = 39 {'Logloss': 0.23278308932319106, 'AUC': 0.826883367187688}\n",
    "typ9.learn(X,y, iterations=37) # best iter = 37 {'Logloss': 0.23312091900160384, 'AUC': 0.8257515762557716}\n",
    "typ16.learn(X,y,iterations=37) # best iter = 37 {'Logloss': 0.23312091900160384, 'AUC': 0.8257515762557716}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapa stack predict med alla typer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack predict for all models\n",
    "def stack_predict(X_, models):\n",
    "    X = X_.copy()\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        X['proba'+nr] = typ.predict(X)\n",
    "        X['kelly'+nr] = kelly(X['proba'+nr], X[['streck']], None)\n",
    "    # cols=X.columns[-8]    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learn med TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# for train_index, test_index in tscv.split(df_stack):\n",
    "#    print(\"TRAIN:\", train_index[-1], \"TEST:\", test_index[0])\n",
    "#    X_train = df_stack.loc[train_index]\n",
    "#    X_test = df_stack.loc[test_index]\n",
    "#    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The complete learning process with all steps in stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()  # The meta model\n",
    "    \n",
    "# fit my models on split date for timeseries   \n",
    "print('START fitting and predicting TimeseriesSplit') \n",
    "cross_val_predict=pd.DataFrame()\n",
    "for id_train, id_test in TimeSeriesSplit(n_splits=5).split(df_stack):  \n",
    "    for typ in [typ6, typ1, typ9, typ16]:\n",
    "        typ.learn(df_stack.loc[id_train],y.loc[id_train], iterations=25)\n",
    "    df_pred = stack_predict(df_stack.loc[id_test], [typ6, typ1, typ9, typ16])\n",
    "    df_pred['y']=y.loc[id_test]\n",
    "    cross_val_predict = pd.concat([cross_val_predict, df_pred.iloc[:,-9:]])\n",
    "       \n",
    "print('\\nFitting my models with all data')\n",
    "# final fit with all the available data\n",
    "for typ in [typ6, typ1, typ9, typ16]:\n",
    "    typ.learn(df_stack, y, iterations=20)\n",
    "\n",
    "print('\\nFitting meta_model on predicted above')\n",
    "# fit a rf meta_model on cross_val_predict\n",
    "meta_model = RandomForestClassifier(max_depth=None, n_estimators=100, oob_score=True, verbose=1, n_jobs=10, random_state=2022)\n",
    "meta_model.fit(cross_val_predict.iloc[:, :-1], cross_val_predict.iloc[:, -1])\n",
    "print('OOB_score', meta_model.oob_score_)   # 0.9305314451043094\n",
    "# pickle save stacking\n",
    "pickle.dump(meta_model, open('..\\\\modeller\\\\meta_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on unseen data\n",
    "def unseen_predictions(X_, models, meta_model):\n",
    "    X = X_.copy()\n",
    "    for model in models:\n",
    "        nr = model.name[3:]\n",
    "        X['proba'+nr] = model.predict(X)\n",
    "        X['kelly'+nr] = kelly(X['proba'+nr], X[['streck']], None)\n",
    "        \n",
    "    return(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "\n",
    "# a small test:\n",
    "unseen_predictions(df_stack.iloc[-80:,:], [typ6, typ1, typ9, typ16], meta_model)[:,1],y.iloc[-80:].values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
