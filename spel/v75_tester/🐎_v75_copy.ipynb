{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Detta är en kopia av 1_🐎_v75.py\n",
    "##########################################################################################\n",
    "\n",
    "#%%\n",
    "\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "import logging\n",
    "import typ as tp\n",
    "import V75_scraping as vs\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import sys\n",
    "# import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import concurrent.futures\n",
    "import time\n",
    "import datetime\n",
    "import sklearn\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "\n",
    "sys.path.append(\n",
    "    'C:\\\\Users\\\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel\\\\modeller\\\\')\n",
    "pref = ''\n",
    "logging.basicConfig(filename='app.log', filemode='w',\n",
    "                    format='%(name)s - %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Här följer streamlit grejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "#  st.set_page_config(page_title=\"v75 Spel\", page_icon=\"🐎\")\n",
    "#  st.sidebar.header(\"🐎 V75 Spel\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ tas bort ############\n",
    "def remove_features(df_, remove_mer=[]):\n",
    "    df = df_.copy()\n",
    "    df.drop(['startnr', 'vodds', 'podds', 'bins', 'h1_dat',\n",
    "            'h2_dat', 'h3_dat', 'h4_dat', 'h5_dat'], axis=1, inplace=True)\n",
    "    if remove_mer:\n",
    "        df.drop(remove_mer, axis=1, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def v75_scraping(full=True):\n",
    "    if not full:\n",
    "        # st.write(\"ANVÄNDER SPARAT\")\n",
    "        df = pd.read_csv('sparad_scrape_spela.csv')\n",
    "        try:\n",
    "            df.drop(['plac'], axis=1, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        print('start vs.v75_scraping')\n",
    "        df = vs.v75_scraping(resultat=False, history=True, headless=True)\n",
    "\n",
    "    for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        df[f] = df[f].str.lower()\n",
    "    return df\n",
    "\n",
    "    # Alternativ metod\n",
    "    # Ta fram rader för varje typ enligt test-resultaten innan\n",
    "    # låt meta_model välja mellan typerna tills max insats, sorterat på meta_proba\n",
    "\n",
    "# Funktioner för att prioritera mellan hästar\n",
    "# Skapa ett Kelly-värde baserat på streck omvandlat till odds\n",
    "\n",
    "\n",
    "def kelly(proba, streck, odds):  # proba = prob winning, streck i % = streck\n",
    "    with open('rf_streck_odds.pkl', 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "\n",
    "    if odds is None:\n",
    "        o = rf.predict(streck.copy())\n",
    "    else:\n",
    "        o = rf.predict(streck.copy())\n",
    "\n",
    "    # for each values > 40 in odds set to 1\n",
    "    o[o > 40] = 1\n",
    "    return (o*proba - (1-proba))/o\n",
    "\n",
    "# för en omgång (ett datum) ta ut största diff för streck per avd\n",
    "# om only_clear=True, enbart för diff >= 25\n",
    "\n",
    "\n",
    "def lista_med_favoriter(df_, ant, only_clear):\n",
    "    df = df_.copy()\n",
    "    min_diff = 25 if only_clear else 0\n",
    "    # sortera på avd,streck\n",
    "    df = df.sort_values(['avd', 'streck'], ascending=[False, False])\n",
    "    diff_list = []\n",
    "    for avd in range(1, 8):\n",
    "        diff = df.loc[df.avd == avd].streck.iloc[0] - \\\n",
    "            df.loc[df.avd == avd].streck.iloc[1]\n",
    "        if diff >= min_diff:\n",
    "            diff_list.append((avd, diff))\n",
    "\n",
    "     # sortera på diff\n",
    "    diff_list = sorted(diff_list, key=lambda x: x[1], reverse=True)\n",
    "    return diff_list[:ant]\n",
    "\n",
    "# temp is a list of tuples (avd, diff). check if avd is in the list\n",
    "\n",
    "\n",
    "def check_avd(avd, temp):\n",
    "    for t in temp:\n",
    "        if t[0] == avd:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def compute_total_insats(df):\n",
    "    summa = df.groupby('avd').avd.count().prod() / 2\n",
    "    return summa\n",
    "\n",
    "# feature med antal hästar per avdeling\n",
    "\n",
    "\n",
    "def lägg_in_antal_hästar(df_):\n",
    "    df = df_.copy()\n",
    "    df['ant_per_lopp'] = None\n",
    "    df['ant_per_lopp'] = df.groupby(['datum', 'avd'])['avd'].transform('count')\n",
    "    return df\n",
    "\n",
    "# räkna ut mest streck per avdeling\n",
    "\n",
    "\n",
    "def mest_streck(X_, i, datum, avd):\n",
    "    X = X_.copy()\n",
    "    X.sort_values(by=['datum', 'avd', 'streck'], ascending=[\n",
    "                  True, True, False], inplace=True)\n",
    "    return X.loc[(X.datum == datum) & (X.avd == avd), 'streck'].iloc[i]\n",
    "\n",
    "# n flest streck per avd som features\n",
    "\n",
    "\n",
    "def lägg_in_motståndare(X_, ant_motståndare):\n",
    "    X = X_.copy()\n",
    "\n",
    "    # set X['motståndare1'] to largest streck in every avd\n",
    "    grouped = X.groupby(['datum', 'avd'])['streck']\n",
    "    X['motståndare1'] = grouped.transform(max)\n",
    "\n",
    "    for i in range(2, ant_motståndare+1):\n",
    "        # set X['motståndare'+str(i)] to ith largest streck in every avd\n",
    "        X['motståndare' +\n",
    "            str(i)] = grouped.transform(lambda x: x.nlargest(i).min())\n",
    "\n",
    "    return X\n",
    "\n",
    "# som föregående men med diff istf faktiska värden\n",
    "\n",
    "\n",
    "def lägg_in_diff_motståndare(X_, motståndare):\n",
    "    X = X_.copy()\n",
    "\n",
    "    # set X['motståndare1'] to largest streck in every avd\n",
    "    grouped = X.groupby(['datum', 'avd'])['streck']\n",
    "    X['diff1'] = grouped.transform(max) - X.streck\n",
    "\n",
    "    for i in range(2, motståndare+1):\n",
    "        # set X['motståndare'+str(i)] to ith largest streck in every avd\n",
    "        X['diff' +\n",
    "            str(i)] = grouped.transform(lambda x: x.nlargest(i).min()) - X.streck\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "#%%\n",
    "# skapa modeller\n",
    "#             name,  ant_ästar,  proba, kelly, motst_ant,   motst_diff,  ant_favoriter,  only_clear, streck\n",
    "typ6 = tp.Typ('typ6', True,       True, False,     0,\n",
    "              False,          0,            False,    True)\n",
    "typ1 = tp.Typ('typ1', False,      True, False,     2,\n",
    "              True,           2,            True,     False)\n",
    "typ9 = tp.Typ('typ9', True,       True, True,      2,\n",
    "              True,           2,            True,     True)\n",
    "# typ16= tp.Typ('typ16', True,      True, True,      2,          True,          2,            False,    True)\n",
    "\n",
    "typer = [typ6, typ1, typ9]  # load a file with pickl\n",
    "\n",
    "with open('modeller\\\\meta_rf_model.model', 'rb') as f:\n",
    "    meta_model = pickle.load(f)\n",
    "\n",
    "# with open('modeller\\\\meta_ridge_model.model', 'rb') as f:\n",
    "#    meta_model = pickle.load(f)\n",
    "\n",
    "# with open('modeller\\\\meta_lasso_model.model', 'rb') as f:\n",
    "#     meta_model = pickle.load(f)\n",
    "\n",
    "\n",
    "#%%\n",
    "# för stacking ta med alla hästar per typ och proba plus kelly\n",
    "def build_stack_df(X_, typer):\n",
    "    X = X_.copy()\n",
    "    first_features = ['datum', 'avd', 'startnr', 'häst']\n",
    "    stacked_data = X[first_features].copy()\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        # print('stack '+typ.name)\n",
    "        stacked_data['proba'+nr] = typ.predict(X)\n",
    "        stacked_data['kelly' +\n",
    "                     nr] = kelly(stacked_data['proba'+nr], X[['streck']], None)\n",
    "\n",
    "    with open(pref+'META_FEATURES.txt', 'r', encoding='utf-8') as f:\n",
    "        meta_features = f.read().splitlines()\n",
    "    stacked_data = stacked_data[first_features + meta_features]\n",
    "\n",
    "    return stacked_data\n",
    "\n",
    "\n",
    "def meta_knn_predict(X_):\n",
    "    # X_ innehåller även datum,startnr och avd\n",
    "    first_features = ['datum', 'avd', 'startnr', 'häst']\n",
    "    pred_columns = ['proba'+str(i) for i in [6, 1, 9]] + \\\n",
    "        ['kelly'+str(i) for i in [6, 1, 9]]\n",
    "\n",
    "    X = X_.copy()\n",
    "    assert list(\n",
    "        X.columns[:4]) == first_features, 'meta_model måste ha datum, avd och startnr, häst för att kunna välja'\n",
    "    with open('modeller\\\\meta_knn_model.model', 'rb') as f:\n",
    "        meta_model = pickle.load(f)\n",
    "\n",
    "    # print(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "    X['meta_predict'] = meta_model.predict_proba(X[pred_columns])[:, 1]\n",
    "    my_columns = first_features + pred_columns + ['meta_predict']\n",
    "\n",
    "    return X[my_columns]\n",
    "\n",
    "\n",
    "def meta_rf_predict(X_):\n",
    "    # X_ innehåller även datum,startnr och avd\n",
    "    first_features = ['datum', 'avd', 'startnr', 'häst']\n",
    "    pred_columns = ['proba'+str(i) for i in [6, 1, 9]] + \\\n",
    "        ['kelly'+str(i) for i in [6, 1, 9]]\n",
    "\n",
    "    X = X_.copy()\n",
    "    assert list(\n",
    "        X.columns[:4]) == first_features, 'meta_model måste ha datum, avd och startnr, häst för att kunna välja'\n",
    "    with open('modeller\\\\meta_rf_model.model', 'rb') as f:\n",
    "        meta_model = pickle.load(f)\n",
    "\n",
    "    # print(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "    X['meta_predict'] = meta_model.predict_proba(X[pred_columns])[:, 1]\n",
    "    my_columns = first_features + pred_columns + ['meta_predict']\n",
    "\n",
    "    return X[my_columns]\n",
    "\n",
    "\n",
    "def meta_ridge_predict(X_):\n",
    "    # X_ innehåller även datum,startnr och avd\n",
    "    first_features = ['datum', 'avd', 'startnr', 'häst']\n",
    "    pred_columns = ['proba'+str(i) for i in [6, 1, 9]] + \\\n",
    "        ['kelly'+str(i) for i in [6, 1, 9]]\n",
    "\n",
    "    assert list(\n",
    "        X_.columns[:4]) == first_features, 'meta_model måste ha datum, avd och startnr, häst för att kunna välja'\n",
    "    X = X_.copy()\n",
    "    with open('modeller\\\\meta_ridge_model.model', 'rb') as f:\n",
    "        meta_model = pickle.load(f)\n",
    "\n",
    "    # print(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "    X['meta_predict'] = meta_model._predict_proba_lr(X[pred_columns])[:, 1]\n",
    "    my_columns = first_features + pred_columns + ['meta_predict']\n",
    "\n",
    "    return X[my_columns]\n",
    "\n",
    "\n",
    "def meta_lasso_predict(X_):\n",
    "    # X_ innehåller även datum,startnr och avd\n",
    "    first_features = ['datum', 'avd', 'startnr', 'häst']\n",
    "    pred_columns = ['proba'+str(i) for i in [6, 1, 9]] + \\\n",
    "        ['kelly'+str(i) for i in [6, 1, 9]]\n",
    "\n",
    "    assert list(\n",
    "        X_.columns[:4]) == first_features, 'meta_model måste ha datum, avd och startnr, häst för att kunna välja'\n",
    "    X = X_.copy()\n",
    "    with open('modeller\\\\meta_lasso_model.model', 'rb') as f:\n",
    "        meta_model = pickle.load(f)\n",
    "\n",
    "    # print(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "    X['meta_predict'] = meta_model.predict(X[pred_columns])\n",
    "    my_columns = first_features + pred_columns + ['meta_predict']\n",
    "\n",
    "    return X[my_columns]\n",
    "\n",
    "\n",
    "def mesta_diff_per_avd(X_):\n",
    "    sm = X_.copy()\n",
    "    # select the highest meta_predict per avd\n",
    "    sm['first'] = sm.groupby('avd')['meta_predict'].transform(\n",
    "        lambda x: x.nlargest(2).reset_index(drop=True)[0])\n",
    "    sm['second'] = sm.groupby('avd')['meta_predict'].transform(\n",
    "        lambda x: x.nlargest(2).reset_index(drop=True)[1])\n",
    "\n",
    "    sm = sm.query(\"(first==meta_predict or second==meta_predict)\").copy()\n",
    "    sm['diff'] = sm['first'] - sm['second']\n",
    "\n",
    "    # drop duplicates per avd\n",
    "    sm = sm.drop_duplicates(subset='avd', keep='first')\n",
    "\n",
    "    sm.sort_values(by='diff', ascending=False, inplace=True)\n",
    "    # sm.to_csv('mesta_diff_per_avd.csv')\n",
    "    return sm\n",
    "\n",
    "\n",
    "def välj_rad(df_meta_predict, max_insats=300):\n",
    "    veckans_rad = df_meta_predict.copy()\n",
    "    veckans_rad['välj'] = False   # inga rader valda ännu\n",
    "\n",
    "    # first of all: select one horse per avd\n",
    "    for avd in veckans_rad.avd.unique():\n",
    "        max_pred = veckans_rad[veckans_rad.avd == avd]['meta_predict'].max()\n",
    "        veckans_rad.loc[(veckans_rad.avd == avd) & (\n",
    "            veckans_rad.meta_predict == max_pred), 'välj'] = True\n",
    "    # veckans_rad.query(\"välj==True\").to_csv('veckans_basrad.csv')\n",
    "    veckans_rad = veckans_rad.sort_values(by=['meta_predict'], ascending=False)\n",
    "    veckans_rad = veckans_rad.reset_index(drop=True)\n",
    "\n",
    "    mest_diff = mesta_diff_per_avd(veckans_rad)\n",
    "\n",
    "    cost = 0.5  # 1 rad\n",
    "\n",
    "    # now select the rest of the horses one by one sorted by meta_predict\n",
    "    for i, row in veckans_rad.iterrows():\n",
    "        if row.avd == mest_diff.avd.iloc[0]:\n",
    "            continue\n",
    "        if row.avd == mest_diff.avd.iloc[1]:\n",
    "            continue\n",
    "        # print('i',i)\n",
    "        veckans_rad.loc[i, 'välj'] = True\n",
    "        cost = compute_total_insats(veckans_rad[veckans_rad.välj])\n",
    "        # print('cost',cost)\n",
    "        if cost > max_insats:\n",
    "            # veckans_rad.loc[i, 'välj'] = False\n",
    "            break\n",
    "\n",
    "    # print('cost', cost_before)\n",
    "    veckans_rad.sort_values(by=['välj', 'avd'], ascending=[\n",
    "                            False, True], inplace=True)\n",
    "    # display(veckans_rad[veckans_rad.välj])\n",
    "    return veckans_rad\n",
    "\n",
    "\n",
    "#%%\n",
    "#############################\n",
    "#### läs in meta_scores  ####\n",
    "#############################\n",
    "try:\n",
    "    with open(pref+'modeller/meta_scores.pkl', 'rb') as f:\n",
    "        meta_scores = pickle.load(f)\n",
    "except:\n",
    "    st.write('No meta_scores.pkl found')\n",
    "    print('No meta_scores.pkl found')\n",
    "    meta_scores = {'knn': 0.6, 'rf': 0.4, 'ridge': 0.7, 'lasso': 0.8}\n",
    "# print('meta_scores:', meta_scores)\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "def sort_list_of_meta(m):\n",
    "    try:\n",
    "        if meta_scores[m] == None:\n",
    "            print(f'No score for {m} found')\n",
    "            return 0\n",
    "        return meta_scores[m]\n",
    "    except:\n",
    "        st.write(f'{m} not found')\n",
    "        print(f'{m} not found')\n",
    "        return -1\n",
    "\n",
    "\n",
    "#%%\n",
    "## Streamlit kod startar här\n",
    "v75 = st.container()\n",
    "scraping = st.container()\n",
    "avd = st.container()\n",
    "sortera = st.container()\n",
    "\n",
    "if 'datum' in st.session_state:\n",
    "    datum = st.session_state['datum']\n",
    "    year = int(datum[:4])\n",
    "    month = int(datum[5:7])\n",
    "    day = int(datum[8:])\n",
    "    datum = st.sidebar.date_input(\n",
    "        'Välj datum', datetime.date(year, month, day))\n",
    "    datum = datum.strftime('%Y-%m-%d')\n",
    "\n",
    "    if datum != st.session_state['datum']:\n",
    "        st.session_state['datum'] = datum\n",
    "        datum = \"https://www.atg.se/spel/\"+datum+\"/V75/\"\n",
    "        omg_df = pd.DataFrame([datum], columns=['Link'])\n",
    "        omg_df.to_csv('omg_att_spela_link.csv', index=False)\n",
    "\n",
    "\n",
    "# typ16 och typ9 är samma förutom hur man väljer rader\n",
    "models = [typ6, typ1, typ9]\n",
    "\n",
    "\n",
    "def use_meta(df_stack, meta):\n",
    "    if meta == 'knn':\n",
    "        df_meta = meta_knn_predict(df_stack)\n",
    "    elif meta == 'rf':\n",
    "        df_meta = meta_rf_predict(df_stack)\n",
    "    elif meta == 'lasso':\n",
    "        df_meta = meta_lasso_predict(df_stack)\n",
    "    elif meta == 'ridge':\n",
    "        df_meta = meta_ridge_predict(df_stack)\n",
    "    else:\n",
    "        st.error(f'meta={meta} finns inte - avänder RandomForestClassifier')\n",
    "        df_meta = meta_rf_predict(df_stack)\n",
    "\n",
    "    df_meta.reset_index(drop=True, inplace=True)\n",
    "    df = välj_rad(df_meta)\n",
    "    st.session_state.df = df\n",
    "    st.experimental_rerun()\n",
    "\n",
    "\n",
    "# define st.state\n",
    "if 'df' not in st.session_state:\n",
    "    st.session_state['df'] = None\n",
    "    print(\"sklearn version\", sklearn.__version__)\n",
    "\n",
    "if 'meta' not in st.session_state:\n",
    "    st.session_state['meta'] = 'rf'\n",
    "\n",
    "with scraping:\n",
    "    def scrape(full=True, meta='rf'):\n",
    "        scraping.write('web-scraping för ny data')\n",
    "        with st.spinner('Ta det lugnt!'):\n",
    "            # st.image('winning_horse.png')  # ,use_column_width=True)\n",
    "\n",
    "            #####################\n",
    "            # start v75_scraping as a thread\n",
    "            #####################\n",
    "\n",
    "            i = 0.0\n",
    "            seconds = 0\n",
    "            placeholder = st.empty()\n",
    "\n",
    "            my_bar = st.progress(i)\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                future = executor.submit(v75_scraping, full)\n",
    "                while future.running():\n",
    "                    time.sleep(1)\n",
    "                    seconds += 1\n",
    "                    placeholder.write(f\"⏳ {seconds} sekunder\")\n",
    "                    i += 1/65\n",
    "                    if i < 0.99:\n",
    "                        my_bar.progress(i)\n",
    "                my_bar.progress(1.0)\n",
    "                df_scraped = future.result()\n",
    "\n",
    "                df_scraped.to_csv('sparad_scrape_spela.csv', index=False)\n",
    "\n",
    "            st.balloons()\n",
    "            my_bar.empty()\n",
    "            placeholder.empty()\n",
    "            # print(df_scraped.datum.unique())\n",
    "            df_stack = build_stack_df(df_scraped, typer)\n",
    "            df_stack.to_csv('sparad_stack.csv', index=False)\n",
    "            use_meta(df_stack, meta)\n",
    "\n",
    "    col1, col2 = st.columns([1, 4])\n",
    "\n",
    "    do_scraping = False\n",
    "    with col1:\n",
    "        if st.button('scrape'):\n",
    "            do_scraping = True\n",
    "    with col2:\n",
    "        if st.button('reuse scrape'):\n",
    "            try:\n",
    "                df = pd.read_csv('sparad_scrape_spela.csv')\n",
    "\n",
    "                if df.datum.iloc[0] != st.session_state.datum:\n",
    "                    st.error(\n",
    "                        f'Datum i data = {df.datum.iloc[0]} \\n\\n är inte samma som i omgång')\n",
    "                else:\n",
    "                    # st.success(f'inläst data med datum = {temp_df.datum.iloc[0]}')\n",
    "                    st.info(\n",
    "                        f'inläst data med datum = {df.datum.iloc[0]} kör nu scrape med full=False')\n",
    "                    try:\n",
    "                        df.drop(['plac'], axis=1, inplace=True)\n",
    "                    except:\n",
    "                        pass\n",
    "                    # scrape(False, meta=st.session_state['meta'])\n",
    "                    # st.info('scrape klar')\n",
    "                    del st.session_state.datum  # säkra att datum är samma som i scraping\n",
    "            except:\n",
    "                # write error message\n",
    "                st.error('<Dey finns ingen sparad data')\n",
    "\n",
    "    if do_scraping:\n",
    "        scrape(meta=st.session_state['meta'])\n",
    "        del st.session_state.datum  # säkra att datum är samma som i scraping\n",
    "\n",
    "    scraping.empty()\n",
    "\n",
    "with v75:\n",
    "    if 'datum' not in st.session_state:\n",
    "        omg_df = pd.read_csv('omg_att_spela_link.csv')\n",
    "        urlen = omg_df.Link.values[0]\n",
    "        datum = urlen.split('spel/')[1][0:10]\n",
    "        st.session_state.datum = datum\n",
    "\n",
    "    st.title('🐎 v75 -  ' + st.session_state.datum)\n",
    "\n",
    "\n",
    "with avd:\n",
    "    if st.session_state.df is not None:\n",
    "        use = avd.radio('Välj avdelning', ('Avd 1 och 2',\n",
    "                        'Avd 3 och 4', 'Avd 5 och 6', 'Avd 7', 'clear'))\n",
    "        avd.subheader(use)\n",
    "        st.write('TA BORT OUTLIERS')\n",
    "        col1, col2 = st.columns(2)\n",
    "        # print(df.iloc[0].häst)\n",
    "        dfi = st.session_state.df\n",
    "        dfi.rename(columns={'startnr': 'nr',\n",
    "                   'meta_predict': 'Meta'}, inplace=True)\n",
    "        try:\n",
    "            dfi['kelly'] = (dfi[['kelly1', 'kelly6', 'kelly9']]).max(axis=1)\n",
    "        except:\n",
    "            # om 'kelly-kolumnen saknas' så skapas den\n",
    "            scrape(False, meta=st.session_state['meta'])\n",
    "            del st.session_state.datum  # säkra att datum är samma som i scraping\n",
    "\n",
    "        # print(dfi[dfi.välj][['avd','nr','häst','kelly1','kelly6','kelly9','kelly16','Meta']])\n",
    "        # CSS to inject contained in a string\n",
    "        hide_dataframe_row_index = \"\"\"\n",
    "            <style>\n",
    "            .row_heading.level0 {display:none}\n",
    "            .blank {display:none}\n",
    "            </style>\n",
    "            \"\"\"\n",
    "\n",
    "        # Inject CSS with Markdown\n",
    "        st.markdown(hide_dataframe_row_index, unsafe_allow_html=True)\n",
    "\n",
    "        if use == 'Avd 1 och 2':\n",
    "            col1.table(dfi[(dfi.avd == 1) & dfi.välj].sort_values(by=['Meta'], ascending=False)[\n",
    "                       ['nr', 'häst', 'Meta', 'kelly']])\n",
    "            col2.table(dfi[(dfi.avd == 2) & dfi.välj].sort_values(by=['Meta'], ascending=False)[\n",
    "                       ['nr', 'häst', 'Meta', 'kelly']])\n",
    "        elif use == 'Avd 3 och 4':\n",
    "            col1.table(dfi[(dfi.avd == 3) & dfi.välj].sort_values(by=['Meta'], ascending=False)[\n",
    "                       ['nr', 'häst', 'Meta', 'kelly']])\n",
    "            col2.table(dfi[(dfi.avd == 4) & dfi.välj].sort_values(by=['Meta'], ascending=False)[\n",
    "                       ['nr', 'häst', 'Meta', 'kelly']])\n",
    "        elif use == 'Avd 5 och 6':\n",
    "            col1.table(dfi[(dfi.avd == 5) & dfi.välj].sort_values(by=['Meta'], ascending=False)[\n",
    "                       ['nr', 'häst', 'Meta', 'kelly']])\n",
    "            col2.table(dfi[(dfi.avd == 6) & dfi.välj].sort_values(by=['Meta'], ascending=False)[\n",
    "                       ['nr', 'häst', 'Meta', 'kelly']])\n",
    "        elif use == 'Avd 7':\n",
    "            col1.table(dfi[(dfi.avd == 7) & dfi.välj].sort_values(by=['Meta'], ascending=False)[\n",
    "                       ['nr', 'häst', 'Meta', 'kelly']])\n",
    "        elif use == 'clear':\n",
    "            st.stop()\n",
    "        else:\n",
    "            st.write('ej klart')\n",
    "\n",
    "        st.write(compute_total_insats(dfi[dfi.välj]))\n",
    "\n",
    "with sortera:\n",
    "    if st.sidebar.checkbox('se data'):\n",
    "        dfr = st.session_state.df\n",
    "        sort = st.sidebar.radio('sortera på', ['Meta', 'kelly', 'avd'])\n",
    "        if sort:\n",
    "            if sort == 'kelly':\n",
    "                st.write(dfr[['avd', 'nr', 'häst', 'Meta', 'kelly']].sort_values(\n",
    "                    by=['kelly', 'avd'], ascending=[False, False]))\n",
    "            elif sort == 'Meta':\n",
    "                st.write(dfr[['avd', 'nr', 'häst', 'Meta', 'kelly']].sort_values(\n",
    "                    by=['Meta', 'avd', 'nr'], ascending=[False, False, False]))\n",
    "            else:\n",
    "                dfra = dfr[['avd', 'nr', 'häst', 'proba6', 'proba9', 'proba1',\n",
    "                            'kelly6', 'kelly9', 'kelly1', 'Meta', 'välj', 'kelly']]\n",
    "                st.write(dfra.sort_values(\n",
    "                    by=['avd', 'nr'], ascending=[True, True]))\n",
    "\n",
    "meta_list = ['rf', 'knn', 'ridge', 'lasso']\n",
    "meta_list.sort(reverse=True, key=lambda x: sort_list_of_meta(x))\n",
    "meta = st.sidebar.radio('välj meta_model', meta_list)\n",
    "\n",
    "if meta != st.session_state.meta:\n",
    "    st.session_state.meta = meta\n",
    "    st.write('meta_model:', meta)\n",
    "    df_scraped = pd.read_csv('sparad_scrape_spela.csv')\n",
    "    try:\n",
    "        df_scraped.drop(['plac'], axis=1, inplace=True)\n",
    "        st.info('this file is not up to date - a scrape is needed')\n",
    "    except:\n",
    "        pass\n",
    "    df_stack = build_stack_df(df_scraped, typer)\n",
    "    df_stack.to_csv('sparad_stack.csv', index=False)\n",
    "    use_meta(df_stack, meta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d733caf4ffc39d0fbd9a2ba54ef4b7d515956d8048931f8241efe3827fb2d1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
