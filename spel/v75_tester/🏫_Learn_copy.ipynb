{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "### Kopia av 2_🏫_Learn.py\n",
    "### I ett första steg inför travdata\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END 09.19.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel\\\\')\n",
    "\n",
    "import typ_copy as tp\n",
    "import travdata as td\n",
    "import V75_scraping as vs\n",
    "import concurrent.futures\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "# import streamlit as st\n",
    "from logging import PlaceHolder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, mean_absolute_error\n",
    "# import streamlit as st\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 260)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 120)\n",
    "\n",
    "\n",
    "# sys.path.append('C:\\\\Users\\\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel\\\\modeller\\\\')\n",
    "\n",
    "\n",
    "pref =  '../'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "streamlit grejer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############## streamlit grejer #############################################\n",
    "# st.set_page_config(page_title=\"V75 Learning\", page_icon=\"🏫\")\n",
    "# st.markdown(\"# 🏫 V75 Learning\")\n",
    "print('st.sidebar.header(\"🏫 V75 Learning\")')\n",
    "#############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "# -------------- skapa test-modeller\n",
    "    #               name,   #häst     proba,    kelly,  #motst,  motst_diff, #fav, only_cl, streck, test,  pref\n",
    "test1 = tp.Typ('test1',  True,    True,     False,       0,   False,      0,   False,    True,  True, pref=pref)\n",
    "test2 = tp.Typ('test2',  True,    True,     False,       0,   False,      0,   False,    False, True, pref=pref)\n",
    "test3 = tp.Typ('test3',  True,    True,     False,       0,   False,      0,   False,    False, True, pref=pref)\n",
    "test4 = tp.Typ('test4',  True,    True,     False,       0,   False,      0,   False,    True,  False, pref=pref)\n",
    "\n",
    "modeller = [test1, test2, test3, test4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "################################################\n",
    "#              Web scraping                    #\n",
    "################################################\n",
    "\n",
    "def v75_scraping():\n",
    "    df = vs.v75_scraping(history=True, resultat=True, headless=True)\n",
    "\n",
    "    for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        df[f] = df[f].str.lower()\n",
    "    return df\n",
    "\n",
    "def remove_features(df_, remove_mer=[]):\n",
    "    df = df_.copy()\n",
    "    df.drop(['startnr', 'vodds', 'podds', 'bins', 'h1_dat',\n",
    "            'h2_dat', 'h3_dat', 'h4_dat', 'h5_dat'], axis=1, inplace=True)\n",
    "    \n",
    "    if remove_mer:\n",
    "        df.drop(remove_mer, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "################################################\n",
    "#              Web scraping                    #\n",
    "################################################\n",
    "\n",
    "def v75_scraping():\n",
    "    df = vs.v75_scraping(history=True, resultat=True, headless=True)\n",
    "\n",
    "    for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        df[f] = df[f].str.lower()\n",
    "    return df\n",
    "\n",
    "def remove_features(df_, remove_mer=[]):\n",
    "    df = df_.copy()\n",
    "    df.drop(['startnr', 'vodds', 'podds', 'bins', 'h1_dat',\n",
    "            'h2_dat', 'h3_dat', 'h4_dat', 'h5_dat'], axis=1, inplace=True)\n",
    "    \n",
    "    if remove_mer:\n",
    "        df.drop(remove_mer, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "###############################################\n",
    "#              LEARNING                       #\n",
    "###############################################\n",
    "\n",
    "def förbered_old(df, meta_fraction=None):\n",
    "    # Följande datum saknar avd==5 och kan inte användas\n",
    "    saknas = ['2015-08-15', '2016-08-13', '2017-08-12']\n",
    "    df = df[~df.datum.isin(saknas)]\n",
    "    X = df.copy()\n",
    "    X.drop('plac', axis=1, inplace=True)\n",
    "\n",
    "    # läs in FEATURES.txt\n",
    "    with open(pref+'FEATURES.txt', 'r', encoding='utf-8') as f:\n",
    "        features = f.read().splitlines()\n",
    "\n",
    "    X = X[features]\n",
    "\n",
    "    assert len(features) == len(\n",
    "        X.columns), f'features {len(features)} and X.columns {len(X.columns)} are not the same length'\n",
    "    assert set(features) == set(\n",
    "        X.columns), f'features {set(features)} and X.columns {set(X.columns)} are not the same'\n",
    "\n",
    "    y = (df.plac == 1)*1   # plac 1 eller 0\n",
    "\n",
    "    for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        X[f] = X[f].str.lower()\n",
    "\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    if meta_fraction == 0:\n",
    "        # no meta data\n",
    "        return X, y, None, None\n",
    "\n",
    "    # use a fraction for meta data\n",
    "    meta_antal = int(len(X.datum.unique())*meta_fraction)\n",
    "    meta_datum = X.datum.unique()[-meta_antal:]\n",
    "\n",
    "    X_val = X.loc[X.datum.isin(meta_datum)]\n",
    "    y_val = y[X_val.index]\n",
    "    X = X.loc[~X.datum.isin(meta_datum)]\n",
    "    y = y.loc[X.index]\n",
    "    return X, y, X_val, y_val\n",
    "\n",
    "\n",
    "def concat_data_old(df_all, df_ny, save=True):\n",
    "    df_ny = df_ny[df_all.columns]\n",
    "    df_all = pd.concat([df_all, df_ny])\n",
    "    # remove duplicates\n",
    "    all_shape = df_all.shape\n",
    "\n",
    "    df_all = df_all.drop_duplicates(subset=['datum', 'avd', 'häst'])\n",
    "    assert df_all.shape[0] + \\\n",
    "        90 > all_shape[0], f'{df_all.shape[0]+90} should be more than {all_shape[0]}'\n",
    "    assert df_all.shape[1] == all_shape[1], f'{df_all.shape[1]} should be {all_shape[1]}'\n",
    "    if save == True:\n",
    "        df_all.to_csv(pref+'all_data.csv', index=False)\n",
    "    return df_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### RidgeClassifier (meta model) #####\n",
    "def learn_meta_ridge_model(X, y, save=True):\n",
    "\n",
    "    with open(pref+'optimera/params_meta_ridge.json', 'r') as f:\n",
    "        params = json.load(f)['params']\n",
    "        # st.write(params)\n",
    "\n",
    "    ridge_model = RidgeClassifier(**params, random_state=2022)\n",
    "\n",
    "    ridge_model.fit(X, y)\n",
    "\n",
    "    if save:\n",
    "        with open(pref+'modeller/meta_ridge.model', 'wb') as f:\n",
    "            pickle.dump(ridge_model, f)\n",
    "\n",
    "    return ridge_model\n",
    "\n",
    "##### RandomForestClassifier (meta model) #####\n",
    "\n",
    "\n",
    "def learn_meta_rf_model(X, y, save=True):\n",
    "\n",
    "    with open(pref+'optimera/params_meta_rf.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "        params = params['params']\n",
    "        # st.write(params)\n",
    "\n",
    "    rf_model = RandomForestClassifier(**params, n_jobs=6, random_state=2022)\n",
    "    rf_model.fit(X, y)\n",
    "\n",
    "    ######################### for testing ###############################\n",
    "    rf_train = X.copy(deep=True)\n",
    "    rf_train['y'] = y\n",
    "    rf_train.to_csv(pref+'rf_train.csv', index=False)\n",
    "    #########################              ###############################\n",
    "\n",
    "    if save:\n",
    "        with open(pref+'modeller/meta_rf.model', 'wb') as f:\n",
    "            pickle.dump(rf_model, f)\n",
    "\n",
    "    return rf_model\n",
    "\n",
    "\n",
    "##### KNeighborsClassifier (meta model) #####\n",
    "def learn_meta_knn_model(X, y, save=True):\n",
    "    with open(pref+'optimera/params_meta_knn.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "        params = params['params']\n",
    "        # st.write(params)\n",
    "\n",
    "    knn_model = KNeighborsClassifier(**params, n_jobs=6)\n",
    "    knn_model.fit(X, y)\n",
    "\n",
    "    if save:\n",
    "        with open(pref+'modeller/meta_knn.model', 'wb') as f:\n",
    "            pickle.dump(knn_model, f)\n",
    "\n",
    "    return knn_model\n",
    "\n",
    "def learn_meta_et_model(X, y, save=True):\n",
    "    with open(pref+'optimera/params_meta_et.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "        params = params['params']\n",
    "\n",
    "    params = {'n_estimators':10, 'max_depth':None, 'min_samples_leaf':5}\n",
    "    et_model = ExtraTreesClassifier(**params, n_jobs=6, random_state=2022)\n",
    "    et_model.fit(X, y)\n",
    "\n",
    "    if save:\n",
    "        with open(pref+'modeller/meta_et.model', 'wb') as f:\n",
    "            pickle.dump(et_model, f)\n",
    "\n",
    "    return et_model\n",
    "\n",
    "def prepare_stack_data(stack_data_, ENC=None):\n",
    "    \"\"\"Hantera missing values, NaN, etc för meta-modellerna\"\"\"\n",
    "\n",
    "    assert 'y' in stack_data_.columns, 'y is missing in stack_data'\n",
    "    stack_data = stack_data_.copy()\n",
    "    stack_data.y = stack_data.y.astype(int)\n",
    "\n",
    "    \"\"\" rensa bort features som inte ska användas \"\"\"\n",
    "    # stack_data.drop(['startnr', 'vodds', 'podds', 'bins', 'h1_dat',\n",
    "    #             'h2_dat', 'h3_dat', 'h4_dat', 'h5_dat'], axis=1, inplace=True)\n",
    "\n",
    "    \"\"\" Fyll i saknade numeriska värden med 0 \"\"\"\n",
    "    numericals = stack_data.drop('y', axis=1).select_dtypes(exclude=['object']).columns\n",
    "    stack_data[numericals] = stack_data[numericals].fillna(0)\n",
    "\n",
    "    \"\"\" Fyll i saknade kategoriska värden med 'missing' \"\"\"\n",
    "    categoricals = stack_data.drop('y',axis=1).select_dtypes(include=['object']).columns\n",
    "    stack_data[categoricals] = stack_data[categoricals].fillna('missing')\n",
    "\n",
    "    # \"\"\" Hantera high cardinality \"\"\"\n",
    "    # cardinality_list=['häst','kusk','h1_kusk','h2_kusk','h3_kusk','h4_kusk','h5_kusk']\n",
    "\n",
    "    \"\"\" Target encoding\"\"\"\n",
    "    target_encode_list = ['bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana',\n",
    "                          'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n",
    "\n",
    "    y = stack_data['y']\n",
    "    if ENC is None:\n",
    "        ENC = TargetEncoder(cols=target_encode_list, min_samples_leaf=20, smoothing=10).fit(stack_data, y)\n",
    "       \n",
    "    stack_data = ENC.transform(stack_data)\n",
    "\n",
    "    return stack_data, ENC\n",
    "\n",
    "def learn_meta_models(stack_data, meta_features, save=True):\n",
    "    \"\"\" all meta models will be fitted on X and y \"\"\"  \n",
    "    \n",
    "    stack_data, ENC = prepare_stack_data(stack_data)\n",
    "     # save encoder\n",
    "    with open(pref+'modeller/encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(ENC, f)\n",
    "        \n",
    "    stack_data.to_csv(pref+'prepared_stack_data.csv', index=False)   # for testing purposes\n",
    "    \n",
    "    Ridge_Classifier = learn_meta_ridge_model(stack_data[meta_features], stack_data.y, save=save)\n",
    "    RandomForest_Classifier = learn_meta_rf_model(stack_data[meta_features], stack_data.y, save=save)\n",
    "    Knn_model = learn_meta_knn_model(stack_data[meta_features], stack_data.y, save=save)\n",
    "    ExtraTrees_Classifier = learn_meta_et_model(stack_data[meta_features], stack_data.y, save=save)\n",
    "\n",
    "    return Ridge_Classifier, RandomForest_Classifier, Knn_model, ExtraTrees_Classifier, ENC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nytt ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skapa_data_för_datum(df_, curr_datum_ix, frac=0.5):\n",
    "    df = df_.copy()\n",
    "    datumar = df.datum.unique()\n",
    "    curr_datum = datumar[curr_datum_ix]\n",
    "    base_datum_ix = int(len(datumar[:curr_datum_ix]) * frac)  # base models\n",
    "\n",
    "    base_datum = datumar[base_datum_ix]\n",
    "    X_train = df.query(f'datum < @base_datum')\n",
    "    y_train = X_train.y\n",
    "    X_train = X_train.drop('y', axis=1)\n",
    "\n",
    "    X_meta = df.query(f'datum >= @base_datum and datum < @curr_datum')\n",
    "    y_meta = X_meta.y\n",
    "    X_meta = X_meta.drop('y', axis=1)\n",
    "\n",
    "    X_curr = df.query(f'datum == @curr_datum')\n",
    "    y_curr = X_curr.y\n",
    "    X_curr = X_curr.drop(['y'], axis=1)\n",
    "\n",
    "    return X_train, y_train, X_meta, y_meta, X_curr, y_curr\n",
    "\n",
    "\n",
    "\n",
    "def skapa_stack_data(model, name, X_meta, stack_data):\n",
    "    \"\"\"Skapa stack_data\"\"\"\n",
    "    assert 'y' in stack_data.columns, 'y is missing in stack_data'\n",
    "    this_proba = model.predict(X_meta)\n",
    "    # print(f'X_meta.shape = {X_meta.shape} this_proba.shape={this_proba.shape}')\n",
    "\n",
    "    # Bygg up meta-kolumnerna (proba) för denns modell\n",
    "    nr = name[3:]\n",
    "    stack_data['proba'+nr] = this_proba\n",
    "    return stack_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_out_val_data(df_work, val_fraction):\n",
    "    y=df_work.y\n",
    "    X=df_work.drop('y', axis=1)\n",
    "    if val_fraction == 0:\n",
    "        # no validation data\n",
    "        X_val, y_val = None, None\n",
    "    else:    \n",
    "        # use a fraction for meta data\n",
    "        datumar=df_work.datum.unique()\n",
    "        val_antal = int(len(datumar)*val_fraction)\n",
    "        val_datum = datumar[-val_antal:]\n",
    "\n",
    "        X_val = X.loc[X.datum.isin(val_datum)]\n",
    "        y_val = y[X_val.index]\n",
    "        X = X.loc[~X.datum.isin(val_datum)]\n",
    "        y = y.loc[X.index]\n",
    "    return X, y, X_val, y_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_modeller(modeller, X_train, y_train, X_meta, y_meta):\n",
    "    ############################################################################################################\n",
    "    #                        Här görs en första learn av modeller och sedan skapas stack_data\n",
    "    #                        - Learn modeller på X,y\n",
    "    #                        - Ha en egen skapa_stack_funktion (som också används längre ner)\n",
    "    #                           - Skapa stack_data med predict X_meta med nya modellerna\n",
    "    #                           - Spara även X_meta, y_meta i stack_data\n",
    "    ############################################################################################################\n",
    "    stack_data = X_meta.copy()\n",
    "    stack_data['y'] = y_meta\n",
    "    assert 'y' in stack_data.columns, '1. y is missing in stack_data'\n",
    "    for model in modeller:\n",
    "        name = model.name\n",
    "        print(f'first Learn {name} {X_train.datum.min()} -{X_train.datum.max()}')\n",
    "\n",
    "        model.learn(X_train, y_train, params=None, save=True)\n",
    "\n",
    "        stack_data = skapa_stack_data(model, name, X_meta, stack_data)\n",
    "\n",
    "    assert 'y' in stack_data.columns, '3. y is missing in stack_data'\n",
    "    # stack_data, enc = prepare_stack_data(stack_data)\n",
    "\n",
    "    return stack_data\n",
    "\n",
    "def normal_learning(modeller, meta_modeller, X_train, y_train, X_meta, y_meta):\n",
    "    stack_data = learn_modeller(modeller, X_train, y_train, X_meta, y_meta)\n",
    "    assert 'y' in stack_data.columns, 'y is missing in stack_data'\n",
    "    stack_data.to_csv('first_stack_data.csv', index=False)\n",
    "\n",
    "    # \"\"\" Learn meta_modeller på stack_data \"\"\"\n",
    "    meta_features = stack_data.drop(['datum', 'avd','y'],axis=1).columns.to_list()\n",
    "    _, _, _, _, ENC = learn_meta_models(stack_data, meta_features)\n",
    "    \n",
    "    return stack_data[meta_features + ['y']]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeSeriesLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesSplit learning models\n",
    "def TimeSeries_learning(df_ny_, modeller, n_splits=5, val_fraction=0.25, save=True, learn_models=True):\n",
    "    \"\"\"\n",
    "    Skapar en stack med {1 - meta_fraction} av X från alla modeller. Används som input till meta_model.\n",
    "        - learn_models=True betyder att vi både gör en learning och skapar en stack\n",
    "        - learn_models=False betyder att vi bara skapar en stack och då har param save ingen funktion\n",
    "    \"\"\"\n",
    "    \n",
    "    # Skapa v75-instans\n",
    "    v75 = td.v75(pref=pref)\n",
    "    \n",
    "    base_features = v75.get_df().columns.to_list()\n",
    "    \n",
    "    if df_ny_ is not None:  # Har vi en ny omgång?\n",
    "        df_ny = df_ny_[base_features].copy()\n",
    "        v75.concat(df_ny, update_work=True, save=True)\n",
    "\n",
    "    # Hämta data från v75\n",
    "    _ = v75.förbered_data(missing_num=False)  # num hanteras av catboost\n",
    "    df_work = v75.test_lägg_till_kolumner()\n",
    "    \n",
    "    # base_ix = 100  # antal omgångar som vi startar bas-modellerna från i backtesting\n",
    "\n",
    "    # datumar = df_work.datum.unique()\n",
    "    # startdatum = datumar[base_ix]\n",
    "\n",
    "    # assert val_fraction==0, 'meta_fraction måste vara 0 tills vidare'\n",
    "    X, y, X_val, y_val = hold_out_val_data(df_work, val_fraction)\n",
    "    \n",
    "    validation_text = \"\"\n",
    "\n",
    "    if X_val is not None:\n",
    "        validation_text = f', Validation: {X_val.datum.iloc[0]} - {X_val.datum.iloc[-1]}'\n",
    "\n",
    "    # st.info(f'Train: {X.datum.iloc[0]} - {X.datum.iloc[-1]} {validation_text}')\n",
    "    print(f\"Train: {X.datum.iloc[0]} - {X.datum.iloc[-1]} {validation_text}\")\n",
    "\n",
    "    ts = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    stacked_data = pd.DataFrame()\n",
    "\n",
    "    ###############################################################################\n",
    "    #         Step 1: Learn the models on ts.split X_train and predict on X_test  #\n",
    "    ###############################################################################\n",
    "    # st.write('Skapar stacked_data till meta')\n",
    "    # my_bar = st.progress(0)\n",
    "\n",
    "    step = 1/(n_splits*len(modeller))-0.0000001\n",
    "    steps = 0.0\n",
    "\n",
    "    for enum, (train_index, test_index) in enumerate(ts.split(X, y)):\n",
    "        print('shape of X', X.shape, 'shape of X_train', X.iloc[train_index].shape, 'shape of X_test', X.iloc[test_index].shape)\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "        temp_stack = X_test.copy()\n",
    "        temp_stack['y'] = y_test\n",
    "        for model in modeller:\n",
    "            steps += step\n",
    "            # progress bar continues to complete from 0 to 100\n",
    "            \n",
    "            # my_bar.progress(steps)\n",
    "\n",
    "            if learn_models:\n",
    "                with open(pref+'optimera/params_'+model.name+'.json', 'r') as f:\n",
    "                    params = json.load(f)\n",
    "                    params = params['params']\n",
    "                # learn på X_train-delen\n",
    "                \n",
    "                cbc = model.learn(X_train, y_train, X_test,\n",
    "                                y_test, params=params, save=save)\n",
    "\n",
    "            # predict the new fitted model on X_test-delen\n",
    "            nr = model.name[3:]\n",
    "            this_proba = model.predict(X_test)\n",
    "\n",
    "            # Bygg up meta-kolumnen proba för denns modell\n",
    "            temp_stack['proba'+nr] = this_proba\n",
    "\n",
    "        if stacked_data.empty:\n",
    "            stacked_data = temp_stack.copy()\n",
    "        else:        \n",
    "            stacked_data = pd.concat([stacked_data, temp_stack], ignore_index=True)\n",
    "        stacked_data.y = stacked_data.y.astype(int)\n",
    "\n",
    "    \n",
    "    # stacked_data_y = stacked_data.pop('y')\n",
    "    meta_features = stacked_data.drop(['datum', 'avd', 'y'], axis=1).columns.to_list()\n",
    "\n",
    "    # my_bar.progress(1.0)\n",
    "\n",
    "    ###############################################################################\n",
    "    #         Step 2:       Learn the meta models                                 #\n",
    "    ###############################################################################\n",
    "    # st.write('Learning meta models')\n",
    "    print('Learning meta models')\n",
    "    _, _, _, _, ENC = learn_meta_models(stacked_data, meta_features)\n",
    "    # save ENC\n",
    "    with open(pref+'modeller/encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(ENC, f)    \n",
    "\n",
    "    ###############################################################################\n",
    "    #         Step 3: learn models on all of X - what iteration to use?           #\n",
    "    ###############################################################################\n",
    "    # st.write('Learn models on all of Train')\n",
    "    print('Learn models on all of Train')\n",
    "    \n",
    "    # my_bar2 = st.progress(0)\n",
    "    ant_meta_models = 4\n",
    "    step = 1/(ant_meta_models) - 0.0000001\n",
    "    steps = 0.0\n",
    "    # my_bar2.progress(steps)\n",
    "\n",
    "    for model in modeller:\n",
    "        steps += step\n",
    "        # my_bar2.progress(steps)\n",
    "        if learn_models:\n",
    "            with open(pref+'optimera/params_'+model.name+'.json', 'r') as f:\n",
    "                params = json.load(f)\n",
    "\n",
    "            params = params['params']\n",
    "            cbc = model.learn(X, y, None, None, \n",
    "                              iterations=500, \n",
    "                              params=params, \n",
    "                              save=save)\n",
    "\n",
    "    # my_bar2.progress(1.0)\n",
    "    # st.empty()\n",
    "    \n",
    "    return stacked_data[meta_features + ['y']]\n",
    "\n",
    "\n",
    "def skapa_stack_learning(X_, y,meta_features):\n",
    "    # För validate\n",
    "    X = X_.copy()\n",
    "    print(X.shape)\n",
    "    print(len(meta_features))\n",
    "    stacked_data = X[meta_features].copy()\n",
    "    for model in modeller:\n",
    "        part = model.name[3:]\n",
    "        stacked_data['proba'+part] = model.predict(X)\n",
    "        meta_features += ['proba'+part]\n",
    "\n",
    "    assert list(stacked_data.columns) == meta_features, f'columns in stacked_data is wrong {list(stacked_data.columns)} \\n {meta_features}'\n",
    "    assert len(stacked_data) == len(y), f'stacked_data {len(stacked_data)} and y {len(y)} should have same length'\n",
    "    return stacked_data[meta_features], meta_features, y  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "##############################################################\n",
    "#                     VALIDATE                               #\n",
    "##############################################################\n",
    "\n",
    "def predict_meta_ridge_model(X, ridge_model=None):\n",
    "    if ridge_model is None:\n",
    "        with open(pref+'modeller/meta_ridge.model', 'rb') as f:\n",
    "            ridge_model = pickle.load(f)\n",
    "\n",
    "    return ridge_model._predict_proba_lr(X)\n",
    "\n",
    "\n",
    "def predict_meta_rf_model(X, rf_model=None):\n",
    "    if rf_model is None:\n",
    "        with open(pref+'modeller/meta_rf.model', 'rb') as f:\n",
    "            rf_model = pickle.load(f)\n",
    "\n",
    "    return rf_model.predict_proba(X)\n",
    "\n",
    "\n",
    "def predict_meta_et_model(X, et_model=None):\n",
    "    if et_model is None:\n",
    "        with open(pref+'modeller/meta_et.model', 'rb') as f:\n",
    "            et_model = pickle.load(f)\n",
    "\n",
    "    return et_model.predict_proba(X)\n",
    "\n",
    "def predict_meta_knn_model(X, knn_model=None):\n",
    "    if knn_model is None:\n",
    "        with open(pref+'modeller/meta_knn.model', 'rb') as f:\n",
    "            knn_model = pickle.load(f)\n",
    "\n",
    "    return knn_model.predict_proba(X)\n",
    "\n",
    "def predict_meta_mean(preds, type):   # type='geometric' or 'arithmetic'\n",
    "    if type=='arithmetic':\n",
    "        return (preds.rf + preds.et + preds.ridge + preds.knn)/4\n",
    "    \n",
    "    return (preds.rf * preds.et * preds.ridge * preds.knn)**(1/4)\n",
    "\n",
    "def predict_meta_models(stack_data, meta_features):\n",
    "    preds = pd.DataFrame(columns=['rf', 'ridge', 'knn', 'meta'])\n",
    "    \n",
    "    with open(pref+'modeller/meta_enc.pkl', 'rb') as f:\n",
    "        ENC = pickle.load(f)\n",
    "        \n",
    "    stack_data, _ = prepare_stack_data(stack_data, ENC)\n",
    "    preds['rf'] = predict_meta_rf_model(stack_data[meta_features])[:, 1]\n",
    "    preds['ridge'] = predict_meta_ridge_model(stack_data[meta_features])[:, 1]\n",
    "    preds['knn'] = predict_meta_knn_model(stack_data[meta_features])[:, 1]\n",
    "    preds['et']  = predict_meta_et_model(stack_data[meta_features])[:, 1]\n",
    "    preds['meta'] = predict_meta_mean(preds, type='geometric')\n",
    "    \n",
    "    return preds\n",
    "    \n",
    "\n",
    "# write the scores\n",
    "\n",
    "\n",
    "def display_scores(y_true, y_pred, spelade):\n",
    "    # st.write('AUC', round(roc_auc_score(y_true, y_pred), 5), 'F1', round(f1_score(y_true, y_pred), 5), 'Acc', round(\n",
    "    #     accuracy_score(y_true, y_pred), 5), 'MAE', round(mean_absolute_error(y_true, y_pred), 5), '\\n', spelade)\n",
    "    print('AUC', round(roc_auc_score(y_true, y_pred), 5), 'F1', round(f1_score(y_true, y_pred), 5), 'Acc', round(\n",
    "        accuracy_score(y_true, y_pred), 5), 'MAE', round(mean_absolute_error(y_true, y_pred), 5), '\\n', spelade)\n",
    "    return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def find_threshold(y_pred, fr, to, margin):\n",
    "    \"\"\" hitta threshold som ger 2.5 spelade per avdelning \"\"\"\n",
    "    thresh = 0\n",
    "    cnt = 0\n",
    "    # make a binary search\n",
    "    while cnt < 1000:\n",
    "        thresh = (fr + to) / 2\n",
    "        antal_spelade_per_avd = 12 * sum(y_pred > thresh)/len(y_pred)\n",
    "        if (antal_spelade_per_avd > (2.5 - margin)) and (antal_spelade_per_avd < (2.5 + margin)):\n",
    "            break\n",
    "\n",
    "        if antal_spelade_per_avd > 2.5:\n",
    "            fr = thresh-0.00001\n",
    "        else:\n",
    "            to = thresh+0.00001\n",
    "        cnt += 1\n",
    "\n",
    "    # print('ant', cnt, 'thresh', round(thresh, 4))\n",
    "    if cnt >= 1000:\n",
    "        print('threshold not found', 'fr', round(fr, 6), 'to', round(to, 6))\n",
    "\n",
    "    return thresh\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model, fr=0.0, to=0.9, margin=0.001):\n",
    "\n",
    "    #### Först:  hitta ett threshold som tippar ca 2.5 hästar per avd ####\n",
    "    # thresh = 0\n",
    "    # for thresh in np.arange(fr, to, step):\n",
    "    #     cost = 12*sum(y_pred > thresh)/len(y_pred)\n",
    "    #     if cost < 2.5:\n",
    "    #         break\n",
    "    thresh = round(find_threshold(y_pred, fr, to, margin), 4)\n",
    "    print(f'Threshold: {thresh}\\n')\n",
    "    y_pred = (y_pred > thresh).astype(int)\n",
    "    # confusion_matrix_graph(y_true, y_pred, f'{model} threshold={thresh}')\n",
    "\n",
    "    #### Sedan: confusion matrix graph ####\n",
    "    title = f'{model} threshold={thresh}'\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred,)\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.set(font_scale=2.0)\n",
    "    sns.heatmap(cm/np.sum(cm), annot=True, fmt=\".2%\", linewidths=.5,\n",
    "                square=True, cmap='Blues_r')\n",
    "\n",
    "    # increase font size\n",
    "    plt.rcParams['font.size'] = 20\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.show()\n",
    "    # st.write(fig)\n",
    "\n",
    "    # read dict from disk\n",
    "    try:\n",
    "        with open(pref+'modeller/meta_scores.pkl', 'rb') as f:\n",
    "            meta_scores = pickle.load(f)\n",
    "    except:\n",
    "        # st.write('No meta_scores.pkl found')\n",
    "        print('No meta_scores.pkl found')\n",
    "        meta_scores = {'knn': 0, 'rf': 0, 'ridge': 0, 'et': 0}\n",
    "\n",
    "    #### print scores ####\n",
    "    typ_AUC = display_scores(\n",
    "        y_true, y_pred, f'spelade per lopp: {round(12 * sum(y_pred)/len(y_pred),4)}')\n",
    "    meta_scores[model] = float(typ_AUC)\n",
    "    #### save dict to disk ####\n",
    "    with open(pref+'modeller/meta_scores.pkl', 'wb') as f:\n",
    "        pickle.dump(meta_scores, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate(drop=[], fraction=None):\n",
    "    # Skapa v75-instans\n",
    "    v75 = td.v75(pref=pref)\n",
    "\n",
    "    base_features = v75.get_df().columns.to_list()\n",
    "\n",
    "    # Hämta data från v75\n",
    "    _ = v75.förbered_data(missing_num=False)  # num hanteras av catboost\n",
    "    df_work = v75.test_lägg_till_kolumner()\n",
    "\n",
    "    # st.info('skall endast  köras efter \"Learn for Validation\"')\n",
    "    # df_all = pd.read_csv(pref+'all_data.csv')\n",
    "\n",
    "    \n",
    "    _, _, X_val, y_val = hold_out_val_data(df_work, fraction)\n",
    "    # st.info(f'Validerar på:  {X_val.datum.iloc[0]} - -{X_val.datum.iloc[-1]}')\n",
    "    print(f'Validerar på:  {X_val.datum.iloc[0]} - -{X_val.datum.iloc[-1]}')\n",
    "\n",
    "    # # create the stack from validation data\n",
    "    # meta_features = all columns except avd and datum\n",
    "    meta_features = [col for col in df_work.columns if col not in ['datum','avd', 'y']]\n",
    "\n",
    "    stacked_val, meta_features, y_val = skapa_stack_learning(X_val, y_val, meta_features)\n",
    "\n",
    "    stacked_val = stacked_val.drop(drop, axis=1)\n",
    "\n",
    "    # ##############################################################\n",
    "    # #                          Meta models                       #\n",
    "    # ##############################################################\n",
    "\n",
    "    stacked_val['y'] = y_val\n",
    "    y_true = y_val.values\n",
    "\n",
    "    y_preds = predict_meta_models(stacked_val, meta_features)\n",
    "\n",
    "    # ############## write y_true to file for testing ##############\n",
    "    # # first make y_true a dataframe\n",
    "    # rf_y_true = pd.DataFrame(y_true, columns=['y'])\n",
    "    # rf_y_true.to_csv(pref+'rf_y_true.csv', index=False)\n",
    "    # ##############################################################\n",
    "\n",
    "    print(\"st.info('förbereder meta plot')\")\n",
    "    plot_confusion_matrix(y_true, y_preds.meta, 'meta', fr=0.0, to=0.9)\n",
    "\n",
    "    # st.write('\\n')\n",
    "    print(\"st.info('förbereder rf plot')\")\n",
    "    plot_confusion_matrix(y_true, y_preds.rf, 'rf',\n",
    "                        fr=0.0, to=1.0, margin=0.01)\n",
    "\n",
    "    # st.write('\\n')\n",
    "    print(\"st.info('förbereder et plot')\")\n",
    "    plot_confusion_matrix(y_true, y_preds.et, 'et',\n",
    "                      fr=0.0, to=1.0, margin=0.01)\n",
    "\n",
    "    # st.write('\\n')\n",
    "    print(\"st.info('förbereder knn plot')\")\n",
    "    plot_confusion_matrix(y_true, y_preds.knn, 'knn', fr=0.0, to=0.9)\n",
    "\n",
    "    # st.write('\\n')\n",
    "    print(\"st.info('förbereder ridge plot')\")\n",
    "    plot_confusion_matrix(y_true, y_preds.ridge, 'ridge', fr=0.0, to=0.9)\n",
    "    # # placeholder.empty()\n",
    "\n",
    "    # st.write('\\n')\n",
    "    # st.info('förbereder lasso plot')\n",
    "    # plot_confusion_matrix(y_true, predict_meta_model(stacked_val, meta_model='lasso'),\n",
    "    #                       'lasso', fr=0.0, to=0.9)\n",
    "    # # placeholder.empty()\n",
    "\n",
    "    # stacked_val['y'] = y_true\n",
    "    # stacked_val['avd'] = X_val.avd.values\n",
    "\n",
    "    # ################################################################\n",
    "    # #                         proba 6, 1, 9, (16)                  #\n",
    "    # ################################################################\n",
    "    # st.write('\\n')\n",
    "    # for model in typer:\n",
    "    #     st.write('\\n')\n",
    "    #     name = 'proba' + model.name[3:]\n",
    "    #     y_pred = stacked_val[name]\n",
    "    #     plot_confusion_matrix(y_true, y_pred, name, fr=0.0, to=0.9)\n",
    "\n",
    "#%%\n",
    "##############################################################\n",
    "#            FINAL LEARNING                                  #\n",
    "##############################################################\n",
    "\n",
    "def final_learning(modeller, n_splits=5):\n",
    "    # st.info('Final learning on all the data')\n",
    "    print('Final learning on all the data')\n",
    "    _ = TimeSeries_learning( None, modeller, n_splits=n_splits, meta_fraction=0, save=True)\n",
    "\n",
    "    # st.info('Step 2: Final learn meta model')\n",
    "    # _, _, _, _, enc = learn_meta_models(stacked_data, meta_featues)\n",
    "\n",
    "    # st.success('✔️ Final learning done')\n",
    "    print('Final learning done')\n",
    "\n",
    "#%%\n",
    "def scrape(full=True):\n",
    "    # scraping.write('Starta web-scraping för ny data')\n",
    "    # with st.spinner('Ta det lugnt!'):\n",
    "        # st.image('winning_horse.png')  # ,use_column_width=True)\n",
    "        #####################\n",
    "        # start v75_scraping as a thread\n",
    "        #####################\n",
    "        i = 0.0\n",
    "        # placeholder = st.empty()\n",
    "        seconds = 0\n",
    "        # my_bar = st.progress(i)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(v75_scraping)\n",
    "            while future.running():\n",
    "                time.sleep(1)\n",
    "                seconds += 1\n",
    "                # placeholder.write(f\"⏳ {seconds} sekunder\")\n",
    "                i += 1/65\n",
    "                if i < 0.99:\n",
    "                    pass\n",
    "                    # my_bar.progress(i)\n",
    "            # my_bar.progress(1.0)\n",
    "            # scraping.write('✔️ Scraping done, pls wait')\n",
    "            print('✔️ Scraping done, pls wait')\n",
    "            time.sleep(2)\n",
    "            df = future.result()\n",
    "            # scraping.write(f'✔️ {len(df)} rader hämtade')\n",
    "            print(f'✔️ {len(df)} rader hämtade')\n",
    "            \n",
    "            df.to_csv('sparad_scrape_learn.csv', index=False)\n",
    "\n",
    "        # st.balloons()\n",
    "        # my_bar.empty()\n",
    "        # placeholder.empty()\n",
    "\n",
    "        # st.session_state.df = df\n",
    "\n",
    "\n",
    "# models = [typ6, typ1, typ9]\n",
    "\n",
    "#%%\n",
    "# top = st.container()\n",
    "# buttons = st.container()\n",
    "# scraping = st.container()\n",
    "\n",
    "############################################\n",
    "#   Init session_state                     #\n",
    "############################################\n",
    "# with top:\n",
    "#     if 'fraction' not in st.session_state:\n",
    "#         st.session_state['fraction'] = 0.25\n",
    "fraction = 0.25\n",
    "#     if 'df' not in st.session_state:\n",
    "#         st.session_state['df'] = None\n",
    "omg_df = pd.read_csv(pref+'omg_att_spela_link.csv')\n",
    "urlen = omg_df.Link.values[0]\n",
    "datum = urlen.split('spel/')[1][0:10]\n",
    "#     if 'datum' not in st.session_state:\n",
    "#         omg_df = pd.read_csv('omg_att_spela_link.csv')\n",
    "#         urlen = omg_df.Link.values[0]\n",
    "#         datum = urlen.split('spel/')[1][0:10]\n",
    "#         st.session_state.datum = datum\n",
    "\n",
    "#     if 'datum' in st.session_state:\n",
    "#         datum = st.session_state['datum']\n",
    "#         year = int(datum[:4])\n",
    "#         month = int(datum[5:7])\n",
    "#         day = int(datum[8:])\n",
    "#         datum = st.sidebar.date_input(\n",
    "#             'Välj datum', datetime.date(year, month, day))\n",
    "#         datum = datum.strftime('%Y-%m-%d')\n",
    "\n",
    "        # if datum != st.session_state['datum']:\n",
    "        #     st.session_state['datum'] = datum\n",
    "        #     datum = \"https://www.atg.se/spel/\"+datum+\"/V75/\"\n",
    "        #     omg_df = pd.DataFrame([datum], columns=['Link'])\n",
    "        #     omg_df.to_csv('omg_att_spela_link.csv', index=False)\n",
    "\n",
    "    # st.header(f'Omgång:  {st.session_state.datum}')\n",
    "\n",
    "###########################################\n",
    "# control flow with buttons               #\n",
    "###########################################\n",
    "# with buttons:\n",
    "#     if st.sidebar.button('scrape'):\n",
    "#         st.write(f'web scraping {st.session_state.datum}')\n",
    "#         try:\n",
    "#             scrape()\n",
    "#             del st.session_state.datum  # säkra att datum är samma som i scraping\n",
    "#         except:\n",
    "#             st.error(\n",
    "#                 \"Fel i web scraping. Kolla att resultat finns för datum och internet är tillgängligt\")\n",
    "\n",
    "#     if st.sidebar.button('reuse scrape'):\n",
    "#         # del st.session_state.datum  # säkra att datum är samma som i scraping\n",
    "#         try:\n",
    "#             df = pd.read_csv('sparad_scrape_learn.csv')\n",
    "#             st.session_state.df = df\n",
    "#             if df.datum.iloc[0] != st.session_state.datum:\n",
    "#                 st.error(\n",
    "#                     f'Datum i data = {df.datum.iloc[0]} \\n\\n är inte samma som i omgång')\n",
    "#             else:\n",
    "#                 st.success(f'inläst data med datum = {df.datum.iloc[0]}')\n",
    "#         except:\n",
    "#             # write error message\n",
    "#             st.error('Ingen data sparad')\n",
    "\n",
    "#     if st.session_state.df is not None:\n",
    "#         if st.sidebar.button('Learn for validation'):\n",
    "#             st.write('TimeSeries learning for validation')\n",
    "#             fraction = st.session_state.fraction\n",
    "#             df = st.session_state.df\n",
    "#             st.write(\n",
    "#                 f'learn models and meta models on first {(1-fraction)*100} % of the data')\n",
    "\n",
    "#             stacked_data = TimeSeries_learning(\n",
    "#                 df, yper, n_splits=5, meta_fraction=fraction, save=True, learn_models=True)\n",
    "#             st.success('✔️ TimeSeries learning done')\n",
    "\n",
    "#         if st.sidebar.button('Validate'):\n",
    "#             validate(fraction=st.session_state.fraction)\n",
    "\n",
    "#         if st.sidebar.button('Final learning'):\n",
    "#             final_learning(yper)\n",
    "\n",
    "#         if st.sidebar.button('Clear'):\n",
    "#             st.empty()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För Testerna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "button = 'test'   # 'scrape'  # 'reuse'  # 'learn'  # 'validate'  # 'final'  # 'clear'\n",
    "\n",
    "\n",
    "if button == 'scrape':\n",
    "    print(f'web scraping {datum}')\n",
    "    try:\n",
    "        scrape()\n",
    "        # del st.session_state.datum  # säkra att datum är samma som i scraping\n",
    "    except:\n",
    "        print(\"Fel i web scraping. Kolla att resultat finns för datum och internet är tillgängligt\")\n",
    "else: # resuse scrape\n",
    "    try:\n",
    "        df_ny = pd.read_csv(pref+'sparad_scrape_learn.csv')\n",
    "        # st.session_state.df = df\n",
    "    except:\n",
    "        # write error message\n",
    "        print('Ingen data sparad')\n",
    "        \n",
    "if button=='learn':\n",
    "    print('TimeSeries learning for validation')\n",
    "    try:\n",
    "        df_ny = pd.read_csv(pref+'sparad_scrape_learn.csv')\n",
    "        loaded=True\n",
    "        # st.session_state.df = df\n",
    "    except:\n",
    "        loaded=False\n",
    "        # write error message\n",
    "        print('Ingen data sparad')\n",
    "    if loaded:\n",
    "        print(f'learn models and meta models on first {(1-fraction)*100} % of the data')\n",
    "\n",
    "        stacked_data = TimeSeries_learning(df_ny, modeller, n_splits=5, val_fraction=fraction, save=True, learn_models=True)\n",
    "        display(stacked_data)\n",
    "        print('✔️ TimeSeries learning done')\n",
    "        \n",
    "if button == 'validate':\n",
    "    print('Validation')\n",
    "\n",
    "    # validate(fraction=st.session_state.fraction)\n",
    "    validate(fraction=fraction)\n",
    "\n",
    "if button == 'test':\n",
    "    print('test inheritance')\n",
    "    \n",
    "    class v75_ny(td.v75):\n",
    "        def __init__(self, df_ny, pref=''):  #, filnamn='all_data.csv', pref=''):\n",
    "            \"\"\" init - used for df_ny in order to reuse the code in v75 \"\"\"\n",
    "            self.pref=pref\n",
    "            self.df = df_ny\n",
    "            self.work_df = self.df.copy()   # arbetskopia \n",
    "            \n",
    "    #<<<<<<<<<<<<<<<<<<<<< Skapa test-data<<<<<<<<<<<<<<<\n",
    "    v75 = td.v75(pref=pref)\n",
    "    df_work = v75.get_work_df()\n",
    "    # # Hämta data från v75\n",
    "    # _ = v75.förbered_data(missing_num=False)  # num hanteras av catboost\n",
    "    # df_work = v75.test_lägg_till_kolumner()\n",
    "    ny_df = df_work.iloc[0:10].copy()\n",
    "    ny_df.pop('plac')\n",
    "    #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    \n",
    "    ny_ =v75_ny(ny_df,pref=pref)\n",
    "    # ny_.kolla()\n",
    "    \n",
    "    ny_.förbered_data(missing_num=False)\n",
    "    df_work = ny_.test_lägg_till_kolumner()\n",
    "    df_work.shape\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allsköns tester  \n",
    "Fråga: Kan man merga olka dataframes med olika features till en meningsfull stack_data för meta_modellerna?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det blir en massa Nan värden i stack_data från de modeller som inte har samma features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "# pickle load ENC  \n",
    "ENC = pickle.load(open('../modeller/meta_encoder.pkl', 'rb'))\n",
    "\n",
    "fes=ENC.feature_names\n",
    "fesat=pd.DataFrame(columns=fes)\n",
    "fesat\n",
    "fesat.drop([],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from category_encoders import *\n",
    "# import pandas as pd\n",
    "# from sklearn.datasets import load_boston\n",
    "# bunch = load_boston()\n",
    "# y = bunch.target\n",
    "# X = pd.DataFrame(bunch.data, columns=bunch.feature_names)\n",
    "# enc = TargetEncoder(cols=['CHAS','RAD'], min_samples_leaf=20, smoothing=10).fit(X.drop(['B'],axis=1), y)\n",
    "# numeric_dataset = enc.transform(X.drop(['B'],axis=1))\n",
    "# # numeric_dataset\n",
    "# y  .shape, y.  shape, 'BÅDA GÅR BRA!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../all_data.csv\n",
      "Loading dataframe from the file: ../all_data.csv\n",
      "plac finns i df\n",
      "['datum', 'avd', 'bana', 'häst', 'kusk', 'streck', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'kön', 'pris', 'h1_kusk', 'h1_bana', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_kusk', 'h2_bana', 'h2_spår', 'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_kusk', 'h3_bana', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_kusk', 'h4_bana', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_kusk', 'h5_bana', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4', 'y', 'rel_kr', 'streck_avst', 'rel_rank', 'h1_samma_bana', 'h2_samma_bana', 'h3_samma_bana', 'h1_samma_kusk', 'h2_samma_kusk', 'h3_samma_kusk']\n",
      "streck: True i init för test1\n",
      "Gör denna till produktion\n",
      "streck: False i init för test2\n",
      "Gör denna till produktion\n",
      "streck: False i init för test3\n",
      "streck: False i init för test4\n"
     ]
    }
   ],
   "source": [
    "# Skapa v75-instans\n",
    "v75 = td.v75(pref=pref)\n",
    "\n",
    "base_features = v75.get_df().columns.to_list()\n",
    "\n",
    "# Hämta data från v75\n",
    "_ = v75.förbered_data(missing_num=False)  # num hanteras av catboost\n",
    "df_work = v75.test_lägg_till_kolumner()\n",
    "print(df_work.columns.to_list())\n",
    "\n",
    "#               name,   #häst  #motst,  motst_diff, streck, test,  pref\n",
    "test1 = tp.Typ('test1',  False,   0,    False,      True,   True,  pref=pref)\n",
    "test2 = tp.Typ('test2',  False,   0,    False,      False,   True,  pref=pref)\n",
    "test3 = tp.Typ('test3',  True,    0,    False,      False,   False, pref=pref)\n",
    "test4 = tp.Typ('test4',  True,    3,    True,       False,   False, pref=pref)\n",
    "\n",
    "modeller = [test1, test2, test3, test4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\ops\\array_ops.py:73: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(datetime.date(2022, 8, 13), datetime.date(2022, 8, 17))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bryt_datum = pd.Timestamp('2022-08-17')\n",
    "train = df_work.loc[df_work.datum < bryt_datum]\n",
    "test = df_work.loc[df_work.datum >= bryt_datum]\n",
    "\n",
    "train.datum.max(), test.datum.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'name': 'test1',\n",
       "  'ant_hästar': False,\n",
       "  'motst_ant': 0,\n",
       "  'motst_diff': False,\n",
       "  'streck': True,\n",
       "  'pref': '../',\n",
       "  'rel_kr': True,\n",
       "  'rel_rank': True,\n",
       "  'streck_avst': True,\n",
       "  'hx_samma_bana': True,\n",
       "  'hx_sammam_kusk': True},\n",
       " {'name': 'test2',\n",
       "  'ant_hästar': False,\n",
       "  'motst_ant': 0,\n",
       "  'motst_diff': False,\n",
       "  'streck': False,\n",
       "  'pref': '../',\n",
       "  'rel_kr': True,\n",
       "  'rel_rank': True,\n",
       "  'streck_avst': True,\n",
       "  'hx_samma_bana': True,\n",
       "  'hx_sammam_kusk': True},\n",
       " {'name': 'test3',\n",
       "  'ant_hästar': True,\n",
       "  'motst_ant': 0,\n",
       "  'motst_diff': False,\n",
       "  'streck': False,\n",
       "  'pref': '../',\n",
       "  'rel_kr': False,\n",
       "  'rel_rank': False,\n",
       "  'streck_avst': False,\n",
       "  'hx_samma_bana': False,\n",
       "  'hx_sammam_kusk': False},\n",
       " {'name': 'test4',\n",
       "  'ant_hästar': True,\n",
       "  'motst_ant': 3,\n",
       "  'motst_diff': True,\n",
       "  'streck': False,\n",
       "  'pref': '../',\n",
       "  'rel_kr': False,\n",
       "  'rel_rank': False,\n",
       "  'streck_avst': False,\n",
       "  'hx_samma_bana': False,\n",
       "  'hx_sammam_kusk': False})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.get_params(), test2.get_params(), test3.get_params(), test4.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning test1\n"
     ]
    }
   ],
   "source": [
    "# data = test1.prepare_for_model(train)\n",
    "# print('streck' in data.columns)\n",
    "model1=test1.learn(train.drop('y', axis=1), train['y'], save=False)\n",
    "proba1 = test1.predict(test.drop('y', axis=1), model=model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning test2\n",
      "drop streck\n"
     ]
    }
   ],
   "source": [
    "model2=test2.learn(train.drop('y', axis=1), train['y'], save=False)\n",
    "proba2 = test2.predict(test.drop('y', axis=1), model=model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning test3\n",
      "drop streck\n"
     ]
    }
   ],
   "source": [
    "model3=test3.learn(train.drop('y', axis=1), train['y'], save=False)\n",
    "proba3 = test3.predict(test.drop('y', axis=1), model=model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning test4\n",
      "drop streck\n"
     ]
    }
   ],
   "source": [
    "model4=test4.learn(train.drop('y', axis=1), train['y'], save=False)\n",
    "proba4 = test4.predict(test.drop('y', axis=1), model=model4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature Id  Importances\n",
      "0        rel_rank    58.833500\n",
      "1     streck_avst    22.161446\n",
      "2            häst     5.966338\n",
      "3          rel_kr     5.392149\n",
      "4            kusk     1.153969\n",
      "5         h3_odds     0.417064\n",
      "6            spår     0.336664\n",
      "7         h1_odds     0.293777\n",
      "8         h2_odds     0.282564\n",
      "9         h4_odds     0.275877\n",
      "10        h1_kusk     0.271322\n",
      "11            kön     0.219368\n",
      "12        h2_plac     0.202970\n",
      "13        h1_perf     0.201586\n",
      "14        h1_plac     0.173612\n",
      "15          ålder     0.168131\n",
      "16        h3_perf     0.159713\n",
      "17        h2_perf     0.158035\n",
      "18       h2_kmtid     0.141174\n",
      "19       h1_kmtid     0.139084\n",
      "20        h3_plac     0.131870\n",
      "21        h1_bana     0.123209\n",
      "22        h4_perf     0.118882\n",
      "23        h2_pris     0.117009\n",
      "24        h2_bana     0.116475\n",
      "25        h3_pris     0.115992\n",
      "26        h5_perf     0.114948\n",
      "27        h4_bana     0.113802\n",
      "28        h3_bana     0.112843\n",
      "29        h5_pris     0.112609\n",
      "30        h5_odds     0.110291\n",
      "31        h5_bana     0.102725\n",
      "32         senast     0.101013\n",
      "33          start     0.083649\n",
      "34        h5_kusk     0.083258\n",
      "35       h3_kmtid     0.073411\n",
      "36        h1_pris     0.072249\n",
      "37         delta1     0.069040\n",
      "38        h1_dist     0.066719\n",
      "39       h5_kmtid     0.062160\n",
      "40       h4_kmtid     0.061576\n",
      "41        h2_kusk     0.060443\n",
      "42        h4_spår     0.059609\n",
      "43      lopp_dist     0.054984\n",
      "44           bana     0.054096\n",
      "45         delta2     0.047092\n",
      "46         delta3     0.045701\n",
      "47        h4_plac     0.044505\n",
      "48        h3_dist     0.043617\n",
      "49         delta4     0.042014\n",
      "50           pris     0.040923\n",
      "51        h4_kusk     0.039528\n",
      "52  h2_samma_kusk     0.039499\n",
      "53        h4_pris     0.038498\n",
      "54        h1_spår     0.038145\n",
      "55        h3_spår     0.035484\n",
      "56        h2_spår     0.034950\n",
      "57  h3_samma_kusk     0.033560\n",
      "58        h5_dist     0.033423\n",
      "59        h4_dist     0.028333\n",
      "60        h2_auto     0.024407\n",
      "61        h3_kusk     0.022295\n",
      "62        h2_dist     0.018266\n",
      "63        h5_auto     0.017622\n",
      "64  h1_samma_kusk     0.014753\n",
      "65           dist     0.014363\n",
      "66        h5_plac     0.014281\n",
      "67        h5_spår     0.012023\n",
      "68  h3_samma_bana     0.011429\n",
      "69        h4_auto     0.009793\n",
      "70  h2_samma_bana     0.008029\n",
      "71        h3_auto     0.006261\n",
      "72        h1_auto     0.000000\n",
      "73  h1_samma_bana     0.000000\n",
      "['bana', 'häst', 'kusk', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'kön', 'pris', 'h1_kusk', 'h1_bana', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_kusk', 'h2_bana', 'h2_spår', 'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_kusk', 'h3_bana', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_kusk', 'h4_bana', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_kusk', 'h5_bana', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4', 'rel_kr', 'streck_avst', 'rel_rank', 'h1_samma_bana', 'h2_samma_bana', 'h3_samma_bana', 'h1_samma_kusk', 'h2_samma_kusk', 'h3_samma_kusk'] 74\n"
     ]
    }
   ],
   "source": [
    "# print(model1.get_feature_importance(prettified=True))\n",
    "print(model2.get_feature_importance(prettified=True))\n",
    "# print(model3.get_feature_importance(prettified=True))\n",
    "# print(model4.get_feature_importance(prettified=True))\n",
    "model1_features = model1.feature_names_\n",
    "model2_features = model2.feature_names_\n",
    "model3_features = model3.feature_names_\n",
    "model4_features = model4.feature_names_\n",
    "# print(model1_features,len(model1_features))\n",
    "print(model2_features,len(model2_features))\n",
    "# print(model3_features,len(model3_features))\n",
    "# print(model4_features,len(model4_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avd', 'datum', 'y'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = test1.prepare_for_model(test.drop('y', axis=1))\n",
    "X1=tp.prepare_for_catboost(X1,model1_features)[0]\n",
    "X2 = test2.prepare_for_model(test.drop('y', axis=1))\n",
    "X2=tp.prepare_for_catboost(X2,model2_features)[0]\n",
    "X3 = test3.prepare_for_model(test.drop('y', axis=1))\n",
    "X3=tp.prepare_for_catboost(X3,model3_features)[0]\n",
    "X4 = test4.prepare_for_model(test.drop('y', axis=1))\n",
    "X4=tp.prepare_for_catboost(X4,model4_features)[0]\n",
    "set(train.columns.to_list()) - set(model1.feature_names_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kolla hur vi kan få fram en dataframes med alla möjliga features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datum</th>\n",
       "      <th>avd</th>\n",
       "      <th>bana</th>\n",
       "      <th>häst</th>\n",
       "      <th>kusk</th>\n",
       "      <th>streck</th>\n",
       "      <th>spår</th>\n",
       "      <th>dist</th>\n",
       "      <th>lopp_dist</th>\n",
       "      <th>start</th>\n",
       "      <th>ålder</th>\n",
       "      <th>kön</th>\n",
       "      <th>pris</th>\n",
       "      <th>h1_kusk</th>\n",
       "      <th>h1_bana</th>\n",
       "      <th>h1_spår</th>\n",
       "      <th>h1_plac</th>\n",
       "      <th>h1_pris</th>\n",
       "      <th>h1_odds</th>\n",
       "      <th>h1_kmtid</th>\n",
       "      <th>h2_kusk</th>\n",
       "      <th>h2_bana</th>\n",
       "      <th>h2_spår</th>\n",
       "      <th>h2_plac</th>\n",
       "      <th>h2_pris</th>\n",
       "      <th>h2_odds</th>\n",
       "      <th>h2_kmtid</th>\n",
       "      <th>h3_kusk</th>\n",
       "      <th>h3_bana</th>\n",
       "      <th>h3_spår</th>\n",
       "      <th>h3_plac</th>\n",
       "      <th>h3_pris</th>\n",
       "      <th>h3_odds</th>\n",
       "      <th>h3_kmtid</th>\n",
       "      <th>h4_kusk</th>\n",
       "      <th>h4_bana</th>\n",
       "      <th>h4_spår</th>\n",
       "      <th>h4_plac</th>\n",
       "      <th>h4_pris</th>\n",
       "      <th>h4_odds</th>\n",
       "      <th>h4_kmtid</th>\n",
       "      <th>h5_kusk</th>\n",
       "      <th>h5_bana</th>\n",
       "      <th>h5_spår</th>\n",
       "      <th>h5_plac</th>\n",
       "      <th>h5_pris</th>\n",
       "      <th>h5_odds</th>\n",
       "      <th>h5_kmtid</th>\n",
       "      <th>h1_dist</th>\n",
       "      <th>h2_dist</th>\n",
       "      <th>h3_dist</th>\n",
       "      <th>h4_dist</th>\n",
       "      <th>h5_dist</th>\n",
       "      <th>h1_auto</th>\n",
       "      <th>h2_auto</th>\n",
       "      <th>h3_auto</th>\n",
       "      <th>h4_auto</th>\n",
       "      <th>h5_auto</th>\n",
       "      <th>h1_perf</th>\n",
       "      <th>h2_perf</th>\n",
       "      <th>h3_perf</th>\n",
       "      <th>h4_perf</th>\n",
       "      <th>h5_perf</th>\n",
       "      <th>senast</th>\n",
       "      <th>delta1</th>\n",
       "      <th>delta2</th>\n",
       "      <th>delta3</th>\n",
       "      <th>delta4</th>\n",
       "      <th>rel_kr</th>\n",
       "      <th>streck_avst</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>h1_samma_bana</th>\n",
       "      <th>h2_samma_bana</th>\n",
       "      <th>h3_samma_bana</th>\n",
       "      <th>h1_samma_kusk</th>\n",
       "      <th>h2_samma_kusk</th>\n",
       "      <th>h3_samma_kusk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46420</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>strängnäs palema</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>v</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>gävle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.91</td>\n",
       "      <td>12.1</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>axevalla</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.05</td>\n",
       "      <td>13.9</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>bergsåker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>14.4</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>färjestad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>13.8</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.43</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1484.131591</td>\n",
       "      <td>6651.416330</td>\n",
       "      <td>900.171313</td>\n",
       "      <td>569.318327</td>\n",
       "      <td>697.269701</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.108275</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46421</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>destino d.j.</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>axevalla</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>13.2</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>örebro</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>15.5</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>14.3</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.30</td>\n",
       "      <td>15.3</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>eskilstuna</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>16.8</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2609.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10966.331584</td>\n",
       "      <td>12260.731443</td>\n",
       "      <td>8494.483919</td>\n",
       "      <td>8494.483919</td>\n",
       "      <td>6935.717077</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.183798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46422</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>nat king cole</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>gävle</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>40.95</td>\n",
       "      <td>12.8</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>14.9</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.47</td>\n",
       "      <td>15.0</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.63</td>\n",
       "      <td>15.8</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>halmstad</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54.60</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>900.171313</td>\n",
       "      <td>1895.375557</td>\n",
       "      <td>8494.483919</td>\n",
       "      <td>6935.717077</td>\n",
       "      <td>6935.717077</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.081840</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            datum  avd      bana              häst             kusk  streck  spår    dist  lopp_dist  start  ålder kön      pris          h1_kusk   h1_bana  h1_spår  h1_plac  h1_pris  h1_odds  h1_kmtid          h2_kusk   h2_bana  h2_spår  h2_plac  h2_pris  \\\n",
       "46420  2022-08-17  1.0  solvalla  strängnäs palema      hans crebas    14.0   1.0  1640.0     1640.0      1      3   v  300000.0      hans crebas     gävle      1.0      5.0    100.0    22.91      12.1      hans crebas  axevalla      1.0      2.0    100.0   \n",
       "46421  2022-08-17  1.0  solvalla      destino d.j.     jorma kontio    63.0   3.0  1640.0     1640.0      1      3   h  300000.0     jorma kontio  axevalla      2.0      1.0    100.0     2.30      13.2     jorma kontio    örebro      2.0      1.0    125.0   \n",
       "46422  2022-08-17  1.0  solvalla     nat king cole  adrian kolgjini     2.0   4.0  1640.0     1640.0      1      3   h  300000.0  adrian kolgjini     gävle      3.0      6.0    100.0    40.95      12.8  adrian kolgjini  solvalla      3.0      4.0     60.0   \n",
       "\n",
       "       h2_odds  h2_kmtid          h3_kusk    h3_bana  h3_spår  h3_plac  h3_pris  h3_odds  h3_kmtid          h4_kusk    h4_bana  h4_spår  h4_plac  h4_pris  h4_odds  h4_kmtid          h5_kusk     h5_bana  h5_spår  h5_plac  h5_pris  h5_odds  h5_kmtid  h1_dist  \\\n",
       "46420    38.05      13.9      hans crebas  bergsåker      1.0      6.0    100.0     4.08      14.4      hans crebas  färjestad      1.0      6.0     40.0     3.51      13.8      hans crebas    solvalla      1.0      6.0     60.0    10.43      15.3   1640.0   \n",
       "46421     2.77      15.5     jorma kontio   solvalla      2.0      1.0     60.0     6.51      14.3     jorma kontio   solvalla      2.0      1.0     60.0    10.30      15.3     jorma kontio  eskilstuna      2.0      1.0     40.0     2.94      16.8   2140.0   \n",
       "46422     3.58      14.9  adrian kolgjini   solvalla      3.0      1.0     60.0     3.47      15.0  adrian kolgjini   solvalla      3.0      1.0     40.0    20.63      15.8  adrian kolgjini    halmstad      3.0      1.0     40.0    54.60      23.4   1640.0   \n",
       "\n",
       "       h2_dist  h3_dist  h4_dist  h5_dist  h1_auto  h2_auto  h3_auto  h4_auto  h5_auto       h1_perf       h2_perf      h3_perf      h4_perf      h5_perf  senast  delta1  delta2  delta3  delta4    rel_kr  streck_avst  rel_rank  h1_samma_bana  h2_samma_bana  \\\n",
       "46420   2140.0   2140.0   2140.0   2140.0        1        1        1        1        0   1484.131591   6651.416330   900.171313   569.318327   697.269701    13.0    11.0    38.0    17.0    12.0  0.108275         49.0  0.285714          False          False   \n",
       "46421   2609.0   2140.0   2140.0   2140.0        1        1        1        0        0  10966.331584  12260.731443  8494.483919  8494.483919  6935.717077    24.0    10.0    27.0    30.0     8.0  0.183798          0.0  0.142857          False          False   \n",
       "46422   2140.0   2140.0   2140.0   2140.0        1        1        0        0        0    900.171313   1895.375557  8494.483919  6935.717077  6935.717077    13.0    22.0    21.0     9.0    21.0  0.081840         61.0  0.857143          False           True   \n",
       "\n",
       "       h3_samma_bana  h1_samma_kusk  h2_samma_kusk  h3_samma_kusk  \n",
       "46420          False           True           True           True  \n",
       "46421           True           True           True           True  \n",
       "46422           True           True           True           True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datum</th>\n",
       "      <th>avd</th>\n",
       "      <th>bana</th>\n",
       "      <th>häst</th>\n",
       "      <th>kusk</th>\n",
       "      <th>streck</th>\n",
       "      <th>spår</th>\n",
       "      <th>dist</th>\n",
       "      <th>lopp_dist</th>\n",
       "      <th>start</th>\n",
       "      <th>ålder</th>\n",
       "      <th>kön</th>\n",
       "      <th>pris</th>\n",
       "      <th>h1_kusk</th>\n",
       "      <th>h1_bana</th>\n",
       "      <th>h1_spår</th>\n",
       "      <th>h1_plac</th>\n",
       "      <th>h1_pris</th>\n",
       "      <th>h1_odds</th>\n",
       "      <th>h1_kmtid</th>\n",
       "      <th>h2_kusk</th>\n",
       "      <th>h2_bana</th>\n",
       "      <th>h2_spår</th>\n",
       "      <th>h2_plac</th>\n",
       "      <th>h2_pris</th>\n",
       "      <th>h2_odds</th>\n",
       "      <th>h2_kmtid</th>\n",
       "      <th>h3_kusk</th>\n",
       "      <th>h3_bana</th>\n",
       "      <th>h3_spår</th>\n",
       "      <th>h3_plac</th>\n",
       "      <th>h3_pris</th>\n",
       "      <th>h3_odds</th>\n",
       "      <th>h3_kmtid</th>\n",
       "      <th>h4_kusk</th>\n",
       "      <th>h4_bana</th>\n",
       "      <th>h4_spår</th>\n",
       "      <th>h4_plac</th>\n",
       "      <th>h4_pris</th>\n",
       "      <th>h4_odds</th>\n",
       "      <th>h4_kmtid</th>\n",
       "      <th>h5_kusk</th>\n",
       "      <th>h5_bana</th>\n",
       "      <th>h5_spår</th>\n",
       "      <th>h5_plac</th>\n",
       "      <th>h5_pris</th>\n",
       "      <th>h5_odds</th>\n",
       "      <th>h5_kmtid</th>\n",
       "      <th>h1_dist</th>\n",
       "      <th>h2_dist</th>\n",
       "      <th>h3_dist</th>\n",
       "      <th>h4_dist</th>\n",
       "      <th>h5_dist</th>\n",
       "      <th>h1_auto</th>\n",
       "      <th>h2_auto</th>\n",
       "      <th>h3_auto</th>\n",
       "      <th>h4_auto</th>\n",
       "      <th>h5_auto</th>\n",
       "      <th>h1_perf</th>\n",
       "      <th>h2_perf</th>\n",
       "      <th>h3_perf</th>\n",
       "      <th>h4_perf</th>\n",
       "      <th>h5_perf</th>\n",
       "      <th>senast</th>\n",
       "      <th>delta1</th>\n",
       "      <th>delta2</th>\n",
       "      <th>delta3</th>\n",
       "      <th>delta4</th>\n",
       "      <th>ant_per_lopp</th>\n",
       "      <th>diff1</th>\n",
       "      <th>diff2</th>\n",
       "      <th>diff3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46420</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>strängnäs palema</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>v</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>gävle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.91</td>\n",
       "      <td>12.1</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>axevalla</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.05</td>\n",
       "      <td>13.9</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>bergsåker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>14.4</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>färjestad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>13.8</td>\n",
       "      <td>hans crebas</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.43</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1484.131591</td>\n",
       "      <td>6651.416330</td>\n",
       "      <td>900.171313</td>\n",
       "      <td>569.318327</td>\n",
       "      <td>697.269701</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46421</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>destino d.j.</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>axevalla</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>13.2</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>örebro</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>15.5</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>14.3</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.30</td>\n",
       "      <td>15.3</td>\n",
       "      <td>jorma kontio</td>\n",
       "      <td>eskilstuna</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>16.8</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2609.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10966.331584</td>\n",
       "      <td>12260.731443</td>\n",
       "      <td>8494.483919</td>\n",
       "      <td>8494.483919</td>\n",
       "      <td>6935.717077</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46422</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>nat king cole</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>gävle</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>40.95</td>\n",
       "      <td>12.8</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>14.9</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.47</td>\n",
       "      <td>15.0</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>solvalla</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.63</td>\n",
       "      <td>15.8</td>\n",
       "      <td>adrian kolgjini</td>\n",
       "      <td>halmstad</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54.60</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>900.171313</td>\n",
       "      <td>1895.375557</td>\n",
       "      <td>8494.483919</td>\n",
       "      <td>6935.717077</td>\n",
       "      <td>6935.717077</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            datum  avd      bana              häst             kusk  streck  spår    dist  lopp_dist  start  ålder kön      pris          h1_kusk   h1_bana  h1_spår  h1_plac  h1_pris  h1_odds  h1_kmtid          h2_kusk   h2_bana  h2_spår  h2_plac  h2_pris  \\\n",
       "46420  2022-08-17  1.0  solvalla  strängnäs palema      hans crebas    14.0   1.0  1640.0     1640.0      1      3   v  300000.0      hans crebas     gävle      1.0      5.0    100.0    22.91      12.1      hans crebas  axevalla      1.0      2.0    100.0   \n",
       "46421  2022-08-17  1.0  solvalla      destino d.j.     jorma kontio    63.0   3.0  1640.0     1640.0      1      3   h  300000.0     jorma kontio  axevalla      2.0      1.0    100.0     2.30      13.2     jorma kontio    örebro      2.0      1.0    125.0   \n",
       "46422  2022-08-17  1.0  solvalla     nat king cole  adrian kolgjini     2.0   4.0  1640.0     1640.0      1      3   h  300000.0  adrian kolgjini     gävle      3.0      6.0    100.0    40.95      12.8  adrian kolgjini  solvalla      3.0      4.0     60.0   \n",
       "\n",
       "       h2_odds  h2_kmtid          h3_kusk    h3_bana  h3_spår  h3_plac  h3_pris  h3_odds  h3_kmtid          h4_kusk    h4_bana  h4_spår  h4_plac  h4_pris  h4_odds  h4_kmtid          h5_kusk     h5_bana  h5_spår  h5_plac  h5_pris  h5_odds  h5_kmtid  h1_dist  \\\n",
       "46420    38.05      13.9      hans crebas  bergsåker      1.0      6.0    100.0     4.08      14.4      hans crebas  färjestad      1.0      6.0     40.0     3.51      13.8      hans crebas    solvalla      1.0      6.0     60.0    10.43      15.3   1640.0   \n",
       "46421     2.77      15.5     jorma kontio   solvalla      2.0      1.0     60.0     6.51      14.3     jorma kontio   solvalla      2.0      1.0     60.0    10.30      15.3     jorma kontio  eskilstuna      2.0      1.0     40.0     2.94      16.8   2140.0   \n",
       "46422     3.58      14.9  adrian kolgjini   solvalla      3.0      1.0     60.0     3.47      15.0  adrian kolgjini   solvalla      3.0      1.0     40.0    20.63      15.8  adrian kolgjini    halmstad      3.0      1.0     40.0    54.60      23.4   1640.0   \n",
       "\n",
       "       h2_dist  h3_dist  h4_dist  h5_dist  h1_auto  h2_auto  h3_auto  h4_auto  h5_auto       h1_perf       h2_perf      h3_perf      h4_perf      h5_perf  senast  delta1  delta2  delta3  delta4  ant_per_lopp  diff1  diff2  diff3  \n",
       "46420   2140.0   2140.0   2140.0   2140.0        1        1        1        1        0   1484.131591   6651.416330   900.171313   569.318327   697.269701    13.0    11.0    38.0    17.0    12.0             7   49.0    0.0   -5.0  \n",
       "46421   2609.0   2140.0   2140.0   2140.0        1        1        1        0        0  10966.331584  12260.731443  8494.483919  8494.483919  6935.717077    24.0    10.0    27.0    30.0     8.0             7    0.0  -49.0  -54.0  \n",
       "46422   2140.0   2140.0   2140.0   2140.0        1        1        0        0        0    900.171313   1895.375557  8494.483919  6935.717077  6935.717077    13.0    22.0    21.0     9.0    21.0             7   61.0   12.0    7.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X1.head(3))\n",
    "display(X4.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46224, 78), (726, 77), (726, 77), (726, 69), (726, 72))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# differrence between dicts\n",
    "def diff(li1, li2):\n",
    "    return (list(set(li1) - set(li2))+list(set(li2) - set(li1)))\n",
    "\n",
    "# make dict from X1\n",
    "X1_dict = X1.to_dict('list')\n",
    "X4_dict = X4.to_dict('list')\n",
    "X1_dict\n",
    "test_dict = test.to_dict('list')\n",
    "diff(X1_dict,X4_dict)\n",
    "train.shape, X1.shape,X2.shape,X3.shape,X4.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:50:36) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d733caf4ffc39d0fbd9a2ba54ef4b7d515956d8048931f8241efe3827fb2d1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
