{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En ny learning och validering   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beskrivning:  \n",
    "\n",
    "Normal learning:  \n",
    "- Learning: gör webscrape av omgång(ar) och kör en learning\n",
    "\n",
    "GridSearch optimering:  \n",
    "- gör gridsearch av de olika modellerna typ1, typ6, typ9 och typ16 samt meta_modellen\n",
    "  - inkludera imbalanced-lösningar\n",
    "  - spara de bästa hyperparametrarna\n",
    "  \n",
    "Värdera:  \n",
    "- Cross_validate: ts_split and ts cross_validate of the stack of models plus the meta_model\n",
    "  - save the results in pickle\n",
    "- Vinst: beräknar vinsten för de olika modellerna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Först kolla artiklar om stacking, cv för stacking samt cv för stacking av timeseries \n",
    "- https://machinelearningmastery.com/implementing-stacking-scratch-python/   (Även kod i Pieces)  \n",
    "Även allmänt om stacking ensembles  \n",
    "- https://machinelearningmastery.com/essence-of-stacking-ensembles-for-machine-learning/  \n",
    "Slutligen CV för Timeseries stacking  (se kod i Pieces)  \n",
    "- https://datascience.stackexchange.com/questions/41378/how-to-apply-stacking-cross-validation-for-time-series-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generella funktioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moduler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from IPython.display import display\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "sys.path.append(\n",
    "    'C:\\\\Users\\\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel\\\\')\n",
    "\n",
    "import typ as tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# läs in data\n",
    "def läs_in_data_och_förbered():\n",
    "    df = pd.read_csv('..\\\\all_data.csv')\n",
    "    # Följande datum saknar avd==5 och kan inte användas\n",
    "    saknas = ['2015-08-15', '2016-08-13', '2017-08-12']\n",
    "    df = df[~df.datum.isin(saknas)]\n",
    "    X = df.copy()\n",
    "    X.drop('plac', axis=1, inplace=True)\n",
    "    \n",
    "    y = (df.plac == 1)*1   # plac 1 eller 0\n",
    "\n",
    "    for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        X[f] = X[f].str.lower()\n",
    "\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # läs in FEATIRES.txt\n",
    "    with open('..\\\\FEATURES.txt', 'r') as f:    \n",
    "        features = f.read().splitlines()\n",
    "    \n",
    "    assert len(features) == len(X.columns), f'features {len(features)} and X.columns {len(X.columns)} are not the same length'   \n",
    "    assert set(features) == set(X.columns), f'features {set(features)} and X.columns {set(X.columns)} are not the same'\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#              namn, ant_hästar, proba, Kelly,  motst_ant, motst_diff, ant_favoriter,   only_clear, streck\n",
    "typ6 = tp.Typ('typ6', True,       True, False,     0,       False,          0,            False,    True)\n",
    "typ1 = tp.Typ('typ1', False,      True, False,     2,       True,           2,            True,     False)\n",
    "typ9 = tp.Typ('typ9', True,       True, True,      2,       True,           2,            True,     True)\n",
    "typ16= tp.Typ('typ16',True,       True, True,      2,       True,           2,            False,    True)\n",
    "\n",
    "typer = [typ6, typ1, typ9, typ16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(df_, remove_mer=[]):\n",
    "    df = df_.copy()\n",
    "    df.drop(['startnr', 'vodds', 'podds', 'bins', 'h1_dat',\n",
    "             'h2_dat', 'h3_dat', 'h4_dat', 'h5_dat'], axis=1, inplace=True)\n",
    "    if remove_mer:\n",
    "        df.drop(remove_mer, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV av typ6, typ1, typ9, typ16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA\n",
    "    # Läs in data\n",
    "    # remove_features\n",
    "\n",
    "# modeller konfigurering, CatBoostClassifier  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a GridSearch for CatBoostClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "def create_grid_search(X_, y_, typ, verbose=False):\n",
    "    X = X_.copy()\n",
    "    y = y_.copy()\n",
    "    # remove features\n",
    "    X = typ.prepare_for_model(X)\n",
    "    if not typ.streck:\n",
    "        X.drop('streck', axis=1, inplace=True)\n",
    "    \n",
    "    X, cat_features = tp.prepare_for_catboost(X)\n",
    "    print('cat_features\\n',cat_features)\n",
    "    X = remove_features(X, remove_mer=['datum','avd'])\n",
    "    # get numerical features and cat_features\n",
    "    num_features = list(X.select_dtypes(include=[np.number]).columns)\n",
    "    cat_features = list(X.select_dtypes(include=['object']).columns)\n",
    "    # print('cat_features:\\n',cat_features,'\\n')\n",
    "    # print(X[cat_features].info())\n",
    "    assert X[cat_features].isnull().sum().sum() == 0, 'there are NaN values in cat_features'\n",
    "    # create a GridSearch\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
    "        'depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9, 11, 13, 15],\n",
    "        'iterations': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "        'bagging_temperature': [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9],\n",
    "        'rsm': [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9],\n",
    "        'depth_per_tree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'border_count': [32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "        'fold_permutation_block_size': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'od_pval': [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9],\n",
    "        'od_wait': [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3,  1.5, 1.7, 1.9],\n",
    "        'od_type': ['IncToDec', 'Iter'],\n",
    "    }\n",
    "\n",
    "    # X.datum = pd.to_datetime(X.datum)\n",
    "    # X.datum = X.datum.dt.date\n",
    "    # alla_datum = X.datum.unique()\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    # for train_index, test_index in tscv.split(X):\n",
    "    #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        # X_train, X_test = X[train_index], X[test_index]\n",
    "        # y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = CatBoostClassifier(iterations=500, loss_function='Logloss', eval_metric='AUC',\n",
    "                               use_best_model=False, early_stopping_rounds=100, verbose=verbose,)\n",
    "\n",
    "    grid = {'learning_rate': [0.002,0.005],\n",
    "            'depth': [2,4,6,8],\n",
    "            'l2_leaf_reg': [8, 9, 10,11]}\n",
    "    \n",
    "    # print(X[cat_features].info())\n",
    "    assert X[cat_features].isnull().sum().sum() == 0, 'there are NaN values in cat_features'\n",
    "\n",
    "    grid_search_result = model.grid_search(grid,\n",
    "                                        X=Pool(X, y, cat_features=cat_features),\n",
    "                                        cv=tscv.split(X),\n",
    "                                        shuffle=False,\n",
    "                                        search_by_train_test_split=False,\n",
    "                                        verbose=verbose,\n",
    "                                        plot=True)\n",
    "    return grid_search_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testa grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total GridSearchCV där jag använder egen TimeseriesSplit\n",
    "if False:\n",
    "    X, y = läs_in_data_och_förbered()\n",
    "    results6 = create_grid_search(X, y, typ6)\n",
    "\n",
    "    X, y = läs_in_data_och_förbered()\n",
    "    results1 = create_grid_search(X, y, typ1)\n",
    "\n",
    "    X,y = läs_in_data_och_förbered()\n",
    "    results9 = create_grid_search(X, y, typ9)\n",
    "\n",
    "    X, y = läs_in_data_och_förbered()\n",
    "    results16 = create_grid_search(X, y, typ16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "      <th>typ</th>\n",
       "      <th>best_params</th>\n",
       "      <th>comm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296</td>\n",
       "      <td>0.797722</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.263087</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.260534</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>1</td>\n",
       "      <td>'d': 4, 'l2': 9, 'LR': 0.005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283</td>\n",
       "      <td>0.813249</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.259381</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.255515</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>6</td>\n",
       "      <td>'d': 6, 'l2': 9, 'LR': 0.005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.257471</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.254232</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>9</td>\n",
       "      <td>'d': 4, 'l2': 10, 'LR': 0.005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.257471</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.254232</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>16</td>\n",
       "      <td>'d': 4, 'l2': 10, 'LR': 0.005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>0.798138</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.267621</td>\n",
       "      <td>0.011353</td>\n",
       "      <td>0.265052</td>\n",
       "      <td>0.011595</td>\n",
       "      <td>1</td>\n",
       "      <td>'d': 4, 'l2': 11, 'LR': 0.005</td>\n",
       "      <td>fler val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>299</td>\n",
       "      <td>0.813913</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.258810</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.256468</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>6</td>\n",
       "      <td>'d': 2, 'l2': 9, 'LR': 0.005</td>\n",
       "      <td>fler val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>297</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.257471</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.254232</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>9</td>\n",
       "      <td>'d': 4, 'l2': 10, 'LR': 0.005</td>\n",
       "      <td>fler val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>297</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.257471</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.254232</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>16</td>\n",
       "      <td>'d': 4, 'l2': 10, 'LR': 0.005</td>\n",
       "      <td>fler val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>432</td>\n",
       "      <td>0.799307</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.260090</td>\n",
       "      <td>0.021130</td>\n",
       "      <td>0.256483</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>1</td>\n",
       "      <td>'d': 4, 'l2': 8, 'LR': 0.005</td>\n",
       "      <td>ökade iter=500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>460</td>\n",
       "      <td>0.815003</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>0.244052</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.240895</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>6</td>\n",
       "      <td>'d': 2, 'l2': 9, 'LR': 0.005</td>\n",
       "      <td>ökade iter=500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>496</td>\n",
       "      <td>0.814913</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.242677</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.239123</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>9</td>\n",
       "      <td>'d': 2, 'l2': 10, 'LR': 0.005</td>\n",
       "      <td>ökade iter=500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>496</td>\n",
       "      <td>0.814913</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.242677</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.239123</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>16</td>\n",
       "      <td>'d': 2, 'l2': 10, 'LR': 0.005</td>\n",
       "      <td>ökade iter=500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  test-Logloss-std  train-Logloss-mean  train-Logloss-std  typ                    best_params            comm\n",
       "0          296       0.797722      0.003251           0.263087          0.002299            0.260534           0.000938    1   'd': 4, 'l2': 9, 'LR': 0.005             NaN\n",
       "1          283       0.813249      0.003424           0.259381          0.001801            0.255515           0.001394    6   'd': 6, 'l2': 9, 'LR': 0.005             NaN\n",
       "2          297       0.813179      0.004967           0.257471          0.001976            0.254232           0.000886    9  'd': 4, 'l2': 10, 'LR': 0.005             NaN\n",
       "3          297       0.813179      0.004967           0.257471          0.001976            0.254232           0.000886   16  'd': 4, 'l2': 10, 'LR': 0.005             NaN\n",
       "4          298       0.798138      0.004514           0.267621          0.011353            0.265052           0.011595    1  'd': 4, 'l2': 11, 'LR': 0.005        fler val\n",
       "5          299       0.813913      0.004760           0.258810          0.001824            0.256468           0.000602    6   'd': 2, 'l2': 9, 'LR': 0.005        fler val\n",
       "6          297       0.813179      0.004967           0.257471          0.001976            0.254232           0.000886    9  'd': 4, 'l2': 10, 'LR': 0.005        fler val\n",
       "7          297       0.813179      0.004967           0.257471          0.001976            0.254232           0.000886   16  'd': 4, 'l2': 10, 'LR': 0.005        fler val\n",
       "8          432       0.799307      0.003276           0.260090          0.021130            0.256483           0.024002    1   'd': 4, 'l2': 8, 'LR': 0.005  ökade iter=500\n",
       "9          460       0.815003      0.004842           0.244052          0.002184            0.240895           0.001442    6   'd': 2, 'l2': 9, 'LR': 0.005  ökade iter=500\n",
       "10         496       0.814913      0.004943           0.242677          0.002470            0.239123           0.001752    9  'd': 2, 'l2': 10, 'LR': 0.005  ökade iter=500\n",
       "11         496       0.814913      0.004943           0.242677          0.002470            0.239123           0.001752   16  'd': 2, 'l2': 10, 'LR': 0.005  ökade iter=500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResults = pd.read_csv('results.csv')\n",
    "def results(typ, dfResults, comm=[]):\n",
    "    s = \"results\"+str(typ)\n",
    "    temp1 =globals()[s]\n",
    "    temp = pd.DataFrame(temp1['cv_results'])\n",
    "    temp['typ'] = typ\n",
    "    max=temp['test-AUC-mean'].max()\n",
    "    temp=temp[temp['test-AUC-mean']==max]\n",
    "    if len(comm)>0:\n",
    "        temp['comm'] = comm\n",
    "    str(temp1['params'])\n",
    "    temp['best_params'] = str(temp1['params']).replace('{','').replace('}','').replace('depth','d').replace('l2_leaf_reg','l2').replace('learning_rate','LR')\n",
    "    dfResults = pd.concat([dfResults,temp])\n",
    "    return dfResults\n",
    "\n",
    "#### Slår ihop alla resultaten från GridSearch i funktionen ovan\n",
    "if False:\n",
    "    dfResults = results(1, dfResults,  'ökade iter=500')\n",
    "    dfResults = results(6, dfResults,  'ökade iter=500')\n",
    "    dfResults = results(9, dfResults,  'ökade iter=500')\n",
    "    dfResults = results(16, dfResults, 'ökade iter=500')\n",
    "    dfResults.to_csv('results.csv', index=False)\n",
    "dfResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spara modeller och optimala parms (kanske skall läras på del 1-4?)\n",
    "- Predict på den sista 5:e delen och skapa input till meta-model\n",
    "- gridsearchcv meta_model på detta. Spara optimala parms\n",
    "- avsluta med en learn på hela 5:- delen med optimala parms och spara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_temp(typ, X_, y_, iterations, depth, learning_rate, l2_leaf_reg,save=False):\n",
    "    X = X_.copy()\n",
    "    y = y_.copy()\n",
    "    \n",
    "    typ.learn(X, y, learning_rate=learning_rate, iterations=iterations, depth=depth, l2_leaf_reg=l2_leaf_reg, save=save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "def learn_all_models(totals = False, save=False):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    X, y = läs_in_data_och_förbered()\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        #print(\"TRAIN:\", train_index[-1:], \"TEST:\", test_index[0])\n",
    "        train_until = train_index[-1:][0]\n",
    "        test_from = train_until+1\n",
    "\n",
    "    if totals == False:\n",
    "        ### sista 5:e delen av data\n",
    "        print('train_until',train_until, 'test_from',test_from)\n",
    "\n",
    "        X_train, X_test = X.iloc[:test_from], X.iloc[test_from:]\n",
    "        y_train, y_test = y[:test_from], y[test_from:]\n",
    "    else:\n",
    "        ### all data\n",
    "        print('train all')\n",
    "\n",
    "        X_train = X.copy()\n",
    "        y_train = y.copy()\n",
    "    results = pd.read_csv('results.csv')\n",
    "\n",
    "    # typ6: 'd': 2, 'l2': 9, 'LR': 0.005\n",
    "    print(results[results.typ==6][['typ','iterations','best_params']].iloc[-1].values)\n",
    "    iter=460\n",
    "    d=2\n",
    "    LR=0.005\n",
    "    L2=9\n",
    "    learn_temp(typ6, X_train, y_train, iterations=iter, depth=d, learning_rate=LR, l2_leaf_reg=L2,save=save)\n",
    "\n",
    "    # typ1: 'd': 4, 'l2': 8, 'LR': 0.005\n",
    "    print(results[results.typ == 1][['typ', 'iterations', 'best_params']].iloc[-1].values)\n",
    "    iter = 432\n",
    "    d = 4\n",
    "    LR = 0.005\n",
    "    L2 = 9\n",
    "    learn_temp(typ1, X_train, y_train, iterations=iter, depth=d,\n",
    "               learning_rate=LR, l2_leaf_reg=L2, save=save)\n",
    "    # typ9: 'd': 2, 'l2': 10, 'LR': 0.005\n",
    "    print(results[results.typ == 9][['typ', 'iterations', 'best_params']].iloc[-1].values)\n",
    "    iter = 496\n",
    "    d = 2\n",
    "    LR = 0.005\n",
    "    L2 = 10\n",
    "    learn_temp(typ9, X_train, y_train, iterations=iter, depth=d,\n",
    "               learning_rate=LR, l2_leaf_reg=L2, save=save)\n",
    "\n",
    "    # typ16:'d': 2, 'l2': 10, 'LR': 0.005\n",
    "    print(results[results.typ == 16][['typ', 'iterations', 'best_params']].iloc[-1].values)\n",
    "    iter = 496\n",
    "    d = 2\n",
    "    LR = 0.005\n",
    "    L2 = 10\n",
    "    learn_temp(typ16, X_train, y_train, iterations=iter, depth=d,\n",
    "               learning_rate=LR, l2_leaf_reg=L2, save=save)\n",
    "\n",
    "if False:\n",
    "    learn_all_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa ett Kelly-värde baserat på streck omvandlat till odds\n",
    "def kelly(proba, streck, odds):  # proba = prob winning, streck i % = streck\n",
    "    with open('rf_streck_odds.pkl', 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "\n",
    "    if odds is None:\n",
    "        o = rf.predict(streck.copy())\n",
    "    else:\n",
    "        o = rf.predict(streck.copy())\n",
    "\n",
    "    # for each values > 40 in odds set to 1\n",
    "    o[o > 40] = 1\n",
    "    return (o*proba - (1-proba))/o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_from for meta 36554\n",
      "typ6, Lägg in ant_hästar, \n",
      "Number of NaN in cat before: 10\n",
      "Number of NaN in cat after: 0\n",
      "predict typ6\n",
      "typ1, Lägg in diff motståndare, \n",
      "Number of NaN in cat before: 10\n",
      "Number of NaN in cat after: 0\n",
      "predict typ1\n",
      "typ9, Lägg in ant_hästar, Lägg in diff motståndare, \n",
      "Number of NaN in cat before: 10\n",
      "Number of NaN in cat after: 0\n",
      "predict typ9\n",
      "typ16, Lägg in ant_hästar, Lägg in diff motståndare, \n",
      "Number of NaN in cat before: 10\n",
      "Number of NaN in cat after: 0\n",
      "predict typ16\n",
      "Index(['proba6', 'kelly6', 'proba1', 'kelly1', 'proba9', 'kelly9', 'proba16', 'kelly16'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba6</th>\n",
       "      <th>kelly6</th>\n",
       "      <th>proba1</th>\n",
       "      <th>kelly1</th>\n",
       "      <th>proba9</th>\n",
       "      <th>kelly9</th>\n",
       "      <th>proba16</th>\n",
       "      <th>kelly16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056455</td>\n",
       "      <td>-0.026782</td>\n",
       "      <td>0.043391</td>\n",
       "      <td>-0.040998</td>\n",
       "      <td>0.063922</td>\n",
       "      <td>-0.018656</td>\n",
       "      <td>0.063922</td>\n",
       "      <td>-0.018656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294226</td>\n",
       "      <td>0.105674</td>\n",
       "      <td>0.301050</td>\n",
       "      <td>0.114322</td>\n",
       "      <td>0.248929</td>\n",
       "      <td>0.048276</td>\n",
       "      <td>0.248929</td>\n",
       "      <td>0.048276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004607</td>\n",
       "      <td>-0.026405</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>-0.026150</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>-0.016514</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>-0.016514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296817</td>\n",
       "      <td>0.063331</td>\n",
       "      <td>0.252327</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.388570</td>\n",
       "      <td>0.185549</td>\n",
       "      <td>0.388570</td>\n",
       "      <td>0.185549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107029</td>\n",
       "      <td>-0.085896</td>\n",
       "      <td>0.105438</td>\n",
       "      <td>-0.087832</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>-0.082405</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>-0.082405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>0.031760</td>\n",
       "      <td>-0.003367</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>-0.023185</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>-0.010891</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>-0.010891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7306</th>\n",
       "      <td>0.012385</td>\n",
       "      <td>-0.018385</td>\n",
       "      <td>0.033464</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.037044</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.037044</td>\n",
       "      <td>0.007042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307</th>\n",
       "      <td>0.067805</td>\n",
       "      <td>0.014609</td>\n",
       "      <td>0.050618</td>\n",
       "      <td>-0.003559</td>\n",
       "      <td>0.095576</td>\n",
       "      <td>0.043964</td>\n",
       "      <td>0.095576</td>\n",
       "      <td>0.043964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>0.277928</td>\n",
       "      <td>0.121925</td>\n",
       "      <td>0.328757</td>\n",
       "      <td>0.183736</td>\n",
       "      <td>0.196334</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.196334</td>\n",
       "      <td>0.022702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7309</th>\n",
       "      <td>0.171557</td>\n",
       "      <td>-0.038126</td>\n",
       "      <td>0.141782</td>\n",
       "      <td>-0.075436</td>\n",
       "      <td>0.185888</td>\n",
       "      <td>-0.020167</td>\n",
       "      <td>0.185888</td>\n",
       "      <td>-0.020167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7310 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        proba6    kelly6    proba1    kelly1    proba9    kelly9   proba16   kelly16\n",
       "0     0.056455 -0.026782  0.043391 -0.040998  0.063922 -0.018656  0.063922 -0.018656\n",
       "1     0.294226  0.105674  0.301050  0.114322  0.248929  0.048276  0.248929  0.048276\n",
       "2     0.004607 -0.026405  0.004855 -0.026150  0.014200 -0.016514  0.014200 -0.016514\n",
       "3     0.296817  0.063331  0.252327  0.004068  0.388570  0.185549  0.388570  0.185549\n",
       "4     0.107029 -0.085896  0.105438 -0.087832  0.109900 -0.082405  0.109900 -0.082405\n",
       "...        ...       ...       ...       ...       ...       ...       ...       ...\n",
       "7305  0.031760 -0.003367  0.012636 -0.023185  0.024499 -0.010891  0.024499 -0.010891\n",
       "7306  0.012385 -0.018385  0.033464  0.003350  0.037044  0.007042  0.037044  0.007042\n",
       "7307  0.067805  0.014609  0.050618 -0.003559  0.095576  0.043964  0.095576  0.043964\n",
       "7308  0.277928  0.121925  0.328757  0.183736  0.196334  0.022702  0.196334  0.022702\n",
       "7309  0.171557 -0.038126  0.141782 -0.075436  0.185888 -0.020167  0.185888 -0.020167\n",
       "\n",
       "[7310 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stack for learning meta_model\n",
    "def skapa_stack_learning(X_, y, save=True):\n",
    "    X=X_.copy()\n",
    "    stacked_data = pd.DataFrame()\n",
    "    for typ in typer:\n",
    "            nr = typ.name[3:]\n",
    "            stacked_data['proba'+nr] = typ.predict(X)\n",
    "            stacked_data['kelly' + nr] = kelly(stacked_data['proba' + nr], X[['streck']], None)\n",
    "\n",
    "    print(stacked_data.columns)\n",
    "    assert len(stacked_data) == len(y), f'stacked_data {len(stacked_data)} and y {len(y)} should have same length'\n",
    "    return stacked_data,y   # enbart stack-info\n",
    "\n",
    "if True: # förbered data och kör stacking\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    X, y = läs_in_data_och_förbered()\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        #print(\"TRAIN:\", train_index[-1:], \"TEST:\", test_index[0])\n",
    "        train_from = test_index[0]   # sic!\n",
    "\n",
    "    ### sista 5:e delen av data\n",
    "    print('train_from for meta', train_from)\n",
    "\n",
    "    X_train, y_train = X.iloc[train_from:], y[train_from:]\n",
    "    X_stack,y_stack = skapa_stack_learning(X_train, y_train, False)\n",
    "    display(X_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "konf 1 n_estimators 10 max_depth None min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.9320109439124487\n",
      "konf 2 n_estimators 10 max_depth None min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.9292749658002736\n",
      "konf 3 n_estimators 10 max_depth None min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.9264021887824897\n",
      "konf 4 n_estimators 10 max_depth 2 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8177838577291382\n",
      "konf 5 n_estimators 10 max_depth 2 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8177838577291382\n",
      "konf 6 n_estimators 10 max_depth 2 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8177838577291382\n",
      "konf 7 n_estimators 10 max_depth 4 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8341997264021888\n",
      "konf 8 n_estimators 10 max_depth 4 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8341997264021888\n",
      "konf 9 n_estimators 10 max_depth 4 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8341997264021888\n",
      "konf 10 n_estimators 10 max_depth 6 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8668946648426813\n",
      "konf 11 n_estimators 10 max_depth 6 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8701778385772914\n",
      "konf 12 n_estimators 10 max_depth 6 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8694938440492476\n",
      "konf 13 n_estimators 10 min_samples_split 2 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8177838577291382\n",
      "konf 14 n_estimators 10 min_samples_split 2 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8177838577291382\n",
      "konf 15 n_estimators 10 min_samples_split 2 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8177838577291382\n",
      "konf 16 n_estimators 10 min_samples_split 4 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8341997264021888\n",
      "konf 17 n_estimators 10 min_samples_split 4 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8341997264021888\n",
      "konf 18 n_estimators 10 min_samples_split 4 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8341997264021888\n",
      "konf 19 n_estimators 10 min_samples_split 6 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8668946648426813\n",
      "konf 20 n_estimators 10 min_samples_split 6 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8701778385772914\n",
      "konf 21 n_estimators 10 min_samples_split 6 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8694938440492476\n",
      "konf 22 n_estimators 100 max_depth None min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.9430916552667579\n",
      "konf 23 n_estimators 100 max_depth None min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.9429548563611491\n",
      "konf 24 n_estimators 100 max_depth None min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.9399452804377565\n",
      "konf 25 n_estimators 100 max_depth 2 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8291381668946648\n",
      "konf 26 n_estimators 100 max_depth 2 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8291381668946648\n",
      "konf 27 n_estimators 100 max_depth 2 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8291381668946648\n",
      "konf 28 n_estimators 100 max_depth 4 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8514363885088919\n",
      "konf 29 n_estimators 100 max_depth 4 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8514363885088919\n",
      "konf 30 n_estimators 100 max_depth 4 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8514363885088919\n",
      "konf 31 n_estimators 100 max_depth 6 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8760601915184678\n",
      "konf 32 n_estimators 100 max_depth 6 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8753761969904241\n",
      "konf 33 n_estimators 100 max_depth 6 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8763337893296853\n",
      "konf 34 n_estimators 100 min_samples_split 2 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8291381668946648\n",
      "konf 35 n_estimators 100 min_samples_split 2 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8291381668946648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "konf 36 n_estimators 100 min_samples_split 2 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n",
      "OOB_score 0.8291381668946648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "konf 37 n_estimators 100 min_samples_split 4 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8514363885088919\n",
      "konf 38 n_estimators 100 min_samples_split 4 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8514363885088919\n",
      "konf 39 n_estimators 100 min_samples_split 4 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8514363885088919\n",
      "konf 40 n_estimators 100 min_samples_split 6 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8760601915184678\n",
      "konf 41 n_estimators 100 min_samples_split 6 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8753761969904241\n",
      "konf 42 n_estimators 100 min_samples_split 6 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8763337893296853\n",
      "konf 43 n_estimators 200 max_depth None min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.9430916552667579\n",
      "konf 44 n_estimators 200 max_depth None min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.9424076607387141\n",
      "konf 45 n_estimators 200 max_depth None min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.9400820793433653\n",
      "konf 46 n_estimators 200 max_depth 2 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8277701778385773\n",
      "konf 47 n_estimators 200 max_depth 2 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8277701778385773\n",
      "konf 48 n_estimators 200 max_depth 2 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8277701778385773\n",
      "konf 49 n_estimators 200 max_depth 4 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8529411764705882\n",
      "konf 50 n_estimators 200 max_depth 4 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8529411764705882\n",
      "konf 51 n_estimators 200 max_depth 4 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8528043775649795\n",
      "konf 52 n_estimators 200 max_depth 6 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8790697674418605\n",
      "konf 53 n_estimators 200 max_depth 6 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8779753761969904\n",
      "konf 54 n_estimators 200 max_depth 6 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8775649794801642\n",
      "konf 55 n_estimators 200 min_samples_split 2 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8277701778385773\n",
      "konf 56 n_estimators 200 min_samples_split 2 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8277701778385773\n",
      "konf 57 n_estimators 200 min_samples_split 2 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8277701778385773\n",
      "konf 58 n_estimators 200 min_samples_split 4 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8529411764705882\n",
      "konf 59 n_estimators 200 min_samples_split 4 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8529411764705882\n",
      "konf 60 n_estimators 200 min_samples_split 4 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8528043775649795\n",
      "konf 61 n_estimators 200 min_samples_split 6 min_samples_split 2\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8790697674418605\n",
      "konf 62 n_estimators 200 min_samples_split 6 min_samples_split 4\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8779753761969904\n",
      "konf 63 n_estimators 200 min_samples_split 6 min_samples_split 6\n",
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.8775649794801642\n",
      "{1: 0.9320109439124487, 2: 0.9292749658002736, 3: 0.9264021887824897, 4: 0.8177838577291382, 5: 0.8177838577291382, 6: 0.8177838577291382, 7: 0.8341997264021888, 8: 0.8341997264021888, 9: 0.8341997264021888, 10: 0.8668946648426813, 11: 0.8701778385772914, 12: 0.8694938440492476, 13: 0.8177838577291382, 14: 0.8177838577291382, 15: 0.8177838577291382, 16: 0.8341997264021888, 17: 0.8341997264021888, 18: 0.8341997264021888, 19: 0.8668946648426813, 20: 0.8701778385772914, 21: 0.8694938440492476, 22: 0.9430916552667579, 23: 0.9429548563611491, 24: 0.9399452804377565, 25: 0.8291381668946648, 26: 0.8291381668946648, 27: 0.8291381668946648, 28: 0.8514363885088919, 29: 0.8514363885088919, 30: 0.8514363885088919, 31: 0.8760601915184678, 32: 0.8753761969904241, 33: 0.8763337893296853, 34: 0.8291381668946648, 35: 0.8291381668946648, 36: 0.8291381668946648, 37: 0.8514363885088919, 38: 0.8514363885088919, 39: 0.8514363885088919, 40: 0.8760601915184678, 41: 0.8753761969904241, 42: 0.8763337893296853, 43: 0.9430916552667579, 44: 0.9424076607387141, 45: 0.9400820793433653, 46: 0.8277701778385773, 47: 0.8277701778385773, 48: 0.8277701778385773, 49: 0.8529411764705882, 50: 0.8529411764705882, 51: 0.8528043775649795, 52: 0.8790697674418605, 53: 0.8779753761969904, 54: 0.8775649794801642, 55: 0.8277701778385773, 56: 0.8277701778385773, 57: 0.8277701778385773, 58: 0.8529411764705882, 59: 0.8529411764705882, 60: 0.8528043775649795, 61: 0.8790697674418605, 62: 0.8779753761969904, 63: 0.8775649794801642}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# fit meta_model\n",
    "def learn_meta_model(X, y,  save=True,\n",
    "                     n_estimators=100, \n",
    "                     max_depth=None,\n",
    "                     min_samples_split=2, \n",
    "                     min_samples_leaf=1, \n",
    "                     max_features='auto', \n",
    "                     max_leaf_nodes=None,\n",
    "                     max_samples=None,):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    print('\\nFitting meta_model on X with all models predictions')\n",
    "\n",
    "    meta_model = RandomForestClassifier(\n",
    "       class_weight='balanced',    #{0:1,1:10},\n",
    "       oob_score=True, verbose=1, n_jobs=8, random_state=2022,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators, \n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        max_samples=max_samples,)\n",
    "    \n",
    "    meta_model.fit(X, y)\n",
    "\n",
    "    print('OOB_score', meta_model.oob_score_)   # 0.9430916552667579\n",
    "    # pickle save stacking\n",
    "    if save:\n",
    "        with open('../modeller/meta_model.model', 'wb') as f:\n",
    "            pickle.dump(meta_model, f)\n",
    "\n",
    "    return meta_model\n",
    "\n",
    "if True:\n",
    "    grid ={\n",
    "        'n_estimators': [10,100,200],\n",
    "        'max_depth': [None,2,4,6],\n",
    "        'min_samples_split': [2,4,6],\n",
    "        'min_samples_leaf':[1],  # 2,3],\n",
    "        'max_features': ['auto'], # 'log2', None],\n",
    "        'max_leaf_nodes': [None], # 20, 10, 5],\n",
    "        'max_samples':[None], # 0.1, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    }\n",
    "    \n",
    "    oob_dict = {}\n",
    "    n=1\n",
    "    keys = list(grid.keys())\n",
    "    for i, key in enumerate(keys[:3]):\n",
    "        # loop over all values in key\n",
    "        for value in grid[key]:\n",
    "            for key2 in keys[i+1:3]:\n",
    "                for value2 in grid[key2]:\n",
    "                    for key3 in keys[i+2:3]:\n",
    "                        for value3 in grid[key3]:\n",
    "                            \n",
    "                            print('konf', n, key, value, key2, value2, key3, value3)\n",
    "                \n",
    "                            meta_model = learn_meta_model(X_stack, y_stack, save=True,\n",
    "                                                  n_estimators = value,\n",
    "                                                  max_depth = value2,\n",
    "                                                  min_samples_split = value3,\n",
    "                                                  min_samples_leaf = 1,  # 2,3], \n",
    "                                                  max_features = 'auto', # 'log2', None], \n",
    "                                                  max_leaf_nodes = None, # 20, 10, 5],  \n",
    "                                                  max_samples    = None,)\n",
    "                            # keep n:oob_score in dict\n",
    "                            oob_dict[n] = meta_model.oob_score_\n",
    "        \n",
    "                            n+=1\n",
    "    print(oob_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "Manuellt hittade jag: n_estimators=100, max_depth=None,min_samples_split=2\n"
     ]
    }
   ],
   "source": [
    "# print key where max value in oob_dict\n",
    "print(max(oob_dict, key=oob_dict.get))  \n",
    "print('Manuellt hittade jag: n_estimators=100, max_depth=None,min_samples_split=2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final: learn meta_model med optimala parms och learn allt för modellerna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting meta_model on X with all models predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB_score 0.9430916552667579\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    #####    X_stack och y_stack måste vara definierade ovan   #####\n",
    "    meta_model = learn_meta_model(X_stack, y_stack, save=True,\n",
    "                                  n_estimators=100,\n",
    "                                  max_depth=None,\n",
    "                                  min_samples_split=2,\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train all\n",
      "[6 460 \"'d': 2, 'l2': 9, 'LR': 0.005\"]\n",
      "typ6, Lägg in ant_hästar, \n",
      "Number of NaN in cat before: 246\n",
      "Number of NaN in cat after: 0\n",
      "best score {'learn': {'Logloss': 0.24209788316629433}}\n",
      "[1 432 \"'d': 4, 'l2': 8, 'LR': 0.005\"]\n",
      "typ1, Lägg in diff motståndare, \n",
      "Number of NaN in cat before: 246\n",
      "Number of NaN in cat after: 0\n",
      "best score {'learn': {'Logloss': 0.24774235064314085}}\n",
      "[9 496 \"'d': 2, 'l2': 10, 'LR': 0.005\"]\n",
      "typ9, Lägg in ant_hästar, Lägg in diff motståndare, \n",
      "Number of NaN in cat before: 246\n",
      "Number of NaN in cat after: 0\n",
      "best score {'learn': {'Logloss': 0.2406367497366329}}\n",
      "[16 496 \"'d': 2, 'l2': 10, 'LR': 0.005\"]\n",
      "typ16, Lägg in ant_hästar, Lägg in diff motståndare, \n",
      "Number of NaN in cat before: 246\n",
      "Number of NaN in cat after: 0\n",
      "best score {'learn': {'Logloss': 0.2406367497366329}}\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    ### alla värden enligt ovan körningar för modellerna ###\n",
    "    learn_all_models(totals=True, save=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funktioner för att prioritera mellan hästar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se även kelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# för en omgång (ett datum) ta ut största diff för streck per avd \n",
    "# om only_clear=True, enbart för diff >= 25\n",
    "def lista_med_favoriter(df_, ant, only_clear):\n",
    "    df = df_.copy()\n",
    "    min_diff = 25 if only_clear else 0\n",
    "    # sortera på avd,streck\n",
    "    df = df.sort_values(['avd', 'streck'], ascending=[False, False])\n",
    "    diff_list = []\n",
    "    for avd in range(1, 8):\n",
    "        diff = df.loc[df.avd == avd].streck.iloc[0] - \\\n",
    "            df.loc[df.avd == avd].streck.iloc[1]\n",
    "        if diff >= min_diff:\n",
    "            diff_list.append((avd, diff))\n",
    "\n",
    "     # sortera på diff\n",
    "    diff_list = sorted(diff_list, key=lambda x: x[1], reverse=True)\n",
    "    return diff_list[:ant]\n",
    "\n",
    "# temp is a list of tuples (avd, diff). check if avd is in the list\n",
    "def check_avd(avd, temp):\n",
    "    for t in temp:\n",
    "        if t[0] == avd:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_insats(df):\n",
    "    insats = 0\n",
    "    # group by avd\n",
    "    summa = df.groupby('avd').avd.count().prod() / 2\n",
    "    return summa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning-fasen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gör en scrape på senaste veckan (behövs inte i denna test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_streck_to_odds(X_):\n",
    "    X = X_.copy()\n",
    "    # import modules for linear regression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "    # import random forest module\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    X_odds = X.loc[X.vodds <= 40]  # remove outliers\n",
    "    ix_break = int(len(X_odds.datum.unique())*0.75)\n",
    "    test_start = X_odds.datum.unique()[ix_break]\n",
    "\n",
    "    X_train, X_test = X_odds[X_odds.datum < test_start], X_odds[X_odds.datum >= test_start]\n",
    "    y_train, y_test = X_train['vodds'], X_test['vodds']\n",
    "    X_train = X_train[['streck']].astype(float)\n",
    "    X_test = X_test[['streck']].astype(float)\n",
    "\n",
    "    # make a model of RF\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_predrf = rf.predict(X_test)\n",
    "    # make a model and fit it\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_predlr = linreg.predict(X_test)\n",
    "\n",
    "    # print the coefficients\n",
    "    print('Coefficients:', linreg.coef_)\n",
    "    # print the mean absolute error\n",
    "    print(\"LR Mean absolute error: %.2f\" % mae(y_test, y_predlr))\n",
    "    print(\"RF Mean absolute error: %.2f\" % mae(y_test, y_predrf))\n",
    "\n",
    "    return linreg, rf\n",
    "\n",
    "\n",
    "# _, rf = model_streck_to_odds(X)   # used in next cell\n",
    "\n",
    "# # spara rf\n",
    "# import pickle\n",
    "# with open('rf_streck_odds.pkl', 'wb') as f:\n",
    "#     pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Läs in all_data.csv \n",
    "Baka ihop senaste vekan med all_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skapa_stack_learning(X_, y, features, iterations=1000, random_state=2022, verbose=False, save=True):\n",
    "    \"\"\"\n",
    "    Skapar en stack med proba och kelly\n",
    "    X måste ha datum och avd\n",
    "    \"\"\"\n",
    "    X = X_.copy()\n",
    "    stacked_data = pd.DataFrame()\n",
    "    \n",
    "    cbc = CatBoostClassifier(iterations=iterations, loss_function='Logloss', eval_metric='AUC', verbose=verbose)\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        model = typ.learn(X, y, features, iterations=iterations, save=save, verbose=verbose)\n",
    "        stacked_data['proba'+nr] = typ.predict(X) \n",
    "        stacked_data['kelly'+nr] = kelly(stacked_data['proba' + nr], X[['streck']], None)\n",
    "    \n",
    "    # print(stacked_data.columns)\n",
    "    return stacked_data   # enbart stack-info\n",
    "\n",
    "# fit meta_model\n",
    "def learn_meta_model(X,y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    print('\\nFitting meta_model on X with all models predictions')\n",
    "    \n",
    "    meta_model = RandomForestClassifier(max_depth=None, n_estimators=100, oob_score=True, verbose=1, n_jobs=10, random_state=2022)\n",
    "    meta_model.fit(X, y)\n",
    "    \n",
    "    print('OOB_score', meta_model.oob_score_)   # 0.9305314451043094\n",
    "    # pickle save stacking\n",
    "    pickle.dump(meta_model, open('..\\\\modeller\\\\meta.model', 'wb'))\n",
    "    \n",
    "    return meta_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read feature list from a file (ej plac)\n",
    "def read_feature_list(file='../FEATURES.txt'):\n",
    "    with open(file, 'r') as f:\n",
    "        return f.read().splitlines()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liten_cv_timeseries_demo(x_,y_):\n",
    "    X = x_.copy()\n",
    "    y = y_.copy()\n",
    "    print('Holdout validation data from X = X[~validation]')\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        print(f\"TRAIN each model on this: {train_index[0]}-{train_index[-1]}, Predict on: {test_index[0]}-{test_index[-1]}\")\n",
    "        print('save the predictions of each model')\n",
    "        X_train = X.loc[train_index]\n",
    "        X_test = X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    print('Train meta_model on all models predictions')\n",
    "    print('validate meta_model on the validation data')\n",
    "    \n",
    "    print('\\nHandle stratified and unbalanced data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kör learning-skiten här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = read_feature_list(\"../FEATURES.txt\")\n",
    "\n",
    "X_train, y_train = läs_in_data_och_förbered()\n",
    "assert X_train.shape[1] == len(FEATURES), f'X_train.shape[1] {X_train.shape[1]} != len(FEATURES) {len(FEATURES)}'\n",
    "assert set(X_train.columns) == set(FEATURES), f'set(X_train.columns) {set(X_train.columns)} != set(FEATURES) {set(FEATURES)}'\n",
    "X_train = X_train[FEATURES]  # för att få kolumner i rätt ordning\n",
    "\n",
    "if True:\n",
    "    liten_cv_timeseries_demo(X_train, y_train)\n",
    "else:    \n",
    "    X_stacked = skapa_stack_learning(X_train, y_train, FEATURES, iterations=100,random_state=2022, verbose=False, save=True)\n",
    "    # display(X_stacked)\n",
    "    meta_model = learn_meta_model(X_stacked, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spela-fasen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    'C:\\\\Users\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel\\\\')\n",
    "import V75_scraping as vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape-funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v75_scrape():\n",
    "    df, strukna = vs.v75_scraping(history=True, resultat=False)\n",
    "    \n",
    "    # df = pd.read_csv('../sparad_scrape.csv')\n",
    "    for f in ['häst','bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        df[f] = df[f].str.lower()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativ metod\n",
    "# Ta fram rader för varje typ enligt test-resultaten innan\n",
    "# låt meta_model välja mellan typerna - hur? Hur maximer insatsen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion som bygger stack-data från modellerna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# för stacking ta med alla hästar per typ och proba plus kelly\n",
    "def build_stack_df(X_):\n",
    "    X = X_.copy()\n",
    "    stacked_data = X[['datum','avd', 'startnr','häst']].copy()\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        stacked_data['proba'+nr] = typ.predict(X)\n",
    "        stacked_data['kelly'+nr] = kelly(stacked_data['proba'+nr], X[['streck']], None)\n",
    "    return stacked_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion där meta_model gör predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_predict(X_):\n",
    "    # X_ innehåller även datum,startnr och avd\n",
    "    extra = ['datum', 'avd', 'startnr', 'häst']\n",
    "    assert list(X_.columns[:4]) == extra, 'meta_model måste ha datum, avd och startnr, häst för att kunna välja'\n",
    "    X = X_.copy()\n",
    "    with open('../modeller\\\\meta.model', 'rb') as f:\n",
    "        meta_model = pickle.load(f)\n",
    "        \n",
    "    # print(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "    X['meta_predict'] = meta_model.predict_proba(X.iloc[:,-8:])[:,1]\n",
    "    my_columns = extra + list(X.columns)[-9:] \n",
    "    \n",
    "    return X[my_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion som väljer rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_cost(antal_rader):\n",
    "    cost = (antal_rader**2)/2\n",
    "    return antal_rader,cost\n",
    "\n",
    "def välj_rad(X_):\n",
    "    \n",
    "    max_insats=320\n",
    "    veckans_rad = X_.copy()\n",
    "    veckans_rad['välj'] = False\n",
    "\n",
    "    for avd in veckans_rad.avd.unique():\n",
    "        max_pred = veckans_rad[veckans_rad.avd == avd]['meta_predict'].max()\n",
    "        veckans_rad.loc[(veckans_rad.avd == avd) & (veckans_rad.meta_predict == max_pred), 'välj'] = True\n",
    "    antal_rader=1    \n",
    "    veckans_rad = veckans_rad.sort_values(by=['meta_predict'], ascending=False)\n",
    "    \n",
    "    # 3. Använda ensam favorit för ett par avd? Kolla test-resultat\n",
    "    # for each row in rad, välj=True if select_func(cost,avd) == True\n",
    "    cost = antal_rader*0.5\n",
    "    for i, row in veckans_rad.iterrows():\n",
    "        new_antal,new_cost = comp_cost(antal_rader+1)\n",
    "        # print(the_cost)\n",
    "        if new_cost > max_insats:\n",
    "            break\n",
    "        \n",
    "        antal_rader = new_antal\n",
    "        cost = new_cost\n",
    "        veckans_rad.loc[i, 'välj'] = True\n",
    "        # print(cost)\n",
    "    veckans_rad.sort_values(by=['välj', 'avd'], ascending=[False, True], inplace=True)\n",
    "\n",
    "    return veckans_rad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kör hela välj-rad-skiten här"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = v75_scrape()\n",
    "print(X.datum.unique())\n",
    "df_stack = build_stack_df(X,FEATURES)\n",
    "df_meta = meta_predict(df_stack)\n",
    "df_meta.reset_index(drop=True, inplace=True)\n",
    "veckans_rad = välj_rad(df_meta)\n",
    "# rename columns \n",
    "veckans_rad.rename(columns={'startnr':'nr', 'meta_predict':'Meta', 'välj':'Välj'}, inplace=True)\n",
    "\n",
    "display(veckans_rad[veckans_rad.välj])\n",
    "print('kostnad', veckans_rad.välj.sum()**2/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En massa gammal - kanske reusable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Läs in all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for Learn!\n",
    "def init_learn():\n",
    "    df = pd.read_csv('..\\\\all_data.csv')\n",
    "    # Följande datum saknar avd==5 och kan inte användas\n",
    "    saknas = ['2015-08-15', '2016-08-13', '2017-08-12']\n",
    "    df = df[~df.datum.isin(saknas)]\n",
    "    X = df.copy()\n",
    "    X.drop('plac', axis=1, inplace=True)\n",
    "    # X = ordinal_enc(X, 'häst')\n",
    "    y = (df.plac == 1)*1   # plac 1 eller 0\n",
    "\n",
    "    for f in ['häst', 'bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "        X[f] = X[f].str.lower()\n",
    "\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X, cat_features = tp.prepare_for_catboost(X)\n",
    "    print('cat_features:', cat_features)\n",
    "    X.head()\n",
    "    return X, y, cat_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modell för streck_to_odds - skall vara fix och inte ändras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_streck_to_odds(X_):\n",
    "    X = X_.copy()\n",
    "    # import modules for linear regression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "    # import random forest module\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    X_odds = X.loc[X.vodds <= 40]  # remove outliers\n",
    "    ix_break = int(len(X_odds.datum.unique())*0.75)\n",
    "    test_start = X_odds.datum.unique()[ix_break]\n",
    "\n",
    "    X_train, X_test = X_odds[X_odds.datum <\n",
    "                             test_start], X_odds[X_odds.datum >= test_start]\n",
    "    y_train, y_test = X_train['vodds'], X_test['vodds']\n",
    "    X_train = X_train[['streck']].astype(float)\n",
    "    X_test = X_test[['streck']].astype(float)\n",
    "\n",
    "    # make a model of RF\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_predrf = rf.predict(X_test)\n",
    "    # make a model and fit it\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_predlr = linreg.predict(X_test)\n",
    "\n",
    "    # print the coefficients\n",
    "    print('Coefficients:', linreg.coef_)\n",
    "    # print the mean absolute error\n",
    "    print(\"LR Mean absolute error: %.2f\" % mae(y_test, y_predlr))\n",
    "    print(\"RF Mean absolute error: %.2f\" % mae(y_test, y_predrf))\n",
    "\n",
    "    return linreg, rf\n",
    "\n",
    "\n",
    "linreg, rf = model_streck_to_odds(X)   # used in next cell\n",
    "# spara rf\n",
    "import pickle\n",
    "with open('rf_streck_odds.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engångsgrej för att initiera typ-instanserna med learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bara första gången. Initierar Typ-klassen\n",
    "def learn(X_train, y_train, X_test=None, y_test=None, cat_features=[],  iterations=1000,  verbose=False):\n",
    "    cbc = CatBoostClassifier(iterations=iterations, loss_function='Logloss', eval_metric='AUC', verbose=verbose)\n",
    "    X_train = remove_features(X_train, remove_mer=['avd','datum'])\n",
    "    cat_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    train_pool = Pool(X_train, label=y_train, cat_features=cat_features)\n",
    "    if X_test is not None:\n",
    "        X_test = remove_features(X_test, remove_mer=['avd', 'datum'])\n",
    "        test_pool = Pool(X_test, label=y_test, cat_features=cat_features)\n",
    "        cbc.fit(train_pool, eval_set=test_pool, early_stopping_rounds=100, use_best_model=True, verbose=verbose)\n",
    "    else:\n",
    "        cbc.fit(train_pool, use_best_model=True, verbose=verbose)\n",
    "    return cbc\n",
    "\n",
    "def beräkna_datum(X,fract=0.75):\n",
    "    ix_break = int(len(X.datum.unique())*fract)\n",
    "    test_start = X.datum.unique()[ix_break]\n",
    "    return test_start\n",
    "\n",
    "if False: # Kör en initiering av typerna \n",
    "    Xlearn, cat_features= prepare_for_catboost(X)  \n",
    "    # print(Xlearn.columns)\n",
    "    for typ in [typ6, typ1, typ9, typ16]:\n",
    "        print(typ.name)\n",
    "        Xtyp = typ.prepare_for_model(Xlearn)                                 ###########\n",
    "\n",
    "        if not typ.streck:                                                ################\n",
    "            Xtyp.drop('streck', axis=1, inplace=True)\n",
    "            \n",
    "        if True: # använda X_test    \n",
    "            test_start = beräkna_datum(Xtyp)    \n",
    "            X_train, X_test = Xtyp[Xtyp.datum < test_start], Xtyp[Xtyp.datum >= test_start]\n",
    "            y_train, y_test = y[X_train.index], y[X_test.index]\n",
    "            # print('innan learn',X_train.columns)\n",
    "            typ_model = learn(X_train, y_train, X_test, y_test)  ##########\n",
    "            print('best iteration',typ_model.best_iteration_)                             ##########\n",
    "            print('best score',    typ_model.best_score_)                                 ##########\n",
    "        # save model\n",
    "        typ.save_model(typ_model)                                                       ##########                          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapa typ6 till typ16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = läs_in_data_och_förbered()\n",
    "X,cat_features = tp.prepare_for_catboost(X)\n",
    "typ6.learn(X,y, iterations=33) # best iter = 25 {'Logloss': 0.23245952928761984, 'AUC': 0.8262112132692319}\n",
    "typ1.learn(X,y, iterations=39) # best iter = 39 {'Logloss': 0.23278308932319106, 'AUC': 0.826883367187688}\n",
    "typ9.learn(X,y, iterations=37) # best iter = 37 {'Logloss': 0.23312091900160384, 'AUC': 0.8257515762557716}\n",
    "typ16.learn(X,y,iterations=37) # best iter = 37 {'Logloss': 0.23312091900160384, 'AUC': 0.8257515762557716}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skapa stack predict med alla typer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack predict for all models\n",
    "def stack_predict(X_, models):\n",
    "    X = X_.copy()\n",
    "    for typ in typer:\n",
    "        nr = typ.name[3:]\n",
    "        X['proba'+nr] = typ.predict(X)\n",
    "        X['kelly'+nr] = kelly(X['proba'+nr], X[['streck']], None)\n",
    "    # cols=X.columns[-8]    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The complete learning process with all steps in stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()  # The meta model\n",
    "    \n",
    "# fit my models on split date for timeseries   \n",
    "print('START fitting and predicting TimeseriesSplit') \n",
    "cross_val_predict=pd.DataFrame()\n",
    "for id_train, id_test in TimeSeriesSplit(n_splits=5).split(df_stack):  \n",
    "    for typ in [typ6, typ1, typ9, typ16]:\n",
    "        typ.learn(df_stack.loc[id_train],y.loc[id_train], iterations=25)\n",
    "    df_pred = stack_predict(df_stack.loc[id_test], [typ6, typ1, typ9, typ16])\n",
    "    df_pred['y']=y.loc[id_test]\n",
    "    cross_val_predict = pd.concat([cross_val_predict, df_pred.iloc[:,-9:]])\n",
    "       \n",
    "print('\\nFitting my models with all data')\n",
    "# final fit with all the available data\n",
    "for typ in [typ6, typ1, typ9, typ16]:\n",
    "    typ.learn(df_stack, y, iterations=20)\n",
    "\n",
    "print('\\nFitting meta_model on predicted above')\n",
    "# fit a rf meta_model on cross_val_predict\n",
    "meta_model = RandomForestClassifier(max_depth=None, n_estimators=100, oob_score=True, verbose=1, n_jobs=10, random_state=2022)\n",
    "meta_model.fit(cross_val_predict.iloc[:, :-1], cross_val_predict.iloc[:, -1])\n",
    "print('OOB_score', meta_model.oob_score_)   # 0.9305314451043094\n",
    "# pickle save stacking\n",
    "pickle.dump(meta_model, open('..\\\\modeller\\\\meta_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on unseen data\n",
    "def unseen_predictions(X_, models, meta_model):\n",
    "    X = X_.copy()\n",
    "    for model in models:\n",
    "        nr = model.name[3:]\n",
    "        X['proba'+nr] = model.predict(X)\n",
    "        X['kelly'+nr] = kelly(X['proba'+nr], X[['streck']], None)\n",
    "        \n",
    "    return(meta_model.predict_proba(X.iloc[:, -8:]))\n",
    "\n",
    "# a small test:\n",
    "unseen_predictions(df_stack.iloc[-80:,:], [typ6, typ1, typ9, typ16], meta_model)[:,1],y.iloc[-80:].values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
