{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Testa allt mellan himmel och jord \"\"\"\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "pref = '../'\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel')\n",
    "import typ as tp\n",
    "import travdata as td\n",
    "import time\n",
    "import concurrent.futures\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import pickle\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 260)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Läs in all data och tvätta    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                           Läs in all data och tvätta                        #\n",
    "###############################################################################\n",
    "def läs_in_data(förbered=True, lägg_till=True):\n",
    "    v75 = td.v75(pref=pref)\n",
    "    _ = v75.förbered_data(missing_num=True)  # num hanteras av catboost\n",
    "    df = v75.test_lägg_till_kolumner()\n",
    "    return df,v75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../all_data.csv\n",
      "Loading dataframe from the file: ../all_data.csv\n",
      "plac finns i df\n",
      "2022-10-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datum</th>\n",
       "      <th>avd</th>\n",
       "      <th>bana</th>\n",
       "      <th>häst</th>\n",
       "      <th>rel_kr</th>\n",
       "      <th>streck_avst</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>h1_samma_bana</th>\n",
       "      <th>h1_bana</th>\n",
       "      <th>h2_samma_bana</th>\n",
       "      <th>h3_samma_bana</th>\n",
       "      <th>h1_samma_kusk</th>\n",
       "      <th>h2_samma_kusk</th>\n",
       "      <th>h3_samma_kusk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>örebro</td>\n",
       "      <td>allaballakaitoz</td>\n",
       "      <td>0.102926</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>False</td>\n",
       "      <td>eskilstuna</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>örebro</td>\n",
       "      <td>aristocat boko</td>\n",
       "      <td>0.114914</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>False</td>\n",
       "      <td>åby</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        datum  avd    bana             häst    rel_kr  streck_avst  rel_rank  h1_samma_bana     h1_bana  h2_samma_bana  h3_samma_bana  h1_samma_kusk  h2_samma_kusk  h3_samma_kusk\n",
       "0  2014-12-28  1.0  örebro  allaballakaitoz  0.102926         43.0  0.416667          False  eskilstuna          False          False           True           True           True\n",
       "1  2014-12-28  1.0  örebro   aristocat boko  0.114914         41.0  0.250000          False         åby          False          False          False          False           True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df,v75 = läs_in_data()\n",
    "print(df.datum.max())\n",
    "\n",
    "df[['datum','avd', 'bana','häst', 'rel_kr',\t'streck_avst',\t'rel_rank',\t'h1_samma_bana','h1_bana',\t'h2_samma_bana',\t'h3_samma_bana',\t'h1_samma_kusk',\t'h2_samma_kusk',\t'h3_samma_kusk']].head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datum', 'avd', 'bana', 'häst', 'kusk', 'streck', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'kön', 'pris', 'h1_kusk', 'h1_bana', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_kusk', 'h2_bana', 'h2_spår', 'h2_plac', 'h2_pris',\n",
       "       'h2_odds', 'h2_kmtid', 'h3_kusk', 'h3_bana', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_kusk', 'h4_bana', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_kusk', 'h5_bana', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds',\n",
       "       'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4', 'startnr', 'y', 'rel_kr',\n",
       "       'streck_avst', 'rel_rank', 'h1_samma_bana', 'h2_samma_bana', 'h3_samma_bana', 'h1_samma_kusk', 'h2_samma_kusk', 'h3_samma_kusk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb1L1: 75\n",
      "['bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'pris', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_spår', 'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4', 'startnr', 'rel_kr', 'streck_avst', 'rel_rank', 'h1_samma_bana', 'h2_samma_bana', 'h3_samma_bana', 'h1_samma_kusk', 'h2_samma_kusk', 'h3_samma_kusk']\n",
      "\n",
      "xgb2L1: 76\n",
      "['bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana', 'streck', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'pris', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_spår', 'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4', 'startnr', 'rel_kr', 'streck_avst', 'rel_rank', 'h1_samma_bana', 'h2_samma_bana', 'h3_samma_bana', 'h1_samma_kusk', 'h2_samma_kusk', 'h3_samma_kusk']\n",
      "\n",
      "xgb1L2: 79\n",
      "['bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'pris', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_spår', 'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4', 'startnr', 'rel_kr', 'streck_avst', 'rel_rank', 'h1_samma_bana', 'h2_samma_bana', 'h3_samma_bana', 'h1_samma_kusk', 'h2_samma_kusk', 'h3_samma_kusk', 'probat1L1', 'probat2L1', 'probab1L1', 'probab2L1']\n",
      "\n",
      "xgb2L2: 80\n",
      "['bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana', 'streck', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'pris', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_spår', 'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4', 'startnr', 'rel_kr', 'streck_avst', 'rel_rank', 'h1_samma_bana', 'h2_samma_bana', 'h3_samma_bana', 'h1_samma_kusk', 'h2_samma_kusk', 'h3_samma_kusk', 'probat1L1', 'probat2L1', 'probab1L1', 'probab2L1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# läs in xgb-modellerna och testa vilka features de är fit på\n",
    "modeller = ['xgb1L1','xgb2L1', 'xgb1L2', 'xgb2L2']\n",
    "\n",
    "for model in modeller:\n",
    "    print(model, end=': ')\n",
    "    with open(f'{pref}modeller/{model}.model', 'rb') as f:\n",
    "        xgb_model = pickle.load(f)\n",
    "    print(len(xgb_model.get_booster().feature_names))\n",
    "    print(xgb_model.get_booster().feature_names)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testa random grid search xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random grid search för xgb\n",
    "def randomGrid_xgb(use_model):\n",
    "    \n",
    "    ############ Inledande skit #####################################################\n",
    "    modell_dict = {'cat1': {'#hästar': False, '#motst': 3, 'motst_diff': True, 'streck': False},\n",
    "                   'cat2': {'#hästar': True,  '#motst': 3, 'motst_diff': True, 'streck': True},\n",
    "                   'xgb1': {'#hästar': False, '#motst': 3, 'motst_diff': True, 'streck': False},\n",
    "                   'xgb2': {'#hästar': True,  '#motst': 3, 'motst_diff': True, 'streck': True}\n",
    "                   }\n",
    "\n",
    "\n",
    "    L1_modeller = dict()\n",
    "    L2_modeller = dict()\n",
    "\n",
    "    for key, typ in modell_dict.items():\n",
    "        L1_key = key + 'L1'\n",
    "        model = tp.Typ(L1_key, typ['#hästar'], typ['#motst'],\n",
    "                    typ['motst_diff'], typ['streck'])\n",
    "        L1_modeller[L1_key] = model\n",
    "\n",
    "        L2_key = key + 'L2'\n",
    "        model = tp.Typ(L2_key, typ['#hästar'], typ['#motst'],\n",
    "                    typ['motst_diff'], typ['streck'])\n",
    "        L2_modeller[L2_key] = model\n",
    "\n",
    "    print('keys and names i modeller')\n",
    "    # print keys in dict modeller\n",
    "    for key, typ in L1_modeller.items():\n",
    "        assert key == typ.name, \"key and value.name should be the same in modeller\"\n",
    "        print(key)\n",
    "\n",
    "    print('keys and names i meta_modeller')\n",
    "    for key, typ in L2_modeller.items():\n",
    "        assert key == typ.name, \"key and value.name should be the same in meta_modeller\"\n",
    "        print(key)\n",
    "\n",
    "    # Läs in NUM_FEATURES.txt och CAT_FEATURES.txt\n",
    "    with open(pref+'CAT_FEATURES.txt', 'r', encoding='utf-8') as f:\n",
    "        cat_features = f.read().split()\n",
    "\n",
    "    # läs in NUM_FEATURES.txt till num_features\n",
    "    with open(pref+'NUM_FEATURES.txt', 'r', encoding='utf-8') as f:\n",
    "        num_features = f.read().split()\n",
    "    use_features = cat_features + num_features\n",
    "    \n",
    "    print('use_features:\\n', use_features)\n",
    "    \n",
    "    ############ SLUT Inledande skit #################################################\n",
    "    typ=L1_modeller[use_model]\n",
    "\n",
    "    grid = {'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "            #  'iterations': [100, 200, 300, 400, 500],   n_estimators\n",
    "             'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "              'n_estimators': [100, 200, 300, 400, 500],\n",
    "              'reg_lambda': [0.1, 1, 2, 3, 4],\n",
    "              'subsample': [0.5, 0.8, 1]}\n",
    "\n",
    "\n",
    "    if not typ.streck:\n",
    "        print('remove streck')\n",
    "        use_features.remove('streck')\n",
    "\n",
    "    \n",
    "    df,_=v75.förbered_data(extra=True)\n",
    "    X = typ.prepare_for_model(df.drop(['y'],axis=1))\n",
    "    y = df.y.copy()\n",
    "    \n",
    "    # xgb_encoder till ENC\n",
    "    with open(pref+'xgb_encoder.pkl', 'rb') as f:\n",
    "        ENC = pickle.load(f)\n",
    "        \n",
    "    X, ENC = tp.prepare_for_xgboost(X, encoder=ENC)\n",
    "    display(X[use_features].head(1))\n",
    "\n",
    "    \n",
    "    assert X[use_features].isnull().sum().sum() == 0, 'there are NaN values in cat_features'\n",
    "    # assert that all cat_features are numeric\n",
    "    non_numeric_columns = X[use_features].select_dtypes(exclude=[np.number]).columns\n",
    "    assert len(non_numeric_columns)==0, f\"Följande kolumner är inte numeriska: {non_numeric_columns}\"\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc', random_state=2023)\n",
    "\n",
    "    display(f'XGB Randomized search')\n",
    "    grid_search_result = RandomizedSearchCV(model, param_distributions=grid,\n",
    "                                                    cv=tscv.split(X[use_features]),\n",
    "                                                    scoring=['roc_auc','neg_log_loss'],\n",
    "                                                    random_state=2023,\n",
    "                                                    refit='roc_auc',\n",
    "                                                    n_jobs=-1,\n",
    "                                                    verbose=1)\n",
    "    grid_search_result.fit(X[use_features], y)\n",
    "\n",
    "    return grid_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streck: False i init för cat1L1\n",
      "streck: False i init för cat1L2\n",
      "streck: True i init för cat2L1\n",
      "streck: True i init för cat2L2\n",
      "streck: False i init för xgb1L1\n",
      "streck: False i init för xgb1L2\n",
      "streck: True i init för xgb2L1\n",
      "streck: True i init för xgb2L2\n",
      "keys and names i modeller\n",
      "cat1L1\n",
      "cat2L1\n",
      "xgb1L1\n",
      "xgb2L1\n",
      "keys and names i meta_modeller\n",
      "cat1L2\n",
      "cat2L2\n",
      "xgb1L2\n",
      "xgb2L2\n",
      "use_features:\n",
      " ['bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana', 'streck', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'pris', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_spår', 'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4', 'startnr', 'rel_kr', 'streck_avst', 'rel_rank', 'h1_samma_bana', 'h2_samma_bana', 'h3_samma_bana', 'h1_samma_kusk', 'h2_samma_kusk', 'h3_samma_kusk']\n",
      "remove streck\n",
      "plac finns i df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bana</th>\n",
       "      <th>häst</th>\n",
       "      <th>kusk</th>\n",
       "      <th>kön</th>\n",
       "      <th>h1_kusk</th>\n",
       "      <th>h1_bana</th>\n",
       "      <th>h2_kusk</th>\n",
       "      <th>h2_bana</th>\n",
       "      <th>h3_kusk</th>\n",
       "      <th>h3_bana</th>\n",
       "      <th>h4_kusk</th>\n",
       "      <th>h4_bana</th>\n",
       "      <th>h5_kusk</th>\n",
       "      <th>h5_bana</th>\n",
       "      <th>spår</th>\n",
       "      <th>dist</th>\n",
       "      <th>lopp_dist</th>\n",
       "      <th>start</th>\n",
       "      <th>ålder</th>\n",
       "      <th>pris</th>\n",
       "      <th>h1_spår</th>\n",
       "      <th>h1_plac</th>\n",
       "      <th>h1_pris</th>\n",
       "      <th>h1_odds</th>\n",
       "      <th>h1_kmtid</th>\n",
       "      <th>h2_spår</th>\n",
       "      <th>h2_plac</th>\n",
       "      <th>h2_pris</th>\n",
       "      <th>h2_odds</th>\n",
       "      <th>h2_kmtid</th>\n",
       "      <th>h3_spår</th>\n",
       "      <th>h3_plac</th>\n",
       "      <th>h3_pris</th>\n",
       "      <th>h3_odds</th>\n",
       "      <th>h3_kmtid</th>\n",
       "      <th>h4_spår</th>\n",
       "      <th>h4_plac</th>\n",
       "      <th>h4_pris</th>\n",
       "      <th>h4_odds</th>\n",
       "      <th>h4_kmtid</th>\n",
       "      <th>h5_spår</th>\n",
       "      <th>h5_plac</th>\n",
       "      <th>h5_pris</th>\n",
       "      <th>h5_odds</th>\n",
       "      <th>h5_kmtid</th>\n",
       "      <th>h1_dist</th>\n",
       "      <th>h2_dist</th>\n",
       "      <th>h3_dist</th>\n",
       "      <th>h4_dist</th>\n",
       "      <th>h5_dist</th>\n",
       "      <th>h1_auto</th>\n",
       "      <th>h2_auto</th>\n",
       "      <th>h3_auto</th>\n",
       "      <th>h4_auto</th>\n",
       "      <th>h5_auto</th>\n",
       "      <th>h1_perf</th>\n",
       "      <th>h2_perf</th>\n",
       "      <th>h3_perf</th>\n",
       "      <th>h4_perf</th>\n",
       "      <th>h5_perf</th>\n",
       "      <th>senast</th>\n",
       "      <th>delta1</th>\n",
       "      <th>delta2</th>\n",
       "      <th>delta3</th>\n",
       "      <th>delta4</th>\n",
       "      <th>startnr</th>\n",
       "      <th>rel_kr</th>\n",
       "      <th>streck_avst</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>h1_samma_bana</th>\n",
       "      <th>h2_samma_bana</th>\n",
       "      <th>h3_samma_bana</th>\n",
       "      <th>h1_samma_kusk</th>\n",
       "      <th>h2_samma_kusk</th>\n",
       "      <th>h3_samma_kusk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.086178</td>\n",
       "      <td>0.110221</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.080678</td>\n",
       "      <td>0.083552</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.104309</td>\n",
       "      <td>0.092676</td>\n",
       "      <td>0.090703</td>\n",
       "      <td>0.075912</td>\n",
       "      <td>0.035038</td>\n",
       "      <td>0.103769</td>\n",
       "      <td>0.028726</td>\n",
       "      <td>0.095196</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>14.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>52.42</td>\n",
       "      <td>14.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>12.3</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2640.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3935.030968</td>\n",
       "      <td>6006.507182</td>\n",
       "      <td>11.18034</td>\n",
       "      <td>8.3666</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102926</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bana      häst      kusk       kön   h1_kusk  h1_bana   h2_kusk   h2_bana   h3_kusk   h3_bana   h4_kusk   h4_bana   h5_kusk   h5_bana  spår    dist  lopp_dist  start  ålder      pris  h1_spår  h1_plac  h1_pris  h1_odds  h1_kmtid  h2_spår  h2_plac  \\\n",
       "0  0.086178  0.110221  0.007834  0.080678  0.083552   0.0883  0.104309  0.092676  0.090703  0.075912  0.035038  0.103769  0.028726  0.095196   6.0  2100.0     2100.0      0      6  125000.0      3.0      2.0     35.0     3.92      16.8      3.0      1.0   \n",
       "\n",
       "   h2_pris  h2_odds  h2_kmtid  h3_spår  h3_plac  h3_pris  h3_odds  h3_kmtid  h4_spår  h4_plac  h4_pris  h4_odds  h4_kmtid  h5_spår  h5_plac  h5_pris  h5_odds  h5_kmtid  h1_dist  h2_dist  h3_dist  h4_dist  h5_dist  h1_auto  h2_auto  h3_auto  h4_auto  h5_auto  \\\n",
       "0     30.0      3.7      14.9      3.0     15.0    125.0    52.42      14.3      3.0     15.0     70.0      5.2      13.9      3.0     15.0     25.0      2.2      12.3   2140.0   2140.0   2640.0   2140.0   1609.0        1        1        1        1        1   \n",
       "\n",
       "       h1_perf      h2_perf   h3_perf  h4_perf  h5_perf  senast  delta1  delta2  delta3  delta4  startnr    rel_kr  streck_avst  rel_rank  h1_samma_bana  h2_samma_bana  h3_samma_bana  h1_samma_kusk  h2_samma_kusk  h3_samma_kusk  \n",
       "0  3935.030968  6006.507182  11.18034   8.3666      5.0    21.0    19.0    17.0    10.0    18.0      0.0  0.102926         43.0  0.416667              0              0              0              1              1              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'XGB Randomized search'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "grid_search_result = randomGrid_xgb('xgb1L1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1,\n",
       " 'reg_lambda': 0.1,\n",
       " 'n_estimators': 200,\n",
       " 'max_depth': 4,\n",
       " 'learning_rate': 0.1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9147060283374773"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.1823268853433424"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9147060283374773"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(grid_search_result.best_params_)\n",
    "display(grid_search_result.best_score_)\n",
    "ix = grid_search_result.best_index_\n",
    "display(-grid_search_result.cv_results_['mean_test_neg_log_loss'][ix])\n",
    "display(grid_search_result.cv_results_['mean_test_roc_auc'] [ix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fejka_resultat_tabell():\n",
    "    ### init resutat-tabell\n",
    "    df_resultat = pd.DataFrame(columns = ['datum', 't1_7', 't1_6', 't1_5', 't1_kostn', 't1_utd', 't1_vinst' ])\n",
    "    df_resultat.set_index('datum',drop=True, inplace=True)\n",
    "    df_resultat.loc['2019-08-01'] = [0, 0, 8,300,200, -100]\n",
    "    df_resultat.loc['2019-08-08'] = [0, 0, 0,600,200, -400]\n",
    "    df_resultat.loc['2019-08-15'] = [0, 1, 2,900,600, -300]\n",
    "    df_resultat.loc['2019-08-22'] = [1, 2, 8,1200,1000, -200]\n",
    "    df_resultat.sort_index(ascending=True,inplace=True)\n",
    "    # 3. plotta\n",
    "    print(df_resultat.head())\n",
    "    # bigger plot\n",
    "    df_resultat.plot(kind='line',  y='t1_vinst', rot=45, legend=True, figsize=(20,10))\n",
    "    return df_resultat\n",
    "\n",
    "df_resultat = fejka_resultat_tabell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTA DETTA I IPYNB\n",
    "# testar diverse lösningar till v75 (streamlit)\n",
    "# import module for randomforrest\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "\n",
    "def kelly(proba, streck, odds):  # proba = prob winning, streck i % = streck\n",
    "    # läs in streck_to_odds.pkl\n",
    "    import pickle\n",
    "    with open(pref+'rf_streck_odds.pkl', 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "        \n",
    "    if odds is None:\n",
    "        o = rf.predict(streck.copy())\n",
    "    else:\n",
    "        o = rf.predict(streck.copy())\n",
    "\n",
    "    # for each values > 40 in odds set to 1\n",
    "    o[o > 40] = 1\n",
    "    return (o*proba - (1-proba))/o\n",
    "\n",
    "def compute_total_insats(veckans_rad):\n",
    "    summa = veckans_rad.groupby('avd').avd.count().prod() / 2\n",
    "    return summa\n",
    "\n",
    "def beräkna_utdelning(datum, sjuor, sexor, femmor, df_utdelning):\n",
    "    min_utdelning = df_utdelning.loc[df_utdelning.datum==datum,['7rätt', '6rätt','5rätt']]\n",
    "    \n",
    "    return (min_utdelning['7rätt'] * sjuor + min_utdelning['6rätt'] * sexor + min_utdelning['5rätt'] * femmor).values[0]\n",
    "\n",
    "def ta_fram_rad(veckans_rad_, spik_strategi,kelly_strategi, max_cost=300, min_avst=0.25):\n",
    "    \"\"\" Denna funktion tar fram en rad för typ-modeller (ej meta-modell)\n",
    "    df nnehåller _en omgång_\n",
    "    _spik_strategi_: None - inget, '1a' - forcera 1 spik, '2a' - forcera 2 spikar, '1b' - 1 spik endast om klar favorit, '2b' - spikar för endast klara favoriter \n",
    "    _kelly_strategi_: None - ingen kelly, 1 - kelly varannan gång om positiv\n",
    "    \"\"\"\n",
    "\n",
    "    veckans_rad = veckans_rad_.copy()\n",
    "    veckans_rad['välj'] = False   # inga rader valda ännu\n",
    "    veckans_rad['spik'] = False   # inga spikar valda ännu\n",
    "    # a) ta ut en häst i varje avd - markera valda i df\n",
    "    \n",
    "    for avd in veckans_rad.avd.unique():\n",
    "        # max av proba i veckans_rad \n",
    "        max_proba = veckans_rad[veckans_rad.avd == avd]['proba'].max()\n",
    "        veckans_rad.loc[(veckans_rad.avd == avd) & (veckans_rad.proba == max_proba), 'välj'] = True\n",
    "    \n",
    "    # b) leta 1-2 spikar om så begärs - markera valda i df\n",
    "    spikad_avd = []\n",
    "    if spik_strategi:\n",
    "        print('spik_strategi', spik_strategi)\n",
    "        assert spik_strategi in ['1a','1b','2a','2b'], \"spik_strategi måste ha något av värdena i listn\"\n",
    "        # Hitta spik-kandidater\n",
    "        if spik_strategi[0] in ['1','2']:\n",
    "            spik1 = veckans_rad.nlargest(1,'proba').index[0]   # largest in dataset\n",
    "            avd = veckans_rad.loc[spik1,'avd']\n",
    "            no2 = veckans_rad.query(\"avd==@avd\").nlargest(2, 'proba').index[1]  # second in avd\n",
    "            print(f'hösta proba={veckans_rad.loc[spik1, \"proba\"]} i avd={avd}; no2 i avd={avd} är {veckans_rad.loc[no2,\"proba\"]}')\n",
    "            avstånd = veckans_rad.loc[spik1, 'proba'] - veckans_rad.loc[no2, 'proba']\n",
    "            print('avst', avstånd)\n",
    "            if (spik_strategi[1] == 'b') and (avstånd > min_avst):\n",
    "                print('strategi', spik_strategi[1], 'valde spik i avd',avd)\n",
    "                # add avd to a list\n",
    "                spikad_avd.append(avd)\n",
    "                \n",
    "                veckans_rad.loc[spik1,'spik'] = True\n",
    "                veckans_rad.loc[spik1, 'välj'] = True\n",
    "            elif spik_strategi[1] == 'a':\n",
    "                print('strategi',spik_strategi[1], 'valde spik i avd',avd)\n",
    "                spikad_avd.append(avd)\n",
    "                veckans_rad.loc[spik1,['spik']]= True\n",
    "                veckans_rad.loc[spik1, 'välj']= True\n",
    "                \n",
    "        if spik_strategi[0] == '2':\n",
    "            spik2 = veckans_rad.nlargest(2,'proba').index[1] # second in dataset\n",
    "            avd = veckans_rad.loc[spik2, 'avd']\n",
    "            no2 = veckans_rad.query(\"avd==@avd\").nlargest(2, 'proba').index[1]  # second in avd\n",
    "            print(f'näst högsta proba={veckans_rad.loc[spik2, \"proba\"]} i avd={avd}; no2 i avd={avd} är {veckans_rad.loc[no2,\"proba\"]}')\n",
    "            avstånd = veckans_rad.loc[spik2, 'proba'] - veckans_rad.loc[no2, 'proba']\n",
    "            print('avst',avstånd)\n",
    "            if (spik_strategi[1] =='b') and (avstånd > min_avst):\n",
    "                print('strategi', spik_strategi[1], 'valde spik i avd', avd)    \n",
    "                spikad_avd.append(avd)\n",
    "                veckans_rad.loc[spik2, 'spik'] = True\n",
    "                veckans_rad.loc[spik2, 'välj'] = True\n",
    "            elif spik_strategi[1] == 'a':\n",
    "                print('strategi', spik_strategi[1], 'i avd',avd)\n",
    "                spikad_avd.append(avd)\n",
    "                veckans_rad.loc[spik2,'spik'] = True\n",
    "                veckans_rad.loc[spik2,'välj'] = True\n",
    "                \n",
    "    # c) sortera upp i proba-ordning. Om kelly skapa en sortering efter kelly-ordning\n",
    "    veckans_rad = veckans_rad.sort_values(by=['proba'], ascending=False)\n",
    "    veckans_rad = veckans_rad.reset_index(drop=True)\n",
    "    if kelly_strategi == '1':\n",
    "        veckans_kelly = veckans_rad.sort_values(by=['kelly'], ascending=False)\n",
    "        veckans_kelly = veckans_kelly.reset_index(drop=True)\n",
    "    \n",
    "    cost = 0.5 # 1 rad\n",
    "    while cost < max_cost:\n",
    "        # d) plocka en och en - först proba sedan ev positiv kelly markera som valda i df\n",
    "        curr_index = veckans_rad.query(\"välj==False and avd not in @spikad_avd\").nlargest(1,'proba').index\n",
    "        veckans_rad.loc[curr_index,'välj'] = True\n",
    "        # e) avbryt vid 300:-\n",
    "        cost = compute_total_insats(veckans_rad.query(\"välj==True\"))\n",
    "        if  cost > max_cost:\n",
    "            veckans_rad.loc[curr_index, 'välj'] = False  # ta tillbaks den sist spelade\n",
    "            break\n",
    "        if kelly_strategi == '1' and veckans_rad.query(\"välj==False and avd not in @spikad_avd and kelly > 0\").shape[0] > 0:\n",
    "            curr_index = veckans_rad.query(\"välj==False and avd not in @spikad_avd and kelly > 0\").nlargest(1,'kelly').index\n",
    "            cost = compute_total_insats(veckans_rad.query(\"välj==True\"))\n",
    "            veckans_rad.loc[curr_index, 'välj'] = True\n",
    "            if  cost > max_cost:\n",
    "                veckans_rad.loc[curr_index, 'välj'] = False  # ta tillbaks den sist spelade\n",
    "                break\n",
    "    cost = compute_total_insats(veckans_rad.query(\"välj==True\"))\n",
    "    return veckans_rad, cost\n",
    "\n",
    "def rätta_rad(df, datum, df_utdelning ):\n",
    "    \"\"\"\n",
    "    Räkna ut antal 5:or, 6:or resp. 7:or\n",
    "    Hämta ev utdelning\n",
    "    Spara datum, resultat, utdelning och rad-kostnad\n",
    "    \"\"\"\n",
    "    sjuor, sexor, femmor, utdelning = 0,0,0,0\n",
    "    \n",
    "    min_tabell = df[['y', 'avd', 'häst', 'rel_rank', 'välj']].copy()\n",
    "    min_tabell.sort_values(by=['avd', 'y'], ascending=False,inplace=True)\n",
    "\n",
    "    # 1. om jag har max 7 rätt\n",
    "    if min_tabell.query('välj==True and y==1').y.sum() == 7:\n",
    "        sjuor=1\n",
    "        sexor = (min_tabell.groupby('avd').välj.sum()).sum()-7\n",
    "        # antal femmor\n",
    "        ant1 = min_tabell.query('avd==1 and välj==True').välj.sum()-1\n",
    "        ant2 = min_tabell.query('avd==2 and välj==True').välj.sum()-1\n",
    "        ant3 = min_tabell.query('avd==3 and välj==True').välj.sum()-1\n",
    "        ant4 = min_tabell.query('avd==4 and välj==True').välj.sum()-1\n",
    "        ant5 = min_tabell.query('avd==5 and välj==True').välj.sum()-1\n",
    "        ant6 = min_tabell.query('avd==6 and välj==True').välj.sum()-1\n",
    "        ant7 = min_tabell.query('avd==7 and välj==True').välj.sum()-1\n",
    "        femmor = ant1*ant2+ant1*ant2+ant1*ant3+ant1*ant4+ant1*ant5+ant1*ant6+ant1*ant7 +\\\n",
    "                ant2*ant3+ant2*ant4+ant2*ant5+ant2*ant6+ant2*ant7 + \\\n",
    "                ant3*ant4+ant3*ant5+ant3*ant6+ant3*ant7 + \\\n",
    "                ant4*ant5+ant4*ant6+ant4*ant7 + \\\n",
    "                ant5*ant6+ant5*ant7 + \\\n",
    "                ant6*ant7\n",
    "\n",
    "    # 2. jag har max 6 rätt\n",
    "    if min_tabell.query('välj==True and y==1').y.sum() == 6:\n",
    "        avd_fel = min_tabell.loc[((min_tabell.välj==False) & (min_tabell.y==1)),'avd'].values[0]\n",
    "        print(min_tabell.query('avd== @avd_fel').välj.sum())\n",
    "        sexor = min_tabell.query('avd==@avd_fel').välj.sum()\n",
    "        # antal femmor\n",
    "        femmor_fel, femmor_rätt = 0,0\n",
    "        for avd in range(1,8):\n",
    "            if avd == avd_fel:\n",
    "                femmor_fel += min_tabell.loc[min_tabell.avd==avd_fel].välj.sum()\n",
    "                \n",
    "            femmor_rätt += min_tabell.query('avd==@avd and välj==True').välj.sum()-1\n",
    "        print(f'femmor_rätt = {femmor_rätt} femmor_fel = {femmor_fel}')    \n",
    "        femmor = femmor_fel * femmor_rätt\n",
    "\n",
    "    # 3. jag har max 5 rätt\n",
    "    if min_tabell.query('välj==True and y==1').y.sum() == 5:\n",
    "        avd_fel = min_tabell.loc[((min_tabell.välj==False) & (min_tabell.y==1)),'avd'].values\n",
    "        femmor = min_tabell.loc[min_tabell.avd==avd_fel[0]].välj.sum() * min_tabell.loc[min_tabell.avd==avd_fel[1]].välj.sum()\n",
    "    \n",
    "    # 4. utdelning \n",
    "    \n",
    "    return sjuor, sexor, femmor, beräkna_utdelning(datum, sjuor,sexor,femmor, df_utdelning)\n",
    "\n",
    "###############################################################################\n",
    "#      main logic v75\n",
    "def testa_main_v75():\n",
    "    df_utdelning = pd.read_csv(pref+'/utdelning.csv')\n",
    "    test1 = tp.Typ('test1',  True,    True,     False,       0,  False,          0,        False,    True, pref=pref)\n",
    "\n",
    "    startdatum = '1900-01-01'\n",
    "    # 0. ta fram startdatum  (datum=startdatum)\n",
    "    curr_datix = len(df.datum.unique()) - 200      # ca 3 å3 tillbaks\n",
    "    startdatum = df.datum.unique()[curr_datix]   # ca 3 år tillbaks\n",
    "    datum = startdatum\n",
    "    # 1. learn fram till datum\n",
    "    print(f'learn fram till {datum}')\n",
    "    X = df.query(f'datum < @datum').copy()\n",
    "    y = X.y\n",
    "    X = X.drop('y', axis=1)\n",
    "    X_test = df.query(f'datum > @datum').copy()\n",
    "    y_test = X_test.y\n",
    "    X_test = X_test.drop('y', axis=1)\n",
    "    X_curr = df.query(f'datum == @datum').copy()\n",
    "    veckans_rad = X_curr[['datum','avd','häst','bana','kusk','streck','streck_avst','rel_rank','y']].copy()\n",
    "    y_curr = X_curr.y\n",
    "    X_curr = X_curr.drop(['y'], axis=1)\n",
    "\n",
    "    params = {\"depth\": 2, \"l2_leaf_reg\": 3,\"iterations\": 500, \"learning_rate\": 0.008}\n",
    "    model = test1.learn(X, y, X_test=X_test, y_test=y_test,save=True, params=params)\n",
    "    print(X.shape)\n",
    "    print(X_curr.shape)\n",
    "    veckans_rad['proba'] = test1.predict(X_curr)\n",
    "    veckans_rad['kelly'] = kelly(veckans_rad.proba, veckans_rad[['streck']], None)\n",
    "\n",
    "    # 2. ta fram rad för datum, rätta och spara\n",
    "    # inkluderar spik_strategi,kelly_strategi,\n",
    "    veckans_rad, kostnad = ta_fram_rad(veckans_rad, '2b', '1', min_avst=0.3)\n",
    "\n",
    "    sjuor, sexor, femmor, utdelning = rätta_rad(veckans_rad, datum, df_utdelning)\n",
    "    print('kostnad',kostnad, 'utdelning', utdelning)\n",
    "\n",
    "    display(\"SPARA RESLUTAT\")\n",
    "    # 3. plotta\n",
    "\n",
    "        # loopa över olika setup\n",
    "\n",
    "    # 4. startdatum+1\n",
    "    # 5. gå till 1\n",
    "\n",
    "    return datum, kostnad, utdelning, sjuor, sexor, femmor, veckans_rad\n",
    "\n",
    "def testa_resultat(datum,kostnad, utdelning, sjuor, sexor, femmor):\n",
    "    df_resultat = pd.DataFrame(\n",
    "        columns=['datum', 't1_7', 't1_6', 't1_5', 't1_kostn', 't1_utd', 't1_vinst'])\n",
    "    df_resultat.set_index('datum', drop=True, inplace=True)\n",
    "    dict = {'t1_7': sjuor, 't1_6': sexor, 't1_5': femmor,\n",
    "            't1_kostn': kostnad, 't1_utd': utdelning, 't1_vinst': utdelning-kostnad}\n",
    "    dict = [sjuor, sexor, femmor, kostnad,  utdelning,  utdelning-kostnad]\n",
    "    # set last row to dict\n",
    "    df_resultat.loc[datum] = dict\n",
    "    datum = '2022-07-08'\n",
    "    df_resultat.loc[datum] = [sjuor+1, sexor, femmor,\n",
    "                            kostnad,  utdelning,  utdelning-kostnad]\n",
    "\n",
    "    df_resultat.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "    df_resultat\n",
    "\n",
    "    return df_resultat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum ,kostnad, utdelning, sjuor, sexor, femmor, veckans_rad = testa_main_v75()\n",
    "df_resultat = testa_resultat(datum,kostnad, utdelning, sjuor, sexor, femmor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kolla_värdena(veckans_rad, sjuor, sexor, femmor, kostnad, utdelning):\n",
    "    ##### kolla värdena\n",
    "    print(kostnad)\n",
    "    print('sjuor',sjuor,'sexor', sexor, 'femmor', femmor)\n",
    "    print(len(veckans_rad.query(\"välj==True\")))\n",
    "    veckans_rad.query(\"välj==True\").sort_values(by=['avd','proba'],ascending=[True,False])\n",
    "    # veckans_rad.query(\"välj==True\").sort_values(by='avd')\n",
    "    # min_utdelning = df_utdelning.loc[df_utdelning.datum == datum, ['7rätt', '6rätt', '5rätt']]\n",
    "    # print(min_utdelning)\n",
    "    # min_utdelning['7rätt'] * sjuor + min_utdelning['6rätt'] * sexor + min_utdelning['5rätt'] * femmor\n",
    "\n",
    "kolla_värdena(veckans_rad, sjuor, sexor, femmor, kostnad, utdelning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_meta_proba(X_):\n",
    "    sm = X_.copy()\n",
    "    # select the highest meta_predict per avd\n",
    "    sm['first'] = sm.groupby('avd')['meta_predict'].transform(\n",
    "        lambda x: x.nlargest(2).reset_index(drop=True)[0])\n",
    "    sm['second'] = sm.groupby('avd')['meta_predict'].transform(\n",
    "        lambda x: x.nlargest(2).reset_index(drop=True)[1])\n",
    "\n",
    "    sm = sm.query(\"(first==meta_predict or second==meta_predict)\").copy()\n",
    "    sm['diff'] = sm['first'] - sm['second']\n",
    "\n",
    "    # drop duplicates per avd\n",
    "    sm = sm.drop_duplicates(subset='avd', keep='first')\n",
    "\n",
    "    sm.sort_values(by='diff', ascending=False, inplace=True)\n",
    "    # sm.to_csv('mesta_diff_per_avd.csv')\n",
    "    return sm\n",
    "\n",
    "\n",
    "def diff_streck(df, curr_datum='2022-07-30'):\n",
    "    larg = df.query('datum == curr_datum').groupby(\n",
    "        ['avd'])['streck'].nlargest(2)\n",
    "    larg = larg.reset_index().drop('level_1', axis=1)\n",
    "\n",
    "    # select the first row for each avd\n",
    "    first = larg.groupby(['avd']).head(1).set_index('avd')\n",
    "    second = larg.groupby(['avd']).tail(1).set_index('avd')\n",
    "\n",
    "    diff = first.sub(second, axis=0)\n",
    "    # print(diff)\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hx_samma_bana(df_, datum='2022-07-30'):\n",
    "    df = df_.copy()\n",
    "    return df[df.datum == datum].bana == df[df.datum == datum].h1_bana\n",
    "# hx_samma_bana(df)\n",
    "\n",
    "\n",
    "def hx_samma_kusk(df_, datum='2022-07-30'):\n",
    "    df = df_.copy()\n",
    "    return df[df.datum == datum].kusk == df[df.datum == datum].h1_kusk\n",
    "\n",
    "\n",
    "hx_samma_kusk(df).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ta ut max srteck per avd\n",
    "def max_streck_per_avd(df_):\n",
    "    df = df_.copy()\n",
    "    df['max_streck'] = df.groupby(\n",
    "        ['datum', 'avd']).streck.transform(lambda x: x.max())\n",
    "\n",
    "    df['streck_avst'] = df.max_streck - df.streck\n",
    "    df.drop(['max_streck'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "max_streck_per_avd(df)[['häst', 'avd', 'streck_avst', 'streck', ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plats i streck per avd\n",
    "def plats_i_streck_per_avd(df_):\n",
    "    df = df_.copy()\n",
    "    # sortera streck per datum,avd\n",
    "    # df = df.sort_values(by=['datum', 'avd', 'streck'])\n",
    "    # ranking per avd\n",
    "    df['rank'] = df.groupby(['datum', 'avd'])['streck'].rank(ascending=False, method='dense')\n",
    "    df.sort_values(by=['datum', 'avd', 'rank'], inplace=True)\n",
    "    return df\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "plats_i_streck_per_avd(df)[['avd','häst','streck','streck_avst','rank']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what row has max kr in total in df\n",
    "df['välj']=False\n",
    "kelly_strategi = '1'\n",
    "df.loc[df.nlargest(2,'rel_kr').index,'välj'] = True\n",
    "\n",
    "df.loc[df.query(\"välj==False\").nlargest(1,'rel_kr').index,'välj'] = True\n",
    "\n",
    "if df.query(\"välj==False and rel_rank > 0\").shape[0] > 0:\n",
    "    df.loc[df.query(\"välj==False and rel_rank > 0\").nlargest(1, 'rel_rank').index, 'välj'] = True\n",
    "\n",
    "df.välj.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a new row by appending the new values to df_resultat\n",
    "# last_row = df_resultat.iloc[-1] + [sjuor,sexor,femmor,kostnad,utdelning,utdelning-kostnad]\n",
    "# datum='2022-08-26'\n",
    "# # add the new row to df_resultat with loc datum\n",
    "# df_resultat.loc[datum] = last_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utred varför rf blir så dålig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# write the scores\n",
    "def display_scores(y_true, y_pred, spelade):\n",
    "    print('AUC', round(roc_auc_score(y_true, y_pred), 5), 'F1', round(f1_score(y_true, y_pred), 5), 'Acc', round(\n",
    "        accuracy_score(y_true, y_pred), 5), 'MAE', round(mean_absolute_error(y_true, y_pred), 5), '\\n', spelade)\n",
    "    return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def find_threshold(y_pred, fr, to, margin):\n",
    "    \"\"\" hitta threshold som ger 2.5 spelade per avdelning \"\"\"\n",
    "    thresh = 0\n",
    "    cnt = 0\n",
    "    # make a binary search\n",
    "    while cnt < 1000:\n",
    "        thresh = (fr + to) / 2\n",
    "        antal_spelade_per_avd = 12 * sum(y_pred > thresh)/len(y_pred)\n",
    "        if (antal_spelade_per_avd > (2.5 - margin)) and (antal_spelade_per_avd < (2.5 + margin)):\n",
    "            break\n",
    "\n",
    "        if antal_spelade_per_avd > 2.5:\n",
    "            fr = thresh-0.00001\n",
    "        else:\n",
    "            to = thresh+0.00001\n",
    "        cnt += 1\n",
    "\n",
    "    print('ant', cnt, 'thresh', round(thresh, 4))\n",
    "    if cnt >= 1000:\n",
    "        print('threshold not found', 'fr', round(fr, 6), 'to', round(to, 6))\n",
    "\n",
    "    return thresh\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, typ, fr=0.0, to=0.9, margin=0.001):\n",
    "    thresh = round(find_threshold(y_pred,fr,to,margin), 4)\n",
    "    print(f'Threshold: {thresh}\\n')\n",
    "    y_pred = (y_pred > thresh).astype(int)\n",
    "    # confusion_matrix_graph(y_true, y_pred, f'{typ} threshold={thresh}')\n",
    "\n",
    "    #### Sedan: confusion matrix graph ####\n",
    "    title = f'{typ} threshold={thresh}'\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred,)\n",
    "    fig, ax = plt.subplots()\n",
    "    # make it bigger\n",
    "    fig.set_size_inches(10, 10)\n",
    "    sns.set(font_scale=2.0)\n",
    "    sns.heatmap(cm/np.sum(cm), annot=True, fmt=\".2%\", linewidths=.5,\n",
    "                square=True, cmap='Blues_r')\n",
    "\n",
    "    # increase font size\n",
    "    plt.rcParams['font.size'] = 20\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(title)\n",
    "    # plot fig\n",
    "    plt.show()\n",
    "    \n",
    "    _=display_scores(y_true, y_pred, f'spelade per lopp: {round(12 * sum(y_pred)/len(y_pred),4)}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train = pd.read_csv(pref + 'rf_train.csv')\n",
    "rf_validate = pd.read_csv(pref + 'rf_validate.csv')\n",
    "rf_y_pred = pd.read_csv(pref + 'rf_y_pred.csv')\n",
    "rf_y_true = pd.read_csv(pref + 'rf_y_true.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import json\n",
    "with open(pref+'optimera/params_rf.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "        params = params['params']\n",
    "        # st.write(params)\n",
    "\n",
    "rf_model = RandomForestClassifier(**params, n_jobs=6, random_state=2022)\n",
    "rf_fit=rf_model.fit(rf_train.drop('y',axis=1), rf_train.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = rf_fit.predict_proba(rf_validate)[:,1]\n",
    "print('förbereder rf plot')\n",
    "plot_confusion_matrix(rf_y_true, new_pred,\n",
    "                      'rf', fr=0.0, to=1.0, margin=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d733caf4ffc39d0fbd9a2ba54ef4b7d515956d8048931f8241efe3827fb2d1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
