{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Try stacking for V75"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "import pandas as pd \r\n",
    "import numpy as np \r\n",
    "from IPython.display import display \r\n",
    "\r\n",
    "from catboost import CatBoostClassifier,Pool, cv, utils \r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\r\n",
    "from sklearn.tree   import DecisionTreeClassifier\r\n",
    "from sklearn.linear_model import LinearRegression\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\r\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "from sklearn_pandas import DataFrameMapper\r\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, Pipeline\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "\r\n",
    "from sklearn.preprocessing import FunctionTransformer\r\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelBinarizer\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\r\n",
    "# import sklearn.metrics, sklearn.compose\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***What to do***:\r\n",
    "- Kör en enkel modell utan 'streck'  \r\n",
    "- kolla om ekipage-nr gör någon skillnad  optimera m\r\n",
    "- kolla om 'avd' göt någon skillnad \r\n",
    "- skapa en flaml-ensemble utan streck\r\n",
    "- Se hu bra denna ensemble är jämfört med 'streck' inkluderat\r\n",
    "- Blir den lika bra som min pipe?\r\n",
    "- Kan  med och utan 'streck' användas tillsammans ?\r\n",
    "  - Man kan ha som innan på den första och proba-order eller f/insats som kriterium för den andra som ju bara skall hitta överraskningar\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "### läs in data och returnera df, alla datum samt index till split-punkt\r\n",
    "def load_data(proc=0.75):\r\n",
    "    \r\n",
    "    df = pd.read_csv('..\\\\all_data.csv')     \r\n",
    "    alla_datum = list(df.datum.unique())\r\n",
    "    split_ix = int(len(df)*proc)\r\n",
    "    \r\n",
    "    return df,alla_datum,split_ix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "### return a CatBoost model with some default parameters\r\n",
    "def get_model(d=6,l2=2,iterations=3000,use_best=True,verbose=False):\r\n",
    "    model = CatBoostClassifier(iterations=iterations,use_best_model=use_best, \r\n",
    "        custom_metric=['Logloss', 'AUC','Recall', 'Precision', 'F1', 'Accuracy'],\r\n",
    "\r\n",
    "        eval_metric='Accuracy', \r\n",
    "        depth=d,l2_leaf_reg=l2,\r\n",
    "        auto_class_weights='Balanced',verbose=verbose, random_state=2021) \r\n",
    "    return model                "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "### Features som inte används vid träning\r\n",
    "def remove_features(df,remove_mer=[]):\r\n",
    "    #remove_mer=['h5_perf','h5_auto','h4_perf','h4_auto', 'h3_perf', 'h2_perf']\r\n",
    "    df.drop(['avd','startnr','vodds','podds','bins','h1_dat','h2_dat','h3_dat','h4_dat','h5_dat'],axis=1,inplace=True) #\r\n",
    "    if remove_mer:\r\n",
    "        df.drop(remove_mer,axis=1,inplace=True)\r\n",
    "    \r\n",
    "    # df=check_unique(df.copy())\r\n",
    "    # df=check_corr(df.copy())\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bygg min första riktiga Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "# Set a smooth mean value to the features in X_train  ##\r\n",
    "def calc_smooth_mean(X, y, by, m=100, tot_mean=None):\r\n",
    "    Xcopy = X.copy()\r\n",
    "    Xcopy['plac'] = y\r\n",
    "\r\n",
    "    # Compute the number of values and the mean of each group\r\n",
    "    agg = Xcopy.groupby(by)['plac'].agg(['count', 'mean'])\r\n",
    "    counts = agg['count']\r\n",
    "    means = agg['mean']\r\n",
    "\r\n",
    "    # Compute the \"smoothed\" means\r\n",
    "    smooth = (counts * means + m * tot_mean) / (counts + m)\r\n",
    "    \r\n",
    "    return smooth.to_dict()\r\n",
    "\r\n",
    "\r\n",
    "# transform model to stacking estimator\r\n",
    "class ModelTransformer(TransformerMixin):\r\n",
    "    \r\n",
    "    def __init__(self, model):\r\n",
    "        self.model = model\r\n",
    "\r\n",
    "    def fit(self, *args, **kwargs):\r\n",
    "        self.model.fit(*args, **kwargs)\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X, **transform_params):\r\n",
    "        return pd.DataFrame(self.model.predict_proba(X))\r\n",
    "    \r\n",
    "def create_ekipage(df):\r\n",
    "    prefix = ['','h1_','h2_','h3_','h4_','h5_',]\r\n",
    "    ekipage=[]\r\n",
    "    for pref in prefix:\r\n",
    "        df[pref+'ekipage'] = df[pref+'kusk'].str.cat(df['häst'], sep =\", \")  # concatenate 'häst' and 'kusk' into one column\r\n",
    "        ekipage.append(pref+'ekipage')\r\n",
    "        df.drop([pref+'kusk'],axis=1,inplace=True)\r\n",
    "        \r\n",
    "    df.drop(['häst'],axis=1,inplace=True )   \r\n",
    "        \r\n",
    "    return df, ekipage   \r\n",
    "    \r\n",
    "# Handle ekipage (häst and kusk)\r\n",
    "class CustomSmoothMean(BaseEstimator, TransformerMixin):\r\n",
    "    def __init__(self,cols,plac='plac', m=100):\r\n",
    "        super().__init__()\r\n",
    "        self.map = {}\r\n",
    "        self.total_mean=None\r\n",
    "        self.cols=cols\r\n",
    "        self.plac=plac\r\n",
    "        self.m=m\r\n",
    "\r\n",
    "    def fit(self, X, y=None):\r\n",
    "        # print('CustSmooth fit start')\r\n",
    "        self.total_mean=y.mean()\r\n",
    "        self.map = calc_smooth_mean(X, y, by='ekipage', m=self.m, tot_mean=self.total_mean)\r\n",
    "        self.map['missing'] = 0\r\n",
    "\r\n",
    "        display(f'using m={self.m}')\r\n",
    "        # print('CustSmooth fit end')\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X, y=None):\r\n",
    "        # print('CustSmooth transform start')   \r\n",
    "        for col in self.cols:\r\n",
    "            X[col] = X[col].map(self.map)\r\n",
    "            X[col].fillna(0,inplace=True)\r\n",
    "            \r\n",
    "        # display(X.isna().sum())    \r\n",
    "        # print('CustSmooth transform end')    \r\n",
    "        return X\r\n",
    "    \r\n",
    "    def get_feature_names(self):\r\n",
    "        return self.cols, self.plac, self.m, self.total_mean,self.map    \r\n",
    "####\r\n",
    "\r\n",
    "def set_lower(dfo):\r\n",
    "    # print('set_lower start')\r\n",
    "    df=dfo.copy()\r\n",
    "    for c in df.columns:\r\n",
    "        df[c] = df[c].str.lower()\r\n",
    "    # print('set_lower end')    \r\n",
    "    return df\r\n",
    "\r\n",
    "lower =  FunctionTransformer(set_lower)\r\n",
    "\r\n",
    "def datum_to_num(df):\r\n",
    "    dfc=df.copy()\r\n",
    "    dfc['datum'] = pd.to_datetime(df.datum).view(float)*10e210\r\n",
    "    return dfc\r\n",
    "\r\n",
    "# Handle ekipage (häst and kusk)\r\n",
    "class transf_bana(BaseEstimator, TransformerMixin):\r\n",
    "    def __init__(self,banor):\r\n",
    "        super().__init__()\r\n",
    "        self.map = {}\r\n",
    "        self.banor = banor\r\n",
    "\r\n",
    "    def fit(self, X, y=None):\r\n",
    "        # print('fit bana start')\r\n",
    "        huvud_bana=self.banor[0]\r\n",
    "        \r\n",
    "        self.map = X[huvud_bana].str.lower().value_counts() \r\n",
    "        self.map[None] = 0\r\n",
    "        self.map['missing'] = 0\r\n",
    "        # print('fit bana end')\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X, y=None):\r\n",
    "        # print('transform bana',X.shape)\r\n",
    "        for bana in self.banor:\r\n",
    "            X[bana] = X[bana].fillna('missing-1')\r\n",
    "            X[bana] = X[bana].str.lower()\r\n",
    "            X[bana] = [item[0] for item in X[bana].str.split('-')]  # remove '-10' from 'solvalla-10' etc\r\n",
    "            # print('transform bana effter split',bana)\r\n",
    "            # print(X[bana][:10])\r\n",
    "            X[bana] = X[bana].map(self.map)\r\n",
    "            X[bana] = X[bana].fillna(0)\r\n",
    "            # print('transform bana innan return')\r\n",
    "        return X\r\n",
    "    \r\n",
    "    def get_feature_names(self):\r\n",
    "        return self.map, self.banor\r\n",
    "    \r\n",
    "####\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Själva pipen"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "df,alla_datum,split_ix = load_data()\r\n",
    "df,ekipage = create_ekipage(df.copy())      # alla ekipage, h1_ekipage-h5_ekipage\r\n",
    "# df = remove_features(df)\r\n",
    "\r\n",
    "X_train=df[:split_ix].copy()\r\n",
    "y_train=(X_train.plac==1)*1\r\n",
    "X_train.drop('plac',axis=1,inplace=True)\r\n",
    "X_test=df[split_ix:].copy()\r\n",
    "y_test=(X_test.plac==1)*1\r\n",
    "X_test.drop('plac',axis=1,inplace=True)\r\n",
    "X_train = remove_features(X_train.copy())\r\n",
    "X_test  = remove_features(X_test.copy())\r\n",
    "\r\n",
    "no_streck=True\r\n",
    "if no_streck:\r\n",
    "    X_train.drop('streck',axis=1,inplace=True)\r\n",
    "    X_test.drop('streck',axis=1,inplace=True)\r\n",
    "\r\n",
    "könen=['kön1','kön2','kön3']\r\n",
    "banor = ['bana','h1_bana','h2_bana','h3_bana','h4_bana','h5_bana',]\r\n",
    "all_nums = list(X_train.select_dtypes('number').columns)\r\n",
    "\r\n",
    "lower_and_ohe = Pipeline([\r\n",
    "        ('lower', lower),\r\n",
    "        ('encode', OneHotEncoder(sparse=False, handle_unknown='ignore'))\r\n",
    "    ])\r\n",
    "\r\n",
    "############ Parms ###############################\r\n",
    "rf_parms={ 'n_jobs': 5,'class_weight': 'balanced'}\r\n",
    "etr_parms={'n_jobs': 5,'class_weight': 'balanced'}\r\n",
    "cb_parms={'iterations': 200,'early_stopping_rounds': 50,'auto_class_weights': 'Balanced','verbose': False}\r\n",
    "final_parms={'n_jobs': 5,'class_weight': 'balanced'}\r\n",
    "################################################### \r\n",
    "\r\n",
    "col_pipe = make_column_transformer(\r\n",
    "                        (transf_bana(banor), banor),\r\n",
    "                        (FunctionTransformer(datum_to_num), ['datum']),\r\n",
    "                        (lower_and_ohe, ['kön']), \r\n",
    "                        (CustomSmoothMean(ekipage,m=100), ekipage),\r\n",
    "                        (SimpleImputer(strategy='constant', fill_value=-1),all_nums  ),\r\n",
    "                        remainder='passthrough',\r\n",
    "                        )\r\n",
    "\r\n",
    "pipe = Pipeline(steps=[\r\n",
    "    ('transformers', col_pipe ),\r\n",
    "    \r\n",
    "    ('estimators', FeatureUnion([\r\n",
    "        ('knn', ModelTransformer(KNeighborsClassifier(n_neighbors=5, n_jobs=4))),\r\n",
    "        ('cat', ModelTransformer(CatBoostClassifier(**cb_parms))),\r\n",
    "        ('dtr', ModelTransformer(DecisionTreeClassifier(class_weight='balanced'))),\r\n",
    "        ('etr', ModelTransformer(ExtraTreesClassifier(**etr_parms))),\r\n",
    "        ('rf', ModelTransformer(RandomForestClassifier(**rf_parms))),  \r\n",
    "    ])),\r\n",
    "    ('estimator', RandomForestClassifier(**final_parms)),\r\n",
    "])\r\n",
    "\r\n",
    "\r\n",
    "# with_streck = pipe.fit(X_train,y=y_train)\r\n",
    "# no_streck = pipe.fit(X_train_nostr,y=y_train)\r\n",
    "# the_stack = pipe.fit(X_train,y_train)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MyOwnSearchCV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Jämför olika modellers score (med och utan 'streck')"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "# räkna ut proba ordning per datum,avd\r\n",
    "def proba_ordning(X,y,df,proba) :   \r\n",
    "    kassa=200\r\n",
    "    X['vann'] = y\r\n",
    "    X['avd'] =df.avd\r\n",
    "    X['vodds'] = df.vodds\r\n",
    "    X['proba'] = proba[:,1]\r\n",
    "    X['f'] = (X.proba*X.vodds - 1) / (X.vodds-1)  # kelly formel\r\n",
    "    X['spela'] = X.f >0\r\n",
    "    X['insats'] = X.spela * X.f * kassa\r\n",
    "    X.sort_values(['datum','avd','proba'],ascending=[False,True,False],inplace=True)\r\n",
    "    proba_order=X.groupby(['datum','avd']).proba.cumcount()\r\n",
    "\r\n",
    "    X['prob_order']=proba_order+1\r\n",
    "\r\n",
    "    return(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "from sklearn.metrics import roc_auc_score,mean_absolute_error,accuracy_score,matthews_corrcoef,f1_score\r\n",
    "if no_streck:\r\n",
    "    print(\"utan 'streck'\")\r\n",
    "train_pred= pipe.predict_proba(X_train)\r\n",
    "print('auc train',roc_auc_score(y_train, train_pred[:,1]))\r\n",
    "test_pred = pipe.predict_proba(X_test)\r\n",
    "print('auc test', roc_auc_score(y_test,test_pred[:,1]))\r\n",
    "print('mae test', mean_absolute_error(y_test,test_pred[:,1]))\r\n",
    "po=proba_ordning(X_test.copy(),y_test,df.copy(),test_pred )[['datum','avd','proba','prob_order','vann']]\r\n",
    "print('mean proba-order för vunna',po.loc[po.vann==1].prob_order.mean())\r\n",
    "print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "utan 'streck'\n",
      "auc train 1.0\n",
      "auc test 0.5117973504026595\n",
      "mae test 0.0957246445949814\n",
      "mean vann order 6.3240534521158125\n",
      "\n",
      "auc 0.5117973504026595\n",
      "mae 0.0957246445949814\n",
      "auc 0.5117973504026595\n",
      "mae 0.0957246445949814\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.02033407572383073"
      ]
     },
     "metadata": {},
     "execution_count": 175
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "#Jämfr CatBoost\r\n",
    "cb = CatBoostClassifier(**cb_parms)\r\n",
    "cb_pipe = make_pipeline(col_pipe, cb)\r\n",
    "cb_pipe.fit(X_train,y_train)\r\n",
    "cb_train_pred= cb_pipe.predict_proba(X_train)\r\n",
    "cb_test_pred =cb_pipe.predict_proba(X_test)\r\n",
    "\r\n",
    "if no_streck:\r\n",
    "    print(\"utan 'streck'\")\r\n",
    "print('auc', roc_auc_score(y_test,cb_test_pred[:,1]))\r\n",
    "print('mae', mean_absolute_error(y_test,cb_test_pred[:,1]))\r\n",
    "po=proba_ordning(X_test.copy(),y_test,df.copy(),cb_test_pred )[['datum','avd','proba','prob_order','vann']]\r\n",
    "print('cb mean vann ',po.loc[po.vann==1].prob_order.mean())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "used m =  100\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'using m=100'"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "auc 0.5753861410576032\n",
      "mae 0.12954190828951184\n",
      "cb mean vann  5.387527839643653\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FLAML"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "#jmfr FLAML\r\n",
    "\r\n",
    "from flaml import AutoML \r\n",
    "automl, automl_raw = None, None\r\n",
    "if False: # med transformed data\r\n",
    "    flml_parms={'automl__task': 'classification','automl__split_type':None, 'automl__verbose':100,\r\n",
    "            'automl__time_budget':500, 'automl__n_jobs':5, 'automl__early_stop':True, 'automl__ensemble':True}\r\n",
    "\r\n",
    "    automl = AutoML( )\r\n",
    "    flm_pipe = make_pipeline(col_pipe, automl)\r\n",
    "    flm=flm_pipe.fit(X_train,y_train, **flml_parms)\r\n",
    "if True: # raw - utan transformed data\r\n",
    "    flml_raw_parms={'task': 'classification','split_type':None, 'verbose': 100,\r\n",
    "            'time_budget':500, 'n_jobs':5, 'early_stop':True, 'ensemble':True}\r\n",
    "\r\n",
    "    automl_raw = AutoML()\r\n",
    "    automl_raw.fit(X_train,y_train, **flml_raw_parms)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[flaml.automl: 09-21 00:18:35] {1427} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 09-21 00:18:36] {1473} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl: 09-21 00:18:36] {1505} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl: 09-21 00:18:36] {1735} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:36] {1914} INFO -  at 1.4s,\tbest lgbm's error=0.3203,\tbest lgbm's error=0.3203\n",
      "[flaml.automl: 09-21 00:18:36] {1735} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:37] {1914} INFO -  at 1.9s,\tbest lgbm's error=0.3154,\tbest lgbm's error=0.3154\n",
      "[flaml.automl: 09-21 00:18:37] {1735} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:37] {1914} INFO -  at 2.4s,\tbest lgbm's error=0.3154,\tbest lgbm's error=0.3154\n",
      "[flaml.automl: 09-21 00:18:37] {1735} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:38] {1914} INFO -  at 3.2s,\tbest lgbm's error=0.2783,\tbest lgbm's error=0.2783\n",
      "[flaml.automl: 09-21 00:18:38] {1735} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:38] {1914} INFO -  at 3.4s,\tbest xgboost's error=0.3139,\tbest lgbm's error=0.2783\n",
      "[flaml.automl: 09-21 00:18:38] {1735} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:38] {1914} INFO -  at 3.6s,\tbest xgboost's error=0.3119,\tbest lgbm's error=0.2783\n",
      "[flaml.automl: 09-21 00:18:38] {1735} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:39] {1914} INFO -  at 4.1s,\tbest lgbm's error=0.2783,\tbest lgbm's error=0.2783\n",
      "[flaml.automl: 09-21 00:18:39] {1735} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:40] {1914} INFO -  at 4.8s,\tbest lgbm's error=0.2771,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:40] {1735} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:40] {1914} INFO -  at 5.0s,\tbest xgboost's error=0.3119,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:40] {1735} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:40] {1914} INFO -  at 5.3s,\tbest xgboost's error=0.3119,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:40] {1735} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:40] {1914} INFO -  at 5.5s,\tbest xgboost's error=0.3057,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:40] {1735} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:41] {1914} INFO -  at 5.8s,\tbest xgboost's error=0.3044,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:41] {1735} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:41] {1914} INFO -  at 6.1s,\tbest xgboost's error=0.3013,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:41] {1735} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:41] {1914} INFO -  at 6.5s,\tbest xgboost's error=0.2980,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:41] {1735} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:42] {1914} INFO -  at 7.2s,\tbest lgbm's error=0.2771,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:42] {1735} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:42] {1914} INFO -  at 7.6s,\tbest xgboost's error=0.2931,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:42] {1735} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:43] {1914} INFO -  at 8.1s,\tbest lgbm's error=0.2771,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:43] {1735} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:43] {1914} INFO -  at 8.6s,\tbest xgboost's error=0.2931,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:43] {1735} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:44] {1914} INFO -  at 9.0s,\tbest xgboost's error=0.2931,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:44] {1735} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:44] {1914} INFO -  at 9.4s,\tbest xgboost's error=0.2931,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:44] {1735} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:44] {1914} INFO -  at 9.5s,\tbest extra_tree's error=0.3282,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:44] {1735} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:45] {1914} INFO -  at 10.0s,\tbest xgboost's error=0.2811,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:45] {1735} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:45] {1914} INFO -  at 10.4s,\tbest xgboost's error=0.2811,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:45] {1735} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:45] {1914} INFO -  at 10.7s,\tbest extra_tree's error=0.2945,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:45] {1735} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:46] {1914} INFO -  at 10.8s,\tbest extra_tree's error=0.2945,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:46] {1735} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:46] {1914} INFO -  at 11.2s,\tbest extra_tree's error=0.2945,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:46] {1735} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:46] {1914} INFO -  at 11.4s,\tbest extra_tree's error=0.2945,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:46] {1735} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:47] {1914} INFO -  at 11.8s,\tbest extra_tree's error=0.2945,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:47] {1735} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:47] {1914} INFO -  at 12.1s,\tbest extra_tree's error=0.2885,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:47] {1735} INFO - iteration 29, current learner rf\n",
      "[flaml.automl: 09-21 00:18:47] {1914} INFO -  at 12.5s,\tbest rf's error=0.3045,\tbest lgbm's error=0.2771\n",
      "[flaml.automl: 09-21 00:18:47] {1735} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:48] {1914} INFO -  at 13.3s,\tbest lgbm's error=0.2726,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:48] {1735} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:49] {1914} INFO -  at 14.0s,\tbest lgbm's error=0.2726,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:49] {1735} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 09-21 00:18:49] {1914} INFO -  at 14.5s,\tbest rf's error=0.2952,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:49] {1735} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:50] {1914} INFO -  at 15.0s,\tbest extra_tree's error=0.2740,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:50] {1735} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:51] {1914} INFO -  at 16.2s,\tbest lgbm's error=0.2726,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:51] {1735} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 09-21 00:18:51] {1914} INFO -  at 16.7s,\tbest rf's error=0.2952,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:51] {1735} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:52] {1914} INFO -  at 16.9s,\tbest extra_tree's error=0.2740,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:52] {1735} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:52] {1914} INFO -  at 17.5s,\tbest xgboost's error=0.2811,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:52] {1735} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:53] {1914} INFO -  at 18.0s,\tbest extra_tree's error=0.2740,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:53] {1735} INFO - iteration 39, current learner rf\n",
      "[flaml.automl: 09-21 00:18:54] {1914} INFO -  at 18.8s,\tbest rf's error=0.2782,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:54] {1735} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:54] {1914} INFO -  at 19.5s,\tbest extra_tree's error=0.2740,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:54] {1735} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:55] {1914} INFO -  at 19.9s,\tbest extra_tree's error=0.2740,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:55] {1735} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:55] {1914} INFO -  at 20.6s,\tbest lgbm's error=0.2726,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:55] {1735} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:56] {1914} INFO -  at 21.1s,\tbest xgboost's error=0.2811,\tbest lgbm's error=0.2726\n",
      "[flaml.automl: 09-21 00:18:56] {1735} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:18:57] {1914} INFO -  at 21.8s,\tbest extra_tree's error=0.2685,\tbest extra_tree's error=0.2685\n",
      "[flaml.automl: 09-21 00:18:57] {1735} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:57] {1914} INFO -  at 22.3s,\tbest xgboost's error=0.2672,\tbest xgboost's error=0.2672\n",
      "[flaml.automl: 09-21 00:18:57] {1735} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 09-21 00:18:58] {1914} INFO -  at 22.9s,\tbest rf's error=0.2782,\tbest xgboost's error=0.2672\n",
      "[flaml.automl: 09-21 00:18:58] {1735} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl: 09-21 00:18:58] {1914} INFO -  at 23.3s,\tbest xgboost's error=0.2672,\tbest xgboost's error=0.2672\n",
      "[flaml.automl: 09-21 00:18:58] {1735} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 09-21 00:18:59] {1914} INFO -  at 24.0s,\tbest lgbm's error=0.2726,\tbest xgboost's error=0.2672\n",
      "[flaml.automl: 09-21 00:18:59] {1735} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 09-21 00:19:00] {1914} INFO -  at 24.8s,\tbest rf's error=0.2782,\tbest xgboost's error=0.2672\n",
      "[flaml.automl: 09-21 00:19:00] {1735} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:00] {1914} INFO -  at 25.4s,\tbest extra_tree's error=0.2683,\tbest xgboost's error=0.2672\n",
      "[flaml.automl: 09-21 00:19:00] {1735} INFO - iteration 51, current learner rf\n",
      "[flaml.automl: 09-21 00:19:01] {1914} INFO -  at 25.8s,\tbest rf's error=0.2782,\tbest xgboost's error=0.2672\n",
      "[flaml.automl: 09-21 00:19:01] {1735} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl: 09-21 00:19:02] {1914} INFO -  at 26.9s,\tbest xgboost's error=0.2639,\tbest xgboost's error=0.2639\n",
      "[flaml.automl: 09-21 00:19:02] {1735} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 09-21 00:19:03] {1914} INFO -  at 27.8s,\tbest rf's error=0.2726,\tbest xgboost's error=0.2639\n",
      "[flaml.automl: 09-21 00:19:03] {1735} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 09-21 00:19:03] {1914} INFO -  at 28.6s,\tbest lgbm's error=0.2726,\tbest xgboost's error=0.2639\n",
      "[flaml.automl: 09-21 00:19:03] {1735} INFO - iteration 55, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:04] {1914} INFO -  at 29.6s,\tbest extra_tree's error=0.2683,\tbest xgboost's error=0.2639\n",
      "[flaml.automl: 09-21 00:19:04] {1735} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 09-21 00:19:05] {1914} INFO -  at 30.3s,\tbest rf's error=0.2726,\tbest xgboost's error=0.2639\n",
      "[flaml.automl: 09-21 00:19:05] {1735} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl: 09-21 00:19:06] {1914} INFO -  at 30.8s,\tbest xgboost's error=0.2639,\tbest xgboost's error=0.2639\n",
      "[flaml.automl: 09-21 00:19:06] {1735} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl: 09-21 00:19:12] {1914} INFO -  at 37.4s,\tbest xgboost's error=0.2594,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:12] {1735} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl: 09-21 00:19:13] {1914} INFO -  at 38.2s,\tbest lgbm's error=0.2726,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:13] {1735} INFO - iteration 60, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:14] {1914} INFO -  at 38.8s,\tbest extra_tree's error=0.2683,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:14] {1735} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 09-21 00:19:14] {1914} INFO -  at 39.7s,\tbest lgbm's error=0.2726,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:14] {1735} INFO - iteration 62, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:15] {1914} INFO -  at 40.2s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:15] {1735} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:15] {1914} INFO -  at 40.6s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:15] {1735} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl: 09-21 00:19:16] {1914} INFO -  at 41.4s,\tbest lgbm's error=0.2726,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:16] {1735} INFO - iteration 65, current learner rf\n",
      "[flaml.automl: 09-21 00:19:17] {1914} INFO -  at 42.3s,\tbest rf's error=0.2726,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:17] {1735} INFO - iteration 66, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:18] {1914} INFO -  at 43.0s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:18] {1735} INFO - iteration 67, current learner rf\n",
      "[flaml.automl: 09-21 00:19:20] {1914} INFO -  at 44.8s,\tbest rf's error=0.2693,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:20] {1735} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl: 09-21 00:19:20] {1914} INFO -  at 45.7s,\tbest lgbm's error=0.2726,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:20] {1735} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl: 09-21 00:19:24] {1914} INFO -  at 49.1s,\tbest xgboost's error=0.2594,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:24] {1735} INFO - iteration 70, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:25] {1914} INFO -  at 49.8s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:25] {1735} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl: 09-21 00:19:32] {1914} INFO -  at 56.8s,\tbest xgboost's error=0.2594,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:32] {1735} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:32] {1914} INFO -  at 57.1s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:32] {1735} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:33] {1914} INFO -  at 57.7s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:33] {1735} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:33] {1914} INFO -  at 58.2s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:33] {1735} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl: 09-21 00:19:34] {1914} INFO -  at 59.1s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:34] {1735} INFO - iteration 76, current learner rf\n",
      "[flaml.automl: 09-21 00:19:35] {1914} INFO -  at 59.9s,\tbest rf's error=0.2693,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:35] {1735} INFO - iteration 77, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:35] {1914} INFO -  at 60.5s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:35] {1735} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 09-21 00:19:38] {1914} INFO -  at 63.4s,\tbest rf's error=0.2604,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:38] {1735} INFO - iteration 79, current learner rf\n",
      "[flaml.automl: 09-21 00:19:40] {1914} INFO -  at 65.6s,\tbest rf's error=0.2604,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:40] {1735} INFO - iteration 80, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:41] {1914} INFO -  at 66.0s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:41] {1735} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 09-21 00:19:45] {1914} INFO -  at 70.0s,\tbest rf's error=0.2604,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:45] {1735} INFO - iteration 82, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:45] {1914} INFO -  at 70.4s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:45] {1735} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:46] {1914} INFO -  at 70.9s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:46] {1735} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:46] {1914} INFO -  at 71.4s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:46] {1735} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl: 09-21 00:19:50] {1914} INFO -  at 74.7s,\tbest xgboost's error=0.2594,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:50] {1735} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:50] {1914} INFO -  at 75.2s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:50] {1735} INFO - iteration 87, current learner rf\n",
      "[flaml.automl: 09-21 00:19:54] {1914} INFO -  at 79.0s,\tbest rf's error=0.2604,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:54] {1735} INFO - iteration 88, current learner rf\n",
      "[flaml.automl: 09-21 00:19:55] {1914} INFO -  at 80.7s,\tbest rf's error=0.2604,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:55] {1735} INFO - iteration 89, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:56] {1914} INFO -  at 81.2s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:56] {1735} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 09-21 00:19:57] {1914} INFO -  at 82.6s,\tbest rf's error=0.2604,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:57] {1735} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:19:58] {1914} INFO -  at 83.0s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2594\n",
      "[flaml.automl: 09-21 00:19:58] {1735} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl: 09-21 00:20:02] {1914} INFO -  at 87.3s,\tbest xgboost's error=0.2429,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:02] {1735} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl: 09-21 00:20:03] {1914} INFO -  at 88.3s,\tbest xgboost's error=0.2429,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:03] {1735} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl: 09-21 00:20:04] {1914} INFO -  at 89.2s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:04] {1735} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:20:05] {1914} INFO -  at 89.7s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:05] {1735} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 09-21 00:20:09] {1914} INFO -  at 94.1s,\tbest rf's error=0.2604,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:09] {1735} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl: 09-21 00:20:39] {1914} INFO -  at 124.3s,\tbest xgboost's error=0.2429,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:39] {1735} INFO - iteration 98, current learner rf\n",
      "[flaml.automl: 09-21 00:20:44] {1914} INFO -  at 129.0s,\tbest rf's error=0.2604,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:44] {1735} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl: 09-21 00:20:45] {1914} INFO -  at 130.0s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:45] {1735} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:20:45] {1914} INFO -  at 130.3s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:45] {1735} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl: 09-21 00:20:48] {1914} INFO -  at 133.0s,\tbest xgboost's error=0.2429,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:48] {1735} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl: 09-21 00:20:49] {1914} INFO -  at 133.9s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:49] {1735} INFO - iteration 103, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:20:49] {1914} INFO -  at 134.4s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:49] {1735} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 09-21 00:20:50] {1914} INFO -  at 135.1s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:50] {1735} INFO - iteration 105, current learner xgboost\n",
      "[flaml.automl: 09-21 00:20:58] {1914} INFO -  at 143.0s,\tbest xgboost's error=0.2429,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:58] {1735} INFO - iteration 106, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:20:58] {1914} INFO -  at 143.5s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:58] {1735} INFO - iteration 107, current learner lgbm\n",
      "[flaml.automl: 09-21 00:20:59] {1914} INFO -  at 144.4s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:20:59] {1735} INFO - iteration 108, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:00] {1914} INFO -  at 145.1s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:00] {1735} INFO - iteration 109, current learner xgboost\n",
      "[flaml.automl: 09-21 00:21:01] {1914} INFO -  at 146.2s,\tbest xgboost's error=0.2429,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:01] {1735} INFO - iteration 110, current learner lgbm\n",
      "[flaml.automl: 09-21 00:21:02] {1914} INFO -  at 147.0s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:02] {1735} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:02] {1914} INFO -  at 147.3s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:02] {1735} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:03] {1914} INFO -  at 147.7s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:03] {1735} INFO - iteration 113, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:03] {1914} INFO -  at 148.4s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:03] {1735} INFO - iteration 114, current learner lgbm\n",
      "[flaml.automl: 09-21 00:21:04] {1914} INFO -  at 149.2s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:04] {1735} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl: 09-21 00:21:05] {1914} INFO -  at 150.1s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:05] {1735} INFO - iteration 116, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:06] {1914} INFO -  at 150.7s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:06] {1735} INFO - iteration 117, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:06] {1914} INFO -  at 151.1s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:06] {1735} INFO - iteration 118, current learner lgbm\n",
      "[flaml.automl: 09-21 00:21:07] {1914} INFO -  at 152.1s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:07] {1735} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:07] {1914} INFO -  at 152.5s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:07] {1735} INFO - iteration 120, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:08] {1914} INFO -  at 153.1s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:08] {1735} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:09] {1914} INFO -  at 154.0s,\tbest extra_tree's error=0.2649,\tbest xgboost's error=0.2429\n",
      "[flaml.automl: 09-21 00:21:09] {1735} INFO - iteration 122, current learner xgboost\n",
      "[flaml.automl: 09-21 00:21:32] {1914} INFO -  at 177.4s,\tbest xgboost's error=0.2428,\tbest xgboost's error=0.2428\n",
      "[flaml.automl: 09-21 00:21:32] {1735} INFO - iteration 123, current learner lgbm\n",
      "[flaml.automl: 09-21 00:21:33] {1914} INFO -  at 178.2s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2428\n",
      "[flaml.automl: 09-21 00:21:33] {1735} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl: 09-21 00:21:34] {1914} INFO -  at 179.0s,\tbest lgbm's error=0.2694,\tbest xgboost's error=0.2428\n",
      "[flaml.automl: 09-21 00:21:34] {1735} INFO - iteration 125, current learner catboost\n",
      "[flaml.automl: 09-21 00:21:47] {1914} INFO -  at 192.3s,\tbest catboost's error=0.1918,\tbest catboost's error=0.1918\n",
      "[flaml.automl: 09-21 00:21:47] {1735} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 09-21 00:21:48] {1914} INFO -  at 193.4s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1918\n",
      "[flaml.automl: 09-21 00:21:48] {1735} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 09-21 00:21:49] {1914} INFO -  at 194.3s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1918\n",
      "[flaml.automl: 09-21 00:21:49] {1735} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 09-21 00:21:50] {1914} INFO -  at 195.4s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1918\n",
      "[flaml.automl: 09-21 00:21:50] {1735} INFO - iteration 129, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:21:51] {1914} INFO -  at 195.8s,\tbest extra_tree's error=0.2649,\tbest catboost's error=0.1918\n",
      "[flaml.automl: 09-21 00:21:51] {1735} INFO - iteration 130, current learner catboost\n",
      "[flaml.automl: 09-21 00:22:10] {1914} INFO -  at 215.4s,\tbest catboost's error=0.1830,\tbest catboost's error=0.1830\n",
      "[flaml.automl: 09-21 00:22:10] {1735} INFO - iteration 131, current learner catboost\n",
      "[flaml.automl: 09-21 00:22:23] {1914} INFO -  at 228.3s,\tbest catboost's error=0.1830,\tbest catboost's error=0.1830\n",
      "[flaml.automl: 09-21 00:22:23] {1735} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:22:24] {1914} INFO -  at 228.8s,\tbest extra_tree's error=0.2649,\tbest catboost's error=0.1830\n",
      "[flaml.automl: 09-21 00:22:24] {1735} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl: 09-21 00:22:25] {1914} INFO -  at 229.8s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1830\n",
      "[flaml.automl: 09-21 00:22:25] {1735} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl: 09-21 00:22:26] {1914} INFO -  at 230.9s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1830\n",
      "[flaml.automl: 09-21 00:22:26] {1735} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl: 09-21 00:22:54] {1914} INFO -  at 258.9s,\tbest catboost's error=0.1830,\tbest catboost's error=0.1830\n",
      "[flaml.automl: 09-21 00:22:54] {1735} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:22:54] {1914} INFO -  at 259.5s,\tbest extra_tree's error=0.2649,\tbest catboost's error=0.1830\n",
      "[flaml.automl: 09-21 00:22:54] {1735} INFO - iteration 137, current learner catboost\n",
      "[flaml.automl: 09-21 00:23:13] {1914} INFO -  at 278.0s,\tbest catboost's error=0.1801,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:13] {1735} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl: 09-21 00:23:14] {1914} INFO -  at 279.7s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:14] {1735} INFO - iteration 139, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:23:15] {1914} INFO -  at 280.1s,\tbest extra_tree's error=0.2649,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:15] {1735} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl: 09-21 00:23:16] {1914} INFO -  at 280.9s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:16] {1735} INFO - iteration 141, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:23:16] {1914} INFO -  at 281.5s,\tbest extra_tree's error=0.2649,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:16] {1735} INFO - iteration 142, current learner rf\n",
      "[flaml.automl: 09-21 00:23:18] {1914} INFO -  at 283.0s,\tbest rf's error=0.2604,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:18] {1735} INFO - iteration 143, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:23:18] {1914} INFO -  at 283.6s,\tbest extra_tree's error=0.2649,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:18] {1735} INFO - iteration 144, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:23:19] {1914} INFO -  at 284.1s,\tbest extra_tree's error=0.2603,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:19] {1735} INFO - iteration 145, current learner catboost\n",
      "[flaml.automl: 09-21 00:23:47] {1914} INFO -  at 311.8s,\tbest catboost's error=0.1801,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:47] {1735} INFO - iteration 146, current learner lgbm\n",
      "[flaml.automl: 09-21 00:23:48] {1914} INFO -  at 312.9s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:48] {1735} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 09-21 00:23:49] {1914} INFO -  at 313.9s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:49] {1735} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 09-21 00:23:50] {1914} INFO -  at 315.4s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:50] {1735} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl: 09-21 00:23:51] {1914} INFO -  at 316.3s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:51] {1735} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 09-21 00:23:52] {1914} INFO -  at 317.1s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:52] {1735} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl: 09-21 00:23:53] {1914} INFO -  at 318.7s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:53] {1735} INFO - iteration 152, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:23:54] {1914} INFO -  at 319.2s,\tbest extra_tree's error=0.2603,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:23:54] {1735} INFO - iteration 153, current learner catboost\n",
      "[flaml.automl: 09-21 00:24:01] {1914} INFO -  at 325.9s,\tbest catboost's error=0.1801,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:24:01] {1735} INFO - iteration 154, current learner lgbm\n",
      "[flaml.automl: 09-21 00:24:02] {1914} INFO -  at 326.9s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:24:02] {1735} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 09-21 00:24:03] {1914} INFO -  at 327.8s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:24:03] {1735} INFO - iteration 156, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:24:03] {1914} INFO -  at 328.4s,\tbest extra_tree's error=0.2603,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:24:03] {1735} INFO - iteration 157, current learner catboost\n",
      "[flaml.automl: 09-21 00:24:25] {1914} INFO -  at 349.7s,\tbest catboost's error=0.1801,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:24:25] {1735} INFO - iteration 158, current learner lgbm\n",
      "[flaml.automl: 09-21 00:24:25] {1914} INFO -  at 350.5s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:24:25] {1735} INFO - iteration 159, current learner rf\n",
      "[flaml.automl: 09-21 00:24:29] {1914} INFO -  at 354.2s,\tbest rf's error=0.2596,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:24:29] {1735} INFO - iteration 160, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:24:29] {1914} INFO -  at 354.6s,\tbest extra_tree's error=0.2603,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:24:29] {1735} INFO - iteration 161, current learner lgbm\n",
      "[flaml.automl: 09-21 00:24:31] {1914} INFO -  at 356.2s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:24:31] {1735} INFO - iteration 162, current learner xgboost\n",
      "[flaml.automl: 09-21 00:25:18] {1914} INFO -  at 402.8s,\tbest xgboost's error=0.2428,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:18] {1735} INFO - iteration 163, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:25:18] {1914} INFO -  at 403.1s,\tbest extra_tree's error=0.2603,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:18] {1735} INFO - iteration 164, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:25:19] {1914} INFO -  at 403.8s,\tbest extra_tree's error=0.2603,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:19] {1735} INFO - iteration 165, current learner rf\n",
      "[flaml.automl: 09-21 00:25:21] {1914} INFO -  at 406.0s,\tbest rf's error=0.2596,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:21] {1735} INFO - iteration 166, current learner catboost\n",
      "[flaml.automl: 09-21 00:25:35] {1914} INFO -  at 420.0s,\tbest catboost's error=0.1801,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:35] {1735} INFO - iteration 167, current learner xgboost\n",
      "[flaml.automl: 09-21 00:25:53] {1914} INFO -  at 437.9s,\tbest xgboost's error=0.2395,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:53] {1735} INFO - iteration 168, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:25:53] {1914} INFO -  at 438.3s,\tbest extra_tree's error=0.2603,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:53] {1735} INFO - iteration 169, current learner lgbm\n",
      "[flaml.automl: 09-21 00:25:54] {1914} INFO -  at 439.0s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:54] {1735} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl: 09-21 00:25:55] {1914} INFO -  at 440.1s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:55] {1735} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 09-21 00:25:56] {1914} INFO -  at 440.8s,\tbest lgbm's error=0.2694,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:25:56] {1735} INFO - iteration 172, current learner catboost\n",
      "[flaml.automl: 09-21 00:26:18] {1914} INFO -  at 463.5s,\tbest catboost's error=0.1801,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:26:18] {1735} INFO - iteration 173, current learner xgboost\n",
      "[flaml.automl: 09-21 00:26:50] {1914} INFO -  at 495.5s,\tbest xgboost's error=0.2385,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:26:50] {1735} INFO - iteration 174, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:26:51] {1914} INFO -  at 496.1s,\tbest extra_tree's error=0.2603,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:26:51] {1735} INFO - iteration 175, current learner rf\n",
      "[flaml.automl: 09-21 00:26:54] {1914} INFO -  at 499.3s,\tbest rf's error=0.2596,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:26:54] {1735} INFO - iteration 176, current learner extra_tree\n",
      "[flaml.automl: 09-21 00:26:54] {1914} INFO -  at 499.6s,\tbest extra_tree's error=0.2603,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:26:54] {1735} INFO - iteration 177, current learner lrl1\n",
      "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'.\n",
      "C:\\Users\\peter\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[flaml.automl: 09-21 00:26:57] {1914} INFO -  at 502.2s,\tbest lrl1's error=0.3888,\tbest catboost's error=0.1801\n",
      "[flaml.automl: 09-21 00:26:57] {2021} INFO - selected model: <catboost.core.CatBoostClassifier object at 0x00000217FDE9CC10>\n",
      "[flaml.automl: 09-21 00:26:57] {2037} INFO - [('catboost', <flaml.model.CatBoostEstimator object at 0x00000218171871C0>), ('xgboost', <flaml.model.XGBoostSklearnEstimator object at 0x00000217FDE4DDC0>), ('rf', <flaml.model.RandomForestEstimator object at 0x0000021817187640>), ('extra_tree', <flaml.model.ExtraTreeEstimator object at 0x00000217FDE9CEB0>), ('lgbm', <flaml.model.LGBMEstimator object at 0x00000218171870A0>), ('lrl1', <flaml.model.LRL1Classifier object at 0x0000021825079820>)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "automl_raw.best_estimator()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "# print('indata flm',  len(banor+['datum']+könen+ekipage+all_nums))\r\n",
    "\r\n",
    "if no_streck:\r\n",
    "    print(\"utan 'streck'\")\r\n",
    "   \r\n",
    "if True :   # raw - ej transformed data\r\n",
    "    # print('indata flm_raw',len(X_train.columns))\r\n",
    "    flm_raw_train_pred= automl_raw.predict_proba(X_train)\r\n",
    "    flm_raw_test_pred = automl_raw.predict_proba(X_test)\r\n",
    "    print('flm_raw test',roc_auc_score(y_test, flm_raw_test_pred[:,1]))\r\n",
    "    print('flm_raw train',roc_auc_score(y_train, flm_raw_train_pred[:,1]))  \r\n",
    "    print('mae', mean_absolute_error(y_test,cb_test_pred[:,1]))\r\n",
    "    po=proba_ordning(X_test.copy(),y_test,df.copy(),flm_raw_test_pred )[['datum','avd','proba','prob_order','vann']]\r\n",
    "    print('flm_raw mean vann',po.loc[po.vann==1].prob_order.mean())\r\n",
    "if True:  # med transformde data\r\n",
    "    flm_train_pred= flm_pipe.predict_proba(X_train)\r\n",
    "    flm_test_pred = flm_pipe.predict_proba(X_test)\r\n",
    "    print('flm test',roc_auc_score(y_test, flm_test_pred[:,1]))\r\n",
    "    print('flm train',roc_auc_score(y_train, flm_train_pred[:,1]))\r\n",
    "    po=proba_ordning(X_test.copy(),y_test,df.copy(),flm_test_pred )[['datum','avd','proba','prob_order','vann']]\r\n",
    "    print('flm test mean vann',po.loc[po.vann==1].prob_order.mean())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "utan 'streck'\n",
      "flm_raw test 0.726974642131447\n",
      "flm_raw train 0.8327028954305613\n",
      "mae 0.12954190828951184\n",
      "flm_raw mean vann 3.736080178173719\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### End Min första Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "source": [
    "# # senaste veckan\r\n",
    "df_nu = pd.read_csv('..//sparad_scrape.csv')\r\n",
    "print(df_nu.datum.unique())\r\n",
    "\r\n",
    "df_nu,ekipage = create_ekipage(df_nu.copy())      # alla ekipage, h1_ekipage-h5_ekipage\r\n",
    "\r\n",
    "X_train_nu = remove_features(df_nu.copy())\r\n",
    "\r\n",
    "# X_test_nu = X_test.loc[X_test.datum=='2021-09-11']\r\n",
    "# y_test_nu=y_test[X_test_nu.index]\r\n",
    "# X_test_nu.shape\r\n",
    "\r\n",
    "flm_raw_train_pred=automl_raw.predict_proba(X_train_nu)\r\n",
    "# flm_raw_test_pred=automl_raw.predict_proba(X_test_nu)\r\n",
    "# print(roc_auc_score(y_test_nu,flm_raw_test_pred[:,1]))\r\n",
    "res = pd.DataFrame()\r\n",
    "# res['y']=y_test_nu\r\n",
    "res['proba']=flm_raw_train_pred[:,1]\r\n",
    "res['avd'] = df_nu.avd\r\n",
    "res['vodds']=df_nu.vodds\r\n",
    "res['datum']=df_nu.datum\r\n",
    "res['startnr']=df_nu.startnr\r\n",
    "res['ekipage']=df_nu.ekipage\r\n",
    "# display(f'mean for test==1 {res.loc[res.y==1].yhat}')\r\n",
    "\r\n",
    "res['f'] = (res.proba*res.vodds - 1) / (res.vodds-1)  # kelly formel\r\n",
    "res['spela'] = res.f >0\r\n",
    "res['insats'] = res.spela * res.f * 200\r\n",
    "\r\n",
    "# Ta ut de 2 bästa per avd\r\n",
    "res.sort_values(['datum','avd','proba'],ascending=[True,True,False],inplace=True)\r\n",
    "proba_order=res.groupby(['datum','avd']).proba.cumcount()\r\n",
    "\r\n",
    "res['prob_order']=proba_order+1\r\n",
    "\r\n",
    "# res.loc[(res.prob_order<5) & (res.prob_order !=0)].sort_values(by='proba',ascending=False)\r\n",
    "res.loc[res.prob_order<8]\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['2021-09-18']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "      <th>avd</th>\n",
       "      <th>vodds</th>\n",
       "      <th>datum</th>\n",
       "      <th>startnr</th>\n",
       "      <th>ekipage</th>\n",
       "      <th>f</th>\n",
       "      <th>spela</th>\n",
       "      <th>insats</th>\n",
       "      <th>prob_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.298143</td>\n",
       "      <td>1</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>1</td>\n",
       "      <td>Carl Johan Jepson, BEARTIME</td>\n",
       "      <td>0.050137</td>\n",
       "      <td>True</td>\n",
       "      <td>10.027442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223853</td>\n",
       "      <td>1</td>\n",
       "      <td>6.01</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>2</td>\n",
       "      <td>Conrad Lugauer, SANDSJÖNS ENZO</td>\n",
       "      <td>0.068933</td>\n",
       "      <td>True</td>\n",
       "      <td>13.786591</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.175190</td>\n",
       "      <td>1</td>\n",
       "      <td>6.31</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>7</td>\n",
       "      <td>Jorma Kontio, MAS CAPACITY</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>True</td>\n",
       "      <td>3.971789</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.132337</td>\n",
       "      <td>1</td>\n",
       "      <td>9.49</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>4</td>\n",
       "      <td>Erik Adielsson, ÖNAS NOUGAT</td>\n",
       "      <td>0.030139</td>\n",
       "      <td>True</td>\n",
       "      <td>6.027786</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131445</td>\n",
       "      <td>1</td>\n",
       "      <td>5.88</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>5</td>\n",
       "      <td>Kim Eriksson, BO C.</td>\n",
       "      <td>-0.046538</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.065016</td>\n",
       "      <td>1</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>Sören Boel, ADDE S.H.</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>True</td>\n",
       "      <td>2.568053</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.055523</td>\n",
       "      <td>1</td>\n",
       "      <td>17.01</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>3</td>\n",
       "      <td>Christoffer Eriksson, INGO</td>\n",
       "      <td>-0.003470</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.422429</td>\n",
       "      <td>2</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>2</td>\n",
       "      <td>Conrad Lugauer, MISTER K.O.Z.</td>\n",
       "      <td>0.179752</td>\n",
       "      <td>True</td>\n",
       "      <td>35.950380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.175806</td>\n",
       "      <td>2</td>\n",
       "      <td>6.09</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>Mikael J Andersson, BLUE FRONTLINE</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>True</td>\n",
       "      <td>2.776432</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.102996</td>\n",
       "      <td>2</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>7</td>\n",
       "      <td>Torbjörn Jansson, PERFECT SCORE ÅS</td>\n",
       "      <td>-0.204198</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.078217</td>\n",
       "      <td>2</td>\n",
       "      <td>16.09</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>5</td>\n",
       "      <td>Magnus A Djuse, EMPEROR</td>\n",
       "      <td>0.017131</td>\n",
       "      <td>True</td>\n",
       "      <td>3.426259</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.051140</td>\n",
       "      <td>2</td>\n",
       "      <td>9.98</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>1</td>\n",
       "      <td>Tomas Pettersson, SARA K.M.E.</td>\n",
       "      <td>-0.054524</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.049399</td>\n",
       "      <td>2</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>4</td>\n",
       "      <td>Örjan Kihlström, HABRIK AM</td>\n",
       "      <td>-0.022074</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.044373</td>\n",
       "      <td>2</td>\n",
       "      <td>25.09</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>12</td>\n",
       "      <td>Jorma Kontio, KENZOKI BOKO</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>True</td>\n",
       "      <td>0.940764</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.278910</td>\n",
       "      <td>3</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>4</td>\n",
       "      <td>Örjan Kihlström, MISSLE HILL</td>\n",
       "      <td>0.040927</td>\n",
       "      <td>True</td>\n",
       "      <td>8.185302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.254766</td>\n",
       "      <td>3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>Magnus A Djuse, GARETH BOKO</td>\n",
       "      <td>-0.043328</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.195499</td>\n",
       "      <td>3</td>\n",
       "      <td>6.70</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>1</td>\n",
       "      <td>Ulf Ohlsson, DISCO VOLANTE</td>\n",
       "      <td>0.054358</td>\n",
       "      <td>True</td>\n",
       "      <td>10.871599</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.172251</td>\n",
       "      <td>3</td>\n",
       "      <td>7.72</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>9</td>\n",
       "      <td>Björn Goop, MELLBY FREE</td>\n",
       "      <td>0.049074</td>\n",
       "      <td>True</td>\n",
       "      <td>9.814772</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.159067</td>\n",
       "      <td>3</td>\n",
       "      <td>4.86</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>3</td>\n",
       "      <td>Erik Adielsson, ANTONIO TROT</td>\n",
       "      <td>-0.058791</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.026492</td>\n",
       "      <td>3</td>\n",
       "      <td>14.91</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>7</td>\n",
       "      <td>Torbjörn Jansson, FORFANTONE AM</td>\n",
       "      <td>-0.043494</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.026150</td>\n",
       "      <td>3</td>\n",
       "      <td>45.84</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>5</td>\n",
       "      <td>Jorma Kontio, URAL</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>True</td>\n",
       "      <td>0.886370</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.275590</td>\n",
       "      <td>4</td>\n",
       "      <td>5.45</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>Magnus A Djuse, MYSTIC MOM</td>\n",
       "      <td>0.112802</td>\n",
       "      <td>True</td>\n",
       "      <td>22.560327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.245250</td>\n",
       "      <td>4</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>4</td>\n",
       "      <td>Robert Bergh, CRAZY FIRST LOVE</td>\n",
       "      <td>-0.085781</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.122364</td>\n",
       "      <td>4</td>\n",
       "      <td>19.75</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>12</td>\n",
       "      <td>Erik Adielsson, DREAM BUILDER</td>\n",
       "      <td>0.075557</td>\n",
       "      <td>True</td>\n",
       "      <td>15.111305</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.109638</td>\n",
       "      <td>4</td>\n",
       "      <td>8.59</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>13</td>\n",
       "      <td>Ulf Ohlsson, DIGITAL CLASS</td>\n",
       "      <td>-0.007669</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.067630</td>\n",
       "      <td>4</td>\n",
       "      <td>19.31</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>5</td>\n",
       "      <td>Conrad Lugauer, ORNELLO</td>\n",
       "      <td>0.016708</td>\n",
       "      <td>True</td>\n",
       "      <td>3.341679</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.059546</td>\n",
       "      <td>4</td>\n",
       "      <td>22.10</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>3</td>\n",
       "      <td>Örjan Kihlström, BORN WINNER</td>\n",
       "      <td>0.014974</td>\n",
       "      <td>True</td>\n",
       "      <td>2.994842</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.054319</td>\n",
       "      <td>4</td>\n",
       "      <td>18.35</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>10</td>\n",
       "      <td>Carl Johan Jepson, KENNEDY</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.516503</td>\n",
       "      <td>5</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>2</td>\n",
       "      <td>Örjan Kihlström, BUGATTI MILES</td>\n",
       "      <td>0.166142</td>\n",
       "      <td>True</td>\n",
       "      <td>33.228471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.094601</td>\n",
       "      <td>5</td>\n",
       "      <td>4.54</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>5</td>\n",
       "      <td>Christoffer Eriksson, LOVEEXPLOSION H.C.</td>\n",
       "      <td>-0.161161</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.089336</td>\n",
       "      <td>5</td>\n",
       "      <td>14.62</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>9</td>\n",
       "      <td>Magnus A Djuse, TATTOO AVENGER</td>\n",
       "      <td>0.022474</td>\n",
       "      <td>True</td>\n",
       "      <td>4.494846</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.063541</td>\n",
       "      <td>5</td>\n",
       "      <td>10.74</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>10</td>\n",
       "      <td>Anders Eriksson, GAYLORD AM</td>\n",
       "      <td>-0.032605</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.037306</td>\n",
       "      <td>5</td>\n",
       "      <td>15.24</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>4</td>\n",
       "      <td>Janne Korpi, MANDELA ZON</td>\n",
       "      <td>-0.030299</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.034584</td>\n",
       "      <td>5</td>\n",
       "      <td>17.51</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>1</td>\n",
       "      <td>Carl Johan Jepson, ZENATO</td>\n",
       "      <td>-0.023891</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.032004</td>\n",
       "      <td>5</td>\n",
       "      <td>12.45</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>Stefan Persson, FOREVER SHADOW</td>\n",
       "      <td>-0.052537</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.357369</td>\n",
       "      <td>6</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>5</td>\n",
       "      <td>Erik Adielsson, TANGEN HAAP</td>\n",
       "      <td>-0.014094</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.265167</td>\n",
       "      <td>6</td>\n",
       "      <td>5.45</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>3</td>\n",
       "      <td>Örjan Kihlström, ÅSRUD VILJA</td>\n",
       "      <td>0.100036</td>\n",
       "      <td>True</td>\n",
       "      <td>20.007168</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.132499</td>\n",
       "      <td>6</td>\n",
       "      <td>9.36</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>2</td>\n",
       "      <td>Kjetil Djöseland, KLEPPE FANDEN</td>\n",
       "      <td>0.028730</td>\n",
       "      <td>True</td>\n",
       "      <td>5.746079</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.110668</td>\n",
       "      <td>6</td>\n",
       "      <td>7.76</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>Björn Goop, VÅLER NIKOLAI</td>\n",
       "      <td>-0.020890</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.102283</td>\n",
       "      <td>6</td>\n",
       "      <td>5.03</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>4</td>\n",
       "      <td>Pål Buer, SÖNDRE JERKELD</td>\n",
       "      <td>-0.120476</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.031961</td>\n",
       "      <td>6</td>\n",
       "      <td>14.98</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>7</td>\n",
       "      <td>Magnus Teien Gundersen, TROLL SOLEN</td>\n",
       "      <td>-0.037284</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.024067</td>\n",
       "      <td>6</td>\n",
       "      <td>34.65</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>10</td>\n",
       "      <td>Mikael J Andersson, EMIL MOLLYN</td>\n",
       "      <td>-0.004935</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.456575</td>\n",
       "      <td>7</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>2</td>\n",
       "      <td>Kristian Malmin, ORACLE TILE</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>True</td>\n",
       "      <td>29.562010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.194303</td>\n",
       "      <td>7</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>7</td>\n",
       "      <td>Örjan Kihlström, DEAL DONE ZET</td>\n",
       "      <td>0.091272</td>\n",
       "      <td>True</td>\n",
       "      <td>18.254445</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.109076</td>\n",
       "      <td>7</td>\n",
       "      <td>8.72</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>1</td>\n",
       "      <td>Björn Goop, MISTER DONALD</td>\n",
       "      <td>-0.006328</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.104159</td>\n",
       "      <td>7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>Mika Forss, GOGOBET SISU</td>\n",
       "      <td>0.031030</td>\n",
       "      <td>True</td>\n",
       "      <td>6.205906</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.095020</td>\n",
       "      <td>7</td>\n",
       "      <td>6.89</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>10</td>\n",
       "      <td>Stefan Persson, FOUR GUYS DREAM</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.050993</td>\n",
       "      <td>7</td>\n",
       "      <td>7.37</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>8</td>\n",
       "      <td>Robert Bergh, REDDINGTON</td>\n",
       "      <td>-0.097987</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.030938</td>\n",
       "      <td>7</td>\n",
       "      <td>21.99</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>5</td>\n",
       "      <td>Ulf Ohlsson, VIEN ICI</td>\n",
       "      <td>-0.015230</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       proba  avd  vodds       datum  startnr  \\\n",
       "0   0.298143    1   3.83  2021-09-18        1   \n",
       "2   0.223853    1   6.01  2021-09-18        2   \n",
       "1   0.175190    1   6.31  2021-09-18        7   \n",
       "4   0.132337    1   9.49  2021-09-18        4   \n",
       "3   0.131445    1   5.88  2021-09-18        5   \n",
       "5   0.065016    1  18.92  2021-09-18        6   \n",
       "6   0.055523    1  17.01  2021-09-18        3   \n",
       "11  0.422429    2   3.38  2021-09-18        2   \n",
       "12  0.175806    2   6.09  2021-09-18        6   \n",
       "13  0.102996    2   3.92  2021-09-18        7   \n",
       "14  0.078217    2  16.09  2021-09-18        5   \n",
       "16  0.051140    2   9.98  2021-09-18        1   \n",
       "17  0.049399    2  14.30  2021-09-18        4   \n",
       "15  0.044373    2  25.09  2021-09-18       12   \n",
       "23  0.278910    3   4.03  2021-09-18        4   \n",
       "24  0.254766    3   3.50  2021-09-18        6   \n",
       "25  0.195499    3   6.70  2021-09-18        1   \n",
       "27  0.172251    3   7.72  2021-09-18        9   \n",
       "26  0.159067    3   4.86  2021-09-18        3   \n",
       "28  0.026492    3  14.91  2021-09-18        7   \n",
       "29  0.026150    3  45.84  2021-09-18        5   \n",
       "33  0.275590    4   5.45  2021-09-18        6   \n",
       "34  0.245250    4   3.28  2021-09-18        4   \n",
       "36  0.122364    4  19.75  2021-09-18       12   \n",
       "35  0.109638    4   8.59  2021-09-18       13   \n",
       "38  0.067630    4  19.31  2021-09-18        5   \n",
       "39  0.059546    4  22.10  2021-09-18        3   \n",
       "37  0.054319    4  18.35  2021-09-18       10   \n",
       "46  0.516503    5   2.38  2021-09-18        2   \n",
       "47  0.094601    5   4.54  2021-09-18        5   \n",
       "48  0.089336    5  14.62  2021-09-18        9   \n",
       "49  0.063541    5  10.74  2021-09-18       10   \n",
       "50  0.037306    5  15.24  2021-09-18        4   \n",
       "52  0.034584    5  17.51  2021-09-18        1   \n",
       "51  0.032004    5  12.45  2021-09-18        6   \n",
       "58  0.357369    6   2.73  2021-09-18        5   \n",
       "59  0.265167    6   5.45  2021-09-18        3   \n",
       "60  0.132499    6   9.36  2021-09-18        2   \n",
       "62  0.110668    6   7.76  2021-09-18        6   \n",
       "61  0.102283    6   5.03  2021-09-18        4   \n",
       "63  0.031961    6  14.98  2021-09-18        7   \n",
       "66  0.024067    6  34.65  2021-09-18       10   \n",
       "67  0.456575    7   2.76  2021-09-18        2   \n",
       "68  0.194303    7   8.82  2021-09-18        7   \n",
       "69  0.109076    7   8.72  2021-09-18        1   \n",
       "71  0.104159    7  13.25  2021-09-18        6   \n",
       "70  0.095020    7   6.89  2021-09-18       10   \n",
       "72  0.050993    7   7.37  2021-09-18        8   \n",
       "73  0.030938    7  21.99  2021-09-18        5   \n",
       "\n",
       "                                     ekipage         f  spela     insats  \\\n",
       "0                Carl Johan Jepson, BEARTIME  0.050137   True  10.027442   \n",
       "2             Conrad Lugauer, SANDSJÖNS ENZO  0.068933   True  13.786591   \n",
       "1                 Jorma Kontio, MAS CAPACITY  0.019859   True   3.971789   \n",
       "4                Erik Adielsson, ÖNAS NOUGAT  0.030139   True   6.027786   \n",
       "3                        Kim Eriksson, BO C. -0.046538  False  -0.000000   \n",
       "5                      Sören Boel, ADDE S.H.  0.012840   True   2.568053   \n",
       "6                 Christoffer Eriksson, INGO -0.003470  False  -0.000000   \n",
       "11             Conrad Lugauer, MISTER K.O.Z.  0.179752   True  35.950380   \n",
       "12        Mikael J Andersson, BLUE FRONTLINE  0.013882   True   2.776432   \n",
       "13        Torbjörn Jansson, PERFECT SCORE ÅS -0.204198  False  -0.000000   \n",
       "14                   Magnus A Djuse, EMPEROR  0.017131   True   3.426259   \n",
       "16             Tomas Pettersson, SARA K.M.E. -0.054524  False  -0.000000   \n",
       "17                Örjan Kihlström, HABRIK AM -0.022074  False  -0.000000   \n",
       "15                Jorma Kontio, KENZOKI BOKO  0.004704   True   0.940764   \n",
       "23              Örjan Kihlström, MISSLE HILL  0.040927   True   8.185302   \n",
       "24               Magnus A Djuse, GARETH BOKO -0.043328  False  -0.000000   \n",
       "25                Ulf Ohlsson, DISCO VOLANTE  0.054358   True  10.871599   \n",
       "27                   Björn Goop, MELLBY FREE  0.049074   True   9.814772   \n",
       "26              Erik Adielsson, ANTONIO TROT -0.058791  False  -0.000000   \n",
       "28           Torbjörn Jansson, FORFANTONE AM -0.043494  False  -0.000000   \n",
       "29                        Jorma Kontio, URAL  0.004432   True   0.886370   \n",
       "33                Magnus A Djuse, MYSTIC MOM  0.112802   True  22.560327   \n",
       "34            Robert Bergh, CRAZY FIRST LOVE -0.085781  False  -0.000000   \n",
       "36             Erik Adielsson, DREAM BUILDER  0.075557   True  15.111305   \n",
       "35                Ulf Ohlsson, DIGITAL CLASS -0.007669  False  -0.000000   \n",
       "38                   Conrad Lugauer, ORNELLO  0.016708   True   3.341679   \n",
       "39              Örjan Kihlström, BORN WINNER  0.014974   True   2.994842   \n",
       "37                Carl Johan Jepson, KENNEDY -0.000187  False  -0.000000   \n",
       "46            Örjan Kihlström, BUGATTI MILES  0.166142   True  33.228471   \n",
       "47  Christoffer Eriksson, LOVEEXPLOSION H.C. -0.161161  False  -0.000000   \n",
       "48            Magnus A Djuse, TATTOO AVENGER  0.022474   True   4.494846   \n",
       "49               Anders Eriksson, GAYLORD AM -0.032605  False  -0.000000   \n",
       "50                  Janne Korpi, MANDELA ZON -0.030299  False  -0.000000   \n",
       "52                 Carl Johan Jepson, ZENATO -0.023891  False  -0.000000   \n",
       "51            Stefan Persson, FOREVER SHADOW -0.052537  False  -0.000000   \n",
       "58               Erik Adielsson, TANGEN HAAP -0.014094  False  -0.000000   \n",
       "59              Örjan Kihlström, ÅSRUD VILJA  0.100036   True  20.007168   \n",
       "60           Kjetil Djöseland, KLEPPE FANDEN  0.028730   True   5.746079   \n",
       "62                 Björn Goop, VÅLER NIKOLAI -0.020890  False  -0.000000   \n",
       "61                  Pål Buer, SÖNDRE JERKELD -0.120476  False  -0.000000   \n",
       "63       Magnus Teien Gundersen, TROLL SOLEN -0.037284  False  -0.000000   \n",
       "66           Mikael J Andersson, EMIL MOLLYN -0.004935  False  -0.000000   \n",
       "67              Kristian Malmin, ORACLE TILE  0.147810   True  29.562010   \n",
       "68            Örjan Kihlström, DEAL DONE ZET  0.091272   True  18.254445   \n",
       "69                 Björn Goop, MISTER DONALD -0.006328  False  -0.000000   \n",
       "71                  Mika Forss, GOGOBET SISU  0.031030   True   6.205906   \n",
       "70           Stefan Persson, FOUR GUYS DREAM -0.058627  False  -0.000000   \n",
       "72                  Robert Bergh, REDDINGTON -0.097987  False  -0.000000   \n",
       "73                     Ulf Ohlsson, VIEN ICI -0.015230  False  -0.000000   \n",
       "\n",
       "    prob_order  \n",
       "0            1  \n",
       "2            2  \n",
       "1            3  \n",
       "4            4  \n",
       "3            5  \n",
       "5            6  \n",
       "6            7  \n",
       "11           1  \n",
       "12           2  \n",
       "13           3  \n",
       "14           4  \n",
       "16           5  \n",
       "17           6  \n",
       "15           7  \n",
       "23           1  \n",
       "24           2  \n",
       "25           3  \n",
       "27           4  \n",
       "26           5  \n",
       "28           6  \n",
       "29           7  \n",
       "33           1  \n",
       "34           2  \n",
       "36           3  \n",
       "35           4  \n",
       "38           5  \n",
       "39           6  \n",
       "37           7  \n",
       "46           1  \n",
       "47           2  \n",
       "48           3  \n",
       "49           4  \n",
       "50           5  \n",
       "52           6  \n",
       "51           7  \n",
       "58           1  \n",
       "59           2  \n",
       "60           3  \n",
       "62           4  \n",
       "61           5  \n",
       "63           6  \n",
       "66           7  \n",
       "67           1  \n",
       "68           2  \n",
       "69           3  \n",
       "71           4  \n",
       "70           5  \n",
       "72           6  \n",
       "73           7  "
      ]
     },
     "metadata": {},
     "execution_count": 227
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df,alla_datum,split_ix = load_data() \r\n",
    "df = remove_features(df.copy())\r\n",
    "CAT_FEATURES=['datum', 'bana', 'häst', 'kusk', 'kön',\r\n",
    "        'h1_kusk', 'h1_bana',\r\n",
    "        'h2_kusk', 'h2_bana', \r\n",
    "        'h3_kusk',  'h3_bana', \r\n",
    "        'h4_kusk', 'h4_bana', \r\n",
    "        'h5_kusk', 'h5_bana',]\r\n",
    "\r\n",
    "NUM_FEATURES=[item for item in df.columns if item not in CAT_FEATURES and item !='plac']\r\n",
    "\r\n",
    "PLAC_MEAN=df.plac.mean()\r\n",
    "PLAC_MEAN"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# den hittade inget, kanske skall testa igen längre fram\r\n",
    "def remove_low_variance_features(df):\r\n",
    "    from sklearn.feature_selection import VarianceThreshold\r\n",
    "    print(df.shape)\r\n",
    "    selection = VarianceThreshold(threshold=(0.1))\r\n",
    "    X=selection.fit_transform(df)\r\n",
    "    print(X.shape)\r\n",
    "    return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Min manuella stacking (TimeSeries)\r\n",
    "TimeSeries kan iinte använda sklearn.stacking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions that are doing the transformations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# för ´categorical\r\n",
    "def impute_test(df):\r\n",
    "    imp1 = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value='missing')\r\n",
    "    df=imp1.fit_transform(df)  # replae NaN's with 'missing'\r\n",
    "    return df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fill missing values in categorical features\r\n",
    "def impute_cat_features(df, cat_features=CAT_FEATURES):\r\n",
    "    imp1 = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value='missing')\r\n",
    "    df[cat_features]=imp1.fit_transform(df[cat_features])  # replae NaN's with 'missing'\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Handle h1-h5_bana\r\n",
    "def transform_hx_bana(df,hx,the_map):\r\n",
    "    from sklearn.impute import SimpleImputer\r\n",
    "    df[hx] = df[hx].str.lower()\r\n",
    "    imp1 = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value='missing')\r\n",
    "    df[hx]=imp1.fit_transform(df[[hx]])  # replae NaN's with 'missing'\r\n",
    "\r\n",
    "    df[hx] = [item[0] for item in df[hx].str.split('-')]  # remove '-10' from 'solvalla-10' etc\r\n",
    "    \r\n",
    "    df[hx]=df[hx].map(the_map)  # transform column to numeric by mapping\r\n",
    "    # after mapping we get new NaN's - now impute 0\r\n",
    "    imp2 = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=0)\r\n",
    "    df[hx] = imp2.fit_transform(df[[hx]])\r\n",
    "    return df\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# Handle bana and hx_bana  \r\n",
    "def transf_bana(df):\r\n",
    "    df['bana'] = df.bana.str.lower()\r\n",
    "    the_map = df.bana.value_counts() \r\n",
    "    the_map['missing']=0    \r\n",
    "\r\n",
    "    df=transform_hx_bana(df,'h1_bana',the_map)\r\n",
    "    df=transform_hx_bana(df,'h2_bana',the_map)\r\n",
    "    df=transform_hx_bana(df,'h3_bana',the_map)\r\n",
    "    df=transform_hx_bana(df,'h4_bana',the_map)\r\n",
    "    df=transform_hx_bana(df,'h5_bana',the_map)\r\n",
    "\r\n",
    "    df['bana']=df.bana.map(the_map)  # transform column to numeric by mapping \r\n",
    "    if df[['h1_bana','h2_bana','h3_bana','h4_bana','h5_bana',]].isna().sum().sum() != 0:\r\n",
    "        print('bana NaNs not 0:',df[['h1_bana','h2_bana','h3_bana','h4_bana','h5_bana',]].isna().sum())\r\n",
    "    \r\n",
    "    df.drop(['bana','h1_bana','h2_bana','h3_bana','h4_bana','h5_bana'],axis=1,inplace=True)\r\n",
    "    return df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# SKIPPA DENNA\r\n",
    "def transf_kusk_häst(df,pref='',m=50,):\r\n",
    "    df[pref+'ekipage'] = df[pref+'kusk'].str.cat(df['häst'], sep =\", \")  # concatenate 'häst' and 'kusk' into one column\r\n",
    "    df[pref+'ekipage'] = calc_smooth_mean(df, y, by=pref+'ekipage',m=50) # make numeric with Target encoding with smooth mean\r\n",
    "    df.drop([pref+'kusk'],axis=1,inplace=True)\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(list(df.select_dtypes('object').columns))\r\n",
    "print()\r\n",
    "print(list(df.select_dtypes('number').columns))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Handle kön  \r\n",
    "def transf_kön(df):\r\n",
    "    from sklearn.preprocessing import OneHotEncoder\r\n",
    "    df['kön'] = df['kön'].str.lower()\r\n",
    "    ohe = OneHotEncoder(sparse=False)\r\n",
    "    dftemp=pd.DataFrame(ohe.fit_transform(df[['kön']]),columns=['kön_h','kön_s','kön_v'] )  # replae kön with One Hot Encoding\r\n",
    "    # df=pd.concat([df,dftemp],axis=1)\r\n",
    "\r\n",
    "    # check that kön is correct encoded\r\n",
    "    if len(df.loc[(df.kön=='h') & (df.kön_h != 1),'kön']):\r\n",
    "        assert False, 'Felaktigt kön h'\r\n",
    "    if len(df.loc[(df.kön=='s') & (df.kön_s != 1),'kön']):\r\n",
    "       assert False, 'Felaktigt kön s'\r\n",
    "    if len(df.loc[(df.kön=='v') & (df.kön_v != 1),'kön']):\r\n",
    "        assert False, 'Felaktigt kön v'\r\n",
    "    df.drop(['kön'],axis=1,inplace=True)\r\n",
    "    return df\r\n",
    "# s_c = FunctionTransformer(set_cols)\r\n",
    "from sklearn.compose import ColumnTransformer,make_column_transformer\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "\r\n",
    "# union = FeatureUnion([('o',df.select_dtypes('object')), \r\n",
    "#                      ('n',df.select_dtypes('object')), \r\n",
    "#                       ]\r\n",
    "#                       )\r\n",
    "\r\n",
    "pipe=make_pipeline(SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=-1))\r\n",
    "\r\n",
    "mapper = DataFrameMapper([\r\n",
    "    (['datum'], None),\r\n",
    "    (['bana'], [lower,\r\n",
    "                SimpleImputer(missing_values=np.nan, strategy='constant',fill_value='missing'), ]),\r\n",
    "    (['h1_bana','h2_bana','h3_bana','h4_bana','h5_bana'], [lower,\r\n",
    "                SimpleImputer(missing_values=np.nan, strategy='constant',fill_value='missing'), ],{'alias':'hx_bana'}),\r\n",
    "    (['kön'], OneHotEncoder(sparse=False),{'alias':'kön'}),\r\n",
    "    \r\n",
    "    (['kusk','h1_kusk','häst','plac'], lower, CustomSmoothMean(cols=['kusk','h1_kusk'],col2='häst',y='plac')),\r\n",
    "    (['h1_kusk','häst'], lower,{'alias':'h1ekipage'}),\r\n",
    "    (['h2_kusk','häst'], lower,{'alias':'h2ekipage'}),\r\n",
    "    (['h3_kusk','häst'], lower,{'alias':'h3ekipage'}),\r\n",
    "    (['h4_kusk','häst'], lower,{'alias':'h4ekipage'}),\r\n",
    "    (['h5_kusk','häst'], lower,{'alias':'h5ekipage'}),\r\n",
    "    \r\n",
    "],df_out=True,input_df=True)\r\n",
    "pipe2=Pipeline([('the_mapper',mapper), ('the_pipe',pipe)])\r\n",
    "display(CustomSmoothMean(['kusk','h1_kusk'],['häst'],y='plac').fit(df).transform(df))\r\n",
    "\r\n",
    "# svar1f = CustomSmoothMean.fit(df)\r\n",
    "# svar1=mapper.fit_transform(df)\r\n",
    "svar2=pipe.fit_transform(df.select_dtypes(include='number'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# test_pipe=make_pipeline(CustomSmoothMean(col1='kusk',col2='häst',y='plac'))\r\n",
    "def date_to_num(df):\r\n",
    "    return pd.DataFrame(pd.to_datetime(df.datum).view(float)*10e210)\r\n",
    "\r\n",
    "tranf_datum = FunctionTransformer(date_to_num)\r\n",
    "    \r\n",
    "preprocessor = make_column_transformer(\r\n",
    "                                    \r\n",
    "                                    (CustomSmoothMean(cols=['kusk','h1_kusk'],col2='häst',y='plac',m=30), ['kusk','h1_kusk','häst','plac']),\r\n",
    "                                    (tranf_datum, ['datum']),\r\n",
    "                                    (OneHotEncoder(), ['kön']), \r\n",
    "                                     remainder='drop')\r\n",
    "\r\n",
    "# test_pipe.fit_transform(df.copy())\r\n",
    "display(preprocessor.fit_transform(df.copy()))\r\n",
    "\r\n",
    "# type((pd.to_datetime(df.datum).view(float)*10e210).values)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## test test\r\n",
    "# Partition data\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['plac']), \r\n",
    "                                                    df['plac'], \r\n",
    "                                                    test_size=.2, \r\n",
    "                                                    random_state=2021)\r\n",
    "\r\n",
    "# Define categorical columns\r\n",
    "categorical = list(X_train.select_dtypes('object').columns)\r\n",
    "print(f\"Categorical columns are: {categorical}\")\r\n",
    "\r\n",
    "# Define numerical columns\r\n",
    "numerical = list(X_train.select_dtypes('number').columns)\r\n",
    "print(f\"Numerical columns are: {numerical}\")# Define categorical pipeline\r\n",
    "cat_pipe = Pipeline([\r\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\r\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\r\n",
    "])\r\n",
    "\r\n",
    "# Define numerical pipeline\r\n",
    "num_pipe = Pipeline([\r\n",
    "    ('imputer', SimpleImputer(strategy='median')),\r\n",
    "    ('scaler', MinMaxScaler())\r\n",
    "])\r\n",
    "\r\n",
    "# Fit column transformer to training data\r\n",
    "preprocessor = ColumnTransformer([\r\n",
    "    ('cat', cat_pipe, categorical),\r\n",
    "    ('num', num_pipe, numerical)\r\n",
    "])\r\n",
    "preprocessor.fit(X_train)\r\n",
    "\r\n",
    "# Prepare column names\r\n",
    "cat_columns = preprocessor.named_transformers_['cat']['encoder'].get_feature_names(categorical)\r\n",
    "columns = np.append(cat_columns, numerical)\r\n",
    "\r\n",
    "# Inspect training data before and after\r\n",
    "print(\"******************** Training data ********************\")\r\n",
    "display(X_train.shape)\r\n",
    "display(len(columns))\r\n",
    "display(preprocessor.transform(X_train).shape)\r\n",
    "final=pd.DataFrame(preprocessor.transform(X_train),columns=columns)\r\n",
    "\r\n",
    "# Inspect test data before and after\r\n",
    "print(\"******************** Test data ********************\")\r\n",
    "# display(X_test)\r\n",
    "display(pd.DataFrame(preprocessor.transform(X_test), columns=columns))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "def impute_all_numeric_NaNs(df):\r\n",
    "    # all features must be numeric\r\n",
    "    from sklearn.impute import SimpleImputer\r\n",
    "    imp1 = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=-1)\r\n",
    "    trdf=imp1.fit_transform(df)  # replae NaN's with 'missing'\r\n",
    "    return pd.DataFrame(trdf,columns=df.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All the transformations in one function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "def transf_all(df):\r\n",
    "    \r\n",
    "    trdf=transf_bana(df.copy())\r\n",
    "    trdf=transf_kusk_häst(trdf)\r\n",
    "    trdf=transf_kusk_häst(trdf,pref='h1_')\r\n",
    "    trdf=transf_kusk_häst(trdf,pref='h2_')\r\n",
    "    trdf=transf_kusk_häst(trdf,pref='h3_')\r\n",
    "    trdf=transf_kusk_häst(trdf,pref='h4_')\r\n",
    "    trdf=transf_kusk_häst(trdf,pref='h5_')\r\n",
    "    trdf.drop(['häst'],axis=1,inplace=True)\r\n",
    "    trdf=transf_kön(trdf)\r\n",
    "    trdf['datum']=pd.to_datetime(trdf.datum).view(float)*10e210\r\n",
    "    \r\n",
    "    return impute_all_numeric_NaNs(trdf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# transform all categoricals and impute all NaNs\r\n",
    "def prepare_all(df):\r\n",
    "    trdf = transf_all(df)\r\n",
    "    \r\n",
    "    y = (trdf.plac==1) * 1\r\n",
    "    trdf = trdf.drop('plac',axis=1)\r\n",
    "    \r\n",
    "    # all features are now numeric\r\n",
    "    trdf = impute_all_numeric_NaNs(trdf)\r\n",
    "    if trdf.isna().sum().sum() != 0:\r\n",
    "        print('still NaNs in data')\r\n",
    "        assert False\r\n",
    "    return trdf,y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## stacking prepare and run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# metrics\r\n",
    "from sklearn.metrics import make_scorer\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import matthews_corrcoef\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "# for tuning\r\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CatBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#catBoost preprocessing\r\n",
    "def catB_preprocess(df):\r\n",
    "        y = (df.plac==1) * 1\r\n",
    "        df = df.drop('plac',axis=1)\r\n",
    "        df = impute_cat_features(df,cat_features=CAT_FEATURES)\r\n",
    "\r\n",
    "        return df,y\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# clean the cat_features\r\n",
    "df_catb, y = catB_preprocess(df.copy())\r\n",
    "df_catb[CAT_FEATURES].isna().sum().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trdf,y=prepare_all(df)\r\n",
    "scorer = make_scorer(roc_auc_score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# CatBoost model GridSearchCV\r\n",
    "my_df_1=df_catb             # catboost with Nans abd cat_features\r\n",
    "my_cats_1 = CAT_FEATURES\r\n",
    "my_df_2 = trdf              # dataset common for all estimators\r\n",
    "my_cats_2 = []\r\n",
    "\r\n",
    "my_df = my_df_2\r\n",
    "my_cats = my_cats_2\r\n",
    "my_pool = Pool(my_df,y,cat_features=my_cats)\r\n",
    "my_catb = CatBoostClassifier(cat_features=my_cats)\r\n",
    "\r\n",
    "tscv = TimeSeriesSplit(n_splits=5)\r\n",
    "params = {'iterations': [50,100,500,1000],\r\n",
    "          'depth': [2,3,4, 5, 6],\r\n",
    "          'loss_function': ['Logloss'],\r\n",
    "          'l2_leaf_reg': np.logspace(-20, -19, 3),\r\n",
    "          'leaf_estimation_iterations': [10],\r\n",
    "          'eval_metric': ['AUC'],\r\n",
    "        #   'use_best_model': ['True'],\r\n",
    "          'logging_level':['Silent'],\r\n",
    "          'random_seed': [2021],\r\n",
    "         }\r\n",
    "# clf.fit(df_catb,y)\r\n",
    "\r\n",
    "catb_grid = RandomizedSearchCV(estimator=my_catb, param_distributions=params, scoring=scorer, cv=tscv)\r\n",
    "\r\n",
    "# GridSearchCV  - compare with default\r\n",
    "catb_grid.fit(my_df,y)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get best estimator and params\r\n",
    "best_catb = catb_grid.best_estimator_\r\n",
    "print('best gridsearch',catb_grid.best_score_)\r\n",
    "best_param = catb_grid.best_params_\r\n",
    "best_param"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(best_catb.fit(my_df,y).best_score_)\r\n",
    "best_catb.get_feature_importance(prettified=True).head(8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# XGBoost model \r\n",
    "import xgboost as xgb\r\n",
    "label = y\r\n",
    "dtrain = xgb.DMatrix(trdf, label=label)\r\n",
    "param = {'max_depth':2, 'eta':1 }\r\n",
    "num_round = 10\r\n",
    "\r\n",
    "# GridSearchCV\r\n",
    "params = {'nthread':[4], #when use hyperthread, xgboost may become slower\r\n",
    "              'objective':['binary:logistic'],\r\n",
    "              'learning_rate': [0.09,0.1,0.15], #so called `eta` value\r\n",
    "              'max_depth': [7,8,9],\r\n",
    "              'min_child_weight': [9,10,11],\r\n",
    "              'use_label_encoder':[False],\r\n",
    "            #   'silent': [1],\r\n",
    "              'eval_metric': ['logloss'],\r\n",
    "              'subsample': [0.5,0.9,1.0],\r\n",
    "              'colsample_bytree': [0.7, 0.9, 1.0],\r\n",
    "              'n_estimators': [7,8,9], #number of trees, change it to 1000 for better results\r\n",
    "              'missing':[-999],\r\n",
    "              'seed': [2021],\r\n",
    "              }\r\n",
    "\r\n",
    "xgb_clf = xgb.XGBClassifier(num_round=num_round)\r\n",
    "xgb_grid = GridSearchCV(estimator=xgb_clf, param_grid=params, n_jobs=3,scoring=scorer, cv=tscv)\r\n",
    "xgb_grid.fit(trdf, y )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get best estimator and params\r\n",
    "best_xgb = xgb_grid.best_estimator_\r\n",
    "print('best gridsearch', xgb_grid.best_score_)\r\n",
    "best_param = xgb_grid.best_params_\r\n",
    "best_param"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(best_xgb.feature_importances_,index=trdf.columns).sort_values(by=0,ascending=False).head(6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ExtraTree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ExtraTree  model\r\n",
    "tscv = TimeSeriesSplit()\r\n",
    "from sklearn.tree import ExtraTreeClassifier\r\n",
    "et = ExtraTreeClassifier(min_samples_split=2, random_state=2021,class_weight='balanced')\r\n",
    "\r\n",
    "# GridSearchCV\r\n",
    "params = {'class_weight': [ 'balanced'  ,None], \r\n",
    "          'max_depth': [None, 5, 10  ,15 ,20],\r\n",
    "          'min_samples_leaf': [1, 2 ,3, 4,],\r\n",
    "          'min_samples_split': [2,30, 30,  40  ,45],   \r\n",
    "          'criterion': [ 'gini'  ,'entropy'],   \r\n",
    "          'splitter': ['random',  'best']\r\n",
    "         }\r\n",
    "\r\n",
    "et_grid = GridSearchCV(estimator=et, param_grid=params, n_jobs=3,scoring=scorer, cv=tscv)\r\n",
    "et_grid.fit(trdf, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get best estimator and params\r\n",
    "best_et = et_grid.best_estimator_\r\n",
    "print('best gridsearch', et_grid.best_score_)\r\n",
    "best_param = et_grid.best_params_\r\n",
    "best_param"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN model\r\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=4, )\r\n",
    "\r\n",
    "# GridSearchCV\r\n",
    "\r\n",
    "tscv = TimeSeriesSplit()\r\n",
    "params = {'n_neighbors': [10,15,20],\r\n",
    "          \r\n",
    "         }\r\n",
    "\r\n",
    "knn_grid = GridSearchCV(estimator=knn, param_grid=params, n_jobs=3,scoring=scorer, cv=tscv)\r\n",
    "\r\n",
    "# GridSearchCV  \r\n",
    "knn_grid.fit(trdf, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_knn = knn_grid.best_estimator_\r\n",
    "print('best gridsearch',knn_grid.best_score_)\r\n",
    "best_param = knn_grid.best_params_\r\n",
    "best_param"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RandomForrest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GridSearch\r\n",
    "rf = RandomForestClassifier()\r\n",
    "\r\n",
    "tscv = TimeSeriesSplit()\r\n",
    "params = {'n_estimators': [5,10,100],\r\n",
    "          'max_depth': [4, 5, 6, None],\r\n",
    "          'class_weight': ['balanced'],\r\n",
    "        #   'loss_function': ['Logloss'],\r\n",
    "        #   'eval_metric': ['F1'],\r\n",
    "        #   'logging_level':['Silent'],\r\n",
    "          'random_state': [2021],\r\n",
    "         }\r\n",
    "# clf.fit(df_catb,y)\r\n",
    "\r\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=params, n_jobs=3,scoring=scorer, cv=tscv)\r\n",
    "\r\n",
    "# GridSearchCV  \r\n",
    "rf_grid.fit(trdf, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_rf = rf_grid.best_estimator_\r\n",
    "print('best gridsearch',rf_grid.best_score_)\r\n",
    "best_param = rf_grid.best_params_\r\n",
    "best_param"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "pd.DataFrame(best_rf.feature_importances_,index=trdf.columns, columns=['importance']).sort_values(by='importance',ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GridSearchCV\r\n",
    "# from sklearn.svm import SVC\r\n",
    "# svc = SVC(C=1.0, gamma='scale', tol=0.001, cache_size=200, class_weight='balanced', random_state=2021)\r\n",
    "\r\n",
    "# tscv = TimeSeriesSplit()\r\n",
    "# params = {'C': [1,2,3],\r\n",
    "#           'gamma': ['scale','auto'],\r\n",
    "#           'class_weight': ['balanced'],\r\n",
    "#           'random_state': [2021],\r\n",
    "#          }\r\n",
    "\r\n",
    "# svc_grid = GridSearchCV(estimator=svc, param_grid=params, n_jobs=3,scoring=scorer, cv=tscv)\r\n",
    "\r\n",
    "# svc_grid.fit(trdf, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # get best estimator and params\r\n",
    "# best_svc = svc_grid.best_estimator_\r\n",
    "# print('best gridsearch', svc_grid.best_score_)\r\n",
    "# best_param = svc_grid.best_params_\r\n",
    "# best_param"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stack'em"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\r\n",
    "from sklearn.ensemble import StackingClassifier\r\n",
    "from sklearn.linear_model import LogisticRegressionCV\r\n",
    "base_models = [('xgb',best_xgb,),\r\n",
    "               ('rf',best_rf,),\r\n",
    "               ('catb', best_catb,),\r\n",
    "              ('knn', best_knn, ),\r\n",
    "              ('et', best_et)              # ger  sämre res\r\n",
    "               # ('ridge', best_ridge, ) ,   # saknar predict_proba - usless!\r\n",
    "            #    ('svc', best_svc, ),        # tar extremt lång tid för fit\r\n",
    "               ]\r\n",
    "meta_model = LogisticRegressionCV(class_weight='balanced')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluate_model(model, X, y, scoring=scorer):\r\n",
    "    print('scorer =',scorer)\r\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\r\n",
    "    scores = cross_val_score(model, X, y, scoring=scoring, cv=tscv, verbose=1, n_jobs=3, error_score='raise')\r\n",
    "    return scores\r\n",
    "\r\n",
    "def Stacking(model_item, X_tr, y_tr, X_final, n_fold):\r\n",
    "    model=model_item[1]\r\n",
    "    print(model_item[0], end=' ')\r\n",
    "    tscv = TimeSeriesSplit(n_splits=n_fold)\r\n",
    "    # valid_pred=np.empty((X_valid.shape[0],1),float)\r\n",
    "    train_pred=np.empty((0,1),float)\r\n",
    "    for n, (train_indices, test_indices) in enumerate(tscv.split(X_tr)):\r\n",
    "        if n==0:\r\n",
    "            the_first_set_len = len(train_indices) # the first set that cannot be used i timeSeries stacking\r\n",
    "            \r\n",
    "        X_train, X_test = X_tr.iloc[train_indices], X_tr.iloc[test_indices]\r\n",
    "        y_train, y_test = y_tr.iloc[train_indices], y_tr.iloc[test_indices]\r\n",
    "        print(n,end=' ')\r\n",
    "        model.fit(X=X_train,y=y_train)\r\n",
    "        train_pred=np.append(train_pred,model.predict_proba(X_test)[:,1])\r\n",
    "    print(f'- final fit (the_first_set_len={the_first_set_len})' )\r\n",
    "    model.fit(X=X_tr,y=y_tr) # fit on all data (except the final data)   \r\n",
    "    valid_pred = model.predict_proba(X_final)[:,1]\r\n",
    "    return model,valid_pred.reshape(-1,1), train_pred, the_first_set_len\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "split_ix = int(len(trdf)*.8)\r\n",
    "train_X = trdf[trdf.index <  split_ix]\r\n",
    "valid_X = trdf[trdf.index >= split_ix]\r\n",
    "train_y = y[y.index <  split_ix]\r\n",
    "valid_y = y[y.index >=  split_ix]\r\n",
    "\r\n",
    "# the estimators\r\n",
    "valid_pred=[None] * len(base_models)\r\n",
    "train_pred=[None] * len(base_models)\r\n",
    "model=[None] * len(base_models)\r\n",
    "for n, model_item in enumerate(base_models):\r\n",
    "    model[n],valid_pred[n] ,train_pred[n], the_first_set_len = Stacking(model_item,n_fold=5, X_tr=train_X, y_tr= train_y, X_final=valid_X)\r\n",
    "    train_pred[n]=pd.DataFrame(train_pred[n],columns=[model_item[0]])\r\n",
    "    valid_pred[n]=pd.DataFrame(valid_pred[n],columns=[model_item[0]])\r\n",
    "    \r\n",
    "    scores=evaluate_model(model[n],train_X,train_y)\r\n",
    "    print(f'mean={np.mean(scores)}: {scores}')\r\n",
    "train_y = train_y.iloc[the_first_set_len:]      # remove the first set that can't be used in timeseries stacking\r\n",
    "train_pred=pd.concat(train_pred,axis=1)\r\n",
    "valid_pred=pd.concat(valid_pred,axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final estimation with the meta model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import time\r\n",
    "meta_model.fit(train_pred,train_y)\r\n",
    "scores=evaluate_model(meta_model,valid_pred,valid_y)\r\n",
    "time.sleep(0.2)\r\n",
    "print('models', list(valid_pred.columns))\r\n",
    "print(f'mean={np.mean(scores)}: {scores}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## rf, catb, knn, et - 0.88803\r\n",
    "## xgb, rf, catb, knn, et - 0.88720"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}