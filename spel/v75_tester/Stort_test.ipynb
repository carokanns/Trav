{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kopia av 4_üí™_Stort_test.py f√∂r tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sys.path.append(\n",
    "    'C:\\\\Users\\\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\spel\\\\')\n",
    "pref = '../'\n",
    "\n",
    "import json\n",
    "import travdata as td\n",
    "import typ_copy as tp\n",
    "import sys\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "import pickle\n",
    "# import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 260)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 120)\n",
    "\n",
    "# st.set_page_config(page_title=\"Stort test av modeller\", page_icon=\"üí™\")\n",
    "\n",
    "# st.markdown(\"# üí™ Stort test av modeller\")\n",
    "# st.sidebar.header(\"üí™ Stort test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_total_insats(veckans_rad):\n",
    "    summa = veckans_rad.groupby('avd').avd.count().prod() / 2\n",
    "    return summa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def starta_upp(df, start_ix=220):\n",
    "    import datetime\n",
    "\n",
    "    startdatum = df.datum.unique()[start_ix]\n",
    "\n",
    "    print(\"st.info(f'Startdatum = {startdatum}'\")\n",
    "\n",
    "    # init resutat-tabell\n",
    "    df_resultat = pd.DataFrame(columns=['datum', 't1_vinst', 't2_vinst', 't3_vinst', 't4_vinst',\n",
    "                                                 't1_utd',   't2_utd',   't3_utd',   't4_utd',\n",
    "                                                 't1_kostn', 't2_kostn', 't3_kostn', 't4_kostn',\n",
    "                                                 't1_7', 't2_7', 't3_7', 't4_7',\n",
    "                                                 't1_6', 't2_6', 't3_6', 't4_6',\n",
    "                                                 't1_5', 't2_5', 't3_5', 't4_5'\n",
    "                                        ])\n",
    "\n",
    "    df_resultat.set_index('datum', drop=True, inplace=True)\n",
    "    # print(df_resultat.head(0))\n",
    "    df_resultat.loc[startdatum] = [0, 0, 0, 0, 0, 0,\n",
    "                                   0, 0, 0, 0, 0, 0,\n",
    "                                   0, 0, 0, 0, 0, 0,\n",
    "                                   0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    return df.datum.unique(), df_resultat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def skapa_data_f√∂r_datum(df_, datum):\n",
    "    df = df_.copy()\n",
    "    X = df.query(f'datum < @datum')\n",
    "    y = X.y\n",
    "    X = X.drop('y', axis=1)\n",
    "    X_test = df.query(f'datum > @datum')\n",
    "    y_test = X_test.y\n",
    "    X_test = X_test.drop('y', axis=1)\n",
    "    X_curr = df.query(f'datum == @datum')\n",
    "    y_curr = X_curr.y\n",
    "    X_curr = X_curr.drop(['y'], axis=1)\n",
    "    return X, y, X_test, y_test, X_curr, y_curr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kelly(proba, streck, odds):  # proba = prob winning, streck i % = streck\n",
    "    # l√§s in streck_to_odds.pkl\n",
    "    # import pickle\n",
    "    with open(pref+'rf_streck_odds.pkl', 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "\n",
    "    if odds is None:\n",
    "        o = rf.predict(streck.copy())\n",
    "    else:\n",
    "        o = rf.predict(streck.copy())\n",
    "\n",
    "    # for each values > 40 in odds set to 1\n",
    "    o[o > 40] = 1\n",
    "    return (o*proba - (1-proba))/o\n",
    "\n",
    "\n",
    "def compute_total_insats(veckans_rad):\n",
    "    summa = veckans_rad.groupby('avd').avd.count().prod() / 2\n",
    "    return summa\n",
    "\n",
    "\n",
    "def ber√§kna_utdelning(datum, sjuor, sexor, femmor, df_utdelning):\n",
    "    datum = datum.strftime('%Y-%m-%d')\n",
    "\n",
    "    min_utdelning = df_utdelning.loc[df_utdelning.datum == datum, [\n",
    "        '7r√§tt', '6r√§tt', '5r√§tt']]\n",
    "\n",
    "    return (min_utdelning['7r√§tt'] * sjuor + min_utdelning['6r√§tt'] * sexor + min_utdelning['5r√§tt'] * femmor).values[0]\n",
    "\n",
    "\n",
    "def varje_avd_minst_en_h√§st(veckans_rad):\n",
    "    # ta ut en h√§st i varje avd - markera valda i df\n",
    "    for avd in veckans_rad.avd.unique():\n",
    "        # max av proba i veckans_rad\n",
    "        max_proba = veckans_rad[veckans_rad.avd == avd]['proba'].max()\n",
    "        veckans_rad.loc[(veckans_rad.avd == avd) & (\n",
    "            veckans_rad.proba == max_proba), 'v√§lj'] = True\n",
    "    return veckans_rad\n",
    "\n",
    "\n",
    "def hitta_spikar(veckans_rad, spikad_avd, spik_strategi, min_avst):\n",
    "    print('spik_strategi', spik_strategi)\n",
    "    assert spik_strategi in [\n",
    "        '1a', '1b', '2a', '2b'], \"spik_strategi m√•ste ha n√•got av v√§rdena i listan\"\n",
    "    # Hitta spik-kandidater\n",
    "    if spik_strategi[0] in ['1', '2']:\n",
    "        ix_spik1 = veckans_rad.nlargest(\n",
    "            1, 'proba').index[0]   # ix for largest in dataset\n",
    "        # avd med h√∂gsta proba totalt\n",
    "        avd = veckans_rad.loc[ix_spik1, 'avd']\n",
    "        no2 = veckans_rad.query(\"avd==@avd\").nlargest(2,\n",
    "                                                      'proba').index[1]  # second i avd ovan\n",
    "        # print(\n",
    "        #     f'h√∂sta proba totalt={veckans_rad.loc[ix_spik1, \"proba\"]} finns i avd={avd}; no2 i avd={avd} √§r {veckans_rad.loc[no2,\"proba\"]}')\n",
    "        avst√•nd = veckans_rad.loc[ix_spik1, 'proba'] - \\\n",
    "            veckans_rad.loc[no2, 'proba']\n",
    "        print('avst', avst√•nd)\n",
    "        if (spik_strategi[1] == 'b') and (avst√•nd > min_avst):  # spik 1 om stort avst\n",
    "            print('strategi', spik_strategi[1], 'valde spik i avd', avd)\n",
    "            spikad_avd.append(avd)      # add avd to a list\n",
    "\n",
    "            veckans_rad.loc[ix_spik1, 'spik'] = True\n",
    "            veckans_rad.loc[ix_spik1, 'v√§lj'] = True\n",
    "        elif spik_strategi[1] == 'a':   # forcerad spik 1\n",
    "            print('strategi', spik_strategi[1], 'valde spik i avd', avd)\n",
    "            spikad_avd.append(avd)      # add avd to a list\n",
    "            veckans_rad.loc[ix_spik1, ['spik']] = True\n",
    "            veckans_rad.loc[ix_spik1, 'v√§lj'] = True\n",
    "\n",
    "    if spik_strategi[0] == '2':\n",
    "        spik2 = veckans_rad.nlargest(2, 'proba').index[1]  # second in dataset\n",
    "        avd = veckans_rad.loc[spik2, 'avd']\n",
    "        no2 = veckans_rad.query(\"avd==@avd\").nlargest(2,\n",
    "                                                      'proba').index[1]  # second in avd\n",
    "        # print(\n",
    "        #     f'n√§st h√∂gsta proba totalt={veckans_rad.loc[spik2, \"proba\"]} finns i avd={avd}; no2 i avd={avd} √§r {veckans_rad.loc[no2,\"proba\"]}')\n",
    "        avst√•nd = veckans_rad.loc[spik2, 'proba'] - \\\n",
    "            veckans_rad.loc[no2, 'proba']\n",
    "        print('avst', avst√•nd)\n",
    "        # spik om stort avst√•nd till 2:an\n",
    "        if (spik_strategi[1] == 'b') and (avst√•nd > min_avst):\n",
    "            print('strategi', spik_strategi[1], 'valde spik i avd', avd)\n",
    "            spikad_avd.append(avd)\n",
    "            veckans_rad.loc[spik2, 'spik'] = True\n",
    "            veckans_rad.loc[spik2, 'v√§lj'] = True\n",
    "        elif spik_strategi[1] == 'a':   # forcerad spik 2\n",
    "            print('strategi', spik_strategi[1], 'i avd', avd)\n",
    "            spikad_avd.append(avd)\n",
    "            veckans_rad.loc[spik2, 'spik'] = True\n",
    "            veckans_rad.loc[spik2, 'v√§lj'] = True\n",
    "    return veckans_rad, spikad_avd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plocka_en_efter_en(veckans_rad, spikad_avd, kelly_strategi, max_cost=300):\n",
    "    \"\"\"_summary_\n",
    "    Args:\n",
    "        veckans_rad (_type_): df att fylla\n",
    "        spikad_avd (_type_): lista med spikade avdelningar\n",
    "        kelly_strategi (_type_): 1 v√§lj med Kelly varannan g√•ng, annars ingen Kelly\n",
    "        max_cost (int, optional): Max kostnad. Defaults to 300.\n",
    "\n",
    "    Returns:\n",
    "        _type_: df med veckans rad samt kostnad\n",
    "    \"\"\"\n",
    "    cost = 0.5  # 1 rad\n",
    "    while cost < max_cost:\n",
    "        # d) plocka en och en - f√∂rst proba sedan ev positiv kelly markera som valda i df\n",
    "        curr_index = veckans_rad.query(\n",
    "            \"v√§lj==False and avd not in @spikad_avd\").nlargest(1, 'proba').index\n",
    "        veckans_rad.loc[curr_index, 'v√§lj'] = True\n",
    "        # e) avbryt vid 300:-\n",
    "        cost = compute_total_insats(veckans_rad.query(\"v√§lj==True\"))\n",
    "        if cost > max_cost:\n",
    "            # ta tillbaks den sist spelade\n",
    "            veckans_rad.loc[curr_index, 'v√§lj'] = False\n",
    "            break\n",
    "\n",
    "        if kelly_strategi == 1:\n",
    "            pass\n",
    "            # veckans_kelly = veckans_rad.query(\n",
    "            #     \"v√§lj==False and kelly > 0 and avd not in @spikad_avd \")\n",
    "            # veckans_kelly = veckans_kelly.sort_values(\n",
    "            #     by=['kelly'], ascending=False)\n",
    "            # try:\n",
    "            #     True\n",
    "            #     # print('kelly')\n",
    "            # except:\n",
    "            #     print('no kelly', veckans_kelly.shape)\n",
    "\n",
    "            # if veckans_kelly.iloc[0]['kelly'] > 0:\n",
    "            #     curr_index = veckans_kelly.iloc[0].name\n",
    "            #     veckans_rad.loc[curr_index, 'v√§lj'] = True\n",
    "            #     veckans_rad.loc[curr_index, 'kelly_val'] = True\n",
    "            #     cost = compute_total_insats(veckans_rad.query(\"v√§lj==True\"))\n",
    "\n",
    "            # if cost > max_cost:\n",
    "            #     # ta tillbaks den sist spelade\n",
    "            #     veckans_rad.loc[curr_index, 'v√§lj'] = False\n",
    "            #     break\n",
    "    cost = compute_total_insats(veckans_rad.query(\"v√§lj==True\"))\n",
    "\n",
    "    return veckans_rad, cost\n",
    "\n",
    "\n",
    "def ta_fram_rad(veckans_rad_, spik_strategi, kelly_strategi, max_cost=300, min_avst=0.175):\n",
    "    \"\"\" Denna funktion tar fram en rad f√∂r typ-modeller (ej meta-modell)\n",
    "    df nneh√•ller _en omg√•ng_\n",
    "    _spik_strategi_: None - inget, '1a' - forcera 1 spik, '2a' - forcera 2 spikar, '1b' - 1 spik endast om klar favorit, '2b' - spikar f√∂r endast klara favoriter \n",
    "    _kelly_strategi_: None - ingen kelly, 1 - kelly varannan g√•ng om positiv\n",
    "    \"\"\"\n",
    "    veckans_rad = veckans_rad_.copy()\n",
    "    # veckans_rad['kelly_val'] = False\n",
    "    veckans_rad['v√§lj'] = False   # inga rader valda √§nnu\n",
    "    veckans_rad['spik'] = False   # inga spikar valda √§nnu\n",
    "\n",
    "    veckans_rad = varje_avd_minst_en_h√§st(veckans_rad)\n",
    "\n",
    "    # b) leta 1-2 spikar om s√• beg√§rs - markera valda i df\n",
    "    spikad_avd = []\n",
    "    if spik_strategi:\n",
    "        veckans_rad, spikad_avd = hitta_spikar(\n",
    "            veckans_rad, spikad_avd, spik_strategi, min_avst)\n",
    "\n",
    "    # c) sortera upp i proba-ordning. Om kelly skapa en sortering efter kelly-ordning\n",
    "    veckans_rad = veckans_rad.sort_values(by=['proba'], ascending=False)\n",
    "    veckans_rad = veckans_rad.reset_index(drop=True)\n",
    "\n",
    "    # plocka en efter en tills kostnaden √§r f√∂r stor\n",
    "    # return veckans_rad, cost\n",
    "    return plocka_en_efter_en(veckans_rad, spikad_avd, kelly_strategi, max_cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ta_fram_meta_rad(veckans_rad_, meta_modeller, spik_strategi, kelly_strategi, max_cost=300, min_avst=0.175):\n",
    "    \"\"\" Denna funktion tar fram en rad f√∂r meta-modellerna genom mean value\n",
    "    df nneh√•ller _en omg√•ng_\n",
    "    _spik_strategi_: None - inget, '1a' - forcera 1 spik, '2a' - forcera 2 spikar, '1b' - 1 spik endast om klar favorit, '2b' - spikar f√∂r endast klara favoriter \n",
    "    _kelly_strategi_: None - ingen kelly, 1 - kelly varannan g√•ng om positiv\n",
    "    \"\"\"\n",
    "    veckans_rad = veckans_rad_.copy()\n",
    "    # veckans_rad['kelly_val'] = False\n",
    "    veckans_rad['v√§lj'] = False   # inga rader valda √§nnu\n",
    "    veckans_rad['spik'] = False   # inga spikar valda √§nnu\n",
    "\n",
    "    veckans_rad['proba'] = 0\n",
    "    # veckans_rad['kelly'] = 0\n",
    "    \n",
    "    for enum, key in enumerate(meta_modeller.keys()):\n",
    "        veckans_rad['proba'] += veckans_rad[key]\n",
    "        # veckans_rad['kelly'] += veckans_rad['kelly'+enum]\n",
    "        \n",
    "    veckans_rad['proba'] /= len(meta_modeller)\n",
    "    # veckans_rad['kelly'] /= len(meta_modeller)\n",
    "    \n",
    "    veckans_rad = varje_avd_minst_en_h√§st(veckans_rad)\n",
    "\n",
    "    # b) leta 1-2 spikar om s√• beg√§rs - markera valda i df\n",
    "    spikad_avd = []\n",
    "    if spik_strategi:\n",
    "        veckans_rad, spikad_avd = hitta_spikar(\n",
    "            veckans_rad, spikad_avd, spik_strategi, min_avst)\n",
    "\n",
    "    # c) sortera upp i proba-ordning. Om kelly skapa en sortering efter kelly-ordning\n",
    "    veckans_rad = veckans_rad.sort_values(by=['proba'], ascending=False)\n",
    "    veckans_rad = veckans_rad.reset_index(drop=True)\n",
    "\n",
    "    # plocka en efter en tills kostnaden √§r f√∂r stor\n",
    "    # return veckans_rad, cost\n",
    "    return plocka_en_efter_en(veckans_rad, spikad_avd, kelly_strategi, max_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def r√§tta_rad(df, datum, df_utdelning):\n",
    "    \"\"\"\n",
    "    R√§kna ut antal 5:or, 6:or resp. 7:or\n",
    "    H√§mta ev utdelning\n",
    "    Spara datum, resultat, utdelning och rad-kostnad\n",
    "    \"\"\"\n",
    "    sjuor, sexor, femmor, utdelning = 0, 0, 0, 0\n",
    "\n",
    "    min_tabell = df[['y', 'avd', 'h√§st', 'rel_rank', 'v√§lj']].copy()\n",
    "    min_tabell.sort_values(by=['avd', 'y'], ascending=False, inplace=True)\n",
    "\n",
    "    print('Antal r√§tt', min_tabell.query('v√§lj==True and y==1').y.sum())\n",
    "    # display(min_tabell)\n",
    "    \n",
    "    # 1. om jag har max 7 r√§tt\n",
    "    if min_tabell.query('v√§lj==True and y==1').y.sum() == 7:\n",
    "        sjuor = 1\n",
    "        sexor = (min_tabell.groupby('avd').v√§lj.sum()).sum()-7\n",
    "        # antal femmor\n",
    "        ant1 = min_tabell.query('avd==1 and v√§lj==True').v√§lj.sum()-1\n",
    "        ant2 = min_tabell.query('avd==2 and v√§lj==True').v√§lj.sum()-1\n",
    "        ant3 = min_tabell.query('avd==3 and v√§lj==True').v√§lj.sum()-1\n",
    "        ant4 = min_tabell.query('avd==4 and v√§lj==True').v√§lj.sum()-1\n",
    "        ant5 = min_tabell.query('avd==5 and v√§lj==True').v√§lj.sum()-1\n",
    "        ant6 = min_tabell.query('avd==6 and v√§lj==True').v√§lj.sum()-1\n",
    "        ant7 = min_tabell.query('avd==7 and v√§lj==True').v√§lj.sum()-1\n",
    "        femmor = ant1*ant2+ant1*ant2+ant1*ant3+ant1*ant4+ant1*ant5+ant1*ant6+ant1*ant7 +\\\n",
    "            ant2*ant3+ant2*ant4+ant2*ant5+ant2*ant6+ant2*ant7 + \\\n",
    "            ant3*ant4+ant3*ant5+ant3*ant6+ant3*ant7 + \\\n",
    "            ant4*ant5+ant4*ant6+ant4*ant7 + \\\n",
    "            ant5*ant6+ant5*ant7 + \\\n",
    "            ant6*ant7\n",
    "\n",
    "    # 2. om jag har max 6 r√§tt\n",
    "    if min_tabell.query('v√§lj==True and y==1').y.sum() == 6:\n",
    "        avd_fel = min_tabell.loc[((min_tabell.v√§lj == False) & (\n",
    "            min_tabell.y == 1)), 'avd'].values[0]\n",
    "        print(min_tabell.query('avd== @avd_fel').v√§lj.sum())\n",
    "        sexor = min_tabell.query('avd==@avd_fel').v√§lj.sum()\n",
    "        # antal femmor\n",
    "        femmor_fel, femmor_r√§tt = 0, 0\n",
    "        for avd in range(1, 8):\n",
    "            if avd == avd_fel:\n",
    "                femmor_fel += min_tabell.loc[min_tabell.avd ==\n",
    "                                             avd_fel].v√§lj.sum()\n",
    "\n",
    "            femmor_r√§tt += min_tabell.query(\n",
    "                'avd==@avd and v√§lj==True').v√§lj.sum()-1\n",
    "        print(f'femmor_r√§tt = {femmor_r√§tt} femmor_fel = {femmor_fel}')\n",
    "        femmor = femmor_fel * femmor_r√§tt\n",
    "\n",
    "    # 3. om jag har max 5 r√§tt\n",
    "    if min_tabell.query('v√§lj==True and y==1').y.sum() == 5:\n",
    "        avd_fel = min_tabell.loc[((min_tabell.v√§lj == False) & (\n",
    "            min_tabell.y == 1)), 'avd'].values\n",
    "        femmor = min_tabell.loc[min_tabell.avd == avd_fel[0]].v√§lj.sum(\n",
    "        ) * min_tabell.loc[min_tabell.avd == avd_fel[1]].v√§lj.sum()\n",
    "\n",
    "    return sjuor, sexor, femmor, ber√§kna_utdelning(datum, sjuor, sexor, femmor, df_utdelning)\n",
    "\n",
    "\n",
    "# def initiera_veckans_rader(X_curr, y_curr, antal_rader):\n",
    "#     # ---------- initier veckans rad med aktuell omg√•ng ----------------------\n",
    "#     veckans_rader = []\n",
    "#     for i in range(antal_rader):\n",
    "#         veckans_rader.append(X_curr[['datum', 'avd', 'h√§st', 'bana',\n",
    "#                                      'kusk', 'streck', 'streck_avst', 'rel_rank']].copy())\n",
    "#         veckans_rader[i]['y'] = y_curr\n",
    "#         veckans_rader[i]['v√§lj'] = False\n",
    "\n",
    "#     return veckans_rader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skapa stack_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "def skapa_stack_data(model, name, X_meta, stack_data):\n",
    "    \"\"\"Skapa stack_data inklusive Kelly\"\"\"\n",
    "    assert 'y' in stack_data.columns, 'y is missing in stack_data'\n",
    "    this_proba = model.predict(X_meta)\n",
    "    print(f'X_meta.shape = {X_meta.shape} this_proba.shape={this_proba.shape}')\n",
    "    \n",
    "    # Bygg up meta-kolumnerna (proba och Kelly) f√∂r denns typ\n",
    "    nr = name[3:]\n",
    "    stack_data['proba'+nr] = this_proba\n",
    "    # stack_data['kelly'+nr] = kelly(this_proba, X_meta[['streck']], None)\n",
    "    print(f'stack_data.shape = {stack_data.shape}')\n",
    "    return stack_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_stack_data(stack_data_):\n",
    "    \"\"\"Hantera missing values, NaN, etc f√∂r meta-modllerna\"\"\"\n",
    "    \n",
    "    assert 'y' in stack_data_.columns, 'y is missing in stack_data'\n",
    "    stack_data = stack_data_.copy()\n",
    "    stack_data.y = stack_data.y.astype(int)\n",
    "    \n",
    "    \"\"\" rensa bort features som inte ska anv√§ndas \"\"\"    \n",
    "    # stack_data.drop(['startnr', 'vodds', 'podds', 'bins', 'h1_dat',\n",
    "    #             'h2_dat', 'h3_dat', 'h4_dat', 'h5_dat'], axis=1, inplace=True)\n",
    "    \n",
    "    \"\"\" Fyll i saknade numeriska v√§rden med 0 \"\"\"\n",
    "    numericals = stack_data.drop('y', axis=1).select_dtypes(exclude=['object']).columns\n",
    "    stack_data[numericals] = stack_data[numericals].fillna(0)\n",
    "        \n",
    "    \"\"\" Fyll i saknade kategoriska v√§rden med 'missing' \"\"\"\n",
    "    categoricals = stack_data.select_dtypes(include=['object']).columns\n",
    "    stack_data[categoricals] = stack_data[categoricals].fillna('missing')\n",
    "    \n",
    "    # \"\"\" Hantera high cardinality \"\"\"\n",
    "    # cardinality_list=['h√§st','kusk','h1_kusk','h2_kusk','h3_kusk','h4_kusk','h5_kusk']\n",
    "    \n",
    "    \"\"\" Target encoding\"\"\"\n",
    "    target_encode_list = ['bana', 'h√§st', 'kusk', 'k√∂n', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', \n",
    "                      'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n",
    "\n",
    "    y = stack_data['y']\n",
    "    enc = TargetEncoder(cols=target_encode_list, min_samples_leaf=20, smoothing=10).fit(stack_data, y)\n",
    "    stack_data = enc.transform(stack_data)\n",
    "        \n",
    "    return stack_data, enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def first_learn_modeller(modeller, X, y, X_meta, y_meta):\n",
    "    ############################################################################################################\n",
    "    #                        H√§r g√∂rs en f√∂rsta learn av modeller och sedan skapas stack_data\n",
    "    #                        - Learn modeller p√• X,y\n",
    "    #                        - Ha en egen skapa_stack_funktion (som ocks√• anv√§nds l√§ngre ner)\n",
    "    #                           - Skapa stack_data med predict X_meta med nya modellerna\n",
    "    #                           - Spara √§ven X_meta, y_meta i stack_data\n",
    "    #                           - Spara √§ven Kelly i stack_data\n",
    "    ############################################################################################################\n",
    "    stack_data = X_meta.copy()\n",
    "    stack_data['y'] = y_meta\n",
    "    assert 'y' in stack_data.columns, '1. y is missing in stack_data'\n",
    "    for model in modeller:\n",
    "        # with open(pref+'optimera/params_'+model.name+'.json', 'r') as f:\n",
    "        #     params = json.load(f)\n",
    "        #     params = params['params']\n",
    "\n",
    "        model.learn(X, y, params=None, save=True)\n",
    "\n",
    "        name=model.name\n",
    "        stack_data = skapa_stack_data(model, name, X_meta, stack_data)\n",
    "        assert 'y' in stack_data.columns, '2. y is missing in stack_data'\n",
    "\n",
    "    assert 'y' in stack_data.columns, '3. y is missing in stack_data'\n",
    "    stack_data, enc = prepare_stack_data(stack_data)\n",
    "    \n",
    "    return stack_data\n",
    "\n",
    "############################################################################################################\n",
    "#                       H√§r g√∂r vi learn av meta_modeller p√• stack_data\n",
    "############################################################################################################\n",
    "def learn_meta_models(meta_modeller, stack_data, save=True):\n",
    "    global ENC\n",
    "    print('Learn meta_modeller p√• stack_data')\n",
    "    assert 'y' in stack_data.columns, 'y is missing in stack_data'\n",
    "    stack_data.to_csv('stack_data_f√∂re_drop.csv', index=False)\n",
    "    \n",
    "    X_meta,ENC = prepare_stack_data(stack_data)\n",
    "    X_meta = stack_data.drop(['datum', 'avd', 'y'], axis=1)\n",
    "    y_meta = stack_data.y\n",
    "    X_meta.to_csv('X_meta_Learn.csv', index=False)\n",
    "    # print(f'Learn X_meta.shape = {X_meta.shape}   columns:')\n",
    "    # print(X_meta.columns)\n",
    "    for key, items in meta_modeller.items():\n",
    "        meta_model = items['model']\n",
    "        \n",
    "        items['model'] = meta_model.fit(X_meta, y_meta)\n",
    "        meta_modeller[key] = items\n",
    "\n",
    "        if save:\n",
    "            with open(pref+'modeller/'+key+'_model.model', 'wb') as f:\n",
    "                pickle.dump(meta_model, f)\n",
    "    \n",
    "    print('Done Learn meta_modeller p√• stack_data')\n",
    "    return meta_modeller\n",
    "\n",
    "\n",
    "def final_learn_modeller(modeller, X, y, X_meta, y_meta):\n",
    "    print('Final_learn modeller')\n",
    "    X_train = pd.concat([X, X_meta])\n",
    "    y_train = pd.concat([y, y_meta])\n",
    "    print(f'X_train.shape = {X_train.shape} X.shape = {X.shape}, X_meta.shape = {X_meta.shape}')\n",
    "    # print(f'X_train.columns = {X_train.columns}')\n",
    "    for model in modeller:\n",
    "        # with open(pref+'optimera/params_'+model.name+'.json', 'r') as f:\n",
    "        #     params = json.load(f)\n",
    "        #     params = params['params']\n",
    "\n",
    "        \n",
    "        model.learn(X_train, y_train, save=True)\n",
    "    print('Done Final_learn modeller')\n",
    "    return modeller\n",
    "\n",
    "\n",
    "def initiera_veckans_rader(X_curr, y_curr, antal_rader):\n",
    "    # ---------- initier veckans rad med aktuell omg√•ng ----------------------\n",
    "    veckans_rader = []\n",
    "    for i in range(antal_rader):\n",
    "        veckans_rader.append(X_curr[['datum', 'avd', 'h√§st', 'bana',\n",
    "                                     'kusk', 'streck', 'streck_avst', 'rel_rank']].copy())\n",
    "        veckans_rader[i]['y'] = y_curr\n",
    "        veckans_rader[i]['v√§lj'] = False\n",
    "\n",
    "    return veckans_rader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_curr_omgang(modeller, meta_modeller, X_curr, y_curr):\n",
    "    \"\"\"\n",
    "        H√§r tas meta_modellernas prediktioner fram\n",
    "        - modeller     : predict X_curr och anv√§nd skapa_stack_data funktionen\n",
    "        - meta_modeller: predict p√• stack_datat och fyll i veckans rader\n",
    "        veckans_rader inneh√•ller nu prediktioner fr√•n alla meta_modeller plus X_curr, y_curr\n",
    "    \"\"\"\n",
    "    stack_data = X_curr.copy()\n",
    "    stack_data['y'] = y_curr\n",
    "    \n",
    "    # ------------- predict aktuell omg√•ng och skapa Kelly -------------------\n",
    "    for model in modeller:\n",
    "        # nr = model.name[3:]\n",
    "        # stack_data['proba'+nr] = model.predict(X_curr)\n",
    "        # stack_data['kelly'+nr] = kelly(stack_data['proba'+nr],\n",
    "        #                                stack_data[['streck']], None)\n",
    "\n",
    "        stack_data = skapa_stack_data(model, model.name, X_curr, stack_data)\n",
    "\n",
    "    veckans_rad, enc = prepare_stack_data(stack_data)\n",
    "    # veckans_rad = stack_data.copy()\n",
    "    \n",
    "    veckans_rad.to_csv('veckans_rad.csv', index=False)\n",
    "    X_curr.to_csv('X_curr.csv', index=False)\n",
    "    print(f'X_curr.shape = {X_curr.shape}')\n",
    "    print(f'predict curr veckans_rad.shape = {veckans_rad.shape}')\n",
    "    temp = veckans_rad.copy().drop(['datum', 'avd', 'y'], axis=1)\n",
    "    print(f'predict curr temp.shape = {temp.shape}  - columns:')\n",
    "    # print(temp.columns)\n",
    "    \n",
    "    for key, values in meta_modeller.items():\n",
    "        print(f'{key} predicts')\n",
    "        meta_model = values['model']\n",
    "\n",
    "        # PREDICTORS???\n",
    "        if 'ridg' in key:\n",
    "            veckans_rad[key] = meta_model.predict(temp)\n",
    "        else:    \n",
    "            veckans_rad[key] = meta_model.predict_proba(temp)[:, 1]\n",
    "        \n",
    "    return veckans_rad\n",
    "\n",
    "\n",
    "def learn_all_and_predict(modeller, meta_modeller, X, y, X_meta, y_meta, X_curr, y_curr):\n",
    "    \"\"\"Learn alla modeller och meta_modeller och g√∂r prediktioner p√• X_curr\"\"\"\n",
    "\n",
    "    # display(X.shape)\n",
    "\n",
    "    # Learn modeller part och skapa stack_data\n",
    "    stack_data = first_learn_modeller(modeller, X, y, X_meta, y_meta)\n",
    "    assert 'y' in stack_data.columns, 'y is missing in stack_data'\n",
    "    stack_data.to_csv('first_stack_data.csv', index=False)\n",
    "    \n",
    "    # Learn meta_modeller p√• stack_data\n",
    "    meta_modeller = learn_meta_models(meta_modeller, stack_data)\n",
    "    # Learn modeller p√• allt utom X_curr, y_curr\n",
    "    modeller = final_learn_modeller(modeller, X, y, X_meta, y_meta)\n",
    "\n",
    "    # fyll i curr_stack and predict current omg√•ng\n",
    "    # curr_stack = pd.DataFrame()\n",
    "    # curr_stack['y'] = y_curr\n",
    "    # for model in modeller:\n",
    "    #     curr_stack = skapa_stack_data(model, model.name, X_curr, curr_stack)\n",
    "    #     # for key, values in meta_modeller.items():\n",
    "    #     #     meta_model = values['model']\n",
    "    \n",
    "        \n",
    "    # # Vilka predictors skall vi ha i learn_meta_models? Det m√•ste vara samm h√§r.\n",
    "    \n",
    "    veckans_rad = predict_curr_omgang(modeller, meta_modeller, X_curr, y_curr)\n",
    "\n",
    "    return veckans_rad\n",
    "\n",
    "\n",
    "def backtest(df, df_resultat, modeller, meta_modeller, datumar, gap=0, proba_val=0.6, base_ix=100, meta_ix=150, cv=False, step=1):\n",
    "    \"\"\" Backtesting anpassad f√∂r travets omg√•ngar, dvs datum istf dagar\"\"\"\n",
    "    global last_row\n",
    "    global vinst, utdelning, kostnad, sjuor, sexor, femmor\n",
    "    assert base_ix < meta_ix, f'base_ix ({base_ix}) m√•ste vara mindrea √§n meta_ix ({meta_ix})'\n",
    "    \"placeholder0 = st.empty()\"\n",
    "    \"placeholder1 = st.empty()\"\n",
    "    \"placeholder2 = st.empty()\"\n",
    "    \"placeholder3 = st.empty()\"\n",
    "\n",
    "    df_utdelning = pd.read_csv('utdelning.csv')\n",
    "\n",
    "    for curr_datum_ix in range(base_ix, len(datumar), step):\n",
    "        datum = datumar[curr_datum_ix]\n",
    "        # placeholder0.empty()\n",
    "        display(\n",
    "            f'Aktuell datum: {datum} {\"        \"} \\nant_omg√•ngar spelade: {curr_datum_ix}')\n",
    "\n",
    "        X, y, X_meta, y_meta, X_curr, y_curr = skapa_data_f√∂r_datum(df, datum)\n",
    "        if X.empty or X_meta.empty or X_curr.empty:\n",
    "            break\n",
    "\n",
    "        print(f'learn fram till {datum}')\n",
    "        veckans_rad = learn_all_and_predict(modeller, meta_modeller, X, y, X_meta, y_meta, X_curr, y_curr)\n",
    "    \n",
    "        assert cv == False, 'cv==True not implemented'\n",
    "\n",
    "        spik_strategier = ['1a', '1b', '2b', None]\n",
    "        kelly_strategier = [None, None,  1,    1]\n",
    "\n",
    "        # ta fram rader och r√§tta dem\n",
    "        femmor, sexor, sjuor, utdelning, kostnad, vinst = [], [], [], [], [], []\n",
    "        last_row = df_resultat.iloc[-1]\n",
    "        for enum,strategi in enumerate(spik_strategier):\n",
    "            veckans_rad, cost = ta_fram_meta_rad(\n",
    "                veckans_rad, meta_modeller, spik_strategier[enum], kelly_strategier[enum], min_avst=0.178)\n",
    "            kostnad.append(cost)\n",
    "            sju, sex, fem, utd = r√§tta_rad(veckans_rad, datum, df_utdelning)\n",
    "            sjuor.append(int(sju))\n",
    "            sexor.append(int(sex))\n",
    "            femmor.append(int(fem))\n",
    "            utdelning.append(int(utd))\n",
    "            vinst.append(utdelning[enum] - kostnad[enum])\n",
    "\n",
    "        last_row += vinst + utdelning + kostnad + sjuor + sexor + femmor\n",
    "        df_resultat.loc[datum] = last_row\n",
    "\n",
    "        df_resultat.to_csv('backtest_resultat.csv', index=True)\n",
    "\n",
    "        # 3. plotta\n",
    "        graf_data = df_resultat.copy()\n",
    "\n",
    "        # graf_data.index = pd.to_datetime(graf_data.index, format=\"%Y-%m-%d\")\n",
    "\n",
    "        \"placeholder1.empty()\"\n",
    "        \"placeholder2.empty()\"\n",
    "        \"placeholder3.empty()\"\n",
    "\n",
    "        # Backtest klart och nu plot\n",
    "        # placeholder1.line_chart(graf_data[[\n",
    "        #                         't1_vinst', 't2_vinst', 't3_vinst', 't4_vinst']], use_container_width=True)\n",
    "        # placeholder2.line_chart(graf_data[[\n",
    "        #                         't1_7', 't2_7', 't3_7', 't4_7']], width=16, height=14, use_container_width=True)\n",
    "\n",
    "        # st.write(df_resultat.plot(kind='line',  y='t1_vinst', rot=45, legend=True, figsize=(20,10)))\n",
    "        display(df_resultat.sort_index(ascending=False).head(40))\n",
    "\n",
    "        assert False, 'stoppa n√§r en omg√•ng √§r klar'\n",
    "    return df_resultat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def k√∂r(df, modeller, meta_modeller, cv=False):\n",
    "\n",
    "    base_ix = 100  # antal omg√•ngar som vi startar bas-modellerna fr√•n i backtesting\n",
    "    meta_ix = 150  # antal omg√•ngar som vi startar meta-modellerna fr√•n i backtesting\n",
    "\n",
    "    ##################################################################################\n",
    "    # Best√§m i f√∂rv√§g vilka predictors som varje meta-model skall anv√§nda?           #\n",
    "    # Best√§m ocks√• spik-strategi och kelly-strategi f√∂r varje meta-model             #\n",
    "    # Kanske en dict √§r bra?                                                         #\n",
    "    ##################################################################################\n",
    "\n",
    "    datumar, df_resultat = starta_upp(df, base_ix)\n",
    "\n",
    "    # backtesting\n",
    "    df_resultat = backtest(df, df_resultat, modeller, meta_modeller,\n",
    "                           datumar, gap=0, proba_val=0.6, base_ix=base_ix, meta_ix=meta_ix, cv=cv, step=1)\n",
    "\n",
    "    return df_resultat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k√∂r main() h√§r - bortkommenterat f√∂r ipynb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # Skapa v75-instans\n",
    "    v75 = td.v75(pref=pref)\n",
    "    # H√§mta data fr√•n v75\n",
    "    _ = v75.f√∂rbered_data(missing_num=False)  # num hanteras av catboost\n",
    "    df = v75.test_l√§gg_till_kolumner()\n",
    "\n",
    "    ###############################################################\n",
    "    # N√•gra id√©er p√• nya kolumner:\n",
    "    #  -   ‚ùå streck/sum(streck f√∂r avd) - fungerar inte bra. N√§stan alla sum == 100 per avd\n",
    "    #  a - ‚úîÔ∏è plats(streck)/ant_h√§star_i_avd (antal startande h√§star i avd)\n",
    "    #  b - ‚ùå pris / tot_pris_i_avd - g√•r inte att anv√§nda ju! pris √§r ju loppets 1.pris - samma f√∂r all i loppet\n",
    "    #  c - ‚úîÔ∏è kr / tot_kr_i_avd     rel_kr\n",
    "    #  d - ‚úîÔ∏è Avst√•ndet till ettan (streck)\n",
    "    #  e - ‚úîÔ∏è hx_bana samma som bana\n",
    "    #  f - ‚úîÔ∏è hx_kusk samma som kusk\n",
    "    #  META\n",
    "    #  g - meta f√•r annan input √§n bara typ-resultat, tex, plats i avd, ettans avst√•nd till tv√•an\n",
    "    #\n",
    "    # N√•gra id√©er p√• regler f√∂r att selektera raden:\n",
    "    #  1 - 1 avd med favorit som spik\n",
    "    #  2 - 2 avd med var sin favorit som spik\n",
    "    #  3 - Endast solklara favoriter - beror p√• avst√•ndet till tv√•an\n",
    "    #  4 - Inga forcerade favoriter\n",
    "    #  5 - V√§lj den h√∂gsta positiva Kelly efter vald proba - om vartannat\n",
    "    ###############################################################\n",
    "    #  Minska max-kostnad f√∂r en rad  - 384 √§r f√∂r mycket\n",
    "    ###############################################################\n",
    "    # Anv√§nd typ9 som grund-modell och l√§gg till resp ta bort kolumner per test-typ\n",
    "    # genererara alla kolumner som vi sedan selekterar fr√•n\n",
    "    # Namnge modeller efter konfig samt selektering tex typ_abcdef235\n",
    "\n",
    "    # -------------- skapa test-modeller\n",
    "    #              name,   ant_h√§star  proba,  kelly,   motst_ant,  motst_diff,  ant_favoriter,  only_clear, streck, test, pref\n",
    "    test1 = tp.Typ('test1',  True,    True,     False,       0,\n",
    "                   False,          0,           False,    True,  True, pref=pref)\n",
    "    test2 = tp.Typ('test2',  True,    True,     False,       0,\n",
    "                   False,          0,           False,    False, True, pref=pref)\n",
    "    test3 = tp.Typ('test3',  True,    True,     False,       0,\n",
    "                   False,          0,           False,    False, True, pref=pref)\n",
    "    test4 = tp.Typ('test4',    True,    True,     False,       0,\n",
    "                   False,          0,           False,    True,  False, pref=pref)\n",
    "\n",
    "    modeller=[test1, test2, test3, test4]\n",
    "    \n",
    "    ##### RandomForestClassifier\n",
    "    with open(pref+'optimera/params_meta1_rf.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "        rf_params=params['params']\n",
    "    rf_model = RandomForestClassifier(**rf_params, n_jobs=6, random_state=2022)\n",
    "    \n",
    "    ##### RidgeClassifier\n",
    "    with open(pref+'optimera/params_meta2_ridge.json', 'r') as f:\n",
    "        ridge_params = json.load(f)['params']\n",
    "        # st.write(params)\n",
    "    ridge_model = RidgeClassifier(**ridge_params,random_state=2022)\n",
    "    \n",
    "    ##### KNN classifier\n",
    "    with open(pref+'optimera/params_meta3_knn.json', 'r') as f:\n",
    "        knn_params = json.load(f)['params']\n",
    "    KNN_model = KNeighborsClassifier(**knn_params, n_jobs=6)\n",
    "    \n",
    "    meta_modeller = {'meta1_rf'   :{'model':rf_model, 'params':rf_params},\n",
    "                     'meta2_ridge':{'model':ridge_model, 'params':ridge_params},\n",
    "                     'meta3_knn'  :{'model':KNN_model, 'params':knn_params}\n",
    "                     }\n",
    "    \n",
    "\n",
    "    # if st.button('k√∂r'):\n",
    "    #     if st.button('med cv'):\n",
    "    #         st.warning(f'df_resultat = k√∂r(df, modeller, cv=True)  √§r inte klar!')\n",
    "    #     else:\n",
    "    df_resultat = k√∂r(df, modeller, meta_modeller, cv=False)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # main()\n",
    "    print('k√∂r main() h√§r - bortkommenterat f√∂r ipynb')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../all_data.csv\n",
      "Loading dataframe from the file: ../all_data.csv\n",
      "streck: True i init\n",
      "streck: False i init\n",
      "streck: False i init\n",
      "streck: True i init\n",
      "st.info(f'Startdatum = {startdatum}'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Aktuell datum: 2016-06-11          \\nant_omg√•ngar spelade: 100'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn fram till 2016-06-11\n",
      "Learning test1\n",
      "Sparar test1.model\n",
      "Loading model: test1\n",
      "X_meta.shape = (38736, 77) this_proba.shape=(38736,)\n",
      "stack_data.shape = (38736, 79)\n",
      "Learning test2\n",
      "Sparar test2.model\n",
      "Loading model: test2\n",
      "drop streck\n",
      "X_meta.shape = (38736, 77) this_proba.shape=(38736,)\n",
      "stack_data.shape = (38736, 80)\n",
      "Learning test3\n",
      "Sparar test3.model\n",
      "Loading model: test3\n",
      "drop streck\n",
      "X_meta.shape = (38736, 77) this_proba.shape=(38736,)\n",
      "stack_data.shape = (38736, 81)\n",
      "Learning test4\n",
      "Sparar test4.model\n",
      "Loading model: test4\n",
      "X_meta.shape = (38736, 77) this_proba.shape=(38736,)\n",
      "stack_data.shape = (38736, 82)\n",
      "Learn meta_modeller p√• stack_data\n",
      "Done Learn meta_modeller p√• stack_data\n",
      "Final_learn modeller\n",
      "X_train.shape = (46866, 77) X.shape = (8130, 77), X_meta.shape = (38736, 77)\n",
      "Learning test1\n",
      "Sparar test1.model\n",
      "Learning test2\n",
      "Sparar test2.model\n",
      "Learning test3\n",
      "Sparar test3.model\n",
      "Learning test4\n",
      "Sparar test4.model\n",
      "Done Final_learn modeller\n",
      "Loading model: test1\n",
      "X_meta.shape = (84, 77) this_proba.shape=(84,)\n",
      "stack_data.shape = (84, 79)\n",
      "Loading model: test2\n",
      "drop streck\n",
      "X_meta.shape = (84, 77) this_proba.shape=(84,)\n",
      "stack_data.shape = (84, 80)\n",
      "Loading model: test3\n",
      "drop streck\n",
      "X_meta.shape = (84, 77) this_proba.shape=(84,)\n",
      "stack_data.shape = (84, 81)\n",
      "Loading model: test4\n",
      "X_meta.shape = (84, 77) this_proba.shape=(84,)\n",
      "stack_data.shape = (84, 82)\n",
      "X_curr.shape = (84, 77)\n",
      "predict curr veckans_rad.shape = (84, 82)\n",
      "predict curr temp.shape = (84, 79)  - columns:\n",
      "meta1_rf predicts\n",
      "meta2_ridge predicts\n",
      "meta3_knn predicts\n",
      "spik_strategi 1a\n",
      "avst 0.053912250942609166\n",
      "strategi a valde spik i avd 3.0\n",
      "Antal r√§tt 5\n",
      "spik_strategi 1b\n",
      "avst 0.053912250942609166\n",
      "Antal r√§tt 5\n",
      "spik_strategi 2b\n",
      "avst 0.053912250942609166\n",
      "avst 0.05765145152631852\n",
      "Antal r√§tt 5\n",
      "Antal r√§tt 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1_vinst</th>\n",
       "      <th>t2_vinst</th>\n",
       "      <th>t3_vinst</th>\n",
       "      <th>t4_vinst</th>\n",
       "      <th>t1_utd</th>\n",
       "      <th>t2_utd</th>\n",
       "      <th>t3_utd</th>\n",
       "      <th>t4_utd</th>\n",
       "      <th>t1_kostn</th>\n",
       "      <th>t2_kostn</th>\n",
       "      <th>t3_kostn</th>\n",
       "      <th>t4_kostn</th>\n",
       "      <th>t1_7</th>\n",
       "      <th>t2_7</th>\n",
       "      <th>t3_7</th>\n",
       "      <th>t4_7</th>\n",
       "      <th>t1_6</th>\n",
       "      <th>t2_6</th>\n",
       "      <th>t3_6</th>\n",
       "      <th>t4_6</th>\n",
       "      <th>t1_5</th>\n",
       "      <th>t2_5</th>\n",
       "      <th>t3_5</th>\n",
       "      <th>t4_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-11</th>\n",
       "      <td>-88</td>\n",
       "      <td>-48</td>\n",
       "      <td>-48</td>\n",
       "      <td>-48</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>256</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t1_vinst  t2_vinst  t3_vinst  t4_vinst  t1_utd  t2_utd  t3_utd  t4_utd  t1_kostn  t2_kostn  t3_kostn  t4_kostn  t1_7  t2_7  t3_7  t4_7  t1_6  t2_6  t3_6  t4_6  t1_5  t2_5  t3_5  t4_5\n",
       "datum                                                                                                                                                                                             \n",
       "2016-06-11       -88       -48       -48       -48     168     168     168     168       256       216       216       216     0     0     0     0     0     0     0     0     4     4     4     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "stoppa n√§r en omg√•ng √§r klar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4520\\1498329987.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_resultat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_resultat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4520\\1494728060.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m#         st.warning(f'df_resultat = k√∂r(df, modeller, cv=True)  √§r inte klar!')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m#     else:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mdf_resultat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk√∂r\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodeller\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_modeller\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4520\\2037002664.py\u001b[0m in \u001b[0;36mk√∂r\u001b[1;34m(df, modeller, meta_modeller, cv)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# backtesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     df_resultat = backtest(df, df_resultat, modeller, meta_modeller,\n\u001b[0m\u001b[0;32m     16\u001b[0m                            datumar, gap=0, proba_val=0.6, base_ix=base_ix, meta_ix=meta_ix, cv=cv, step=1)\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4520\\2076629155.py\u001b[0m in \u001b[0;36mbacktest\u001b[1;34m(df, df_resultat, modeller, meta_modeller, datumar, gap, proba_val, base_ix, meta_ix, cv, step)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_resultat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stoppa n√§r en omg√•ng √§r klar'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_resultat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: stoppa n√§r en omg√•ng √§r klar"
     ]
    }
   ],
   "source": [
    "df_resultat = main()\n",
    "df_resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENC\n",
    "meta_modeller = {'meta1_rf'   :{'model':'rf_model', 'params':'rf_params'},\n",
    "                 'meta2_ridge':{'model':'ridge_model', 'params':'ridge_params'},\n",
    "                 'meta3_knn'  :{'model':'KNN_model', 'params':'knn_params'}\n",
    "                }\n",
    "    \n",
    "\n",
    "\n",
    "pd.DataFrame(meta_modeller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-88.0, -48.0, -48.0, -48.0, 168.0, 168.0, 168.0, 168.0, 256.0, 216.0, 216.0, 216.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 4.0, 4.0]\n",
      "[-88.0, -48.0, -48.0, -48.0] [168, 168, 168, 168] [256.0, 216.0, 216.0, 216.0] [0, 0, 0, 0] [0, 0, 0, 0] [4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "print(list(last_row))\n",
    "print(vinst, utdelning, kostnad, sjuor, sexor, femmor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d733caf4ffc39d0fbd9a2ba54ef4b7d515956d8048931f8241efe3827fb2d1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
