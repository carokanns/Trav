{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "pd.set_option('display.width', 260)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 80)\n",
    "from category_encoders import TargetEncoder\n",
    "from IPython.display import display\n",
    "\n",
    "pref='../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class v75():\n",
    "    def __init__(self, filnamn='all_data.csv', pref=''):\n",
    "        self.pref=pref\n",
    "        self.filnamn = pref+filnamn\n",
    "        self.df = self.load_df()\n",
    "        self.work_df = self.df.copy()\n",
    "        \n",
    "    \n",
    "    def _remove_features(self,remove=['startnr', 'vodds', 'podds', 'bins', 'h1_dat',\n",
    "                'h2_dat', 'h3_dat', 'h4_dat', 'h5_dat']):                 # use in prepare_data()\n",
    "        \n",
    "        self.work_df.drop(remove, axis=1, inplace=True)\n",
    "    \n",
    "        return self.work_df\n",
    "           \n",
    "    def prepare_data(self): # This is the general preparation of data\n",
    "        # remove omgångar som saknar avdelningar\n",
    "        saknas = ['2015-08-15', '2016-08-13', '2017-08-12']\n",
    "        self.work_df = self.work_df[~self.work_df.datum.isin(saknas)]\n",
    "    \n",
    "        # remove_number_from_hx_bana (i.e Åby-1 -> Åby, etc)\n",
    "        self.work_df['h1_bana'] = self.work_df.h1_bana.str.split('-').str[0]\n",
    "        self.work_df['h2_bana'] = self.work_df.h2_bana.str.split('-').str[0]\n",
    "        self.work_df['h3_bana'] = self.work_df.h3_bana.str.split('-').str[0]\n",
    "        self.work_df['h4_bana'] = self.work_df.h4_bana.str.split('-').str[0]\n",
    "        self.work_df['h5_bana'] = self.work_df.h5_bana.str.split('-').str[0]\n",
    "        \n",
    "        # lower case for häst, bana, kusk and hx_bana\n",
    "        for f in ['häst','bana', 'kusk', 'h1_kusk', 'h2_kusk', 'h3_kusk', 'h4_kusk', 'h5_kusk', 'h1_bana', 'h2_bana', 'h3_bana', 'h4_bana', 'h5_bana']:\n",
    "            self.work_df[f] = self.work_df[f].str.lower()\n",
    "        \n",
    "        _=self._remove_features()\n",
    "        \n",
    "        return self.work_df       \n",
    "\n",
    "    def concat(self, ny_df):\n",
    "        features = list(self.df.columns)\n",
    "        assert set(features) == set(list(ny_df.columns)), 'Features in ny_df is not the same as in self.df'\n",
    "        assert features == list(ny_df.columns), 'Features in ny_df and self.df are not equal'\n",
    "        \n",
    "        self.df = pd.concat([self.df, ny_df], axis=0)\n",
    "        self.work_df = self.df.copy()\n",
    "        return self.df\n",
    "    \n",
    "    def train_test_split(self, test_size=0.2):\n",
    "        datumar=self.work_df.datum.unique()\n",
    "        antal = len(datumar)\n",
    "        antal_train = int(antal*(1-test_size))\n",
    "        datum_train = datumar[:antal_train]\n",
    "        print('Antal train datum: ', antal_train)\n",
    "        print('Antal test datum: ', antal-antal_train)\n",
    "        print('Antal datum totalt: ', antal)\n",
    "    \n",
    "        X_train = self.work_df[self.work_df.datum.isin(datum_train)]\n",
    "        X_test = self.work_df[~self.work_df.datum.isin(datum_train)]\n",
    "        \n",
    "        y_train = (X_train.pop('plac')==1) * 1   # make plac=(0,1) instead of true/false (for catboost)\n",
    "        y_test = (X_test.pop('plac')==1) * 1      # make plac=(0,1) instead of true/false (for catboost)\n",
    "        \n",
    "        assert round(len(X_test)/(len(X_train)+len(X_test)),2) == test_size, f'{round(len(X_test)/(len(X_train)+len(X_test)),2)} Test size is not correct'\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def load_df(self):\n",
    "        self.df = pd.read_csv(self.filnamn)\n",
    "        return self.df\n",
    "    \n",
    "    def save_df(self):\n",
    "        self.df.to_csv(self.filnamn, index=False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal train datum:  440\n",
      "Antal test datum:  110\n",
      "Antal datum totalt:  550\n"
     ]
    }
   ],
   "source": [
    "v75_obj = v75(pref='../')\n",
    "v75_obj.prepare_data()\n",
    "X_train, X_test, y_train, y_test = v75_obj.train_test_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avd', 'streck', 'kr', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'pris', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_spår', 'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4']\n",
      "['datum', 'bana', 'häst', 'kusk', 'kön', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana', 'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']\n",
      "bana 32\n",
      "kusk 1032\n",
      "häst 8744\n",
      "h1_bana 119\n",
      "h2_bana 119\n",
      "h3_bana 122\n",
      "h4_bana 125\n",
      "h5_bana 136\n",
      "h1_kusk 1524\n",
      "h2_kusk 1594\n",
      "h3_kusk 1665\n",
      "h4_kusk 1771\n",
      "h5_kusk 1820\n"
     ]
    }
   ],
   "source": [
    "numeric_features = list(X_train.select_dtypes(include=['int64', 'float64']).columns)\n",
    "cat_features = list(X_train.select_dtypes(include=['object']).columns)\n",
    "print(numeric_features)\n",
    "print(cat_features)\n",
    "print('bana',len(X_train.bana.unique()))\n",
    "print('kusk',len(X_train.kusk.value_counts()))\n",
    "print('häst',len(X_train.häst.value_counts()))\n",
    "print('h1_bana',len(X_train.h1_bana.unique()))\n",
    "print('h2_bana',len(X_train.h2_bana.value_counts()))\n",
    "print('h3_bana',len(X_train.h3_bana.value_counts()))\n",
    "print('h4_bana',len(X_train.h4_bana.value_counts()))\n",
    "print('h5_bana',len(X_train.h5_bana.value_counts()))\n",
    "print('h1_kusk',len(X_train.h1_kusk.value_counts()))\n",
    "print('h2_kusk',len(X_train.h2_kusk.value_counts()))\n",
    "print('h3_kusk',len(X_train.h3_kusk.value_counts()))\n",
    "print('h4_kusk',len(X_train.h4_kusk.value_counts()))\n",
    "print('h5_kusk',len(X_train.h5_kusk.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bana 31\n",
      "kusk 188\n",
      "häst 8744\n",
      "h1_bana 87\n",
      "h2_bana 93\n",
      "h3_bana 91\n",
      "h4_bana 96\n",
      "h5_bana 95\n",
      "h1_kusk 242\n",
      "h2_kusk 249\n",
      "h3_kusk 259\n",
      "h4_kusk 253\n",
      "h5_kusk 257\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "enc = TargetEncoder(cols=['bana','kusk','kön','h1_kusk','h2_kusk','h3_kusk','h4_kusk','h5_kusk','h1_bana','h2_bana','h3_bana','h4_bana','h5_bana',    ]).fit(X_train, y_train)\n",
    "X_train=enc.fit_transform(X_train, y_train)\n",
    "X_test = enc.transform(X_test)\n",
    "# X_train.info()\n",
    "print('bana',len(X_train.bana.unique()))\n",
    "print('kusk',len(X_train.kusk.value_counts()))\n",
    "print('häst',len(X_train.häst.value_counts()))\n",
    "print('h1_bana',len(X_train.h1_bana.unique()))\n",
    "print('h2_bana',len(X_train.h2_bana.value_counts()))\n",
    "print('h3_bana',len(X_train.h3_bana.value_counts()))\n",
    "print('h4_bana',len(X_train.h4_bana.value_counts()))\n",
    "print('h5_bana',len(X_train.h5_bana.value_counts()))\n",
    "print('h1_kusk',len(X_train.h1_kusk.value_counts()))\n",
    "print('h2_kusk',len(X_train.h2_kusk.value_counts()))\n",
    "print('h3_kusk',len(X_train.h3_kusk.value_counts()))\n",
    "print('h4_kusk',len(X_train.h4_kusk.value_counts()))\n",
    "print('h5_kusk',len(X_train.h5_kusk.unique()))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d733caf4ffc39d0fbd9a2ba54ef4b7d515956d8048931f8241efe3827fb2d1f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
