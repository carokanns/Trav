#%%
import matplotlib.pyplot as plt
import datetime as dt
import sys
sys.path.append('C:\\Users\\peter\\Documents\\MyProjects\\PyProj\\Trav\\spel')
import typ as tp
from IPython.display import display
import pandas as pd
import numpy as np
import pickle
import streamlit as st
from category_encoders import TargetEncoder
from catboost import CatBoostClassifier, Pool

import travdata as td
import concurrent.futures
import time
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
pref = ''

import skapa_modeller as mod

plt.style.use('fivethirtyeight')

pd.set_option('display.max_colwidth', None)
pd.set_option('display.width', 260)
pd.set_option('display.max_columns', 200)
pd.set_option('display.max_rows', 120)

import logging
logging.basicConfig(level=logging.INFO, filemode='w' , filename='v75.log', force=True, encoding='utf-8', format='Backtest: %(asctime)s - %(levelname)s - %(lineno)d - %(message)s ')
logging.info('***************** Startar *******************')
   
st.set_page_config(page_title="Backtesting av L1 + L2", page_icon="üí™")

st.markdown("# üí™ Backtesting av modeller + meta")
st.sidebar.header("üí™ Backtesting")

#%%
exp = st.expander('Beskrivning av testet')
exp.write("""
## F√∂rst L1-modellerna
S√§tt start_datum tex start_datum = '2016-08-01.    

0. Varje modell har indivduella kolumner samt strategi f√∂r att ta fram raden.  
    a. Speca per modell i Typ-klassen.
1. Loop √∂ver veckor. Learn fram till aktuell vecka och spara modell.  
    a. Skit i cv tillsvidare
    b. Ev Spara modell med aktuell datum i namnet.
2. Predict n√§sta vecka (generera rad enl modellens strategi)
3. R√§tta, H√§mta ev priser och Spara resultat som en df i en csv-fil.
4. plot resultat
5. Repeat f√∂r varje modell och strategi 

## G√∂r detsamma f√∂r meta-modeller (rf, knn, ridge)
- Anv√§nd sparade L1-modeller och generara stack-data fr√•n start_datum till aktuell_datum  
- L√§r upp L2-modeller p√• stack-data, anv√§nd strategins hyperparms 
- Hur vet vi hur l√§nge meta-modellen skall k√∂ra?  
    - Kanske g√∂ra ett test innan p√• ganska stor test-data och spara som hyperparm
- Predict n√§sta vecka enl strategi f√∂r resp L2_modell skapa kolumnerna 'proba_cat1L2', etc  

- Ber√§kna viktade meta_v√§rden fr√•n L2-modellernas output ('proba_cat1L2', etc)
- Ta medelv√§rdet av L2-modelerna aritmetiskt eller gemoetriskt
- R√§tta och spara resultat plus ev priser
- plot resultat
- Repeat f√∂r varje meta-modell

"""
          )

def log_print(text, logging_level='d'):
    """Skriver ut p√• loggen och g√∂r en print samt returnerar str√§ngen (f√∂r assert)"""
    if logging_level == 'd':
        logging.debug(text)
    else:
        if logging_level == 'i':
            logging.info(text)
        elif logging_level == 'w':
            logging.warning(text)
        elif logging_level == 'e':
            logging.error(text)
        print(text)

    return text

# %%
def compute_total_insats(veckans_rad):
    summa = veckans_rad.groupby('avd').avd.count().prod() / 2
    return summa

def starta_upp(df, start_ix=220):
    import datetime

    startdatum = df.datum.unique()[start_ix]

    st.info(f'Startdatum = {startdatum}')

    # init resutat-tabell
    df_resultat = pd.DataFrame(columns=['datum', 't1_vinst', 't2_vinst', 't3_vinst', 't4_vinst',
                                                 't1_utd',   't2_utd',   't3_utd',   't4_utd',
                                                 't1_kostn', 't2_kostn', 't3_kostn', 't4_kostn',
                                                 't1_7', 't2_7', 't3_7', 't4_7',
                                                 't1_6', 't2_6', 't3_6', 't4_6',
                                                 't1_5', 't2_5', 't3_5', 't4_5'
                                        ])

    df_resultat.set_index('datum', drop=True, inplace=True)
    # print(df_resultat.head(0))
    df_resultat.loc[startdatum] = [0, 0, 0, 0, 0, 0,
                                   0, 0, 0, 0, 0, 0,
                                   0, 0, 0, 0, 0, 0,
                                   0, 0, 0, 0, 0, 0]
    # for all columns except datum make int
    for col in df_resultat.columns:
        if col != 'datum':
            df_resultat[col] = df_resultat[col].astype(int)

    return df.datum.unique(), df_resultat

# %%
def skapa_data_f√∂r_datum(df_, curr_datum_ix, frac=0.5):
    df = df_.copy()
    datumar = df.datum.unique()
    curr_datum = datumar[curr_datum_ix]
    base_datum_ix = int(len(datumar[:curr_datum_ix]) * frac)  # base models

    base_datum = datumar[base_datum_ix]
    X_train = df.query(f'datum < @base_datum')
    y_train = X_train.y
    X_train = X_train.drop('y', axis=1)

    X_meta = df.query(f'datum >= @base_datum and datum < @curr_datum')
    y_meta = X_meta.y
    X_meta = X_meta.drop('y', axis=1)

    X_curr = df.query(f'datum == @curr_datum')
    y_curr = X_curr.y
    X_curr = X_curr.drop(['y'], axis=1)

    return X_train, y_train, X_meta, y_meta, X_curr, y_curr

# %%
def compute_total_insats(veckans_rad):
    summa = veckans_rad.groupby('avd').avd.count().prod() / 2
    return summa

def varje_avd_minst_en_h√§st(veckans_rad):
    # ta ut en h√§st i varje avd - markera valda i df
    for avd in veckans_rad.avd.unique():
        # max av proba i veckans_rad
        max_proba = veckans_rad[veckans_rad.avd == avd]['proba'].max()
        veckans_rad.loc[(veckans_rad.avd == avd) & (
            veckans_rad.proba == max_proba), 'v√§lj'] = True
    return veckans_rad

# %%
def hitta_spikar(veckans_rad, spikad_avd, spik_strategi, min_avst):
    print('spik_strategi', spik_strategi)
    if spik_strategi == None:
        return veckans_rad, []

    assert spik_strategi in [
        '1a', '1b', '2a', '2b'], "spik_strategi m√•ste ha n√•got av v√§rdena i listan"

    # avdelningar med st√∂rsta avst√•nd
    avd_avst = []
    for avd in [1, 2, 3, 4, 5, 6, 7]:
        tv√•_b√§sta = veckans_rad.query('avd == @avd').nlargest(2, 'proba')
        avd_avst.append(tv√•_b√§sta.proba.values[0] - tv√•_b√§sta.proba.values[1])

    # print('avst√•nd',avd_avst)

    # index to the two largest values
    max1 = max(avd_avst)
    avd1 = avd_avst.index(max1)+1
    max2 = max([x for x in avd_avst if x != max1])
    avd2 = avd_avst.index(max2)+1

    if spik_strategi == '1a':
        print('strategi', spik_strategi, 'valde forcerad spik i avd', avd1)
        spikad_avd.append(avd1)      # add avd to a list
        ix = veckans_rad.query('avd == @avd1').nlargest(1,
                                                        'proba').index[0]   # ix for largest in avd
        veckans_rad.loc[ix, ['spik']] = True
        veckans_rad.loc[ix, ['v√§lj']] = True

    elif spik_strategi == '1b':
        if max1 <= min_avst:
            print('strategi', spik_strategi,
                  'inte vald d√• avst', max1, '< min', min_avst)
            return veckans_rad, []

        print('strategi', spik_strategi, 'valde spik i avd',
              avd1,  'd√• avst', max1, '> min', min_avst)
        spikad_avd.append(avd1)      # add avd to a list
        ix = veckans_rad.query('avd == @avd1').nlargest(1,
                                                        'proba').index[0]   # ix for largest in avd
        veckans_rad.loc[ix, ['spik']] = True
        veckans_rad.loc[ix, ['v√§lj']] = True

    elif spik_strategi == '2a':
        print('strategi', spik_strategi, 'valde forcerad spik i avd', avd1)
        spikad_avd.append(avd1)      # add avd to a list
        ix = veckans_rad.query('avd == @avd1').nlargest(1,
                                                        'proba').index[0]   # ix for largest in avd
        veckans_rad.loc[ix, ['spik']] = True
        veckans_rad.loc[ix, ['v√§lj']] = True
        print('strategi', spik_strategi, 'valde 2:a forcerad spik i avd', avd2)
        spikad_avd.append(avd2)      # add avd to a list
        ix = veckans_rad.query('avd == @avd2').nlargest(1,
                                                        'proba').index[0]   # ix for largest in avd
        veckans_rad.loc[ix, ['spik']] = True
        veckans_rad.loc[ix, ['v√§lj']] = True

    elif spik_strategi == '2b':
        if max1 <= min_avst:
            print('strategi', spik_strategi,
                  'inget valt d√• avst', max1, '< min', min_avst)
            return veckans_rad, []

        print('strategi', spik_strategi, 'valde spik i avd',
              avd1,  'd√• avst', max1, '> min', min_avst)
        spikad_avd.append(avd1)      # add avd to a list
        ix = veckans_rad.query('avd == @avd1').nlargest(1, 'proba').index[0]
        veckans_rad.loc[ix, ['spik']] = True
        veckans_rad.loc[ix, ['v√§lj']] = True

        if max2 <= min_avst:
            print(print('strategi', spik_strategi,
                  '2:an inte vald d√• avst', max2, '< min', min_avst))
            return veckans_rad, spikad_avd

        print('strategi', spik_strategi, 'valde 2:a spik i avd',
              avd2,  'd√• avst', max2, '> min', min_avst)
        spikad_avd.append(avd2)      # add avd to a list
        ix = veckans_rad.query('avd == @avd2').nlargest(1, 'proba').index[0]
        veckans_rad.loc[ix, ['spik']] = True
        veckans_rad.loc[ix, ['v√§lj']] = True

    # print('spikad_avd', spikad_avd)

    return veckans_rad, spikad_avd

def plocka_en_efter_en(veckans_rad, spikad_avd, max_cost=300):
    """_summary_
    Args:
        veckans_rad (_type_): df att fylla
        spikad_avd (_type_): lista med spikade avdelningar
        max_cost (int, optional): Max kostnad. Defaults to 300.
    Returns:
        _type_: df med veckans rad samt kostnad
    """
    cost = 0.5  # 1 rad
    while cost < max_cost:
        # d) plocka en och en - f√∂rst proba sedan ev positiv kelly markera som valda i df
        curr_index = veckans_rad.query(
            "v√§lj==False and avd not in @spikad_avd").nlargest(1, 'proba').index
        veckans_rad.loc[curr_index, 'v√§lj'] = True
        # e) avbryt vid max_cost
        cost = compute_total_insats(veckans_rad.query("v√§lj==True"))
        if cost > max_cost:
            # ta tillbaks den sist spelade
            veckans_rad.loc[curr_index, 'v√§lj'] = False
            break

    cost = compute_total_insats(veckans_rad.query("v√§lj==True"))

    return veckans_rad, cost

def ta_fram_meta_rad(veckans_rad_, L2_modeller, strategi, max_cost=300, min_avst=0.07, mean='geometric'):
    """ Denna funktion tar fram en rad f√∂r meta-modellerna via medelv√§rdet p√• alla meta-modeller
    veckans_rad inneh√•ller _en omg√•ng_
    strategi: None - inget, vi f√•r se
    mean: 'arithmetic or geometric formula for mean
    """
    veckans_rad = veckans_rad_.copy()
    # veckans_rad['kelly_val'] = False
    veckans_rad['v√§lj'] = False   # inga rader valda √§nnu
    veckans_rad['spik'] = False   # inga spikar valda √§nnu

    veckans_rad['proba'] = 0
    # veckans_rad['kelly'] = 0

    ### H√§r tar vi medelv√§rdet av predict_proba fr√•n meta-modellerna ######
    for enum, key in enumerate(L2_modeller.keys()):
        if mean == 'arithmetic':
            veckans_rad['proba'] += veckans_rad[key]
            # veckans_rad['kelly'] += veckans_rad['kelly'+enum]
        else:
            if enum == 0:
                veckans_rad['proba'] = veckans_rad[key].copy()
                continue
            veckans_rad['proba'] *= veckans_rad[key]

    if mean == 'arithmetic':
        veckans_rad['proba'] /= len(L2_modeller)

    else:  # geometric
        veckans_rad['proba'] = veckans_rad['proba'] ** (1/len(L2_modeller))

    #################################################################

    veckans_rad = varje_avd_minst_en_h√§st(veckans_rad)

    spikad_avd = []
    if strategi:
        print('strategi ej klar')
    else:
        print('ingen spik-strategi')

    # sortera upp i proba-ordning. Om kelly skapa en sortering efter kelly-ordning
    veckans_rad = veckans_rad.sort_values(by=['proba'], ascending=False)
    veckans_rad = veckans_rad.reset_index(drop=True)

    # plocka en efter en tills kostnaden √§r f√∂r stor
    # return veckans_rad, cost
    return plocka_en_efter_en(veckans_rad, spikad_avd, max_cost)

# %%
def build_stack_data(modeller, X_meta, y_meta):
    """ Bygg stack_data inklusive ev Kelly
        X_meta:     inneh√•ller datum och avd men ej y
        stack_data: inneh√•ller 'allt' i slutet av funktionen
    """

    stack_data = X_meta.copy()
    stack_data['y'] = y_meta
    data = X_meta.copy()
    for model in modeller:
        this_proba = model.predict(data)
        nr = model.name[3:]
        # print(nr, 'data.shape', data.shape)
        # print(nr, 'stack_data.shape', stack_data.shape)
        stack_data['proba'+nr] = this_proba

    return stack_data

def prepare_stack_data(stack_data_, y, ENC=None):
    """Hantera missing values, NaN, etc f√∂r meta-modellerna"""
    assert 'y' not in stack_data_.columns, "y shouldn't be in stack_data"

    stack_data = stack_data_.copy()

    if ENC is None:
        # a new encode needs y
        assert y is not None, "y is needed for new encoding"
    else:
        # use the existing encoder - y is not used
        assert y is None, "y should be None for existing encoding"

    #""" Fyll i saknade numeriska v√§rden med 0"""
    numericals = stack_data.select_dtypes(exclude=['object']).columns
    stack_data[numericals] = stack_data[numericals].fillna(0)

    #""" Fyll i saknade kategoriska v√§rden med 'missing'"""
    categoricals = stack_data.select_dtypes(include=['object']).columns
    stack_data[categoricals] = stack_data[categoricals].fillna('missing')

    #""" Hantera high cardinality"""
    # cardinality_list=['h√§st','kusk','h1_kusk','h2_kusk','h3_kusk','h4_kusk','h5_kusk']

    #""" Target encoding"""
    target_encode_list = ['bana', 'h√§st', 'kusk', 'k√∂n', 'h1_kusk', 'h1_bana', 'h2_kusk', 'h2_bana',
                          'h3_kusk', 'h3_bana', 'h4_kusk', 'h4_bana', 'h5_kusk', 'h5_bana']

    if ENC == None:
        ENC = TargetEncoder(cols=target_encode_list,
                            min_samples_leaf=20, smoothing=10).fit(stack_data, y)

    # print('stack_data.shape = ', stack_data.shape)
    stack_data = ENC.transform(stack_data)

    # stack_data[target_encode_list] = stack_data_encoded[target_encode_list]  # update with encoded values
    return stack_data, ENC

def train_L1_models(L1_modeller, X_train, y_train):
    ############################################################################################################
    #                        H√§r g√∂rs en learn av modeller
    #                        - Learn modeller p√• X_train,y_train
    ############################################################################################################

    # features = X_train.drop(['datum','avd','y'], axis=1).columns.tolist()
    # X_train skall inneh√•lla datum och avd
    for model in L1_modeller:
        name = model.name
        print(f'Learn {name} {X_train.datum.min()} t.o.m {X_train.datum.max()}')
 
        # Learn(X_, y=None, X_test_=None, y_test=None, params=None, use_L2_features_=None, save=True)
        model.learn(X_train, y_train, params=None, save=True)

    return

############################################################################################################
#                       H√§r g√∂r vi learn av meta_modeller p√• stack_data
############################################################################################################

def train_L2_models(meta_modeller, stack_data, save=True):
    # global ENC
    # print('Learn meta_modeller p√• stack_data')
    assert 'y' in stack_data.columns, 'y is missing in stack_data'
    stack_data.head(10).to_csv('stack_data_f√∂re_drop.csv', index=False)
    y = stack_data.y.astype(int)
    meta_features = stack_data.drop(['datum', 'avd', 'y'], axis=1).columns.to_list()
    X_meta, ENC = prepare_stack_data(stack_data[meta_features], y)

    with open(pref+'modeller/test_encoder.pkl', 'wb') as f:
        pickle.dump(ENC, f)

    # X_meta.drop(['streck'], axis=1, inplace=True)

    y_meta = y
    # X_meta.to_csv('X_meta_Learn.csv', index=False)
    print(f'Learn meta {stack_data.datum.min()} - {stack_data.datum.max()}')
    # print(X_meta.columns)
    for key, items in meta_modeller.items():
        meta_model = items['model']

        items['model'] = meta_model.fit(X_meta, y_meta)
        meta_modeller[key] = items

        if save:
            with open(pref+'modeller/'+key+'.model', 'wb') as f:
                pickle.dump(meta_model, f)

    # print('Done Learn meta_modeller p√• stack_data')
    return meta_modeller

def initiera_veckans_rader_old(X_curr, y_curr, antal_rader):
    # ---------- initier veckans rad med aktuell omg√•ng ----------------------
    veckans_rader = []
    for i in range(antal_rader):
        veckans_rader.append(X_curr[['datum', 'avd', 'h√§st', 'bana',
                                     'kusk', 'streck', 'streck_avst', 'rel_rank']].copy())
        veckans_rader[i]['y'] = y_curr
        veckans_rader[i]['v√§lj'] = False

    return veckans_rader

def predict_curr_omgang(modeller, meta_modeller, X_curr, y_curr):
    """
        H√§r tas meta_modellernas prediktioner fram
        - modeller     : predict X_curr och anv√§nd skapa_stack_data funktionen
        - meta_modeller: predict p√• stack_datat och fyll i veckans rader
        veckans_rader inneh√•ller nu prediktioner fr√•n alla meta_modeller plus X_curr, y_curr
    """

    print(f'Predict curr_omgang {X_curr.datum.min()} - {X_curr.datum.max()}')

    # ------------- predict aktuell omg√•ng f√∂r att skapa stack_data -------------------
    stack_data = build_stack_data(modeller, X_curr, y_curr)

    # load ENC
    with open(pref+'modeller/test_encoder.pkl', 'rb') as f:
        ENC = pickle.load(f)

    veckans_rad, _ = prepare_stack_data(
        stack_data.drop(['datum', 'avd', 'y'], axis=1), None, ENC)
    temp = veckans_rad.copy()

    # temp.drop(['streck'], axis=1, inplace=True)    # ta bort streck fr√•n meta_features

    for key, values in meta_modeller.items():
        print(f'{key} predicts')
        meta_model = values['model']

        if 'ridg' in key:
            veckans_rad[key] = meta_model._predict_proba_lr(temp)[:, 1]
        else:
            veckans_rad[key] = meta_model.predict_proba(temp)[:, 1]
    veckans_rad[['datum', 'avd', 'y']] = stack_data[['datum', 'avd', 'y']]

    return veckans_rad

def old_learn_all_and_predict(L1_models, L2_models, X_train, y_train, X_meta, y_meta, X_curr, y_curr):
    """Learn alla modeller och meta_modeller och g√∂r prediktioner p√• X_curr"""

    # train L1-modeller p√• allt <= L1_datum
    train_L1_models(L1_models, X_train, y_train)

    # bygg stack_data fr√•n L1-modeller p√• date > L1_datum och <= L2_datum
    stack_data = build_stack_data(L1_models, X_meta, y_meta)
    assert 'y' in stack_data.columns, 'y is missing in stack_data'
    stack_data.to_csv('first_stack_data.csv', index=False)

    #""" Learn meta_modeller p√• stack_data"""
    L2_models = train_L2_models(L2_models, stack_data)

    # predict date==curr_datum
    veckans_rad = predict_curr_omgang(L1_models, L2_models, X_curr, y_curr)

    return veckans_rad

def learn_modeller(df_, curr_datum, L2_datum, L1_modeller, L2_modeller, use_features):
    """ Skapar en DataFrame som inneh√•ller input till L2-modellers predictioner
    Args:
        df_ (DataFrame): allt data rensat och tv√§ttat
        curr_datum (string): aktuell datum som skall predikteras
        L2_datum (string): bryt-datum mellan Layer1 och Layer2
        L1_modeller (list): Layer1-modeller
        L2_modeller (list): Layer2-modeller
        use_features (list): Features f√∂r Layer1-modeller
    Returns:
        DataFrame: stack_f√∂r L2_predictions
        List: L2_features inkluderar proba_features fr√•n L1-modeller
    """
    log_print(
        f'learn_modeller: med curr_datum={curr_datum} och L2_datum={L2_datum}', 'i')
    log_print(f'learn_modeller: orginaldata={df_.shape}', 'i')

    ############# Learn L1-modeller p√• allt <= L2_datum ############################
    L1_learn_input_df = df_.query('datum < @L2_datum').copy()
    assert L1_learn_input_df.shape[0] > 0, log_print(f'L1_learn_input_df √§r tom', 'e')

    log_print(f'learn_modeller: L1_input_df shape={L1_learn_input_df.shape} min_dat= \
    {L1_learn_input_df.datum.min()}, max_dat={L1_learn_input_df.datum.max()}', 'i')

    L1_modeller = mod.learn_L1_modeller(
        L1_modeller, L1_learn_input_df, use_features, save=True)
    log_print(f'learn_modeller: L1_modeller √§r nu l√§rt {L1_modeller.keys()}', 'i')

    ############# Skapa data till L2 p√• datum >= L2_datum och datum < curr_datum #############
    # skall ut√∂kas med probas
    stack_df = df_.query('datum >= @L2_datum and datum < @curr_datum').copy()
    assert stack_df.shape[0] > 0, log_print(f'stack_df √§r tom', 'e')

    stack_df, L2_features = mod.create_L2_input(
        stack_df, L1_modeller, use_features, with_y=True)
    assert stack_df.shape[0] > 0, log_print(f'stack_df √§r tom', 'e')
    log_print(f'learn_modeller: L2_learn_input_df shape={stack_df.shape} min_dat=\
    {stack_df.datum.min()}, max_dat={stack_df.datum.max()}', 'i')

    # filter features in L2_features starting with 'proba_'
    assert len([x for x in L2_features if x.startswith('proba_')]
               ) == 4, log_print(f'Antal proba-kolumner skall vara 4', 'e')
    ############# Nu har vi adderat proba_kolumner till stack_df ############################

    ############# Learn L2-modeller p√• stack_df med proba_kolumner ############################
    L2_modeller = mod.learn_L2_modeller(L2_modeller, stack_df, L2_features, save=True)
    log_print(f'learn_modeller: L2_modeller √§r nu l√§rt {L2_modeller.keys()}', 'i')

    ############# Skapa data till L2 f√∂r curr_datum ############################
    curr_data_df = df.query('datum == @curr_datum').copy()
    log_print(f'learn_modeller: curr_data_df shape={curr_data_df.shape} min_dat=\
    {curr_data_df.datum.min()}, max_dat={curr_data_df.datum.max()}', 'i')

    curr_stack_df, L2_features = mod.create_L2_input(curr_data_df, L1_modeller, use_features, with_y=True)
    assert curr_stack_df.shape[0] > 0, log_print(f'curr_stack_df √§r tom', 'e')

    log_print(f'learn_modeller: curr_stack_df shape={curr_stack_df.shape} min_dat=\
    {curr_stack_df.datum.min()}, max_dat={curr_stack_df.datum.max()}', 'i')

    log_print(f'learn_modeller: L2_features {L2_features[-5:]}', 'i')

    assert len([col for col in curr_stack_df.columns if 'proba' in col]) == 4, \
        log_print(f'learn_modeller: curr_stack_df skall ha 4 proba-kolumner', 'e')
    ############# Nu ligger proba_kolumner i curr_stack_df  ############################

    return curr_stack_df, L2_features

def old_predict_L2(L2_features, L2_modeller, curr_stack_df, mean_type='geometric', weights=None):
    weights = [0.25, 0.25, 0.25, 0.25] if weights==None else weights
    ############# predict curr_stack_df med L2 dvs l√§ggg till viktad meta #####################
    curr_stack_df = mod.predict_med_L2_modeller(L2_modeller, curr_stack_df, L2_features, mean_type=mean_type, weights=weights)
    assert curr_stack_df.shape[0] > 0, log_print(f'curr_stack_df √§r tom', 'e')
    assert 'meta' in curr_stack_df.columns, log_print(f'curr_stack_df saknar meta-kolumn', 'e')

    log_print(f'learn_modeller_och_predict: curr_stack_df shape={curr_stack_df.shape} min_dat=\
    {curr_stack_df.datum.min()}, max_dat={curr_stack_df.datum.max()}', 'i')
    ############# Nu ligger proba_kolumner plus viktad meta i den nya curr_stack_df ############################

    return curr_stack_df

    
def old_learn_modeller_och_predict(df_, curr_datum, L2_datum, L1_modeller, L2_modeller, use_features, mean_type='geometric'):
    """ Skapar en DataFrame som blir grunden till veckans-rad
    Args:
        df_ (DataFrame): allt data rensat och tv√§ttat
        curr_datum (string): aktuell datum som skall predikteras
        L2_datum (string): bryt-datum mellan Layer1 och Layer2
        L1_modeller (list): Layer1-modeller
        L2_modeller (list): Layer2-modeller
        use_features (list): Features f√∂r Layer1-modeller
    Returns:
        DataFrame: F√§rdig df med proba-kolumner plus meta-kolumn
    """
    WEIGHTS = [0.25, 0.25, 0.25, 0.25]
    log_print(f'learn_modeller_och_predict: med curr_datum={curr_datum} och L2_datum={L2_datum}','i')
    log_print(f'learn_modeller_och_predict: orginaldata={df_.shape}','i')
    
    ############# Learn L1-modeller p√• allt <= L2_datum ############################
    L1_learn_input_df = df_.query('datum < @L2_datum').copy()
    assert L1_learn_input_df.shape[0] > 0, log_print(f'L1_learn_input_df √§r tom','e')
     
    log_print(f'learn_modeller_och_predict: L1_input_df shape={L1_learn_input_df.shape} min_dat= \
    {L1_learn_input_df.datum.min()}, max_dat={L1_learn_input_df.datum.max()}','i')
    
    L1_modeller = mod.learn_L1_modeller(L1_modeller, L1_learn_input_df, use_features, save=True)
    log_print(f'learn_modeller_och_predict: L1_modeller √§r nu l√§rt {L1_modeller.keys()}','i')
  
    ############# Skapa data till L2 p√• datum >= L2_datum och datum < curr_datum #############
    stack_df = df_.query('datum >= @L2_datum and datum < @curr_datum').copy()   # skall ut√∂kas med probas
    assert stack_df.shape[0] > 0, log_print(f'stack_df √§r tom', 'e')

    stack_df, L2_features = mod.create_L2_input(stack_df, L1_modeller, use_features, with_y=True) 
    assert stack_df.shape[0] > 0, log_print(f'stack_df √§r tom', 'e')
    log_print(f'learn_modeller_och_predict: L2_learn_input_df shape={stack_df.shape} min_dat=\
    {stack_df.datum.min()}, max_dat={stack_df.datum.max()}', 'i')
    
    # filter features in L2_features starting with 'proba_'
    assert len([x for x in L2_features if x.startswith('proba_')])==4, log_print(f'Antal proba-kolumner skall vara 4', 'e')
    ############# Nu har vi adderat proba_kolumner till stack_df ############################
    
    ############# Learn L2-modeller p√• stack_df med proba_kolumner ############################
    L2_modeller = mod.learn_L2_modeller(L2_modeller, stack_df, L2_features, save=True)
    log_print(f'learn_modeller_och_predict: L2_modeller √§r nu l√§rt {L2_modeller.keys()}','i')
    
    ############# Skapa data till L2 f√∂r curr_datum ############################
    curr_data_df = df.query('datum == @curr_datum').copy()
    log_print(f'learn_modeller_och_predict: curr_data_df shape={curr_data_df.shape} min_dat=\
    {curr_data_df.datum.min()}, max_dat={curr_data_df.datum.max()}', 'i')

    curr_stack_df, L2_features = mod.create_L2_input(curr_data_df, L1_modeller, use_features, with_y=True)
    assert curr_stack_df.shape[0] > 0, log_print(f'curr_stack_df √§r tom', 'e')
    
    log_print(f'learn_modeller_och_predict: curr_stack_df shape={curr_stack_df.shape} min_dat=\
    {curr_stack_df.datum.min()}, max_dat={curr_stack_df.datum.max()}', 'i')
    
    log_print(f'learn_modeller_och_predict: L2_features {L2_features[-5:]}', 'i')
    
    assert len([col for col in curr_stack_df.columns if 'proba' in col]) == 4, \
        log_print(f'curr_stack_df skall ha 4 proba-kolumner', 'e')      
    ############# Nu ligger proba_kolumner i curr_stack_df  ############################

    ############# predict curr_stack_df med L2 dvs l√§ggg till viktad meta #####################
    curr_stack_df = mod.predict_med_L2_modeller(L2_modeller, curr_stack_df, L2_features,mean_type=mean_type, weights=WEIGHTS)
    assert curr_stack_df.shape[0] > 0, log_print(f'curr_stack_df √§r tom'  ,'e')
    assert 'meta' in curr_stack_df.columns, log_print(f'curr_stack_df saknar meta-kolumn'  ,'e')
    
    log_print(f'learn_modeller_och_predict: curr_stack_df shape={curr_stack_df.shape} min_dat=\
    {curr_stack_df.datum.min()}, max_dat={curr_stack_df.datum.max()}','i')
    ############# Nu ligger proba_kolumner plus viktad meta i den nya curr_stack_df ############################
    
    return curr_stack_df

def v√§lj_ut_h√§star_f√∂r_spel(strategi, df_proba):
    
    print(f'df_proba {df_proba.shape}')
    return mod.v√§lj_rad(df_proba)

def ber√§kna_resultat(veckans_rad, curr_datum):
    df_utdelning = pd.read_csv(pref+'data/utdelning.csv')
    # se sju, sex, fem, utd = mod.r√§tta_rad(veckans_rad, curr_datum, df_utdelning)
    return None


def plot_resultat(df_resultat_, placeholder2, placeholder3):
    import matplotlib.dates as mdates
    df_resultat = df_resultat_.copy()
    st.set_option('deprecation.showPyplotGlobalUse', False)
    
    #### Skapa en line plot f√∂r Kumulativ vinst_f√∂rlust per strategi √∂ver datum ####
    
    # Ber√§kna kumulativ vinst_f√∂rlust per strategi √∂ver datum
    df_resultat['cumulative_profit'] = df_resultat.groupby('strategi')[
        'vinst_f√∂rlust'].cumsum()
    df_resultat.to_csv(pref+'BacktestPlot.csv', index=False)
    
    # Skapa line plot
    plt.figure()
    # convert datum to date without time
    df_resultat['datum'] = pd.to_datetime(df_resultat['datum']).dt.date
    
    for strategi in df_resultat['strategi'].unique():
        strategi_data = df_resultat[df_resultat['strategi'] == strategi]
        plt.plot(strategi_data['datum'],
                strategi_data['cumulative_profit'], label=strategi)

    # Anv√§nd mdates f√∂r att s√§tta tidsaxeln
    interval= int((strategi_data['datum'].nunique()+1)/8)
    
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonth=range(1,13), interval=2))

    plt.title('Kumulativ vinst/f√∂rlust √∂ver tid per strategi')
    # plt.xlabel('Datum')
    plt.ylabel('Kumulativ vinst/f√∂rlust')
    plt.legend()
    placeholder2.pyplot()

    #### Skapa en bar plot f√∂r antal 5-7 r√§tt per strategi ####
   
    # skala om 5 och 6 r√§tt s√• att de blir i ung samma skala som 7 r√§tt
    df_resultat['6_r√§tt/10'] = df_resultat['6_r√§tt']/10
    df_resultat['5_r√§tt/100'] = df_resultat['5_r√§tt']/100
    df_resultat.drop(['5_r√§tt', '6_r√§tt'], axis=1, inplace=True)
    
    # Summera 7, 6 och 5 r√§tt per strategi
    df_sum = df_resultat.groupby('strategi').sum()
    df_sum = df_sum.drop(['vinst_f√∂rlust', 'cumulative_profit'], axis=1)
    
    # Skapa bar plot
    plt.figure()
    df_sum.plot(kind='bar', stacked=False)
    # plt.xlabel('Strategi')
    plt.suptitle('Antal 5-7 r√§tt per strategi')
    plt.ylabel('Antal 5-7 r√§tt')
    plt.legend()
    placeholder3.pyplot()

def next_datum(df, curr_datum=None, step=1):
    """ Tar fram n√§sta datum f√∂r testet
    Args:
        df (dataframe): all_data.csv
        curr_datum (string, optional): aktuell datum f√∂r testet. None betyder f√∂rsta g√•ngen.
        step (int, optional): antal datum som ska stegas fram√•t. Defaults to 1.
        gap (int, optional): antal datum ut√∂ver n√§sta mellan learn och predict. Defaults to 0.
    Returns:
        tuple: L2_datum, ny curr_datum
    """
    
    alla_datum = df.datum.unique()                        ###.astype(str).unique().tolist()
    if curr_datum is None:
        curr_datum = alla_datum[200]  # f√∂rsta g√•ngen √§r det 200 veckor f√∂r rej√§l start av training   
    
    log_print(f'next_datum 1: curr_datum: {curr_datum}, type: {type(curr_datum)}', 'i')
    log_print(f'next_datum 2: all_datum[0]: {alla_datum[0]}, type: {type(alla_datum[0])}', 'i')
    
    ix2 = [i for i, date in enumerate(alla_datum) if date == curr_datum][0]+step

    # ix2 = np.where(alla_datum == curr_datum)[0][0]+step   # index till ny curr_datum
    ix1 = int(round(ix2/2)+0.5) # index till L2_datum   (learn fr o m L2_datum till curr_datum)
    # learn L1_modeller p√• allt fram till L2_datum
    
    ############################### L1_datum    
    # G√∂r s√• att next_datum √§r L2_datum.index + 1
    # ber√§kan 50/50 mha next_datum f√∂r L1_datum och L2_datum
    
    if ix2 < len(alla_datum):
        curr_datum = alla_datum[ix2] # n√§sta omg√•ng att testa p√•
        L2_datum = alla_datum[ix1]  # till_datum f√∂r att l√§ra L1-modellern (L2-modellerna startar from L2_datum)
        curr_datum= pd.to_datetime(curr_datum, format='%Y-%m-%d').date()
        L2_datum= pd.to_datetime(L2_datum, format='%Y-%m-%d').date()
    else:
        curr_datum, L2_datum = None, None
    
    log_print(f'next_datum: curr_datum={curr_datum} type={type(curr_datum)}','i'    ) 
    return L2_datum, curr_datum

def backtest(df, L1_modeller, L2_modeller, step=1, gap=0, proba_val=0.6):
    placeholder0 = st.empty()
    placeholder1 = st.empty()
    placeholder2 = st.empty()
    placeholder3 = st.empty()
    
    use_features, cat_features, num_features = mod.read_in_features()
    # Bygg strategier - ha alltid med minst en strategi med 'outer' och l√§gg den f√∂rst i samma grupp
    # 'inner' anv√§nds i predict och betyder att vi inte beh√∂ver k√∂ra learn_modeller
    strategier = {
        'strategi 1': ('inner', 'geomotric','outer', 'layers'),
        'strategi 2': ('inner', 'arithmetic'),
        
        # ... fler strategier ...
        
    }
    df_resultat = pd.DataFrame(columns=['datum', 'strategi', 'vinst_f√∂rlust', '7_r√§tt', '6_r√§tt', '5_r√§tt'])
    df_utdelning = pd.read_csv('utdelning.csv')
    
    # Dela upp datan i l√§r- och test-delar
    L2_datum, curr_datum = next_datum(df, curr_datum=None, step=step)

    # F√∂r varje unikt datum i test-delen
    while curr_datum is not None: 
        # for strategi_name, (strategi, L1_modeller, L2_modeller, use_features) in strategier.items():
        for strategi_namn, strategi in strategier.items():
            log_print(f'curr_datum: {curr_datum}, {strategi_namn}: {strategi}', 'i')
            placeholder0.empty()
            placeholder0.info(f'Aktuell datum: {curr_datum} {"        "} \n {strategi_namn}: {strategi}')
        
            if 'outer' in strategi:
                # L√§r modeller och predict aktuell datum
                curr_stack_df, L2_features = learn_modeller(df, curr_datum, L2_datum, L1_modeller, L2_modeller, use_features)
                log_print(f'curr_stack_df shape={curr_stack_df.shape} min_dat=\
                {curr_stack_df.datum.min()}, max_dat={curr_stack_df.datum.max()}', 'i')
                curr_stack_df.to_csv('backtest_curr_stack_df.csv', index=False)
            else:
                curr_stack_df = pd.read_csv('backtest_curr_stack_df.csv')
                
            ############# predict curr_stack_df med L2 dvs l√§ggg till viktad meta #####################
            weights = [0.25, 0.25, 0.25, 0.25] 
            mean_type = 'arithemtic' if 'arithmetic' in strategi else 'geometric'
            L2_output_df = mod.predict_med_L2_modeller(
                L2_modeller, curr_stack_df, L2_features, mean_type=mean_type, weights=weights)
            assert L2_output_df.shape[0] > 0, log_print(f'L2_output_df √§r tom', 'e')
            assert 'meta' in L2_output_df.columns, log_print(f'L2_output_df saknar meta-kolumn', 'e')
            assert L2_output_df.shape[0] > 0, 'L2_output_df.shape[0] empty'

            ############# Nu ligger proba_kolumner plus viktad meta i L2_output_df ############################

            # V√§lj ut h√§star f√∂r spel df_proba skall inneh√•lla data f√∂r en omg√•ng
            veckans_rad, kostnad = v√§lj_ut_h√§star_f√∂r_spel(strategi, L2_output_df)
            log_print(f'veckans_rad.shape: {veckans_rad.shape}  Kostnad: {kostnad}')
            
            # Ber√§kna resultat
            _7_r√§tt, _6_r√§tt, _5_r√§tt, utdelning = mod.r√§tta_rad(veckans_rad, curr_datum, df_utdelning)
            vinst_f√∂rlust =  utdelning - kostnad
            log_print(f'vinst_f√∂rlust: {vinst_f√∂rlust}  utdelning: {utdelning}  kostnad: {kostnad}','i')
            
            # make a string of the current date
            row = [curr_datum.strftime('%Y-%m-%d'), strategi_namn, vinst_f√∂rlust, _7_r√§tt, _6_r√§tt, _5_r√§tt]
            # print(row)
            df_resultat.loc[len(df_resultat)] = row
            print(df_resultat.tail(3))
            df_resultat.to_csv('BacktestResult.csv', index=False)      
            # Plot resultat
            placeholder1.empty()
            placeholder2.empty()
            placeholder3.empty()
            plot_resultat(df_resultat, placeholder2, placeholder3)
            
        L2_datum, curr_datum = next_datum(df, curr_datum, step)
        
def backtest_old(df, df_resultat, modeller, meta_modeller, datumar, gap=0, proba_val=0.6, base_ix=100, meta_ix=150, cv=False, step=1):
    """ Backtesting anpassad f√∂r travets omg√•ngar, dvs datum istf dagar"""

    assert base_ix < meta_ix, f'base_ix ({base_ix}) m√•ste vara mindrea √§n meta_ix ({meta_ix})'
    placeholder0 = st.empty()
    placeholder1 = st.empty()
    placeholder2 = st.empty()
    placeholder3 = st.empty()

    df_utdelning = pd.read_csv('utdelning.csv')

    for curr_datum_ix in range(base_ix, len(datumar), step):
        curr_datum = datumar[curr_datum_ix]
        placeholder0.empty()
        placeholder0.info(
            f'Aktuell datum: {curr_datum} {"        "} \nomg√•ng: {curr_datum_ix}')

        X_train, y_train, X_meta, y_meta, X_curr, y_curr = skapa_data_f√∂r_datum(
            df, curr_datum_ix)
        if X_train.empty or X_meta.empty or X_curr.empty:
            break

        print(f'learn fram till {curr_datum}')
        veckans_rad = old_learn_all_and_predict(modeller,
                                            meta_modeller,
                                            X_train, y_train,
                                            X_meta, y_meta,
                                            X_curr, y_curr)

        assert cv == False, 'cv==True not implemented'

        spik_strategier = ['1a', '1b', '2b', None]

        # ta fram rader och r√§ttaa dem
        femmor, sexor, sjuor, utdelning, kostnad, vinst = [], [], [], [], [], []
        last_row = df_resultat.iloc[-1]
        for enum, strategi in enumerate(spik_strategier):
            veckans_rad, cost = ta_fram_meta_rad(veckans_rad, meta_modeller, spik_strategier[enum])
            print('cost', cost)
            kostnad.append(cost)
            veckans_rad.to_csv('veckans_rad'+str(enum)+'.csv', index=False)
            sju, sex, fem, utd = mod.r√§tta_rad(veckans_rad, curr_datum, df_utdelning)
            sjuor.append(int(sju))
            sexor.append(int(sex))
            femmor.append(int(fem))
            utdelning.append(int(utd))
            vinst.append(int(utdelning[enum] - kostnad[enum]))

        cols = ['t1_vinst', 't2_vinst', 't3_vinst', 't4_vinst',
                't1_utd', 't2_utd', 't3_utd', 't4_utd',
                't1_kostn', 't2_kostn', 't3_kostn', 't4_kostn', ]
        last_row += vinst + utdelning + kostnad + sjuor + sexor + femmor
        df_resultat.loc[curr_datum] = last_row

        # make all int
        for col in df_resultat.columns:
            df_resultat[col] = df_resultat[col].astype(int)

        df_resultat.to_csv('backtest_resultat.csv', index=True)

        # 3. plotta
        graf_data = df_resultat.copy()

        # graf_data.index = pd.to_datetime(graf_data.index, format="%Y-%m-%d")

        placeholder1.empty()
        placeholder2.empty()
        placeholder3.empty()

        # Backtest klart och nu pandas plot med gridlines
        placeholder1.line_chart(graf_data[[
                                't1_vinst', 't2_vinst', 't3_vinst', 't4_vinst']], use_container_width=True)

        # placeholder2.line_chart(graf_data[[
        #                         't1_7', 't2_7', 't3_7', 't4_7']], width=16, height=14, use_container_width=True)

        # st.write(df_resultat.plot(kind='line',  y='t1_vinst', rot=45, legend=True, figsize=(20,10)))
        placeholder3.dataframe(df_resultat.sort_index(ascending=False).head(40))
        df_resultat.to_csv('backtest_resultat.csv', index=True)
        
    return df_resultat

def k√∂r(df, L1_modeller, L2_modeller, cv=False):

    base_ix = 100  # antal omg√•ngar som vi startar bas-modellerna fr√•n i backtesting
    meta_ix = 150  # antal omg√•ngar som vi startar meta-modellerna fr√•n i backtesting

    ##################################################################################
    # Best√§m i f√∂rv√§g vilka predictors som varje meta-model skall anv√§nda?           #
    # Best√§m ocks√• spik-strategi och kelly-strategi f√∂r varje meta-model             #
    # Kanske en dict √§r bra?                                                         #
    ##################################################################################

    datumar, df_resultat = starta_upp(df, base_ix)

    # backtesting
    assert 'y' in df,log_print(f'y saknas i df')  
    df_resultat = backtest(df, L1_modeller, L2_modeller, gap=0, proba_val=0.6, step=1)

    return df_resultat

def main():
    # Skapa v75-instans
    v75 = td.v75(pref='')
    # H√§mta data fr√•n v75
    df,_ = v75.f√∂rbered_data(extra=True, missing_num=False)  # num hanteras av catboost
    # df = v75.l√§gg_till_kolumner()

    ###############################################################
    # N√•gra id√©er p√• nya kolumner:
    #  -   ‚ùå streck/sum(streck f√∂r avd) - fungerar inte bra. N√§stan alla sum == 100 per avd
    #  a - ‚úîÔ∏è plats(streck)/ant_h√§star_i_avd (antal startande h√§star i avd)
    #  b - ‚ùå pris / tot_pris_i_avd - g√•r inte att anv√§nda ju! pris √§r ju loppets 1.pris - samma f√∂r all i loppet
    #  c - ‚úîÔ∏è kr / tot_kr_i_avd     rel_kr
    #  d - ‚úîÔ∏è Avst√•ndet till ettan (streck)
    #  e - ‚úîÔ∏è hx_bana samma som bana
    #  f - ‚úîÔ∏è hx_kusk samma som kusk

    # -------------- skapa modeller f√∂r backtesting
    L1_modeller, L2_modeller = mod.skapa_modeller()
    
    if st.button('k√∂r'):
        st.write('Inf√∂ra k√∂r med cv?')
        df_resultat = k√∂r(df, L1_modeller, L2_modeller, cv=False)

if __name__ == "__main__":
    # Skapa v75-instans
    v75 = td.v75(pref='')
    # H√§mta data fr√•n v75
    # num hanteras av catboost
    df, encoder = v75.f√∂rbered_data(extra=True, missing_num=False)

    # -------------- skapa modeller f√∂r backtesting
    L1_modeller, L2_modeller = mod.skapa_modeller()

    st.write('Inf√∂ra k√∂r med cv?')
    df_resultat = k√∂r(df, L1_modeller, L2_modeller, cv=False)
