{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternativa feature selection metoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "\n",
    "# preprocessing for numeric columns\n",
    "imp_median = SimpleImputer(strategy='median', add_indicator=True)\n",
    "scaler = StandardScaler()\n",
    "# preprocessing for categorical columns\n",
    "imp_constant = SimpleImputer(strategy='constant',) # fill_value='missing')\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../all_data.csv')\n",
    "df.set_index('datum',inplace=True)\n",
    "df.drop(['avd', 'bana', 'häst', 'kusk', 'vodds','podds', 'startnr', 'bins',\n",
    "         'h1_dat', 'h1_bana', 'h1_kusk', \n",
    "         'h2_dat', 'h2_bana', 'h2_kusk',\n",
    "         'h3_dat', 'h3_bana', 'h3_kusk',\n",
    "         'h4_dat', 'h4_bana', 'h4_kusk',\n",
    "         'h5_dat', 'h5_bana', 'h5_kusk'], axis=1, inplace=True)\n",
    "\n",
    "# test with and without streck\n",
    "df.drop('streck', axis=1, inplace=True)\n",
    "\n",
    "# df['kön']=df['kön'].astype('category') # endast om ej catboost\n",
    "# df['kön']=df['kön'].cat.codes\n",
    "\n",
    "X = df.drop(['plac'], axis=1)\n",
    "y = (df['plac']==1)*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost regression\n",
    "from catboost import CatBoostClassifier,cv,Pool\n",
    "# setup catboost model\n",
    "cat_features = [i for i in X.columns if X[i].dtype == 'object']\n",
    "# pool=Pool(data=X,\n",
    "     # label=y,\n",
    "     # cat_features=[])\n",
    "\n",
    "model = CatBoostClassifier(iterations=100,                 \n",
    "                            # learning_rate=0.1,\n",
    "                            # depth=6,\n",
    "                            loss_function='Logloss',\n",
    "                         #    eval_metric='MAE',\n",
    "                            verbose=False,\n",
    "                            random_seed=42)  \n",
    "# model=model.fit(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns by data type\n",
    "num_cols = make_column_selector(dtype_include='number')\n",
    "cat_cols = make_column_selector(dtype_exclude='number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='median')),\n",
       "                                                                  ('standardscaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001FA5C018BE0>),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('onehotencoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001FA5C018400>)])),\n",
       "                ('catboostclassifier',\n",
       "                 <catboost.core.CatBoostClassifier object at 0x000001FA7FA573A0>)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do all preprocessing in one pipeline\n",
    "preprocessor = make_column_transformer(\n",
    "    (make_pipeline(imp_median, scaler), num_cols),\n",
    "    (make_pipeline(imp_constant, ohe), cat_cols)\n",
    "    )\n",
    "\n",
    "pipe = make_pipeline(preprocessor, model)\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install feature_engine\n",
    "from feature_engine.selection import SelectByShuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (100 iterations wait)\n"
     ]
    }
   ],
   "source": [
    "# meassure performance of the feature selections\n",
    "def catboost_cv(X,y,cat_features):\n",
    "    labels = y\n",
    "\n",
    "    cv_dataset = Pool(data=X,\n",
    "                    label=labels,\n",
    "                    cat_features=cat_features)\n",
    "\n",
    "    params = {\"iterations\": 1000,\n",
    "              'early_stopping_rounds': 100,\n",
    "              \"loss_function\": \"Logloss\",\n",
    "            #   'eval_metric': 'RMSE',\n",
    "              \"verbose\": False}\n",
    "\n",
    "    scores = cv(cv_dataset,\n",
    "                params,\n",
    "                fold_count=3, \n",
    "                )\n",
    "    score =scores['test-Logloss-mean'].min()\n",
    "    return score\n",
    "with_all_features = catboost_cv(X,y,cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectByShuffling(estimator=Pipeline(steps=[('columntransformer',\n",
       "                                             ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                                              Pipeline(steps=[('simpleimputer',\n",
       "                                                                                               SimpleImputer(add_indicator=True,\n",
       "                                                                                                             strategy='median')),\n",
       "                                                                                              ('standardscaler',\n",
       "                                                                                               StandardScaler())]),\n",
       "                                                                              <sklearn.compose._column_transformer.make_column_selector object at 0x000001FA5C018BE0>),\n",
       "                                                                             ('pipeline-2',\n",
       "                                                                              Pipeline(steps=[('simpleimputer',\n",
       "                                                                                               SimpleImputer(strategy='constant')),\n",
       "                                                                                              ('onehotencoder',\n",
       "                                                                                               OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                              <sklearn.compose._column_transformer.make_column_selector object at 0x000001FA5C018400>)])),\n",
       "                                            ('catboostclassifier',\n",
       "                                             <catboost.core.CatBoostClassifier object at 0x000001FA7FA573A0>)]),\n",
       "                  scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will select features based on the drop in the neg_MAE using 3 fold cross-validation:\n",
    "\n",
    "# initialize the feature selector\n",
    "tr = SelectByShuffling(estimator=pipe, scoring=\"neg_mean_absolute_error\", cv=3, threshold=None)\n",
    "\n",
    "# With the method fit() the transformer finds the important variables —those that cause a drop in score when shuffled. By default, \n",
    "# features will be selected if the performance drop is bigger than the mean drop caused by all features.\n",
    "tr.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['kr', 'spår', 'kön', 'pris', 'h1_pris', 'h1_odds', 'h2_pris', 'h2_odds',\n",
       "       'h2_kmtid', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_pris', 'h4_odds',\n",
       "       'h4_kmtid', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_perf', 'h2_perf',\n",
       "       'h5_perf', 'delta1', 'delta3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the method transform() we drop the unselected features from the dataset:\n",
    "\n",
    "Xt = tr.transform(X)\n",
    "\n",
    "# We can inspect the individual feature’s importance through one of the transformer’s attributes:\n",
    "# print('resultat\\n',tr.performance_drifts_)\n",
    "\n",
    "Xt.columns\n",
    "# tr.initial_model_performance_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all features cv: 0.26451734324327303\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "sel features cv: 0.26499260726977464\n"
     ]
    }
   ],
   "source": [
    "print('all features cv:',with_all_features)\n",
    "print('sel features cv:',catboost_cv(Xt, y, cat_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med 'streck'  \n",
    "all features cv: 0.23681292646342436  \n",
    "sel features cv: 0.2368586479074274  \n",
    "\n",
    "Wthout 'streck'  \n",
    "all features cv:   0.26451734324327303  \n",
    "sel features cv:   0.26499260726977464  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kr', 'spår', 'dist', 'lopp_dist', 'start', 'ålder', 'pris', 'h1_spår', 'h1_plac', 'h1_pris', 'h1_odds', 'h1_kmtid', 'h2_spår', 'h2_plac', 'h2_pris', 'h2_odds', 'h2_kmtid', 'h3_spår', 'h3_plac', 'h3_pris', 'h3_odds', 'h3_kmtid', 'h4_spår', 'h4_plac', 'h4_pris', 'h4_odds', 'h4_kmtid', 'h5_spår', 'h5_plac', 'h5_pris', 'h5_odds', 'h5_kmtid', 'h1_dist', 'h2_dist', 'h3_dist', 'h4_dist', 'h5_dist', 'h1_auto', 'h2_auto', 'h3_auto', 'h4_auto', 'h5_auto', 'h1_perf', 'h2_perf', 'h3_perf', 'h4_perf', 'h5_perf', 'senast', 'delta1', 'delta2', 'delta3', 'delta4']\n"
     ]
    }
   ],
   "source": [
    "from feature_engine.selection import SelectBySingleFeaturePerformance\n",
    "\n",
    "# We want to select features whose r2 > 0.01, utilizing a linear regression and using 3 fold cross-validation.\n",
    "\n",
    "# initialize the feature selector\n",
    "sel = SelectBySingleFeaturePerformance(\n",
    "    estimator=pipe, scoring=\"r2\", cv=3, threshold=0.01)\n",
    "\n",
    "\n",
    "# The transformer uses the method fit() to fit 1 model per feature, determine performance, and select the important features.\n",
    "\n",
    "# fit transformer\n",
    "sel.fit(X, y)\n",
    "\n",
    "# We can explore the features that will be dropped:\n",
    "print(sel.features_to_drop_)\n",
    "\n",
    "# We can also examine each individual feature’s performance:\n",
    "# sel.feature_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['kön'], dtype='object')\n",
      "all features cv: 0.26451734324327303\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "sel features cv: 0.29262238873721497\n"
     ]
    }
   ],
   "source": [
    "# drop variables\n",
    "Xt = sel.transform(X)\n",
    "print(Xt.columns)\n",
    "\n",
    "print('all features cv:',with_all_features)\n",
    "print('sel features cv:',catboost_cv(Xt, y,['kön']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med 'streck'  \n",
    "all features cv: 0.23681292646342436  \n",
    "sel features cv: 0.29262238873721497  \n",
    "\n",
    "Utan 'streck' ok   \n",
    "all features cv: 0.26451734324327303  \n",
    "sel features cv: 0.29262238873721497  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target mean performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from feature_engine.selection import SelectByTargetMeanPerformance\n",
    "\n",
    "X.fillna(0, inplace=True)\n",
    "# print(sum(X_tranf==np.nan))\n",
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y,\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "# is there any values in the test set that are missing?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-engine automates the selection of\n",
    "# categorical and numerical variables\n",
    "\n",
    "sel = SelectByTargetMeanPerformance(\n",
    "    variables=None,\n",
    "    scoring=\"roc_auc_score\",\n",
    "    threshold=0.6,\n",
    "    bins=3,\n",
    "    strategy=\"equal_frequency\",\n",
    "    cv=3,  # cross validation\n",
    "    random_state=1,  # seed for reproducibility\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectByTargetMeanPerformance(bins=3, random_state=1,\n",
       "                              strategy='equal_frequency', threshold=0.6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find important features\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "# We can explore the ROC-AUC for each feature:\n",
    "# print(sel.feature_performance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spår',\n",
       " 'dist',\n",
       " 'lopp_dist',\n",
       " 'start',\n",
       " 'ålder',\n",
       " 'kön',\n",
       " 'pris',\n",
       " 'h1_spår',\n",
       " 'h1_plac',\n",
       " 'h1_pris',\n",
       " 'h1_kmtid',\n",
       " 'h2_spår',\n",
       " 'h2_plac',\n",
       " 'h2_pris',\n",
       " 'h2_kmtid',\n",
       " 'h3_spår',\n",
       " 'h3_plac',\n",
       " 'h3_pris',\n",
       " 'h3_kmtid',\n",
       " 'h4_spår',\n",
       " 'h4_plac',\n",
       " 'h4_pris',\n",
       " 'h4_odds',\n",
       " 'h4_kmtid',\n",
       " 'h5_spår',\n",
       " 'h5_plac',\n",
       " 'h5_pris',\n",
       " 'h5_odds',\n",
       " 'h5_kmtid',\n",
       " 'h1_dist',\n",
       " 'h2_dist',\n",
       " 'h3_dist',\n",
       " 'h4_dist',\n",
       " 'h5_dist',\n",
       " 'h1_auto',\n",
       " 'h2_auto',\n",
       " 'h3_auto',\n",
       " 'h4_auto',\n",
       " 'h5_auto',\n",
       " 'h1_perf',\n",
       " 'h2_perf',\n",
       " 'h3_perf',\n",
       " 'h4_perf',\n",
       " 'h5_perf',\n",
       " 'senast',\n",
       " 'delta1',\n",
       " 'delta2',\n",
       " 'delta3',\n",
       " 'delta4']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can find the features that will be dropped from the data:\n",
    "sel.features_to_drop_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['kr', 'h1_odds', 'h2_odds', 'h3_odds'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove features\n",
    "X_tr = sel.transform(X_train)\n",
    "X_te = sel.transform(X_test)\n",
    "X_tr.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all features cv: 0.26451734324327303\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "sel features cv: 0.274721721060698\n"
     ]
    }
   ],
   "source": [
    "X[X_tr.columns]\n",
    "print('all features cv:',with_all_features)\n",
    "print('sel features cv:', catboost_cv(X[X_tr.columns], y,[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med 'streck'  \n",
    "all features cv: 0.23681292646342436   \n",
    "sel features cv: 0.23722614924386112   \n",
    "\n",
    "Utan 'streck'  \n",
    "all features cv: 0.26451734324327303  \n",
    "sel features cv: 0.274721721060698  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8488a4a715be31abb9488591c273d21f6ad2ccf4a90ce6956248586de0eec3a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('threeten': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
