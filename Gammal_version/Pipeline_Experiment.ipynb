{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline Experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U91hkLpi-SBV"
      },
      "source": [
        "Himanshu Chandra: https://iamjustastudent.com/about/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cjFGNq0P_re"
      },
      "source": [
        "### Imports ###\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ7KzRqK-KHL"
      },
      "source": [
        "# Pipeline Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D13TnX_2_mLi"
      },
      "source": [
        "df = pd.DataFrame(columns=['X1', 'X2', 'y'], data=[\n",
        "                                                   [1,16,9],\n",
        "                                                   [4,36,16],\n",
        "                                                   [1,16,9],\n",
        "                                                   [2,9,8],\n",
        "                                                   [3,36,15],\n",
        "                                                   [2,49,16],\n",
        "                                                   [4,25,14],\n",
        "                                                   [5,36,17]\n",
        "])\n",
        "\n",
        "### y = X1 + 2 * sqrt(X2)\n",
        "\n",
        "train = df.iloc[:6]\n",
        "test = df.iloc[6:]\n",
        "\n",
        "train_X = train.drop('y', axis=1)\n",
        "train_y = train.y\n",
        "\n",
        "test_X = test.drop('y', axis=1)\n",
        "test_y = test.y\n",
        "print(train_X.shape,test_X.shape, train_y.shape,test_y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 2) (2, 2) (6,) (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd_emlUpBbig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "d33d7919-f565-4b51-d6b5-cd0dae60604d"
      },
      "source": [
        "# let's see if linear regression is able to predict this properly\n",
        "m1 = LinearRegression()\n",
        "fit1 = m1.fit(train_X, train_y)\n",
        "preds = fit1.predict(test_X)\n",
        "print(f\"\\npreds: {preds}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds))}\\n\")\n",
        "print(f\"MSE: {mean_squared_error(test_y, preds)}\\n\")\n",
        "print(f\"MAE: {mean_absolute_error(test_y, preds)}\\n\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\npreds: [13.72113586 16.93334467]\nRMSE: 0.20274138822160784\n\nMSE: 0.041104070498024704\n\nMAE: 0.1727597347389933\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQayYrzmDWE7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "b9b3321c-e5b9-4777-d673-8bb07def11d3"
      },
      "source": [
        "# what if we square-root X2 and multiply by 2?\n",
        "train_X.X2 = 2 * np.sqrt(train_X.X2)\n",
        "test_X.X2 = 2 * np.sqrt(test_X.X2)\n",
        "print(test_X)\n",
        "m2 = LinearRegression()\n",
        "fit2 = m2.fit(train_X, train_y)\n",
        "preds = fit2.predict(test_X)\n",
        "print(f\"\\npreds: {preds}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds))}\\n\")\n",
        "print(f\"MSE: {mean_squared_error(test_y, preds)}\\n\")\n",
        "print(f\"MAE: {mean_absolute_error(test_y, preds)}\\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   X1    X2\n6   4  10.0\n7   5  12.0\n\npreds: [14. 17.]\nRMSE: 5.17892563931115e-15\n\nMSE: 2.68212707775144e-29\n\nMAE: 4.440892098500626e-15\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMrbwYDDNFKu"
      },
      "source": [
        "# a perfect prediction, because the data after transformation, fits a perfect linear trend.\n",
        "# let's restore the data back to original, and do this via custom transformers using pipeline.\n",
        "train = df.iloc[:6]\n",
        "test = df.iloc[6:]\n",
        "\n",
        "train_X = train.drop('y', axis=1)\n",
        "train_y = train.y\n",
        "\n",
        "test_X = test.drop('y', axis=1)\n",
        "test_y = test.y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD08IkZP-Lam"
      },
      "source": [
        "# references: \n",
        "# https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65\n",
        "# https://machinelearningmastery.com/how-to-transform-target-variables-for-regression-with-scikit-learn/\n",
        "# http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
        "# https://stackoverflow.com/questions/43308042/transformer-initialize-twice-in-pipeline\n",
        "\n",
        "class ExperimentalTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    print('\\n>>>>>>>init() called.\\n')\n",
        "\n",
        "  def fit(self, X, y = None):\n",
        "    print('\\n>>>>>>>fit() called.\\n')\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y = None):\n",
        "    print('\\n>>>>>>>transform() called.\\n')\n",
        "    X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
        "    X_.X2 = 2 * np.sqrt(X_.X2)\n",
        "    return X_"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spUiscMUPY83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "961ad4f6-5143-442a-8a19-bc986910479d"
      },
      "source": [
        "# without input transformation - to validate that we get the same results as before\n",
        "print(\"create pipeline 1\")\n",
        "pipe1 = Pipeline(steps=[\n",
        "                       ('linear_model', LinearRegression())\n",
        "])\n",
        "print(\"fit pipeline 1\")\n",
        "pipe1.fit(train_X, train_y)\n",
        "print(\"predict via pipeline 1\")\n",
        "preds1 = pipe1.predict(test_X)\n",
        "print(f\"\\npreds1: {preds1}\")  # should be [13.72113586 16.93334467]\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds1))}\\n\")  \n",
        "print(f\"MSE: {mean_squared_error(test_y, preds1)}\\n\")  \n",
        "print(f\"MAE: {mean_absolute_error(test_y, preds1)}\\n\")  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create pipeline 1\nfit pipeline 1\npredict via pipeline 1\n\npreds1: [13.72113586 16.93334467]\nRMSE: 0.20274138822160784\n\nMSE: 0.041104070498024704\n\nMAE: 0.1727597347389933\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFTnGVww_kIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "a86df4fa-fa17-4a43-f87a-07167fff174c"
      },
      "source": [
        "# with input transformation\n",
        "print(\"create pipeline 2\")\n",
        "pipe2 = Pipeline(steps=[\n",
        "                       ('experimental_trans', ExperimentalTransformer()),    # this will trigger a call to __init__\n",
        "                       ('linear_model', LinearRegression())\n",
        "])\n",
        "\n",
        "# an alternate, shorter syntax to do the above, without naming each step, is:\n",
        "#pipe2 = make_pipeline(ExperimentalTransformer(), LinearRegression())\n",
        "\n",
        "print(\"fit pipeline 2\")\n",
        "pipe2.fit(train_X, train_y)\n",
        "print(\"predict via pipeline 2\")\n",
        "preds2 = pipe2.predict(test_X)\n",
        "print(f\"\\npreds2: {preds2}\")  # should be [14. 17.]\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds2))}\\n\")\n",
        "print(f\"MAE: {np.sqrt(mean_absolute_error(test_y, preds2))}\\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create pipeline 2\n\n>>>>>>>init() called.\n\nfit pipeline 2\n\n>>>>>>>fit() called.\n\n\n>>>>>>>transform() called.\n\npredict via pipeline 2\n\n>>>>>>>transform() called.\n\n\npreds2: [14. 17.]\nRMSE: 5.17892563931115e-15\n\nMAE: 6.664001874625056e-08\n\n"
          ]
        }
      ]
    },
    {
      "source": [
        "## we've assumed in the transform() function of our ExperimentalTransformer that the column name is X2. Let's not do so and\n",
        "## pass the column name via the constructor, __init__()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "7QAxS_dkSpnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB8bhqpdS-2m"
      },
      "source": [
        "class ExperimentalTransformer_2(BaseEstimator, TransformerMixin):\n",
        "  # add another additional parameter, just for fun, while we are at it\n",
        "  def __init__(self, feature_name, additional_param = \"Himanshu\"):  \n",
        "    print(f'\\n>>>>>>>init({feature_name}) called.\\n')\n",
        "    self.feature_name = feature_name\n",
        "    self.additional_param = additional_param\n",
        "\n",
        "  def fit(self, X, y = None):\n",
        "    print('\\n>>>>>>>fit() called.\\n')\n",
        "    print(f'\\nadditional param ~~~~~ {self.additional_param}\\n')\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y = None):\n",
        "    print('\\n>>>>>>>transform() called.\\n')\n",
        "    X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
        "    X_[self.feature_name] = 2 * np.sqrt(X_[self.feature_name])\n",
        "    return X_"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_WkBgdkTOLU"
      },
      "source": [
        "# take care to keep the parameter name exactly the same in the function argument as well as \n",
        "# the class' variable (feature_name). Changing that will cause problems later when we also\n",
        "# try to transform the target feature (y). It causes a double-call to __init__ for some reason."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB6WV6pUTuu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "bdd1ecc7-285d-4d39-f8f3-d6101bdeeef7"
      },
      "source": [
        "print(\"create pipeline 2\")\n",
        "pipe2 = Pipeline(steps=[\n",
        "                       ('experimental_trans', ExperimentalTransformer_2('X2')),\n",
        "                       ('linear_model', LinearRegression())\n",
        "])\n",
        "print(\"fit pipeline 2\")\n",
        "pipe2.fit(train_X, train_y)\n",
        "print(\"predict via pipeline 2\")\n",
        "preds2 = pipe2.predict(test_X)\n",
        "print(f\"\\npreds2: {preds2}\")  # should be [14. 17.]\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds2))}\\n\")\n",
        "print(f\"MAE: {mean_squared_error(test_y, preds2)}\\n\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create pipeline 2\n\n>>>>>>>init(X2) called.\n\nfit pipeline 2\n\n>>>>>>>fit() called.\n\n\nadditional param ~~~~~ Himanshu\n\n\n>>>>>>>transform() called.\n\npredict via pipeline 2\n\n>>>>>>>transform() called.\n\n\npreds2: [14. 17.]\nRMSE: 5.17892563931115e-15\n\nMAE: 2.68212707775144e-29\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBLKFfxcVhE5"
      },
      "source": [
        "# let's take this a step further by modifying the dataframe to have target as squares of current values:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqY60SOGViBG"
      },
      "source": [
        "df = pd.DataFrame(columns=['X1', 'X2', 'y'], data=[\n",
        "                                                   [1,16,81],\n",
        "                                                   [4,36,256],\n",
        "                                                   [1,16,81],\n",
        "                                                   [2,9,64],\n",
        "                                                   [3,36,225],\n",
        "                                                   [2,49,256],\n",
        "                                                   [4,25,196],\n",
        "                                                   [5,36,289]\n",
        "])\n",
        "\n",
        "### sqrt(y) = X1 + 2 * sqrt(X2)\n",
        "\n",
        "train = df.iloc[:6]\n",
        "test = df.iloc[6:]\n",
        "\n",
        "train_X = train.drop('y', axis=1)\n",
        "train_y = train.y\n",
        "\n",
        "test_X = test.drop('y', axis=1)\n",
        "test_y = test.y"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSAo6KGzViSe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "2b16b778-bcda-4b00-a700-6e85bc162e30"
      },
      "source": [
        "# let's see model's performance with no input & target transformations:\n",
        "print(\"create pipeline 1\")\n",
        "pipe1 = Pipeline(steps=[\n",
        "                       ('linear_model', LinearRegression())\n",
        "])\n",
        "print(\"fit pipeline 1\")\n",
        "pipe1.fit(train_X, train_y)\n",
        "print(\"predict via pipeline 1\")\n",
        "preds1 = pipe1.predict(test_X)\n",
        "print(f\"\\npreds1: {preds1}\")  \n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds1))}\\n\")  \n",
        "print(f\"MAE: {mean_squared_error(test_y, preds1)}\\n\")  \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create pipeline 1\nfit pipeline 1\npredict via pipeline 1\n\npreds1[200.34790002 279.04738423]\nRMSE: 7.679804528409069\n\nMAE: 58.97939759457245\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_PwqZaTVihG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "eb81b244-93a0-42fc-a80e-18a2dc259262"
      },
      "source": [
        "# with input transformation but no target transformation\n",
        "print(\"create pipeline 2\")\n",
        "pipe2 = Pipeline(steps=[\n",
        "                       ('experimental_trans', ExperimentalTransformer_2('X2')),\n",
        "                       ('linear_model', LinearRegression())\n",
        "])\n",
        "print(\"fit pipeline 2\")\n",
        "pipe2.fit(train_X, train_y)\n",
        "print(\"predict via pipeline 2\")\n",
        "preds2 = pipe2.predict(test_X)\n",
        "print(f\"\\npreds2: {preds2}\")  \n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds2))}\\n\")\n",
        "print(f\"MAE: {mean_squared_error(test_y, preds2)}\\n\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create pipeline 2\n\n>>>>>>>init(X2) called.\n\nfit pipeline 2\n\n>>>>>>>fit() called.\n\n\nadditional param ~~~~~ Himanshu\n\n\n>>>>>>>transform() called.\n\npredict via pipeline 2\n\n>>>>>>>transform() called.\n\n\npreds2: [207.42690058 280.94152047]\nRMSE: 9.88719245653434\n\nMAE: 97.75657467254956\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ug-zMF0YISg"
      },
      "source": [
        "# we'll now write a custom target transformer.\n",
        "# this needs 2 functions, one to transform and another to inverse-transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TskWUHTcVit_"
      },
      "source": [
        "def target_transform(target):\n",
        "  print('\\n*****************target_transform() called.\\n')\n",
        "  target_ = target.copy() \n",
        "  target_ = np.sqrt(target_)\n",
        "  return target_\n",
        "\n",
        "def inverse_target_transform(target):\n",
        "  print('\\n*****************inverse_target_transform() called.\\n')\n",
        "  target_ = target.copy() \n",
        "  target_ = target_ ** 2\n",
        "  return target_"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwNd-9__Ywx9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "da2ba50d-8f3d-405d-f137-b8abcb7d2c6d"
      },
      "source": [
        "# with input transformation & target transformation\n",
        "print(\"create pipeline 3\")\n",
        "# no change in input pipeline\n",
        "pipe3 = Pipeline(steps=[\n",
        "                       ('experimental_trans', ExperimentalTransformer_2('X2')),\n",
        "                       ('linear_model', LinearRegression())\n",
        "])\n",
        "\n",
        "# create a TargetTransformer \n",
        "model = TransformedTargetRegressor(regressor=pipe3, \n",
        "                                   func=target_transform, \n",
        "                                   inverse_func=inverse_target_transform)\n",
        "\n",
        "print(\"fit pipeline 3 [fit Model]\")\n",
        "# note the different syntax here; we fit the 'model' now, instead of 'pipe3'\n",
        "model.fit(train_X, train_y)  \n",
        "print(\"predict via pipeline 3 [Model]\")\n",
        "preds3 = model.predict(test_X) # same here, using 'model' to predict\n",
        "print(f\"\\npreds3: {preds3}\")  # should be [196. 289.]\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds3))}\\n\")\n",
        "print(f\"MAE: {mean_squared_error(test_y, preds3)}\\n\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create pipeline 3\n\n>>>>>>>init(X2) called.\n\nfit pipeline 3 [fit Model]\n\n*****************target_transform() called.\n\n\n*****************inverse_target_transform() called.\n\n\n*****************target_transform() called.\n\n\n*****************inverse_target_transform() called.\n\n\n*****************target_transform() called.\n\n\n>>>>>>>init(X2) called.\n\n\n>>>>>>>fit() called.\n\n\nadditional param ~~~~~ Himanshu\n\n\n>>>>>>>transform() called.\n\npredict via pipeline 3 [Model]\n\n>>>>>>>transform() called.\n\n\n*****************inverse_target_transform() called.\n\n\npreds3: [196. 289.]\nRMSE: 1.657256204579568e-13\n\nMAE: 2.7464981276174747e-26\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYQ0HystcAmr"
      },
      "source": [
        "# perfect predictions!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTM-qswpcCwf"
      },
      "source": [
        "# we can even use in-built Transformers instead of user-defined functions. Example-\n",
        "# model = TransformedTargetRegressor(regressor=pipe3, transformer=PowerTransformer())\n",
        "# or\n",
        "# model = TransformedTargetRegressor(regressor=pipe3, transformer=StandardScaler())\n",
        "# using a built-in transformer does not require us to specify the inverse_transformer() as that is taken care of internally."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmEs3zaKEneX"
      },
      "source": [
        "# in case you want to have a custom transformer inside TransformedTargetRegressor, you can do that too. The only additional \n",
        "# function you'll have to implement would be inverse_transform(). Here's an example:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBZ-S3y9_AQz"
      },
      "source": [
        "class CustomTargetTransformer(BaseEstimator, TransformerMixin):\n",
        "  # no need to implement __init__ in this particular case\n",
        "  \n",
        "  def fit(self, target):\n",
        "    return self\n",
        "\n",
        "  def transform(self, target):\n",
        "    print('\\n%%%%%%%%%%%%%%%custom_target_transform() called.\\n')\n",
        "    target_ = target.copy() \n",
        "    target_ = np.sqrt(target_)\n",
        "    return target_\n",
        "\n",
        "  # need to implement this too\n",
        "  def inverse_transform(self, target):\n",
        "    print('\\n%%%%%%%%%%%%%%%custom_inverse_target_transform() called.\\n')\n",
        "    target_ = target.copy() \n",
        "    target_ = target_ ** 2\n",
        "    return target_"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsCBFs6o-gBN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "6ea392f9-7a0a-45d1-a7d5-05a1a0ac0d41"
      },
      "source": [
        "# with input transformation & target transformation\n",
        "print(\"create pipeline 3.1\")\n",
        "# no change in input pipeline\n",
        "pipe3_1 = Pipeline(steps=[\n",
        "                       ('experimental_trans', ExperimentalTransformer_2('X2')),\n",
        "                       ('linear_model', LinearRegression())\n",
        "])\n",
        "\n",
        "# create a TargetTransformer \n",
        "# By default, the provided functions are checked at each fit to be the inverse of each other. However, it is \n",
        "# possible to bypass this checking by setting check_inverse to False.\n",
        "model = TransformedTargetRegressor(regressor=pipe3_1, \n",
        "                                   transformer=CustomTargetTransformer(),\n",
        "                                   check_inverse=False) # avoid repeated calls\n",
        "\n",
        "print(\"fit pipeline 3.1 [fit Model]\")\n",
        "model.fit(train_X, train_y)  \n",
        "print(\"predict via pipeline 3.1 [Model]\")\n",
        "preds3_1 = model.predict(test_X) \n",
        "print(f\"\\npreds3: {preds3_1}\")  # should be [196. 289.]\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds3_1))}\\n\")\n",
        "print(f\"MAE: {mean_squared_error(test_y, preds3_1)}\\n\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create pipeline 3.1\n\n>>>>>>>init(X2) called.\n\nfit pipeline 3.1 [fit Model]\n\n%%%%%%%%%%%%%%%custom_target_transform() called.\n\n\n>>>>>>>init(X2) called.\n\n\n>>>>>>>fit() called.\n\n\nadditional param ~~~~~ Himanshu\n\n\n>>>>>>>transform() called.\n\npredict via pipeline 3.1 [Model]\n\n>>>>>>>transform() called.\n\n\n%%%%%%%%%%%%%%%custom_inverse_target_transform() called.\n\n\npreds3: [196. 289.]\nRMSE: 1.657256204579568e-13\n\nMAE: 2.7464981276174747e-26\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly2iew-uEhdU"
      },
      "source": [
        "# let's now see how to get and set parameters of the model. We'll also cache the transformer to \n",
        "# avoid repeated computation and make it more efficient."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0KB3cjDC5ho",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "e17e937f-9ff3-485a-8730-846e2851a6da"
      },
      "source": [
        "# get all the params of our model\n",
        "model.get_params()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'check_inverse': False,\n",
              " 'func': None,\n",
              " 'inverse_func': None,\n",
              " 'regressor__memory': None,\n",
              " 'regressor__steps': [('experimental_trans',\n",
              "   ExperimentalTransformer_2(feature_name='X2')),\n",
              "  ('linear_model', LinearRegression())],\n",
              " 'regressor__verbose': False,\n",
              " 'regressor__experimental_trans': ExperimentalTransformer_2(feature_name='X2'),\n",
              " 'regressor__linear_model': LinearRegression(),\n",
              " 'regressor__experimental_trans__additional_param': 'Himanshu',\n",
              " 'regressor__experimental_trans__feature_name': 'X2',\n",
              " 'regressor__linear_model__copy_X': True,\n",
              " 'regressor__linear_model__fit_intercept': True,\n",
              " 'regressor__linear_model__n_jobs': None,\n",
              " 'regressor__linear_model__normalize': False,\n",
              " 'regressor': Pipeline(steps=[('experimental_trans',\n",
              "                  ExperimentalTransformer_2(feature_name='X2')),\n",
              "                 ('linear_model', LinearRegression())]),\n",
              " 'transformer': CustomTargetTransformer()}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h729iuXW26OI"
      },
      "source": [
        "from tempfile import mkdtemp\n",
        "from shutil import rmtree\n",
        "# read about caching and side effect at: https://scikit-learn.org/stable/modules/compose.html?highlight=transformedtargetregressor#pipeline-chaining-estimators"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "source": [
        "Fitting transformers may be computationally expensive. With its memory parameter set, Pipeline will cache each transformer after calling fit. This feature is used to avoid computing the fit transformers within a pipeline if the parameters and input data are identical.  \n",
        "A **typical example is** the case of a **grid search** in which the transformers can be fitted only once and reused for each configuration.\n",
        " "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev2o5jU-Cpcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "374c1b5f-6618-4ca7-cd43-72b6f83c008b"
      },
      "source": [
        "cachedir = mkdtemp()\n",
        "print(\"create pipeline 4\")\n",
        "pipe4 = Pipeline(steps=[\n",
        "                        # incorrect column name passed\n",
        "                       ('experimental_trans', ExperimentalTransformer_2('X1')), \n",
        "                       ('linear_model', LinearRegression())\n",
        "], memory=cachedir)\n",
        "# create a TargetTransformer\n",
        "model = TransformedTargetRegressor(regressor=pipe4, \n",
        "                                   func=target_transform, \n",
        "                                   inverse_func=inverse_target_transform, \n",
        "                                   check_inverse=False) \n",
        "# correcting the column name using set_params()\n",
        "model.set_params(regressor__experimental_trans__feature_name = 'X2') \n",
        "\n",
        "print(\"fit pipeline 4 [fit Model]\")\n",
        "model.fit(train_X, train_y)  \n",
        "print(\"predict via pipeline 4 [Model]\")\n",
        "preds4 = model.predict(test_X) \n",
        "print(f\"\\npreds4: {preds4}\")  # should be [196. 289.]\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(test_y, preds4))}\\n\")\n",
        "print(f\"MAE: {mean_squared_error(test_y, preds4)}\\n\")\n",
        "\n",
        "# Clear the cache directory when you don't need it anymore\n",
        "rmtree(cachedir)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create pipeline 4\n\n>>>>>>>init(X1) called.\n\nfit pipeline 4 [fit Model]\n\n*****************target_transform() called.\n\n\n>>>>>>>init(X2) called.\n\n\n>>>>>>>init(X2) called.\n\n\n>>>>>>>fit() called.\n\n\nadditional param ~~~~~ Himanshu\n\n\n>>>>>>>transform() called.\n\npredict via pipeline 4 [Model]\n\n>>>>>>>transform() called.\n\n\n*****************inverse_target_transform() called.\n\n\npreds4: [196. 289.]\nRMSE: 1.657256204579568e-13\n\nMAE: 2.7464981276174747e-26\n\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# NEXT STEPS:\n",
        "\n",
        "1. ***FeatureUnion*** and ***ColumnTransformer***  \n",
        " Some great examples:  \n",
        "  https://scikit-learn.org/stable/modules/compose.html#featureunion-composite-feature-spaces  \n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer\n",
        "\n",
        "\n",
        "2. Using ***GridSearch*** with Pipelines  \n",
        "  Example:  \n",
        "  https://scikit-learn.org/stable/auto_examples/compose/plot_feature_union.html?highlight=pipeline\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "_5ZCrirHIADe"
      }
    }
  ]
}