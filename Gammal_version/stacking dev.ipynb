{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sklearn version 0.21.3\nnumpy version   1.16.5\n"
    }
   ],
   "source": [
    "!pip install -q catboost \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool\n",
    "\n",
    "import sklearn\n",
    "from sklearn import svm  \n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "sys.path.append('C:\\\\Users/peter/Google Drive/Colab Notebooks/Småprojekt/')\n",
    "import fixa_features as ff\n",
    "import class_model as mcl\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"sklearn version\", sklearn.__version__)\n",
    "print(\"numpy version  \", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_fix(): #df = read and fix data\n",
    "    filnamn='C:\\\\Users\\\\peter\\\\Documents\\\\MyProjects\\\\PyProj\\\\Trav\\\\travlopp\\\\komplett.csv'\n",
    "    df=pd.read_csv(filnamn)\n",
    "    df = ff.fix_features(df, True)\n",
    "    df['vann']=df.plac==1.0\n",
    "    df['vann'] *= 1\n",
    "    df.drop('plac',axis=1,inplace=True)\n",
    "    #df['avd'] = 1\n",
    "    #df['vann'] = False\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    A = df.sample(frac=0.55)\n",
    "    B = df.drop(A.index)\n",
    "\n",
    "    return A,B\n",
    "\n",
    "# def bins(df):\n",
    "#   bins=pd.DataFrame({\n",
    "#    'fr':[1.0, 2.1,  2.9,   3.6,  4.1,  4.8,\n",
    "#          5.6, 6.3,  7.1,   7.9,  8.7,  9.7,\n",
    "#         10.7, 11.9, 13.2, 14.8, 16.5, 18.1,\n",
    "#         20.2, 22.5, 25.2, 28.0, 31.5, 35.3,\n",
    "#         39.6, 44.7, 50.0, 56.7, 64.3, 75.4],\n",
    "                           \n",
    "#     'to':[2.1, 2.9,   3.6,  4.1,  4.8, 5.6, \n",
    "#           6.3, 7.1,   7.9,  8.7,  9.7,10.7, \n",
    "#           11.9, 13.2, 14.8, 16.5, 18.1,20.2, \n",
    "#           22.5, 25.2, 28.0, 31.5, 35.3,39.6, \n",
    "#           44.7, 50.0, 56.7, 64.3, 75.4, 2000 ],\n",
    "\n",
    "#     'bin':[0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
    "#           10,11,12,13,14,15,16,17,18,19,\n",
    "#           20,21,22,23,24,25,26,27,28,29]\n",
    "#        })\n",
    "\n",
    "  \n",
    "#   val = bins.loc[:,'fr':'to'].apply(tuple,1).tolist()\n",
    "#   indx = pd.IntervalIndex.from_tuples(val, closed='right')\n",
    "#   df['bins'] = bins.loc[indx.get_indexer(df['vodds']),'bin'].values\n",
    "\n",
    "#   return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pool for CatBoost\n",
    "def create_pool(X_train,y_train,X_test,y_test,cat_features):\n",
    "    \n",
    "    train_pool = Pool(\n",
    "        cat_features=cat_features,\n",
    "        data=X_train, \n",
    "        label=y_train,\n",
    "    )       \n",
    "    if X_test is None:\n",
    "        test_pool = None \n",
    "    else:\n",
    "        test_pool = Pool(\n",
    "            cat_features=cat_features,\n",
    "            data=X_test,\n",
    "            label=y_test\n",
    "        )\n",
    "    return train_pool, test_pool         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kelly algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((odds-1) * percentage_estimate -  (1-percent_estimate))   / (odds-1)  X   100\n",
    "def kelly(pred,odds):\n",
    "    return ( ((odds-1) * pred - (1-pred)) / (odds-1) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeller för första lagret i stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CatBoost\n",
    "def Cat_model(A,B,the_odds,path,häst_suf='h'): #häst_suf 'h' om häst är med, 'u' om inte\n",
    "    params={\n",
    "        'med': {'colsample_bylevel': 0.683, 'depth': 2, 'l2_leaf_reg': 1.189,       #target: -0.2467: 50-50; vinst=29\n",
    "                   'leaf_estimation_iterations': 1, 'learning_rate': 0.0786, \n",
    "                   'min_data_in_leaf': 54, 'subsample': 0.9164},\n",
    "        'utan':  {'colsample_bylevel': 0.2316, 'depth': 1.1, 'l2_leaf_reg': 19.79,  #target: -0.2532:  61-39; vinst=1665\n",
    "                  'leaf_estimation_iterations': 2.3, 'learning_rate': 0.1748, 'min_data_in_leaf': 5.5, 'subsample': 0.8097}}\n",
    "    params[the_odds]['depth']=int(round(params[the_odds]['depth']))\n",
    "    params[the_odds]['leaf_estimation_iterations']=int(round(params[the_odds]['leaf_estimation_iterations']))\n",
    "    params[the_odds]['min_data_in_leaf']=int(round(params[the_odds]['min_data_in_leaf']))\n",
    "\n",
    "    aa = A.copy()\n",
    "    bb = B.copy()\n",
    "\n",
    "    if häst_suf=='u':\n",
    "        aa.drop('häst',axis=1,inplace=True)\n",
    "        bb.drop('häst',axis=1,inplace=True)\n",
    "\n",
    "    A_X_train, A_X_test, A_y_train, A_y_test = train_test_split(aa.drop(['datum','vann'],axis=1), aa.vann, \n",
    "        test_size=0.2, random_state=202006)\n",
    "  \n",
    "    file_name='Cat1'+häst_suf+'_stacking'\n",
    "    if the_odds=='utan':\n",
    "        file_name='Cat2'+häst_suf+'_stacking'      \n",
    "        A_X_train.drop('vodds',axis=1,inplace=True)\n",
    "        A_X_test.drop('vodds',axis=1,inplace=True)\n",
    "        bb.drop('vodds',axis=1,inplace=True)\n",
    "\n",
    "    # preparera data till pool\n",
    "    cat_features = ['start','spår','h1_spår','h2_spår','h3_spår','h4_spår','h5_spår','häst']\n",
    "    if häst_suf=='u':\n",
    "        cat_features = ['start','spår','h1_spår','h2_spår','h3_spår','h4_spår','h5_spår']\n",
    "\n",
    "    A_y_train = A_y_train*1\n",
    "    A_y_test =A_y_test*1\n",
    "    train_pool, test_pool = create_pool(A_X_train,A_y_train,A_X_test,A_y_test,cat_features)\n",
    "    \n",
    "    cb = CatBoostClassifier(  # CatB-modellen\n",
    "      iterations=4000,                 \n",
    "      **params[the_odds],\n",
    "      scale_pos_weight = 1,\n",
    "      eval_metric = 'Logloss',\n",
    "      early_stopping_rounds=100,\n",
    "    )\n",
    "\n",
    "    # fit av A\n",
    "    cb.fit(train_pool, \n",
    "      eval_set = test_pool,\n",
    "      use_best_model=True,\n",
    "      verbose =False\n",
    "    )\n",
    "    \n",
    "    spara(cb,path+file_name)\n",
    "\n",
    "    B_X_pool,_=create_pool(bb.drop(['datum','vann'], axis=1),bb.vann, None,None,cat_features)\n",
    "    \n",
    "    # predict av B\n",
    "    return cb,cb.predict_proba(B_X_pool)[:,1]\n",
    "\n",
    "## Ramdom Forest\n",
    "def rf_model(A,B,the_odds,path):\n",
    "    params= {'med':{'n_estimators': 219, 'min_samples_leaf': 9,'min_samples_split': 10, 'max_depth': None,}, #Logloss: -0.9068\n",
    "        'utan':{'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 200}, #Logloss: -0.9061\n",
    "    }\n",
    "    aa=A.copy()\n",
    "    bb=B.copy()\n",
    "    file_name='rf1_stacking'\n",
    "    if the_odds=='utan':\n",
    "        file_name='rf2_stacking'\n",
    "        aa.drop('vodds',axis=1,inplace=True)\n",
    "        bb.drop('vodds',axis=1,inplace=True)\n",
    "\n",
    "    rf = RF(**params[the_odds]) # rf-modellen\n",
    "\n",
    "    # fit av A\n",
    "    rf.fit(aa.drop(['datum','häst','vann'],axis=1), aa.vann)\n",
    "\n",
    "    spara(rf, PATH+file_name)\n",
    "    \n",
    "    # predict av B\n",
    "    return rf,rf.predict_proba(bb.drop(['datum','häst','vann'],axis=1))[:,1]\n",
    "\n",
    "## Ramdom Forest med 30 bins\n",
    "def rf30_model(A,B,the_odds,path):\n",
    "    params= {'med':{'n_estimators': 219, 'min_samples_leaf': 9,'min_samples_split': 10, 'max_depth': None,}, #Logloss: -0.9068\n",
    "        'utan':{'max_depth': 100, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 200}, #Logloss: -0.9061\n",
    "    }\n",
    "    aa=A.copy()\n",
    "    bb=B.copy()\n",
    "    file_name='rf1_30_stacking'\n",
    "    if the_odds=='utan':\n",
    "        file_name='rf2_30_stacking'\n",
    "        aa.drop('vodds',axis=1,inplace=True)\n",
    "        bb.drop('vodds',axis=1,inplace=True)\n",
    "\n",
    "    rf30 = RF(**params[the_odds]) # rf30-modellen\n",
    "\n",
    "    # fit av A\n",
    "    rf30.fit(aa.drop(['datum','häst','vann'],axis=1), aa.vann)\n",
    "\n",
    "    spara(rf30, PATH+file_name)\n",
    "    \n",
    "    # predict av B\n",
    "    return rf30,rf30.predict_proba(bb.drop(['datum','häst','vann'],axis=1))[:,1]\n",
    "\n",
    "## knn\n",
    "def knn_model(A,B,the_odds,path):\n",
    "    params= {'med':{'leaf_size': 1, 'n_neighbors': 8, 'p': 2},       #target': 0.3273015873015873, precision\n",
    "            'med3':{'leaf_size': 43, 'n_neighbors': 25, 'p': 1},    #target': 0.9058454402452014, accuracy\n",
    "            'med2':{'leaf_size': 22, 'n_neighbors': 23, 'p': 2},    #'target': 0.9057963965963539 accuracy\n",
    "            'utan':{'leaf_size': 14, 'n_neighbors': 16, 'p': 1.0}  #target': 0.31, precision. (44-56) men vinst totalt ändå!\n",
    "    }\n",
    "    aa=A.copy()\n",
    "    bb=B.copy()\n",
    "\n",
    "    file_name='knn1_stacking'\n",
    "    if the_odds=='utan':\n",
    "        file_name='knn2_stacking'\n",
    "        aa.drop('vodds',axis=1,inplace=True)\n",
    "        bb.drop('vodds',axis=1,inplace=True)\n",
    "\n",
    "    knn = KNN(**params[the_odds]) # knn-modellen\n",
    "    \n",
    "    # fit av A\n",
    "    knn.fit(aa.drop(['datum','häst','vann'],axis=1), aa.vann)\n",
    "\n",
    "    spara(knn, PATH+file_name)\n",
    "\n",
    "    # predict av B\n",
    "    return knn,knn.predict_proba(bb.drop(['datum','häst','vann'],axis=1))[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spara/ladda Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spara(modelname, path):\n",
    "    import pickle    \n",
    "    pickle.dump(modelname, open(path, 'wb'))\n",
    "    print(modelname,'\\nsparad på', path)\n",
    "\n",
    "def ladda(modelname, path):\n",
    "    import pickle    \n",
    "    loaded_model = pickle.load(open(path+modelname, 'rb'))\n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Träna första lagret\n",
    "### Fit av A och predict av B ger C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "fixa features start (27449, 28)\nstartar CatB\n<catboost.core.CatBoostClassifier object at 0x0000014ADF727AC8> \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/Cat1h_stacking\n<catboost.core.CatBoostClassifier object at 0x0000014ADF728A88> \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/Cat2h_stacking\n<catboost.core.CatBoostClassifier object at 0x0000014ADF71DA08> \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/Cat2u_stacking\nstartar rf\nRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=9, min_samples_split=10,\n                       min_weight_fraction_leaf=0.0, n_estimators=219,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False) \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/rf1_stacking\nRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=100, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=2, min_samples_split=3,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False) \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/rf2_stacking\nstartar rf30\nRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=9, min_samples_split=10,\n                       min_weight_fraction_leaf=0.0, n_estimators=219,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False) \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/rf1_30_stacking\nRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=100, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=2, min_samples_split=3,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False) \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/rf2_30_stacking\nstartar knn\nKNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n                     weights='uniform') \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/knn1_stacking\nKNeighborsClassifier(algorithm='auto', leaf_size=14, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=16, p=1.0,\n                     weights='uniform') \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/knn2_stacking\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       vann  vodds  start  spår     Cat1h     Cat2h     Cat2u        rf1  \\\n10959     0   3.63      0     1  1.880681  3.848770  9.507993  10.987117   \n18842     0  35.12      0     8 -0.445476 -0.484681 -0.587746  -0.893158   \n22009     0   4.37      0     4  1.078971 -2.853741  7.346626   7.857213   \n10201     0  10.21      1     3 -4.741249 -3.908146 -2.882637  -4.633272   \n6099      0  54.71      0     9  0.217508 -0.019949  0.210488  -0.543694   \n18400     0  44.83      0    10 -0.407635 -0.619284 -0.292420  -0.213544   \n11460     0  32.20      0     7 -0.450262 -0.425971 -0.103524  -1.999795   \n1257      0  33.08      0    10 -0.952069 -0.854123 -0.577426  -0.774312   \n3786      0   8.10      0     9 -4.425097 -6.884797 -6.566575  -7.215518   \n11812     0   3.04      0     1 -6.241117 -7.163519 -9.159525  -2.259883   \n\n             rf2      rf130      rf230       knn1       knn2  \n10959   7.478707  16.385285   1.395023 -38.022814 -12.143536  \n18842  -0.949414  -0.732906  -0.228898   9.935522   3.502345  \n22009  11.676848   8.919250  21.059658   2.744807 -13.464392  \n10201  -8.492798  -5.426209  -5.767544  16.856678   9.928067  \n6099    0.302714  -0.572286   0.396087  -1.861851   4.504515  \n18400   1.140019   0.261384   1.588109  10.503650   4.111054  \n11460  -1.485043  -1.775494  -2.689103  -3.205128  -3.205128  \n1257    0.405964  -1.369881   0.277068   9.772444   9.772444  \n3786   -5.856841  -7.779465  -7.115845 -14.084507 -14.084507  \n11812 -14.668814 -11.538709 -12.822035 -49.019608 -49.019608  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vann</th>\n      <th>vodds</th>\n      <th>start</th>\n      <th>spår</th>\n      <th>Cat1h</th>\n      <th>Cat2h</th>\n      <th>Cat2u</th>\n      <th>rf1</th>\n      <th>rf2</th>\n      <th>rf130</th>\n      <th>rf230</th>\n      <th>knn1</th>\n      <th>knn2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10959</td>\n      <td>0</td>\n      <td>3.63</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.880681</td>\n      <td>3.848770</td>\n      <td>9.507993</td>\n      <td>10.987117</td>\n      <td>7.478707</td>\n      <td>16.385285</td>\n      <td>1.395023</td>\n      <td>-38.022814</td>\n      <td>-12.143536</td>\n    </tr>\n    <tr>\n      <td>18842</td>\n      <td>0</td>\n      <td>35.12</td>\n      <td>0</td>\n      <td>8</td>\n      <td>-0.445476</td>\n      <td>-0.484681</td>\n      <td>-0.587746</td>\n      <td>-0.893158</td>\n      <td>-0.949414</td>\n      <td>-0.732906</td>\n      <td>-0.228898</td>\n      <td>9.935522</td>\n      <td>3.502345</td>\n    </tr>\n    <tr>\n      <td>22009</td>\n      <td>0</td>\n      <td>4.37</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1.078971</td>\n      <td>-2.853741</td>\n      <td>7.346626</td>\n      <td>7.857213</td>\n      <td>11.676848</td>\n      <td>8.919250</td>\n      <td>21.059658</td>\n      <td>2.744807</td>\n      <td>-13.464392</td>\n    </tr>\n    <tr>\n      <td>10201</td>\n      <td>0</td>\n      <td>10.21</td>\n      <td>1</td>\n      <td>3</td>\n      <td>-4.741249</td>\n      <td>-3.908146</td>\n      <td>-2.882637</td>\n      <td>-4.633272</td>\n      <td>-8.492798</td>\n      <td>-5.426209</td>\n      <td>-5.767544</td>\n      <td>16.856678</td>\n      <td>9.928067</td>\n    </tr>\n    <tr>\n      <td>6099</td>\n      <td>0</td>\n      <td>54.71</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.217508</td>\n      <td>-0.019949</td>\n      <td>0.210488</td>\n      <td>-0.543694</td>\n      <td>0.302714</td>\n      <td>-0.572286</td>\n      <td>0.396087</td>\n      <td>-1.861851</td>\n      <td>4.504515</td>\n    </tr>\n    <tr>\n      <td>18400</td>\n      <td>0</td>\n      <td>44.83</td>\n      <td>0</td>\n      <td>10</td>\n      <td>-0.407635</td>\n      <td>-0.619284</td>\n      <td>-0.292420</td>\n      <td>-0.213544</td>\n      <td>1.140019</td>\n      <td>0.261384</td>\n      <td>1.588109</td>\n      <td>10.503650</td>\n      <td>4.111054</td>\n    </tr>\n    <tr>\n      <td>11460</td>\n      <td>0</td>\n      <td>32.20</td>\n      <td>0</td>\n      <td>7</td>\n      <td>-0.450262</td>\n      <td>-0.425971</td>\n      <td>-0.103524</td>\n      <td>-1.999795</td>\n      <td>-1.485043</td>\n      <td>-1.775494</td>\n      <td>-2.689103</td>\n      <td>-3.205128</td>\n      <td>-3.205128</td>\n    </tr>\n    <tr>\n      <td>1257</td>\n      <td>0</td>\n      <td>33.08</td>\n      <td>0</td>\n      <td>10</td>\n      <td>-0.952069</td>\n      <td>-0.854123</td>\n      <td>-0.577426</td>\n      <td>-0.774312</td>\n      <td>0.405964</td>\n      <td>-1.369881</td>\n      <td>0.277068</td>\n      <td>9.772444</td>\n      <td>9.772444</td>\n    </tr>\n    <tr>\n      <td>3786</td>\n      <td>0</td>\n      <td>8.10</td>\n      <td>0</td>\n      <td>9</td>\n      <td>-4.425097</td>\n      <td>-6.884797</td>\n      <td>-6.566575</td>\n      <td>-7.215518</td>\n      <td>-5.856841</td>\n      <td>-7.779465</td>\n      <td>-7.115845</td>\n      <td>-14.084507</td>\n      <td>-14.084507</td>\n    </tr>\n    <tr>\n      <td>11812</td>\n      <td>0</td>\n      <td>3.04</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-6.241117</td>\n      <td>-7.163519</td>\n      <td>-9.159525</td>\n      <td>-2.259883</td>\n      <td>-14.668814</td>\n      <td>-11.538709</td>\n      <td>-12.822035</td>\n      <td>-49.019608</td>\n      <td>-49.019608</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "PATH = F\"C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/\"\n",
    "A,B = read_and_fix()\n",
    "\n",
    "C=B[['vann','vodds','start','spår']]\n",
    "\n",
    "#### catb\n",
    "print('startar CatB')\n",
    "#print('kan ta bort Cat1 och Cat2 som är samma som Cat1h och Cat2h ')\n",
    "#Cat1,C['Cat1'] = Cat_model(A,B, 'med',PATH)*C.vodds\n",
    "#Cat2,C['Cat2'] = Cat_model(A,B, 'utan',PATH)*C.vodds\n",
    "\n",
    "Cat1h,C['Cat1h'] = Cat_model(A,B, 'med',PATH,häst_suf='h')\n",
    "#C.Cat1h *= C.vodds\n",
    "C.Cat1h = kelly(C.Cat1h, C.vodds)\n",
    "Cat2h,C['Cat2h'] = Cat_model(A,B, 'utan',PATH,häst_suf='h')\n",
    "#C.Cat2h *= C.vodds\n",
    "C.Cat2h = kelly(C.Cat2h, C.vodds)\n",
    "Cat2u,C['Cat2u'] = Cat_model(A,B, 'utan',PATH,häst_suf='u')\n",
    "#C.Cat2u *= C.vodds\n",
    "C.Cat2u = kelly(C.Cat2u, C.vodds)\n",
    "\n",
    "##### rf\n",
    "print('startar rf')\n",
    "rf1,C['rf1'] = rf_model(A,B, 'med',PATH)\n",
    "#C.rf1 *= C.vodds\n",
    "C.rf1 = kelly(C.rf1, C.vodds)\n",
    "rf2,C['rf2'] = rf_model(A,B, 'utan',PATH)\n",
    "#C.rf2 *= C.vodds\n",
    "C.rf2 = kelly(C.rf2, C.vodds)\n",
    "\n",
    "##### rf30\n",
    "print('startar rf30')\n",
    "rf130,C['rf130'] = rf30_model(A,B, 'med',PATH)\n",
    "#C.rf130 *= C.vodds\n",
    "C.rf130 = kelly(C.rf130, C.vodds)\n",
    "\n",
    "rf230,C['rf230'] = rf30_model(A,B, 'utan',PATH)\n",
    "#C.rf230 *= C.vodds\n",
    "C.rf230 = kelly(C.rf230, C.vodds)\n",
    "\n",
    "##### knn\n",
    "print('startar knn')\n",
    "knn1,C['knn1'] = knn_model(A,B, 'med',PATH)\n",
    "#C.knn1 *= C.vodds\n",
    "C.knn1 = kelly(C.knn1, C.vodds)\n",
    "\n",
    "knn2,C['knn2'] = knn_model(A,B, 'utan',PATH)\n",
    "#C.knn2 *= C.vodds\n",
    "C.knn2 = kelly(C.knn2, C.vodds)\n",
    "\n",
    "C.sample(10)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Träna sista lagret i stacking\n",
    "### fit av C och evaluera mot OMGÅNGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10136, 13)\nTräna upp en ny final_model\nstarta fit\n[LibSVM]SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='linear', max_iter=-1, probability=True, random_state=202006,\n    shrinking=True, tol=0.001, verbose=True) \nsparad på C:/Users/peter/Documents/MyProjects/PyProj/Trav/Modeller/final_model_L_stacking\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=500,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "## Sista lagret\n",
    "print(C.shape)\n",
    "\n",
    "if True:  #Träna\n",
    "    print('Träna upp en ny final_model')\n",
    "    ## SVC\n",
    "    #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
    "    params={'kernel':'linear'}\n",
    "    final_model = svm.SVC(**params, probability=True, random_state = 202006, verbose=True)\n",
    "    print(\"starta fit\")\n",
    "    final_model.fit(C.drop(['vann'],axis=1), C.vann) \n",
    "    \n",
    "    ## rf\n",
    "    #final_model2 = RF(n_estimators=100)\n",
    "    #final_model2.fit(C.drop(['vann','vodds'],axis=1), C.vann)\n",
    "    \n",
    "    spara(final_model, PATH+'final_model_L_stacking')\n",
    "else:\n",
    "    print('Ladda befintlig final_model')\n",
    "    final_model = ladda('final_model_L_stacking',PATH)    \n",
    "\n",
    "## rf\n",
    "final_model2 = RF(n_estimators=500)\n",
    "final_model2.fit(C.drop(['vann','vodds'],axis=1), C.vann)\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluera mot OMGÅNGAR som först läses in till df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_omgångar(omgångar):\n",
    "    avd=[1,2,3,4,5,6,7]\n",
    "    path='C:\\\\Users/peter/Documents/MyProjects/PyProj/Trav/'\n",
    "    stravd = ''.join(str(x) for x in avd)\n",
    "\n",
    "    df2=pd.DataFrame()\n",
    "    for key,omg in omgångar.items():\n",
    "        omg_sav = omg.replace('/V75/','-')\n",
    "        filnamn=path+omg_sav+stravd+'test.csv'\n",
    "        tmp = pd.read_csv(filnamn)\n",
    "        # tmp.spår = tmp.spår.astype('int')\n",
    "        # tmp.h1_spår = tmp.h1_spår.astype('int')\n",
    "        # tmp.h2_spår = tmp.h2_spår.astype('int')\n",
    "        # tmp.h3_spår = tmp.h3_spår.astype('int')\n",
    "        # tmp.h4_spår = tmp.h4_spår.astype('int')\n",
    "        # tmp.h5_spår = tmp.h5_spår.astype('int')\n",
    "        # tmp=ff.bins(tmp)\n",
    "        \n",
    "        # spara_data(tmp,path,omg_sav,avd)\n",
    "        if sum(tmp.vann) == 0:\n",
    "            print(omg,'saknar vinnare')\n",
    "            continue\n",
    "    \n",
    "        df2 = pd.concat([df2,tmp])\n",
    "        \n",
    "    \n",
    "    df2.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    return(df2)\n",
    "    \n",
    "def spara_data(df,path, omgsav, avd):\n",
    "    stravd = ''.join(str(x) for x in avd)\n",
    "    filnamn=path+omgsav+stravd+'test.csv'\n",
    "    df.to_csv(filnamn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluera stacken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "OMGÅNGAR = {\n",
    "    1: '2020-04-25/V75/aby',\n",
    "    2: '2020-05-02/V75/orebro',\n",
    "    3: '2020-04-18/V75/umaker',\n",
    "    4: '2020-05-09/V75/aby', \n",
    "    5: '2020-05-16/V75/mantorp', \n",
    "    6: '2020-05-23/V75/gavle',\n",
    "    7: '2020-05-30/V75/solvalla',\n",
    "    8: '2020-06-06/V75/ostersund',\n",
    "    9: '2020-06-13/V75/boden',\n",
    "    10: '2020-06-14/V75/bjerke',   \n",
    "    11: '2020-07-04/V75/halmstad',   \n",
    "    12: '2020-06-21/V75/kalmar',   \n",
    "    13: '2020-07-11/V75/arjang',  \n",
    "    14: '2020-07-19/V75/axevalla',  \n",
    "     0: '2020-07-25/V75/bollnas',  \n",
    "} ##### Sätt alltid senaste omgång till 0 och döp om när ny 0:a kommer\n",
    "  \n",
    "df2 = read_omgångar(OMGÅNGAR)\n",
    "# läs in alla MODELLER behövs ju inte nu men sedan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df3 blir första lagrets predict av df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      vann   vodds  start  spår      Cat1h      Cat2h      Cat2u        rf1  \\\n1001     0   81.95      0     6   0.896496   0.990535   1.010093  19.517843   \n176      0   33.97      0     5   0.219513   0.588267   0.091911  21.713330   \n395      0   30.53      1     4  -0.560924  -0.554594   0.145062  10.805884   \n939      0   25.47      1     1  -0.417202   0.070097   0.463820   4.555750   \n469      0   45.27      0     9   0.283205   0.245433  -0.262797  30.856918   \n579      0   45.52      1     7   0.129458  -0.033205   0.152462  12.493259   \n109      0   12.71      1     5  -1.247967  -1.005842  -1.736514  -0.521454   \n301      0    7.12      1     3  -5.914667  -5.555384  -5.446327  12.517122   \n653      0  154.31      1     7   1.420762   1.001659   1.247610   6.224115   \n193      0   53.98      0    12  -0.059857  -0.370230  -0.255918  20.509145   \n774      0   45.58      0     3  -0.149996  -0.266601   0.053208  15.018908   \n70       0   79.10      0     9   0.981911   0.884630   0.638792   6.656553   \n333      0  109.86      1     1   1.324701   1.442638   1.607026  20.298954   \n929      0    7.74      1     2  -3.539637  -2.243216  -4.968692   2.961669   \n281      0   33.81      1     4  -0.015643   0.038446   0.238082  32.174546   \n56       0   16.77      0     6  -2.441022  -2.726421  -2.842528  14.733905   \n981      0   11.32      0     7  -3.985859  -3.681655  -2.634194   6.313940   \n218      0   78.23      0     9   0.848519   0.714335   0.479657   5.412935   \n1104     0    9.03      1     4  -3.947630  -2.703273  -2.972187  20.729687   \n311      0    3.62      1     1  -5.962618  -5.986516  -9.718831  14.794580   \n351      0   19.95      1     7  -2.119578  -1.897912  -0.665802  19.632059   \n971      0    3.92      1     7  -2.458038  -4.883501 -13.385457 -14.729279   \n792      0   54.48      0    12   0.123442   0.130806   0.034387  11.196574   \n302      0   29.83      1     4  -0.800672  -0.880953  -0.478154   9.301938   \n1051     0    7.53      1     9  -4.549581  -5.121566  -8.107194   2.015904   \n340      0   41.61      1     8  -0.355768  -0.740511  -0.469569   8.224939   \n778      0   47.34      0     7   0.244312  -0.017958   0.160094  13.226839   \n51       0   19.88      0     1  -1.057712  -0.642831  -1.258172   2.391128   \n47       0   17.30      0     4  -1.121668  -1.697754  -3.017521   2.474753   \n833      0   10.21      0     3  -2.333459  -0.932551  -0.373200   5.868596   \n949      0   16.02      1     5  -2.506617  -2.912723  -2.021372   8.295012   \n1102     0   26.71      1     2  -0.767889   0.564761   0.432689  16.212392   \n260      0    2.11      1     4 -10.296907 -22.746208 -15.293171 -48.314338   \n77       1   10.49      0     4  -1.947089  -0.788065  -1.961047   8.892286   \n616      0    4.98      1     7   4.007891   8.790398   2.604831  -5.221305   \n763      0   43.69      1    10  -0.320219  -0.632177  -0.630389   5.194541   \n954      0   51.15      1    12   0.034086   0.451429   0.477881  30.627615   \n861      0   81.78      1    11   0.904882   0.881489   1.173405  15.946966   \n849      0    5.64      1     8  -5.046681  -8.884051  -6.835080   2.127097   \n1078     1   14.10      1     2  -2.488691  -2.117087  -3.149221   4.626671   \n1069     0   50.46      1     7   0.487165  -0.061480   0.097375  28.211037   \n166      0   32.38      0     5  -0.577614  -0.145591  -0.220401   6.170272   \n78       0    5.16      0     5   3.854276   7.130456   3.319215  -1.618685   \n1062     0   15.71      1    10  -3.199558  -2.813370  -1.839130   7.385203   \n636      0   74.31      1     5   0.706706   0.565177   0.787228  29.373956   \n917      0   59.75      1    10   0.665635   0.512906   0.046623  25.496106   \n107      0   21.81      1     3  -1.574328  -1.754287  -1.441113  16.941814   \n369      1    6.74      1     1  -7.642815  -2.022637  -5.130434   0.235511   \n581      0    2.06      1     9 -12.995206  -1.488445   4.381754 -53.932325   \n227      0   33.72      1     7   0.449445   0.673961  -0.279037  23.175654   \n\n            rf2      rf130      rf230       knn1       knn2  \n1001  40.365159  18.719788  39.710143  -1.235330   5.091878  \n176   41.038105  22.992670  38.793456  -3.033060   3.406506  \n395   28.930475  10.223029  30.647222  -3.386387   3.075262  \n939   37.603159   5.891285  35.943349   8.924193   2.418778  \n469   48.546747  33.509854  46.626350  -2.258866   4.132313  \n579   33.916102  10.919148  30.988088  -2.246181   4.144205  \n109   24.935746  -0.075036  23.507716  -8.539710  -1.755978  \n301   22.653377  11.192101  20.776473  -1.797386  -9.068627  \n653   30.214424   6.300536  33.284318  -0.652273   5.638494  \n193   38.503613  22.158651  38.225646  23.584371   4.480464  \n774   35.919100  14.950386  34.508997  -2.243158   4.147039  \n70    36.245791   5.653487  38.795686  11.379641   5.049616  \n333   36.316151  19.102684  37.897210  11.696215   5.388802  \n929   32.637283   3.068253  29.739704 -14.836795  -7.659496  \n281   38.648499  34.564484  41.702109  -3.047851   3.392639  \n56    38.003107  16.195953  30.962437  -6.341154   0.305168  \n981   32.284755   5.102861  24.885255   4.021318  -2.834302  \n218   39.516131   4.452290  37.496867  -1.294834   5.036093  \n1104  30.415504  21.040255  26.680448 -12.453300  -5.424969  \n311   18.872392  15.509404  11.231211 -20.896947 -29.532443  \n351   30.534697  19.104196  28.950528  -5.277045   1.302770  \n971    9.552968 -10.666441   9.365715 -34.246575 -25.856164  \n792   37.656860  10.029965  42.268088  -1.869858   4.497008  \n302   27.943968   9.506416  26.984214  -3.468609   2.998179  \n1051  21.394334   3.270390  19.347511  -0.899694  -8.106815  \n340   33.357936   7.985504  34.306934  10.345358   3.941455  \n778   39.789434  16.085324  33.025523  10.611782   4.226910  \n51    36.194642   3.159690  35.793512  -5.296610   1.284428  \n47    35.461094   3.304155  32.623879  -6.134969   0.498466  \n833   33.777004   9.295842  34.875683 -10.857763  -3.929153  \n949   27.567298  10.248858  29.405875   6.674434   0.008322  \n1102  32.560231  16.186805  26.894541  -3.889537   2.603559  \n260  -24.381151 -42.785811 -24.312130 -90.090090 -78.209459  \n77    38.111553   7.633358  35.933703 -10.537408  -3.628820  \n616   15.979630  -5.734572  15.444122 -25.125628 -17.305276  \n763   30.134208   6.100779  30.271680  -2.342469   4.053935  \n954   35.617490  33.956308  36.759459  -1.994018   4.380608  \n861   33.453537  18.187261  35.978258  -1.237930   5.089440  \n849   17.396921   3.005179  15.580639 -21.551724 -13.954741  \n1078  29.050245   5.662512  32.343321  19.274809  -0.906489  \n1069  37.239567  25.619753  37.655549  36.236353   4.354529  \n166   40.883823   6.799492  39.640055  -3.186743   3.262428  \n78    18.441758   2.342769  20.912929 -24.038462 -16.286058  \n1062  33.923128  11.396565  32.470970  -6.798097  -0.123215  \n636   36.883972  33.695012  41.382003  11.306438   4.971184  \n917   33.632097  25.004488  35.255699  -1.702128   4.654255  \n107   31.685606  19.245694  26.823177  -4.805382   1.744954  \n369   29.474349  -0.476774  29.658635 -17.421603 -10.082753  \n581  -17.080368 -53.162788 -20.762796 -94.339623 -82.193396  \n227   32.387749  23.749231  30.192283  22.707824   3.384780  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vann</th>\n      <th>vodds</th>\n      <th>start</th>\n      <th>spår</th>\n      <th>Cat1h</th>\n      <th>Cat2h</th>\n      <th>Cat2u</th>\n      <th>rf1</th>\n      <th>rf2</th>\n      <th>rf130</th>\n      <th>rf230</th>\n      <th>knn1</th>\n      <th>knn2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1001</td>\n      <td>0</td>\n      <td>81.95</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0.896496</td>\n      <td>0.990535</td>\n      <td>1.010093</td>\n      <td>19.517843</td>\n      <td>40.365159</td>\n      <td>18.719788</td>\n      <td>39.710143</td>\n      <td>-1.235330</td>\n      <td>5.091878</td>\n    </tr>\n    <tr>\n      <td>176</td>\n      <td>0</td>\n      <td>33.97</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0.219513</td>\n      <td>0.588267</td>\n      <td>0.091911</td>\n      <td>21.713330</td>\n      <td>41.038105</td>\n      <td>22.992670</td>\n      <td>38.793456</td>\n      <td>-3.033060</td>\n      <td>3.406506</td>\n    </tr>\n    <tr>\n      <td>395</td>\n      <td>0</td>\n      <td>30.53</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-0.560924</td>\n      <td>-0.554594</td>\n      <td>0.145062</td>\n      <td>10.805884</td>\n      <td>28.930475</td>\n      <td>10.223029</td>\n      <td>30.647222</td>\n      <td>-3.386387</td>\n      <td>3.075262</td>\n    </tr>\n    <tr>\n      <td>939</td>\n      <td>0</td>\n      <td>25.47</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.417202</td>\n      <td>0.070097</td>\n      <td>0.463820</td>\n      <td>4.555750</td>\n      <td>37.603159</td>\n      <td>5.891285</td>\n      <td>35.943349</td>\n      <td>8.924193</td>\n      <td>2.418778</td>\n    </tr>\n    <tr>\n      <td>469</td>\n      <td>0</td>\n      <td>45.27</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.283205</td>\n      <td>0.245433</td>\n      <td>-0.262797</td>\n      <td>30.856918</td>\n      <td>48.546747</td>\n      <td>33.509854</td>\n      <td>46.626350</td>\n      <td>-2.258866</td>\n      <td>4.132313</td>\n    </tr>\n    <tr>\n      <td>579</td>\n      <td>0</td>\n      <td>45.52</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.129458</td>\n      <td>-0.033205</td>\n      <td>0.152462</td>\n      <td>12.493259</td>\n      <td>33.916102</td>\n      <td>10.919148</td>\n      <td>30.988088</td>\n      <td>-2.246181</td>\n      <td>4.144205</td>\n    </tr>\n    <tr>\n      <td>109</td>\n      <td>0</td>\n      <td>12.71</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-1.247967</td>\n      <td>-1.005842</td>\n      <td>-1.736514</td>\n      <td>-0.521454</td>\n      <td>24.935746</td>\n      <td>-0.075036</td>\n      <td>23.507716</td>\n      <td>-8.539710</td>\n      <td>-1.755978</td>\n    </tr>\n    <tr>\n      <td>301</td>\n      <td>0</td>\n      <td>7.12</td>\n      <td>1</td>\n      <td>3</td>\n      <td>-5.914667</td>\n      <td>-5.555384</td>\n      <td>-5.446327</td>\n      <td>12.517122</td>\n      <td>22.653377</td>\n      <td>11.192101</td>\n      <td>20.776473</td>\n      <td>-1.797386</td>\n      <td>-9.068627</td>\n    </tr>\n    <tr>\n      <td>653</td>\n      <td>0</td>\n      <td>154.31</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1.420762</td>\n      <td>1.001659</td>\n      <td>1.247610</td>\n      <td>6.224115</td>\n      <td>30.214424</td>\n      <td>6.300536</td>\n      <td>33.284318</td>\n      <td>-0.652273</td>\n      <td>5.638494</td>\n    </tr>\n    <tr>\n      <td>193</td>\n      <td>0</td>\n      <td>53.98</td>\n      <td>0</td>\n      <td>12</td>\n      <td>-0.059857</td>\n      <td>-0.370230</td>\n      <td>-0.255918</td>\n      <td>20.509145</td>\n      <td>38.503613</td>\n      <td>22.158651</td>\n      <td>38.225646</td>\n      <td>23.584371</td>\n      <td>4.480464</td>\n    </tr>\n    <tr>\n      <td>774</td>\n      <td>0</td>\n      <td>45.58</td>\n      <td>0</td>\n      <td>3</td>\n      <td>-0.149996</td>\n      <td>-0.266601</td>\n      <td>0.053208</td>\n      <td>15.018908</td>\n      <td>35.919100</td>\n      <td>14.950386</td>\n      <td>34.508997</td>\n      <td>-2.243158</td>\n      <td>4.147039</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0</td>\n      <td>79.10</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.981911</td>\n      <td>0.884630</td>\n      <td>0.638792</td>\n      <td>6.656553</td>\n      <td>36.245791</td>\n      <td>5.653487</td>\n      <td>38.795686</td>\n      <td>11.379641</td>\n      <td>5.049616</td>\n    </tr>\n    <tr>\n      <td>333</td>\n      <td>0</td>\n      <td>109.86</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.324701</td>\n      <td>1.442638</td>\n      <td>1.607026</td>\n      <td>20.298954</td>\n      <td>36.316151</td>\n      <td>19.102684</td>\n      <td>37.897210</td>\n      <td>11.696215</td>\n      <td>5.388802</td>\n    </tr>\n    <tr>\n      <td>929</td>\n      <td>0</td>\n      <td>7.74</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-3.539637</td>\n      <td>-2.243216</td>\n      <td>-4.968692</td>\n      <td>2.961669</td>\n      <td>32.637283</td>\n      <td>3.068253</td>\n      <td>29.739704</td>\n      <td>-14.836795</td>\n      <td>-7.659496</td>\n    </tr>\n    <tr>\n      <td>281</td>\n      <td>0</td>\n      <td>33.81</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-0.015643</td>\n      <td>0.038446</td>\n      <td>0.238082</td>\n      <td>32.174546</td>\n      <td>38.648499</td>\n      <td>34.564484</td>\n      <td>41.702109</td>\n      <td>-3.047851</td>\n      <td>3.392639</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0</td>\n      <td>16.77</td>\n      <td>0</td>\n      <td>6</td>\n      <td>-2.441022</td>\n      <td>-2.726421</td>\n      <td>-2.842528</td>\n      <td>14.733905</td>\n      <td>38.003107</td>\n      <td>16.195953</td>\n      <td>30.962437</td>\n      <td>-6.341154</td>\n      <td>0.305168</td>\n    </tr>\n    <tr>\n      <td>981</td>\n      <td>0</td>\n      <td>11.32</td>\n      <td>0</td>\n      <td>7</td>\n      <td>-3.985859</td>\n      <td>-3.681655</td>\n      <td>-2.634194</td>\n      <td>6.313940</td>\n      <td>32.284755</td>\n      <td>5.102861</td>\n      <td>24.885255</td>\n      <td>4.021318</td>\n      <td>-2.834302</td>\n    </tr>\n    <tr>\n      <td>218</td>\n      <td>0</td>\n      <td>78.23</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.848519</td>\n      <td>0.714335</td>\n      <td>0.479657</td>\n      <td>5.412935</td>\n      <td>39.516131</td>\n      <td>4.452290</td>\n      <td>37.496867</td>\n      <td>-1.294834</td>\n      <td>5.036093</td>\n    </tr>\n    <tr>\n      <td>1104</td>\n      <td>0</td>\n      <td>9.03</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-3.947630</td>\n      <td>-2.703273</td>\n      <td>-2.972187</td>\n      <td>20.729687</td>\n      <td>30.415504</td>\n      <td>21.040255</td>\n      <td>26.680448</td>\n      <td>-12.453300</td>\n      <td>-5.424969</td>\n    </tr>\n    <tr>\n      <td>311</td>\n      <td>0</td>\n      <td>3.62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-5.962618</td>\n      <td>-5.986516</td>\n      <td>-9.718831</td>\n      <td>14.794580</td>\n      <td>18.872392</td>\n      <td>15.509404</td>\n      <td>11.231211</td>\n      <td>-20.896947</td>\n      <td>-29.532443</td>\n    </tr>\n    <tr>\n      <td>351</td>\n      <td>0</td>\n      <td>19.95</td>\n      <td>1</td>\n      <td>7</td>\n      <td>-2.119578</td>\n      <td>-1.897912</td>\n      <td>-0.665802</td>\n      <td>19.632059</td>\n      <td>30.534697</td>\n      <td>19.104196</td>\n      <td>28.950528</td>\n      <td>-5.277045</td>\n      <td>1.302770</td>\n    </tr>\n    <tr>\n      <td>971</td>\n      <td>0</td>\n      <td>3.92</td>\n      <td>1</td>\n      <td>7</td>\n      <td>-2.458038</td>\n      <td>-4.883501</td>\n      <td>-13.385457</td>\n      <td>-14.729279</td>\n      <td>9.552968</td>\n      <td>-10.666441</td>\n      <td>9.365715</td>\n      <td>-34.246575</td>\n      <td>-25.856164</td>\n    </tr>\n    <tr>\n      <td>792</td>\n      <td>0</td>\n      <td>54.48</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0.123442</td>\n      <td>0.130806</td>\n      <td>0.034387</td>\n      <td>11.196574</td>\n      <td>37.656860</td>\n      <td>10.029965</td>\n      <td>42.268088</td>\n      <td>-1.869858</td>\n      <td>4.497008</td>\n    </tr>\n    <tr>\n      <td>302</td>\n      <td>0</td>\n      <td>29.83</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-0.800672</td>\n      <td>-0.880953</td>\n      <td>-0.478154</td>\n      <td>9.301938</td>\n      <td>27.943968</td>\n      <td>9.506416</td>\n      <td>26.984214</td>\n      <td>-3.468609</td>\n      <td>2.998179</td>\n    </tr>\n    <tr>\n      <td>1051</td>\n      <td>0</td>\n      <td>7.53</td>\n      <td>1</td>\n      <td>9</td>\n      <td>-4.549581</td>\n      <td>-5.121566</td>\n      <td>-8.107194</td>\n      <td>2.015904</td>\n      <td>21.394334</td>\n      <td>3.270390</td>\n      <td>19.347511</td>\n      <td>-0.899694</td>\n      <td>-8.106815</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0</td>\n      <td>41.61</td>\n      <td>1</td>\n      <td>8</td>\n      <td>-0.355768</td>\n      <td>-0.740511</td>\n      <td>-0.469569</td>\n      <td>8.224939</td>\n      <td>33.357936</td>\n      <td>7.985504</td>\n      <td>34.306934</td>\n      <td>10.345358</td>\n      <td>3.941455</td>\n    </tr>\n    <tr>\n      <td>778</td>\n      <td>0</td>\n      <td>47.34</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0.244312</td>\n      <td>-0.017958</td>\n      <td>0.160094</td>\n      <td>13.226839</td>\n      <td>39.789434</td>\n      <td>16.085324</td>\n      <td>33.025523</td>\n      <td>10.611782</td>\n      <td>4.226910</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0</td>\n      <td>19.88</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-1.057712</td>\n      <td>-0.642831</td>\n      <td>-1.258172</td>\n      <td>2.391128</td>\n      <td>36.194642</td>\n      <td>3.159690</td>\n      <td>35.793512</td>\n      <td>-5.296610</td>\n      <td>1.284428</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0</td>\n      <td>17.30</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.121668</td>\n      <td>-1.697754</td>\n      <td>-3.017521</td>\n      <td>2.474753</td>\n      <td>35.461094</td>\n      <td>3.304155</td>\n      <td>32.623879</td>\n      <td>-6.134969</td>\n      <td>0.498466</td>\n    </tr>\n    <tr>\n      <td>833</td>\n      <td>0</td>\n      <td>10.21</td>\n      <td>0</td>\n      <td>3</td>\n      <td>-2.333459</td>\n      <td>-0.932551</td>\n      <td>-0.373200</td>\n      <td>5.868596</td>\n      <td>33.777004</td>\n      <td>9.295842</td>\n      <td>34.875683</td>\n      <td>-10.857763</td>\n      <td>-3.929153</td>\n    </tr>\n    <tr>\n      <td>949</td>\n      <td>0</td>\n      <td>16.02</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-2.506617</td>\n      <td>-2.912723</td>\n      <td>-2.021372</td>\n      <td>8.295012</td>\n      <td>27.567298</td>\n      <td>10.248858</td>\n      <td>29.405875</td>\n      <td>6.674434</td>\n      <td>0.008322</td>\n    </tr>\n    <tr>\n      <td>1102</td>\n      <td>0</td>\n      <td>26.71</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-0.767889</td>\n      <td>0.564761</td>\n      <td>0.432689</td>\n      <td>16.212392</td>\n      <td>32.560231</td>\n      <td>16.186805</td>\n      <td>26.894541</td>\n      <td>-3.889537</td>\n      <td>2.603559</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0</td>\n      <td>2.11</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-10.296907</td>\n      <td>-22.746208</td>\n      <td>-15.293171</td>\n      <td>-48.314338</td>\n      <td>-24.381151</td>\n      <td>-42.785811</td>\n      <td>-24.312130</td>\n      <td>-90.090090</td>\n      <td>-78.209459</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>1</td>\n      <td>10.49</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.947089</td>\n      <td>-0.788065</td>\n      <td>-1.961047</td>\n      <td>8.892286</td>\n      <td>38.111553</td>\n      <td>7.633358</td>\n      <td>35.933703</td>\n      <td>-10.537408</td>\n      <td>-3.628820</td>\n    </tr>\n    <tr>\n      <td>616</td>\n      <td>0</td>\n      <td>4.98</td>\n      <td>1</td>\n      <td>7</td>\n      <td>4.007891</td>\n      <td>8.790398</td>\n      <td>2.604831</td>\n      <td>-5.221305</td>\n      <td>15.979630</td>\n      <td>-5.734572</td>\n      <td>15.444122</td>\n      <td>-25.125628</td>\n      <td>-17.305276</td>\n    </tr>\n    <tr>\n      <td>763</td>\n      <td>0</td>\n      <td>43.69</td>\n      <td>1</td>\n      <td>10</td>\n      <td>-0.320219</td>\n      <td>-0.632177</td>\n      <td>-0.630389</td>\n      <td>5.194541</td>\n      <td>30.134208</td>\n      <td>6.100779</td>\n      <td>30.271680</td>\n      <td>-2.342469</td>\n      <td>4.053935</td>\n    </tr>\n    <tr>\n      <td>954</td>\n      <td>0</td>\n      <td>51.15</td>\n      <td>1</td>\n      <td>12</td>\n      <td>0.034086</td>\n      <td>0.451429</td>\n      <td>0.477881</td>\n      <td>30.627615</td>\n      <td>35.617490</td>\n      <td>33.956308</td>\n      <td>36.759459</td>\n      <td>-1.994018</td>\n      <td>4.380608</td>\n    </tr>\n    <tr>\n      <td>861</td>\n      <td>0</td>\n      <td>81.78</td>\n      <td>1</td>\n      <td>11</td>\n      <td>0.904882</td>\n      <td>0.881489</td>\n      <td>1.173405</td>\n      <td>15.946966</td>\n      <td>33.453537</td>\n      <td>18.187261</td>\n      <td>35.978258</td>\n      <td>-1.237930</td>\n      <td>5.089440</td>\n    </tr>\n    <tr>\n      <td>849</td>\n      <td>0</td>\n      <td>5.64</td>\n      <td>1</td>\n      <td>8</td>\n      <td>-5.046681</td>\n      <td>-8.884051</td>\n      <td>-6.835080</td>\n      <td>2.127097</td>\n      <td>17.396921</td>\n      <td>3.005179</td>\n      <td>15.580639</td>\n      <td>-21.551724</td>\n      <td>-13.954741</td>\n    </tr>\n    <tr>\n      <td>1078</td>\n      <td>1</td>\n      <td>14.10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-2.488691</td>\n      <td>-2.117087</td>\n      <td>-3.149221</td>\n      <td>4.626671</td>\n      <td>29.050245</td>\n      <td>5.662512</td>\n      <td>32.343321</td>\n      <td>19.274809</td>\n      <td>-0.906489</td>\n    </tr>\n    <tr>\n      <td>1069</td>\n      <td>0</td>\n      <td>50.46</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.487165</td>\n      <td>-0.061480</td>\n      <td>0.097375</td>\n      <td>28.211037</td>\n      <td>37.239567</td>\n      <td>25.619753</td>\n      <td>37.655549</td>\n      <td>36.236353</td>\n      <td>4.354529</td>\n    </tr>\n    <tr>\n      <td>166</td>\n      <td>0</td>\n      <td>32.38</td>\n      <td>0</td>\n      <td>5</td>\n      <td>-0.577614</td>\n      <td>-0.145591</td>\n      <td>-0.220401</td>\n      <td>6.170272</td>\n      <td>40.883823</td>\n      <td>6.799492</td>\n      <td>39.640055</td>\n      <td>-3.186743</td>\n      <td>3.262428</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0</td>\n      <td>5.16</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3.854276</td>\n      <td>7.130456</td>\n      <td>3.319215</td>\n      <td>-1.618685</td>\n      <td>18.441758</td>\n      <td>2.342769</td>\n      <td>20.912929</td>\n      <td>-24.038462</td>\n      <td>-16.286058</td>\n    </tr>\n    <tr>\n      <td>1062</td>\n      <td>0</td>\n      <td>15.71</td>\n      <td>1</td>\n      <td>10</td>\n      <td>-3.199558</td>\n      <td>-2.813370</td>\n      <td>-1.839130</td>\n      <td>7.385203</td>\n      <td>33.923128</td>\n      <td>11.396565</td>\n      <td>32.470970</td>\n      <td>-6.798097</td>\n      <td>-0.123215</td>\n    </tr>\n    <tr>\n      <td>636</td>\n      <td>0</td>\n      <td>74.31</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.706706</td>\n      <td>0.565177</td>\n      <td>0.787228</td>\n      <td>29.373956</td>\n      <td>36.883972</td>\n      <td>33.695012</td>\n      <td>41.382003</td>\n      <td>11.306438</td>\n      <td>4.971184</td>\n    </tr>\n    <tr>\n      <td>917</td>\n      <td>0</td>\n      <td>59.75</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.665635</td>\n      <td>0.512906</td>\n      <td>0.046623</td>\n      <td>25.496106</td>\n      <td>33.632097</td>\n      <td>25.004488</td>\n      <td>35.255699</td>\n      <td>-1.702128</td>\n      <td>4.654255</td>\n    </tr>\n    <tr>\n      <td>107</td>\n      <td>0</td>\n      <td>21.81</td>\n      <td>1</td>\n      <td>3</td>\n      <td>-1.574328</td>\n      <td>-1.754287</td>\n      <td>-1.441113</td>\n      <td>16.941814</td>\n      <td>31.685606</td>\n      <td>19.245694</td>\n      <td>26.823177</td>\n      <td>-4.805382</td>\n      <td>1.744954</td>\n    </tr>\n    <tr>\n      <td>369</td>\n      <td>1</td>\n      <td>6.74</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-7.642815</td>\n      <td>-2.022637</td>\n      <td>-5.130434</td>\n      <td>0.235511</td>\n      <td>29.474349</td>\n      <td>-0.476774</td>\n      <td>29.658635</td>\n      <td>-17.421603</td>\n      <td>-10.082753</td>\n    </tr>\n    <tr>\n      <td>581</td>\n      <td>0</td>\n      <td>2.06</td>\n      <td>1</td>\n      <td>9</td>\n      <td>-12.995206</td>\n      <td>-1.488445</td>\n      <td>4.381754</td>\n      <td>-53.932325</td>\n      <td>-17.080368</td>\n      <td>-53.162788</td>\n      <td>-20.762796</td>\n      <td>-94.339623</td>\n      <td>-82.193396</td>\n    </tr>\n    <tr>\n      <td>227</td>\n      <td>0</td>\n      <td>33.72</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.449445</td>\n      <td>0.673961</td>\n      <td>-0.279037</td>\n      <td>23.175654</td>\n      <td>32.387749</td>\n      <td>23.749231</td>\n      <td>30.192283</td>\n      <td>22.707824</td>\n      <td>3.384780</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "####TESTA ATT TA MED start, spår, dist MED ELLER UTAN vodds\n",
    "# Första lagret\n",
    "\n",
    "df2.vann *= 1\n",
    "df3=df2[['vann','vodds','start','spår']]\n",
    "#df3['Cat1_res'] = Cat1.predict_proba(df2.drop(['datum','avd','vann'],axis=1))[:,1]\n",
    "#df3['Cat2_res'] = Cat2.predict_proba(df2.drop(['datum','avd','vodds','vann'],axis=1))[:,1]\n",
    "cath_features = ['start','spår','h1_spår','h2_spår','h3_spår','h4_spår','h5_spår','häst']\n",
    "\n",
    "h1_pool, _ = create_pool(df2.drop(['datum','avd','vann'],axis=1),df2.vann,None,None,cath_features)    \n",
    "#df3['Cat1h'] = Cat1h.predict_proba(h1_pool)[:,1]*df3.vodds\n",
    "df3['Cat1h'] = kelly(Cat1h.predict_proba(h1_pool)[:,1], df3.vodds)\n",
    "\n",
    "h2_pool, _ = create_pool(df2.drop(['datum','avd','vann','vodds'],axis=1),df2.vann,None,None,cath_features)    \n",
    "#df3['Cat2h']  = Cat2h.predict_proba(h2_pool)[:,1]*df3.vodds\n",
    "df3['Cat2h'] = kelly(Cat2h.predict_proba(h2_pool)[:,1], df3.vodds)\n",
    "\n",
    "catu_features = ['start','spår','h1_spår','h2_spår','h3_spår','h4_spår','h5_spår']\n",
    "u2_pool, _ = create_pool(df2.drop(['datum','avd','vann','vodds'],axis=1),df2.vann,None,None,cath_features)    \n",
    "#df3['Cat2u'] = Cat2u.predict_proba(u2_pool)[:,1]*df3.vodds\n",
    "df3['Cat2u'] = kelly(Cat2u.predict_proba(u2_pool)[:,1], df3.vodds)\n",
    "\n",
    "#df3['rf1'] = rf1.predict_proba(df2.drop(['datum','avd','häst','vann'],axis=1))[:,1]*df3.vodds\n",
    "df3['rf1'] = kelly(rf1.predict_proba(df2.drop(['datum','avd','häst','vann'],axis=1))[:,1], df3.vodds)\n",
    "#df3['rf2'] = rf2.predict_proba(df2.drop(['datum','avd','häst','vodds','vann'],axis=1))[:,1]*df3.vodds\n",
    "df3['rf2'] = kelly(rf2.predict_proba(df2.drop(['datum','avd','häst','vodds','vann'],axis=1))[:,1], df3.vodds)\n",
    "\n",
    "#df3['rf130'] = rf130.predict_proba(df2.drop(['datum','avd','häst','vann'],axis=1))[:,1]*df3.vodds\n",
    "df3['rf130'] = kelly( rf130.predict_proba(df2.drop(['datum','avd','häst','vann'],axis=1))[:,1], df3.vodds)\n",
    "#df3['rf230'] = rf230.predict_proba(df2.drop(['datum','avd','häst','vodds','vann'],axis=1))[:,1]*df3.vodds\n",
    "df3['rf230'] = kelly( rf230.predict_proba(df2.drop(['datum','avd','häst','vodds','vann'],axis=1))[:,1], df3.vodds)\n",
    "\n",
    "#df3['knn1'] = knn1.predict_proba(df2.drop(['datum','avd','häst','vann'],axis=1))[:,1]*df3.vodds\n",
    "df3['knn1'] = kelly( knn1.predict_proba(df2.drop( ['datum','avd','häst','vann'],axis=1 ))[:,1], df3.vodds)\n",
    "#df3['knn2'] = (knn2.predict_proba(df2.drop(['datum','avd','häst','vodds','vann'],axis=1))[:,1])*df3.vodds\n",
    "df3['knn2'] = kelly( knn2.predict_proba(df2.drop( ['datum','avd','häst','vodds','vann'],axis=1 ))[:,1], df3.vodds)\n",
    "\n",
    "df3.sample(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sista lagret - gör predict av df3 och räkna ut vinst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "antal hästar = 1115 antal satsade = 10 vinst = 4.5\nper satsad: 0.45\n\nAccuracy: 0.9085\nPrecision:    0\n[[1013    0]\n [ 102    0]]\n"
    }
   ],
   "source": [
    "model=final_model\n",
    "droppa = ['vann']\n",
    "# model=final_model2\n",
    "# droppa = ['vann','vodds']\n",
    "\n",
    "pred=model.predict_proba(df3.drop(droppa,axis=1))[:,1]\n",
    "#print(pred)\n",
    "#spela=pred>0.5\n",
    "#spela=((df3.vodds*pred)>1.5) & ((df3.vodds*pred)<1.68)\n",
    "spela = pred>=0.5\n",
    "\n",
    "utd = df3[spela].vann*df3[spela].vodds\n",
    "tot_utd = utd.sum()\n",
    "vinst = tot_utd - sum(spela)\n",
    "print('antal hästar =',len(spela),'antal satsade =',sum(spela),'vinst =',round(vinst,1))\n",
    "print('per satsad:', round(vinst/sum(spela),2) )\n",
    "print()\n",
    "print(\"Accuracy: %.4g\" % model.score(df3.drop(droppa,axis=1), df3.vann))\n",
    "\n",
    "predZ = model.predict(df3.drop(droppa,axis=1))\n",
    "\n",
    "#print(\"Accuracy: %.4g\" % accuracy_score(df3.vann, predZ))\n",
    "print('Precision: %4g' % precision_score(df3.vann,predZ))\n",
    "print(metrics.confusion_matrix(df3.vann,predZ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kelly criterion\n",
    "## ((odds-1) * percentage_estimate -  (1-percent_estimate))   / (odds-1)  X   100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Cat1h -6.849999999999998\nCat2h -11.350000000000001\nCat2u -4.840000000000003\nrf1 -150.23999999999995\nrf2 -339.6699999999996\nrf130 -141.70999999999998\nrf230 -343.2199999999997\nvinst = 1.6299999999999955 om thresh =  20\nvinst = 7.569999999999993 om thresh =  24\nvinst = 10.569999999999993 om thresh =  25\nvinst = 12.569999999999993 om thresh =  26\nvinst = 6.170000000000016 om thresh =  31\nvinst = 3.8500000000000085 om thresh =  34\nvinst = 14.850000000000009 om thresh =  35\nvinst = 19.85000000000001 om thresh =  36\nvinst = 33.85000000000001 om thresh =  37\nknn1 33.85000000000001\nvinst = 0.07000000000000028 om thresh =  31\nvinst = 0.07000000000000028 om thresh =  32\nvinst = 2.0700000000000003 om thresh =  33\nvinst = 2.0700000000000003 om thresh =  34\nvinst = 2.0700000000000003 om thresh =  35\nvinst = 3.0700000000000003 om thresh =  36\nknn2 3.0700000000000003\n"
    }
   ],
   "source": [
    "df4=df3[['vodds','vann']]\n",
    "mod_res=['Cat1h','Cat2h','Cat2u','rf1','rf2','rf130','rf230','knn1','knn2']\n",
    "\n",
    "for res in mod_res:\n",
    "    df4[res] = df3[res] / df3.vodds\n",
    "\n",
    "    df4['kelly'] = ((df4.vodds-1) * df4[res] - (1-df4[res])) / (df4.vodds-1) * 100\n",
    "    max=-9999\n",
    "    #print(df4.kelly.describe())\n",
    "    for thresh in range(5,40):\n",
    "        utdelning = sum(df4[(df4.vann==1)&(df4.kelly>=thresh)].vodds)\n",
    "        insats = sum(df4.kelly>thresh)\n",
    "        if insats == 0:\n",
    "            break\n",
    "        max = utdelning-insats if utdelning-insats > max else max\n",
    "        if utdelning-insats >0:\n",
    "            print('vinst =',utdelning-insats, 'om thresh = ',thresh )\n",
    "\n",
    "    print(res,max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "18.275862068965512"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "odds=1.58\n",
    "est = 0.7\n",
    "((odds-1) * est - (1-est)) /(odds-1) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda28516eb7b1ad4f7498fc5db163b41db8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}